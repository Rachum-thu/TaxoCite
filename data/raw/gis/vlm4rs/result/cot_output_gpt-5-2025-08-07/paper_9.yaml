"citations":
- "unique_context_marker": "[Chen et al., 2023b]"
  "block_ids":
  - 1
  - 4
  - 5
  "intent_labels":
  - "Prior Methods"
  - "Prior Methods"
  - "Prior Methods"
  "topic_labels":
  - "Vision-Language Connectors to LLMs"
  - "Textualization of Geometry and Masks"
  - "Instruction Tuning and SFT"
- "unique_context_marker": "[Chen et al., 2023a]"
  "block_ids":
  - 1
  - 4
  - 5
  - 7
  - 8
  - 11
  "intent_labels":
  - "Prior Methods"
  - "Prior Methods"
  - "Prior Methods"
  - "Algorithm/Principle Adoption"
  - "Algorithm/Principle Adoption"
  - "Resource Utilization"
  "topic_labels":
  - "Vision-Language Connectors to LLMs"
  - "Textualization of Geometry and Masks"
  - "Instruction Tuning and SFT"
  - "Multiresolution and Patch Strategies"
  - "Visual Grounding Corpora and Geometry Labels"
  - "Vision-Language Connectors to LLMs"
- "unique_context_marker": "[Zhan et al., 2023b]"
  "block_ids":
  - 1
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Task Formulations in RS VLM"
- "unique_context_marker": "[Liu et al., 2023]"
  "block_ids":
  - 1
  - 4
  - 5
  "intent_labels":
  - "Prior Methods"
  - "Prior Methods"
  - "Research Gap"
  "topic_labels":
  - "Instruction Tuning and SFT"
  - "Vision-Language Connectors to LLMs"
  - "Instruction Tuning and SFT"
- "unique_context_marker": "[Yuan et al., 2023a]"
  "block_ids":
  - 1
  - 3
  "intent_labels":
  - "Domain Overview"
  - "Domain Overview"
  "topic_labels":
  - "Task Formulations in RS VLM"
  - "Task Formulations in RS VLM"
- "unique_context_marker": "[Hoxha et al., 2023]"
  "block_ids":
  - 1
  "intent_labels":
  - "Domain Overview"
  "topic_labels":
  - "Image-Level Understanding"
- "unique_context_marker": "[Yuan et al., 2023b]"
  "block_ids":
  - 1
  - 3
  "intent_labels":
  - "Domain Overview"
  - "Domain Overview"
  "topic_labels":
  - "Image-Level Understanding"
  - "Image-Level Understanding"
- "unique_context_marker": "[Zhan et al., 2023a]"
  "block_ids":
  - 1
  - 3
  "intent_labels":
  - "Domain Overview"
  - "Domain Overview"
  "topic_labels":
  - "Object/Region-Level Grounding and Referring"
  - "Object/Region-Level Grounding and Referring"
- "unique_context_marker": "[Bashmal et al., 2023]"
  "block_ids":
  - 1
  - 3
  "intent_labels":
  - "Research Gap"
  - "Domain Overview"
  "topic_labels":
  - "Temporal and Multimodal Variants"
  - "Temporal and Multimodal Variants"
- "unique_context_marker": "[Xiong et al., 2022]"
  "block_ids":
  - 3
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Task Formulations in RS VLM"
- "unique_context_marker": "[OpenAI, 2022]"
  "block_ids":
  - 4
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Language Models and Tokenization"
- "unique_context_marker": "[Touvron et al., 2023a]"
  "block_ids":
  - 4
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Language Models and Tokenization"
- "unique_context_marker": "[OpenAI, 2023]"
  "block_ids":
  - 4
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Language Models and Tokenization"
- "unique_context_marker": "[Chiang et al., 2023]"
  "block_ids":
  - 4
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Language Models and Tokenization"
- "unique_context_marker": "[Li et al., 2023]"
  "block_ids":
  - 4
  - 7
  "intent_labels":
  - "Prior Methods"
  - "Prior Methods"
  "topic_labels":
  - "Vision-Language Connectors to LLMs"
  - "Vision-Language Connectors to LLMs"
- "unique_context_marker": "[Zhu et al., 2023]"
  "block_ids":
  - 4
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Vision-Language Connectors to LLMs"
- "unique_context_marker": "[Wang et al., 2023]"
  "block_ids":
  - 4
  - 5
  "intent_labels":
  - "Prior Methods"
  - "Prior Methods"
  "topic_labels":
  - "Textualization of Geometry and Masks"
  - "Instruction Tuning and SFT"
- "unique_context_marker": "[Hu et al., 2023]"
  "block_ids":
  - 4
  "intent_labels":
  - "Research Gap"
  "topic_labels":
  - "Image-Level Understanding"
- "unique_context_marker": "[Dai et al., 2023]"
  "block_ids":
  - 5
  "intent_labels":
  - "Research Gap"
  "topic_labels":
  - "Instruction Tuning and SFT"
- "unique_context_marker": "[Fang et al., 2023]"
  "block_ids":
  - 7
  "intent_labels":
  - "Model/Architecture Adoption"
  "topic_labels":
  - "Vision Encoder Choices and Scales"
- "unique_context_marker": "[Touvron et al., 2023b]"
  "block_ids":
  - 7
  "intent_labels":
  - "Model/Architecture Adoption"
  "topic_labels":
  - "Language Models and Tokenization"
- "unique_context_marker": "[Mou et al., 2020]"
  "block_ids":
  - 8
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "Temporal and Multimodal Variants"
- "unique_context_marker": "[Li et al., 2020]"
  "block_ids":
  - 8
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "Visual Grounding Corpora and Geometry Labels"
- "unique_context_marker": "[Xia et al., 2018]"
  "block_ids":
  - 8
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "Visual Grounding Corpora and Geometry Labels"
