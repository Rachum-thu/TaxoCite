"citations":
- "unique_context_marker": "[Chen et al., 2023b]"
  "block_ids":
  - 1
  - 4
  - 5
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - - "Vision-Language Connectors to LLMs"
    - "Vision-Language Connectors to LLMs"
    - "Instruction Tuning and SFT"
    - "Vision-Language Connectors to LLMs"
    - "Vision-Language Connectors to LLMs"
  - []
  - []
- "unique_context_marker": "[Chen et al., 2023a]"
  "block_ids":
  - 1
  - 4
  - 5
  - 7
  - 8
  - 11
  "intent_labels":
  - []
  - []
  - []
  - []
  - []
  - []
  "topic_labels":
  - - "Vision-Language Connectors to LLMs"
    - "Vision-Language Connectors to LLMs"
    - "Instruction Tuning and SFT"
    - "Vision-Language Connectors to LLMs"
    - "Vision-Language Connectors to LLMs"
  - []
  - []
  - []
  - - "Visual Grounding Corpora and Geometry Labels"
    - "Visual Grounding Corpora and Geometry Labels"
    - "Visual Grounding Corpora and Geometry Labels"
    - "Visual Grounding Corpora and Geometry Labels"
    - "Visual Grounding Corpora and Geometry Labels"
  - []
- "unique_context_marker": "[Zhan et al., 2023b]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - - "Evaluation Protocols and Diagnostics"
    - "Object/Region-Level Grounding and Referring"
    - "Object/Region-Level Grounding and Referring"
    - "Object/Region-Level Grounding and Referring"
    - "Object/Region-Level Grounding and Referring"
- "unique_context_marker": "[Liu et al., 2023]"
  "block_ids":
  - 1
  - 4
  - 5
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - []
  - []
  - []
- "unique_context_marker": "[Yuan et al., 2023a]"
  "block_ids":
  - 1
  - 3
  "intent_labels":
  - []
  - []
  "topic_labels":
  - []
  - - "Task Formulations in RS VLM"
    - "Task Formulations in RS VLM"
    - "Task Formulations in RS VLM"
    - "Task Formulations in RS VLM"
    - "Task Formulations in RS VLM"
- "unique_context_marker": "[Hoxha et al., 2023]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "unique_context_marker": "[Yuan et al., 2023b]"
  "block_ids":
  - 1
  - 3
  "intent_labels":
  - []
  - []
  "topic_labels":
  - - "Image-Level Understanding"
    - "Image-Level Understanding"
    - "Image-Level Understanding"
    - "Image-Level Understanding"
    - "Image-Level Understanding"
  - - "Image-Level Understanding"
    - "Image-Level Understanding"
    - "Image-Level Understanding"
    - "Image-Level Understanding"
    - "Image-Level Understanding"
- "unique_context_marker": "[Zhan et al., 2023a]"
  "block_ids":
  - 1
  - 3
  "intent_labels":
  - []
  - []
  "topic_labels":
  - []
  - - "Object/Region-Level Grounding and Referring"
    - "Object/Region-Level Grounding and Referring"
    - "Object/Region-Level Grounding and Referring"
    - "Object/Region-Level Grounding and Referring"
    - "Object/Region-Level Grounding and Referring"
- "unique_context_marker": "[Bashmal et al., 2023]"
  "block_ids":
  - 1
  - 3
  "intent_labels":
  - []
  - []
  "topic_labels":
  - []
  - - "Temporal and Multimodal Variants"
    - "Temporal and Multimodal Variants"
    - "Temporal and Multimodal Variants"
    - "Temporal and Multimodal Variants"
    - "Temporal and Multimodal Variants"
- "unique_context_marker": "[Xiong et al., 2022]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - - "Task Formulations in RS VLM"
    - "Other Topics"
    - "Task Formulations in RS VLM"
    - "Task Formulations in RS VLM"
    - "Task Formulations in RS VLM"
- "unique_context_marker": "[OpenAI, 2022]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - []
- "unique_context_marker": "[Touvron et al., 2023a]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - []
- "unique_context_marker": "[OpenAI, 2023]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - []
- "unique_context_marker": "[Chiang et al., 2023]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - []
- "unique_context_marker": "[Li et al., 2023]"
  "block_ids":
  - 4
  - 7
  "intent_labels":
  - []
  - []
  "topic_labels":
  - []
  - []
- "unique_context_marker": "[Zhu et al., 2023]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - []
- "unique_context_marker": "[Wang et al., 2023]"
  "block_ids":
  - 4
  - 5
  "intent_labels":
  - []
  - []
  "topic_labels":
  - []
  - []
- "unique_context_marker": "[Hu et al., 2023]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Image-Level Understanding"
    - "Image-Level Understanding"
    - "Image-Level Understanding"
    - "Image-Level Understanding"
    - "Image-Level Understanding"
- "unique_context_marker": "[Dai et al., 2023]"
  "block_ids":
  - 5
  "intent_labels":
  - []
  "topic_labels":
  - []
- "unique_context_marker": "[Fang et al., 2023]"
  "block_ids":
  - 7
  "intent_labels":
  - []
  "topic_labels":
  - []
- "unique_context_marker": "[Touvron et al., 2023b]"
  "block_ids":
  - 7
  "intent_labels":
  - []
  "topic_labels":
  - []
- "unique_context_marker": "[Mou et al., 2020]"
  "block_ids":
  - 8
  "intent_labels":
  - []
  "topic_labels":
  - []
- "unique_context_marker": "[Li et al., 2020]"
  "block_ids":
  - 8
  "intent_labels":
  - []
  "topic_labels":
  - []
- "unique_context_marker": "[Xia et al., 2018]"
  "block_ids":
  - 8
  "intent_labels":
  - []
  "topic_labels":
  - []
