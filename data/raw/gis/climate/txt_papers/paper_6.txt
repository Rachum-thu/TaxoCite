manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
Long-Range Distillation: Distilling 10,000 Years of
Simulated Climate into Long Timestep AI Weather
Models
Scott A. Martin 1,2∗, Noah Brenowitz 1, Dale Durran 1,3, Mike Pritchard 1
1NVIDIA Research, Santa Clara, CA, USA
2School of Oceanography, University of Washington, Seattle, W A, USA
3Department of Atmospheric & Climate Science, University of Washington, Seattle, W A, USA
Key Points:
• We replace long autoregressive ensemble rollouts for long-range weather forecast-
ing with a single–timestep probabilistic prediction model.
• We distill a massive synthetic training dataset generated by an autoregressive AI
model into a long-range forecast model.
• S2S forecast skill improves with increasing synthetic training data and approaches
ECMWF ensemble skill after fine-tuning on ERA5.
∗Research conducted during an internship at NVIDIA Research
Corresponding author: Scott A. Martin, smart1n@uw.edu
–1–
arXiv:2512.22814v1  [cs.LG]  28 Dec 2025
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
Abstract
Accurate long-range weather forecasting remains a major challenge for AI models, both
because errors accumulate over autoregressive rollouts and because reanalysis datasets
used for training offer a limited sample of the slow modes of climate variability under-
pinning predictability. Most AI weather models are autoregressive, producing short lead
forecasts that must be repeatedly applied to reach subseasonal-to-seasonal (S2S) or sea-
sonal lead times, often resulting in instability and calibration issues. Long-timestep prob-
abilistic models that generate long-range forecasts in a single step offer an attractive al-
ternative, but training on the 40-year reanalysis record leads to overfitting, suggesting
orders of magnitude more training data are required. We introduce long-range distilla-
tion, a method that trains a long-timestep probabilistic “student” model to forecast di-
rectly at long-range using a huge synthetic training dataset generated by a short-timestep
autoregressive “teacher” model. Using the Deep Learning Earth System Model (DLESyM)
as the teacher, we generate over 10,000 years of simulated climate to train distilled stu-
dent models for forecasting across a range of timescales. In perfect-model experiments,
the distilled models outperform climatology and approach the skill of their autoregres-
sive teacher while replacing hundreds of autoregressive steps with a single timestep. In
the real world, they achieve S2S forecast skill comparable to the ECMWF ensemble fore-
cast after ERA5 fine-tuning. The skill of our distilled models scales with increasing syn-
thetic training data, even when that data is orders of magnitude larger than ERA5. This
represents the first demonstration that AI-generated synthetic training data can be used
to scale long-range forecast skill.
Plain Language Summary
Predicting weather weeks to months ahead is extremely challenging. Most current
AI weather models extend short forecasts by repeatedly stepping forward in time, caus-
ing errors to accumulate and long-range predictions to become unstable. In addition, ob-
servational records span only a few decades, limiting the ability to learn slow climate pro-
cesses that control long-range predictability.
We introduce long-range distillation, an approach that trains an AI model to make
long-range forecasts in a single step. We first use an existing AI weather model to gen-
erate over 10,000 years of synthetic climate data, enabling the distilled model to learn
patterns not well represented in the limited observational record.
The resulting model produces stable long-range forecasts using one step instead of
hundreds. In controlled experiments, it nearly matches the performance of the model that
generated the synthetic data, and when adapted to real-world conditions, it achieves skill
comparable to the ECMWF subseasonal-to-seasonal system. Forecast skill improves with
increasing synthetic training data, demonstrating that AI-generated climate simulations
can be used to scale long-range prediction skill.
1 Introduction
In recent years, there has been rapid progress in the development of AI weather
models which now match or exceed the forecast skill of state-of-the-art dynamical mod-
els for medium-range weather forecasting (Pathak et al., 2022; Keisler, 2022; Bi et al.,
2023; K. Chen et al., 2023; L. Chen et al., 2023; Lam et al., 2023; Price et al., 2025; Alet
et al., 2025). Although a wide diversity of model architectures, loss functions, and fine-
tuning strategies have been explored, research in AI weather forecasting has predomi-
nantly focused on autoregressive models. Autoregressive models are trained to predict
the atmospheric state at the next time step, typically a few hours forward, conditioned
on some history of past states. Thus, the training objective is typically short in its time
horizon, with the model effectively learning a timestepper for atmospheric dynamics (Dueben
–2–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
& Bauer, 2018; Weyn et al., 2019). Forecasting at long lead times, including beyond those
optimized during training, is achieved by repeatedly calling the trained model for mul-
tiple iterative time steps. The repeated model calls lead to an accumulation of model
errors when used for longer lead times, though this can be partly alleviated by fine-tuning
with a multi-timestep objective (Weyn et al., 2020; Pathak et al., 2022; Lam et al., 2023;
Nguyen et al., 2024; Price et al., 2025; Bonev et al., 2025) or by coupling to an ocean
model and fine-tuning the full coupled system (Duncan et al., 2025). Autoregressive mod-
els are typically trained on reanalysis data from ERA5 (Hersbach et al., 2020). Train-
ing autoregressive models on reanalysis has proven successful for medium-range weather
forecasting since ERA5 provides a large and diverse library of short-range atmospheric
trajectories, allowing the training of expressive neural network architectures which gen-
eralize well to unseen weather states.
Despite the impressive successes of autoregressive models, they suffer a number of
key limitations when applied to long-range weather forecasting, for example at subseasonal-
to-seasonal (S2S) and seasonal lead times. Autoregressive models must be iteratively rolled
out over many steps for long-range forecasting, typically far beyond the horizon over which
they were trained, often leading to rollout instability when errors accumulate. At S2S
and seasonal lead times, predictability from initial conditions diminishes and the skill
of deterministic models saturates to climatology, necessitating a probabilistic approach.
To produce probabilistic forecasts at long lead times, autoregressive models can be com-
bined with ensembling methods from numerical weather prediction such as perturbed
or lagged initial condition ensembles (Brenowitz, Cohen, et al., 2025), or AI-specific ap-
proaches like model checkpoint ensembles (Weyn et al., 2021; Mahesh et al., 2025, 2025).
Recent studies show that ensembles generated using autoregressive models can achieve
similar skill at S2S time-scales to the ECMWF ensemble forecasting system (Weyn et
al., 2024; L. Chen et al., 2024). However, such ensembling methods have thus far yielded
only modest S2S skill gains compared to ECMWF and calibrating the spread of the en-
semble at long lead times is an involved and delicate procedure. Alternatively, proba-
bilistic predictions can be achieved using probabilistic deep learning models, for exam-
ple diffusion models (Mardani et al., 2025; Price et al., 2025; Brenowitz, Ge, et al., 2025)
or by training an ensemble of perturbed models with probabilistic scoring objectives (Lang
et al., 2024; Alet et al., 2025; Bonev et al., 2025). However, past studies applying prob-
abilistic models still work mostly within an autoregressive framework and are thus still
limited in their long-range forecast skill by error accumulation and are hard to calibrate
at long time horizons. Fundamentally, there is a mismatch between the autoregressive
training objective, learning a short lead timestepper, and the intended inference task in
long-range weather forecasting: a well calibrated probabilistic model of the slow modes
of climate variability that underpin S2S and seasonal predictability.
While autoregressive modeling has become common practice in AI weather fore-
casting, using a single, large model timestep is another viable avenue explored in some
early studies (Sønderby et al., 2020; Rasp & Thuerey, 2021). Rasp and Thuerey (2021)
outline two alternative approaches to autoregression: ‘direct’ modeling, where a sepa-
rate neural network is trained for each lead time, and ‘continuous’ modeling, where a sin-
gle network predicts a variety of lead times with the lead time provided as input con-
ditioning (Sønderby et al., 2020). While these past studies used deterministic training
objectives and targeted short-range lead times of just a few days (Sønderby et al., 2020;
Rasp & Thuerey, 2021), it is plausible that single timestep methods could be adapted
for probabilistic long-range weather forecasting. Training single timestep probabilistic
models to forecast well calibrated ensembles at long lead times appears a promising ap-
proach since it removes the risk of rollout instability and calibrating the predictions of
a single-step model would likely be less challenging than for an ensemble of autoregres-
sive rollouts.
–3–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
Despite their appealing properties for long-range forecasting, training single timestep
models for S2S and seasonal time-scales on ERA5 reanalysis data presents a data spar-
sity problem not encountered for short- and medium-range forecasting. At long lead times,
the number of independent training examples within the ERA5 record diminishes by or-
ders of magnitude due to the significant autocorrelation at long time-scales. ERA5 con-
tains relatively few independent realizations of S2S variability, and even fewer of seasonal
variability. This poses a challenge for training expressive neural network architectures
without overfitting to the limited range of dynamics sampled in the ERA5 record.
In this study, we propose a novel approach to probabilistic long-range weather mod-
eling: long-range distillation. Our approach is inspired by the fact that short timestep
autoregressive models are good generators of realistic atmospheric variability, but that
controlling an ensemble of such models for well calibrated long-range forecasting is chal-
lenging. We propose to use a short timestep autoregressive model as a ‘teacher’ model
to enable the training of a probabilistic long timestep ‘student’ model through synthetic
training data. Autoregressive models are fast and cheap to run and, provided they can
be rolled out stably over long time-horizons, can thus simulate orders of magnitude more
years of atmospheric variability than is available in ERA5. By generating a large vol-
ume of simulated weather states using the autoregressive teacher model, we aim to con-
struct a sufficiently large and diverse training dataset to train a probabilistic model to
produce well calibrated long-range forecasts in a single model timestep. The trained stu-
dent model can then be thought of as a distilled representation of the autoregressive teacher
simulations. By using a single model timestep, the distilled model would provide a con-
trollable interface for long-range modeling which sidesteps the need for a large number
of autoregressive time steps and for extensive tuning of initial condition or model weight
perturbations for well calibrated ensemble forecasts.
The performance of large language models has been shown to scale as both the train-
ing dataset size and model capacity are increased by orders of magnitude, with optimal
results obtained when both are scaled simultaneously (Kaplan et al., 2020). AI weather
models have thus far explored scaling model capacity while keeping training dataset size
fixed, restricted by the limited duration of the ERA5 record. By using computationally
cheap autoregressive models to generate large volumes of synthetic weather data, we aim
to unlock the dataset size scaling axis for our distilled model training. Our departure
away from autoregressive modeling and toward compressing a large volume of climate
data into a conditional generative model is also inspired by recent efforts to develop a
generative foundation model of the global atmosphere (Brenowitz, Ge, et al., 2025).
Training distilled models for long-range prediction requires an autoregressive teacher
model capable of generating a large volume of synthetic training data with physically
plausible S2S and seasonal variability. Here, we use the Deep Learning Earth System Model
(DLESyM) (Cresswell-Clay et al., 2025) as the autoregressive teacher model for our dis-
tilled, long timestep student models. DLESyM is a coupled ocean-atmosphere autore-
gressive model trained on reanalysis data, with the ocean and atmosphere models trained
separately before being coupled at inference. Despite only being optimized over short
time horizons of a few days, DLESyM remains stable when rolled out for 100’s-1000’s
of years and produces emergent modes of coupled ocean-atmosphere variability such as
the El-Nino Southern Oscillation (ENSO), with realistic climatological statistics for a
wide range of processes such as tropical cyclogenesis, the Indian Summer Monsoon, and
mid-latitude blocking events (Cresswell-Clay et al., 2025). While we use DLESyM here,
we emphasize that our long-range distillation framework could be applied in future to
any autoregressive model capable of realistic long-range rollouts, for example SamudrACE
(Duncan et al., 2025; Watt-Meyer et al., 2025; Dheeshjith et al., 2025) or NeuralGCM
(Kochkov et al., 2024). Another advantage of DLESyM as the autoregressive teacher is
that it is trained exclusively on reanalysis data, ensuring that our distilled models learn
dynamics grounded in observations rather than inheriting the inherent biases of physics-
–4–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
based climate models, which have complementary advantages for forced multi-decadal
prediction tasks.
While DLESyM is a promising autoregressive teacher model for long-range distil-
lation due to its long-term stability and coupled ocean–atmosphere variability, it has lim-
itations relevant to this study. First, DLESyM simulates a limited set of state variables,
just 8 atmospheric variables and a single ocean variable, compared with roughly 100 at-
mospheric variables in state-of-the-art medium-range AI weather models (Pathak et al.,
2022; Keisler, 2022; Bi et al., 2023; K. Chen et al., 2023; L. Chen et al., 2023; Lam et
al., 2023; Price et al., 2025; Alet et al., 2025), where the same variable at different pres-
sure levels is counted separately. While this parsimonious state vector promotes long-
term stability, it potentially restricts the range of dynamics the model can represent and
could limit forecast skill relative to larger models. Second, recent studies have shown that
autoregressive AI models struggle to capture the rapid initial growth of small-amplitude
perturbations in the initial conditions (Selz & Craig, 2023). This has implications for
ensemble forecasting using perturbed initial conditions, as considered in Section 3.1, be-
cause it suggests that perturbation strengths may need to be artificially increased be-
yond the true uncertainty in initial conditions to compensate for suppressed error growth.
Selz and Craig (2023) found that the Pangu model (Bi et al., 2023), while failing to re-
produce the initial fast growth of small perturbations compared with a physics-based model
ground truth, largely captured the true error growth for larger initial condition pertur-
bation sizes comparable to the uncertainty of real-world analysis. In contrast, our ex-
periments (Section 3.1) suggest that DLESyM exhibits suppressed error growth even for
large initial perturbations, likely due to its limited state vector, a point warranting fur-
ther investigation beyond the scope of this study. The key implication for this work is
that the predictability of the DLESyM-simulated atmosphere differs from the real world.
This should be kept in mind when interpreting the results of the perfect-model exper-
iment in Section 3.1, though we expect the difference to be most pronounced at short-
to medium-range lead times, where sensitivity to initial conditions is strongest, and less
so at S2S or seasonal scales.
In this study, we explore the feasibility of long-range distillation for probabilistic
forecasting across a range of time-scales through controlled perfect-model experiments,
before applying our framework to real-world S2S forecasting. Section 2 outlines our pro-
posed long-range distillation method. Section 3 describes the setup and results of our
perfect-model experiment. Section 4 describes how we fine-tune and apply our distilled
models for real-world forecasting and benchmarks our method against the ECMWF en-
semble forecast system. We draw conclusions and discuss future research directions in
Section 5.
2 Long-Range Distillation
2.1 Long-Range Distillation Problem Formulation
Long-range distillation assumes access to a short time-step autoregressive model
trained on reanalysis data capable of stable long rollouts, which here will be DLESyM
(Section 2.2). This autoregressive ‘teacher’ model is used to train a distilled ‘student’
model to do long-range forecasting in a single model timestep (Figure 1).
First, a large simulation is created using the teacher model, generating a diverse
dataset of synthetic input-output pairs for forecasting at long time-scales. This dataset
contains orders of magnitude more long-range training examples than the original reanal-
ysis dataset on which the autoregressive teacher was trained.
Given a long rollout from the autoregressive teacher, ( x1, x2, ...), we first define
our long-range target, xN, which is the teacher-simulated state at some large number,
N, of autoregressive steps forward and averaged over a time window of M autoregres-
–5–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
Autoregressive 
Teacher Model 
(DLESyM)
dt = 6 hr
Duration
~50 yrs
Duration 
~10,000 yrs
dt = 6 hr
dt = 4 weeks
Duration 
~10,000 yrs
Long-Range
Distilled Student 
Model
Reanalysis Data 
(ERA5)
Large Teacher 
Simulation
Synthetic Training Data 
for Long-Range Models
Short 
Timestep 
Training
Long 
Autoregressive 
Rollout
Coarsen 
in Time
Long 
Timestep 
Training
Autoregressive Teacher Training Long-Range Distillation
Figure 1. Schematic of long-range distillation approach. First, an autoregressive teacher
model is trained for short lead time prediction using reanalysis datasets like ERA5 — in our
case we leverage DLESyM as a pre-trained autoregressive teacher capable of stable long-running
simulations. The autoregressive teacher is used to generate a huge simulation with orders of mag-
nitude higher temporal coverage than ERA5. Finally, a long timestep probabilistic model, the
”student”, is trained on the autoregressive teacher to do long-range prediction in a single model
timestep.
sive steps,
xN = 1
M
i=M/2X
i=−M/2
xN +i. (1)
Our long-range distilled model then seeks to directly model the conditional probability
of this long-range target
p(xN |x1), (2)
conditioned on the initial state. We thus replace a long autoregressive rollout of poten-
tially hundreds of steps with a single model timestep.
Concretely, at S2S time-scales, given an autoregressive model which takes 6 hr timesteps,
we could choose N = 112 and M = 28 to target a weekly average forecast at 4-week
lead time. In practice, to reduce the data volume of the large autoregressive teacher sim-
ulation we save the teacher simulation with degraded temporal resolution, averaging the
6-hourly timesteps to daily frequency. In practice, we then condition our distilled model
forecasts on a short history of four daily averages rather than a single day. Although the
synthetic training data are generated using a Markov model (i.e., DLESyM), and a his-
tory of states should therefore carry no extra information, we include it to compensate
for information lost through daily averaging.
2.2 DLESyM Climate Simulation
We use DLESyM (Cresswell-Clay et al., 2025) to generate O(10,000 years) of syn-
thetic climate for training our long-range distilled models. To parallelize data genera-
tion, we choose to generate an ensemble of simulations initialized on different dates rather
than running a single long-running simulation. We initialized DLESyM simulations on
200 dates equally spaced between 2008-01-01 and 2016-12-31, running each simulation
for 90 years, yielding 18,000 years of simulated climate. We used the version of DLESyM
distributed through the NVIDIA Earth2Studio package (v0.8.0), with each ensemble mem-
ber using a randomly selected checkpoint from the four checkpoints provided through
the NGC catalog (NVIDIA, 2025c) to boost ensemble variability. The Earth2Studio im-
plementation of DLESyM closely follows that outlined in Cresswell-Clay et al. (2025),
except that the atmospheric model omits outgoing longwave radiation from the set of
prognostic variables predicted, with the model checkpoints being trained again from scratch
following the procedure outlined in Cresswell-Clay et al. (2025). DLESyM is initialized
–6–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
using reanalysis data from ERA5 regridded onto the HEALPix64 grid. The prognostic
variables predicted by this version of DLESyM are:
• Sea surface temperature (SST)
• 2 m air temperature ( T2m)
• Temperature at 850hPa (T850)
• Total column water vapor (TCWV)
• Wind speed at 10m ( w10m)
• Geopotential height at 1000hPa ( z1000)
• Geopotential height at 500hPa ( z500)
• Geopotential height at 250hPa ( z250)
• Difference between geopotential heights at 700hPa and 300hPa ( τ300−700)
Generating this large ensemble of DLESyM simulations took 4 hours when run in
parallel on 96 NVIDIA H100 GPUs, with a throughput of O(1000) simulated years per
day per H100 GPU. This emphasizes the substantial speedup offered by AI climate em-
ulators compared to physics-based climate models. We observed that ∼14% of the DLESyM
ensemble members went unstable before finishing the 90 year rollout. This is in contrast
to the 1,000 year stable rollouts demonstrated by Cresswell-Clay et al. (2025) and this
infrequent instability appears to be specific to the Earth2Studio DLESyM checkpoints
as running the checkpoints from Cresswell-Clay et al. (2025) for the initial conditions
that went unstable here did not show signs of instability in the first 100 years of sim-
ulation (Cresswell-Clay, 2025). Regardless, it is easily identified and pruned in post-processing,
i.e. we simply omit all ensemble members that went unstable during the 90 year sim-
ulation, leaving ∼15,000 years of simulated climate for training and validation of our dis-
tilled models. Details of the DLESyM ensemble simulation are summarized in Appendix
B.
2.3 Distilled Student Model Architecture: HEALPix Conditional Dif-
fusion
We implement our distilled student model as a conditional diffusion model, enabling
probabilistic forecasting. As input conditioning, c, we provide a short history of daily
average weather states for the 4 preceding days. We then seek to model the conditional
distribution, p(x|c), of future global weather states, x, at some long-range target lead
time. All data are represented on the HEALPix64 grid as it provides a satisfying dis-
cretization of the sphere and is consistent with the DLESyM autoregressive teacher model.
The neural network architecture we use to perform global conditional diffusion on the
HEALPix64 grid follows that used in the recently-developed global foundation model,
cBottle (Brenowitz, Ge, et al., 2025). The reader is referred to Brenowitz, Ge, et al. (2025)
for implementation details. Briefly, this architecture adapts the UNet backbone used widely
in diffusion models (Song et al., 2020; Karras et al., 2022) to the HEALPix grid by us-
ing a HEALPix-specific padding scheme proposed by Karlbauer et al. (2024), by adding
a learned spatial embedding to learn non-stationary spatial structures, and by adding
a periodic temporal embedding to represent the day of year and time of day (Brenowitz,
Ge, et al., 2025). Since in this study all forecast and conditioning states are averaged
over at least one day, we drop the time of day embedding used in cBottle but retain the
day of year embedding. We train using a log uniform σ distribution and for sampling
we use σmin = 0 .002, σmax = 200, and 18 sampler steps. Note these settings differ
from those in the original EDM paper (Karras et al., 2022) and were chosen following
the rationale laid out in Brenowitz, Ge, et al. (2025) to ensure that the noise range fully
covers all scales in our data and to ensure the training σ distribution matches the sam-
pler scheme used at inference. All network and sampler hyperparameters are listed in
Appendix B.
–7–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
2.4 Calibrating Distilled Model Forecast with Classifier-Free Guidance
Calibrating forecasts requires a mechanism to control the ensemble spread of the
forecast. For an initial condition ensemble of autoregressive models, this is typically achieved
by varying the strength of the initial condition perturbations. To control the ensemble
spread from our long timestep conditional diffusion models we here exploit classifier-free
guidance (Ho & Salimans, 2022). Classifier-free guidance provides a way to achieve a trade-
off between the diversity of generated samples and the strength of the conditioning.
Concretely, the conditional score, ∇xlog(p(x(t)|c)), used during sampling, is replaced
with a linear combination of the conditional and unconditional scores,
∇xlog (p(x(t)) + w [∇xlog(p(x(t)|c)) − ∇xlog(p(x(t))] , (3)
where w is the classifier-free guidance weight that controls the strength of the guidance.
This is equivalent to sampling from the probability density function p(x(t)|c)wp(x(t))1−w.
When w = 0, the model generates samples unconditionally. When w = 1, the model
generates samples conditionally with no guidance. When w > 1 the model is guided
strongly towards the conditioning, and when 0 < w < 1 the conditioning strength is
reduced. In practice, we jointly learn the conditional and unconditional models with the
same network by randomly setting the input conditioning tensor to zero during train-
ing for 10% of the samples. While classifier-free guidance is common practice in com-
puter vision, this is to our knowledge the first study to propose using it to control en-
semble spread in weather forecasting. Unlike computer vision, where classifier guidance
is used to increase fidelity to conditioning by choosing w > 1, we typically use the guid-
ance to increase ensemble spread by choosing w < 1 (see Section 5a).
3 Perfect-Model Experiment
3.1 Setup
In Section 4.1 we turn to the problem of real-world forecasting and account for the
domain shift needed to apply the DLESyM-trained student model to real-world ERA5
data. First, we evaluate the ability of our long-range distilled models to produce skill-
ful ensemble forecasts across a range of lead times in the controlled setting of a perfect-
model experiment. All evaluation is done using a withheld simulation from the autore-
gressive teacher model (DLESyM). We assess the extent to which both the distilled long
timestep models and the autoregressive DLESyM teacher model can forecast an unseen
DLESyM simulation given imperfect knowledge of initial conditions.
Concretely, we apply the following experiment protocol:
1. Perform a single, multi-year deterministic simulation with DLESyM referred to
hereafter as the Nature Run. This simulation serves as the ground truth reference
and is assumed to represent the unknown, true state of the atmosphere.
2. Select a series of starting-point dates from the Nature Run. Apply a different set
of initial condition perturbations to each of these starting points to create the suite
of imperfect initial conditions for each ensemble forecast.
3. For the distilled long-timestep student model, construct ensemble forecasts using
the conditional diffusion model applied to the imperfect initial conditions from 2.
The spread of the ensemble forecast can be controlled using classifier-free guid-
ance (Section 2.4).
4. For the DLESyM autoregressive teacher model, construct either deterministic or
ensemble forecasts from the same imperfect initial conditions from 2 as used by
the distilled model. To construct an ensemble forecast from DLESyM, we use ini-
tial condition perturbations (perturbing around the already imperfect initial con-
ditions from 2) to generate ensemble spread. The spread of the ensemble forecast
–8–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
0 2 4 6 8
Lead Time [days]
0
100
200
300
400
500
600
700
800Global z500 RMSE [m2/s2]
DLESyM (0.02 std IC pert)
DLESyM (0.025 std IC pert)
DLESyM (0.03 std IC pert)
IFS HRES
Figure 2. Error growth in DLESyM autoregressive ensemble members for varying initial con-
dition perturbation strengths. Global average Z500 RMSE of DLESyM ensemble members with
respect to a withheld ensemble member for varying initial condition perturbation sizes (colored
lines) and the real-world global average Z500 RMSE of IFS for reference (black dashed line). The
initial condition condition perturbation strengths in the legend are provided in normalized units
since we perturb all fields using a multiple of each field’s global standard deviation. For Z500, the
standard deviation is 2605 m2/s2.
can be controlled by varying the strength of the extra initial condition perturba-
tions applied on top of those from 2.
5. Score all forecasts against the unseen Nature Run from 1.
The aim of this experiment is to test the extent to which our distilled models pro-
duce a well-calibrated ensemble forecast, and we compare its performance against an en-
semble forecast made using the DLESyM autoregressive teacher model through initial
condition perturbations for reference. The size of the initial condition perturbation made
to the Nature Run when constructing the imperfect initial conditions is an important
design choice of our experiment. Since DLESyM is a deterministic autoregressive model,
in the limit where we provide a perfect initial condition it will provide a perfect forecast.
Thus we seek to provide a large enough perturbation to ensure the experiment reflects
the practical real-world forecasting ability of DLESyM given imperfect knowledge of ini-
tial conditions. To achieve this, we tune the size of the initial condition perturbation un-
til the RMSE in Z500 at 7-day lead time of a DLESyM ensemble member matches that
of IFS HRES (521 m2/s2) (Rasp et al., 2024). This corresponds to an initial condition
perturbation size of 65 m2/s2 for Z500. We acknowledge this perturbation is larger than
the likely real-world analysis error, IFS HRES has 22 m2/s2 RMSE at 6-hour lead time
–9–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
T able 1. Inputs and outputs for the different distilled student models. N is the lead time in
number of 6-hour autoregressive teacher steps and M is the size of the target averaging window
in 6-hour teacher steps (Equation 1).
Lead Time Inputs Outputs N M
Medium-Range Days 0, -1, -2, -3 Day 7 28 4
S2S Days 0, -1, -2, -3 Average of Days 25-31 112 28
Seasonal Days 0, -1, -2, -3 Average of Days 70-98 336 112
(Rasp et al., 2024), which we interpret as necessary to compensate for the known slower
error growth of autoregressive AI weather models compared to dynamical models (Selz
& Craig, 2023). We perturb all atmospheric variables by the same fraction of their global
standard deviation which is the single parameter we tune to match day-7 IFS HRES RMSE.
For SST we provide a perturbation of 0.1 K. The initial condition perturbations are sam-
pled as Gaussian white noise with spatiotemporal correlation structure given by a Matern
covariance function with de-correlation length-scale 500 km and time-scale 48 hours, us-
ing the implementation in Earth2Studio (NVIDIA, 2025b). This noise structure, which
follows that used by Leutbecher and Palmer (2008), encourages the perturbed fields to
retain physically realistic spatiotemporal structure, while being significantly simpler to
implement than dynamical methods such as bred vectors (Toth & Kalnay, 1993) given
that perturbed initial condition ensembling is not a primary focus of our study.
All validation is done on a withheld DLESyM simulation not seen during training
of the distilled model. In addition to deterministic metrics like ensemble RMSE, we score
all models using continuous ranked probability score (CRPS) (Hersbach, 2000). We test
distilled long timestep models at three distinct lead times, representing three distinct pre-
dictability regimes (Figure 3):
• Medium Range: We forecast a daily average at 7-day lead time ( N = 28, M =
4). For evaluation, we use over 400 initialization dates spaced 2 days apart from
2017-01-01 to 2019-03-10 in simulation years.
• S2S: We forecast a weekly average at 4-week lead time ( N = 112, M = 28).
For evaluation, we use over 400 initialization dates spaced 4 days apart from 2017-
01-01 to 2021-05-16 in simulation years.
• Seasonal: We forecast a monthly average at 12-week lead time ( N = 336, M =
112). For evaluation, we use over 400 initialization dates spaced 8 days apart from
2017-01-01 to 2025-09-28 in simulation years.
We split the 15,000 years of DLESyM simulation into training (75%) and valida-
tion (25%) datasets, splitting by ensemble member in our large ensemble to ensure sep-
aration between training and validation datasets. After applying our train-validation split,
we are left with ∼11,000 years of DLESyM simulations for training. For each lead time,
we train a separate distilled model. See Appendix B for more details about the train-
ing.
In Figure 3 we show an example forecast (single ensemble member) at each lead
time for 2 m air temperature. As the lead time increases, the targets and forecasts be-
come increasingly smooth due to the increasing temporal averaging window, M. At medium-
range (panels a, d, & g), there is agreement between the patterns of variability in both
the target and forecast, consistent with the relatively high predictability of the atmo-
sphere from initial conditions at this lead time. At S2S (panels b, e, & h) and seasonal
–10–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
Figure 3. Example distilled student model 2 m air temperature forecasts across a range of
lead times initialized on 2017-01-01. Ground truth forecast targets from the withheld DLESyM
evaluation simulation or (a) medium-range, (b) S2S, and (c) seasonal lead times. (d-f) Single
forecast member predictions for each lead time. Both forecast targets and ground truth targets
are visualized as anomalies from climatology (a-f). (g-i) Ensemble mean forecast error for a 32-
member ensemble forecast for each lead time. Medium-range forecasts (a, d, g) are daily means
at 7-day lead time, S2S forecasts (b, e, h) are weekly means at 4-week lead time, and seasonal
forecasts (c, f, i) are 4-week means at 12-week lead time.
(panels c, f, & i), the discrepancies between the ensemble member forecast and targets
become larger, emphasizing the need for ensemble forecasting at these lead times. The
forecasts and targets show the closest agreement over oceans, with predictability likely
attributable to the relatively slow evolution of sea surface temperature since ocean dy-
namics evolves slower than the atmosphere and sea surface temperature and surface air
temperature are closely connected. Interestingly, the seasonal forecast (panel f) appears
to show a consistent ENSO phase to the target, with elevated surface temperature in the
tropical Pacific, suggesting the distilled model is learning to leverage ENSO predictabil-
ity for seasonal forecasting.
All forecasts are compared against two climatological forecast baselines calculated
from a withheld 20 years of the DLESyM simulation. First, we refer to a deterministic
climatology by retrieving the long-range forecast targets, with the requisite temporal av-
eraging for the given M, for each of the 20 years and taking the mean. Second, we re-
fer to a probabilistic climatology by using all forecast targets from the 20 year reference
period together as an ensemble forecast.
–11–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
Figure 4. Scaling of distilled student model S2S forecast skill with synthetic training dataset
size. (a) Elucidated diffusion model (EDM) loss (Karras et al., 2022) throughout training for a
40 year training dataset (blue) and the full 11,000 year dataset (orange). Dashed lines indicate
training loss and solid the validation loss. Learning curves have been smoothed for plotting pur-
poses using bin averaging. (b) Distilled model week 4 2 m air temperature global mean CRPS
with increasing number of training years (orange) and the corresponding minimum validation
EDM loss achieved during training (blue). Dashed lines indicate the length of the ERA5 record
and the CRPS skill of climatology for reference. Note all axes are logarithmic.
3.2 Results
3.2.1 Distilled Model Performance Scales with Size of Synthetic Train-
ing Data
Our long-range distillation framework is based on the hypothesis that an increas-
ing volume of synthetic training data from a long-duration autoregressive teacher sim-
ulation improves student skill, even when the teacher simulation duration far exceeds the
reanalysis dataset used for training the teacher. For this to be true, the autoregressive
teacher simulation must generate a diverse range of climate states beyond those seen dur-
ing training, sampling internal variability not captured by the short reanalysis record.
Analyses of long DLESyM rollouts suggest that it can indeed generate new samples of
–12–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
internal climate variability (Cresswell-Clay et al., 2025), but here we test whether this
translates into improved performance of our distilled models with increasing amounts
of synthetic training data.
We test this hypothesis by evaluating distilled S2S forecast models trained over a
range of autoregressive teacher simulation lengths (Figure 4). A distilled model trained
on 40 years of DLESyM simulation, mimicking the availability of ERA5, shows clear signs
of overfitting once trained beyond ∼1M samples, corresponding to ∼15,000 training steps
(Figure 4a). By contrast, the model trained on the full 11,000 year DLESyM simulation
shows no signs of overfitting, with the training and validation losses matching closely through-
out. The reduced overfitting can also be seen in the steadily improving minimum val-
idation loss as the number of training years is increased by orders of magnitude (Figure
4b). Crucially, the improved EDM denoising losses also translate to improvements in S2S
forecast skill. Training on 11,000 years of synthetic data yields a 14% reduction in 2 m
temperature CRPS at a 4-week lead time, compared to training on 40 years. Note, the
scaling of the forecast skill with dataset size appears to be weaker than the power law
scaling curves observed for natural language (Kaplan et al., 2020), with our CRPS val-
ues not following a power law with dataset size. This is either because beyond a certain
point, the simulation becomes large enough to provide comprehensive sampling of the
internal variability of the DLESyM model climate, or because the distilled student model
capacity becomes the bottleneck as we used a fixed architecture for all dataset sizes whereas
Kaplan et al. (2020) scaled both model capacity and dataset size jointly. Nonetheless,
the improvements of week-4 CRPS with training data size far beyond the size of the orig-
inal ERA5 training dataset confirms our hypothesis that generating a large synthetic cor-
pus of training data using autoregressive models enables more skillful long-range mod-
els and is the first demonstration of scaling forecast performance with an increasing vol-
ume of synthetic training data.
Hereafter, we use the shorthand DLESyM10K to refer to the distilled student model
trained on the full O(10,000 year) DLESyM simulation and all distilled student model
results use the model trained on the full dataset.
3.2.2 Classifier-Free Guidance Provides a Simple Recipe for Calibra-
tion of Long Timestep Forecasts
A well calibrated forecast should have a spread-skill ratio near unity. One key mo-
tivation for our long-range distillation approach is that forecasting using a single model
timestep should make it relatively easy to control the ensemble spread, and hence cal-
ibrate the forecasts, compared to controlling ensemble spread over a long autoregressive
rollout. Here, we confirm our working hypothesis that classifier-free guidance (Section
2.4) provides a simple recipe for ensemble calibration.
The ensemble spread of our medium-range (7-day lead time) DLESyM10K fore-
casts varies monotonically with classifier-free guidance strength, enabling simple calibra-
tion (Figure 5). When the guidance strength is set to zero, the model samples uncon-
ditionally and thus its spread is close to that of climatology. In this limit the model is
conditioned only on the day of year and simply generates samples from the learned cli-
matology of its training data (panel a). As the guidance is increased, the ensemble spread
drops as the model generation depends more strongly on the input conditioning. When
the guidance strength is close to unity, the predictions achieve an optimal tradeoff be-
tween forecast spread and accuracy, with a spread-skill ratio of one and the minimum
CRPS (panel b). In hindsight, further exploration of guidance strengths between 0.5 and
1.0 would have helped to find precisely the optimal guidance strength. As the guidance
is increased beyond one, the ensemble spread continues to decrease but the ensemble RMSE
increases, leading to an increasingly overconfident but inaccurate forecast and thus a low
spread-skill ratio and high CRPS. Interestingly, here the optimal CRPS was achieved us-
–13–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
0 100 101
Classifier-Free Guidance Weight
300
400
500
600
700
800
Ensemble Spread × N + 1
N  [m2/s2]
(a)
DLESyM10K
Climatology
0 100 101
Classifier-Free Guidance Weight
0.4
0.5
0.6
0.7
0.8
0.9
1.0
1.1Spread-Skill Ratio
(b)
DLESyM10K
Well Calibrated
0 100 101
Classifier-Free Guidance Weight
200
250
300
350
400
450CRPS [m2/s2]
(c)
DLESyM10K
Climatology (Probabilistic)
Climatology (Deterministic)
Figure 5. Calibration of medium-range distilled student model forecasts using classifier-free
guidance. (a) Day 7 global Z500 ensemble spread for varying classifier-free guidance strengths
(black solid) with reference ensemble spread for a 20 year climatology (red dashed). (b) Distilled
model ensemble spread-skill ratio for varying classifier-free guidance strengths (black solid). En-
semble spread-skill plot uses unbiased estimator for ensemble spread. (c) Day 7 global mean Z500
CRPS for distilled student model with varying classifier-free guidance strengths (black solid),
compared to a probabilistic (red dashed) and deterministic (blue dashed) 20 year climatology.
Vertical grid lines align with integer guidance strengths, with an extra line at 0.5 between 0 and
1.
ing classifier-free guidance strength of one (which is used throughout the rest of the manuscript),
suggesting that the training objective of the conditional model could implicitly encour-
age a good spread-skill ratio even with no further tuning of classifier-free guidance strength.
Nonetheless, in cases where simple conditional sampling (guidance strength of one) doesn’t
immediately yield a well calibrated forecast, we have shown here that adjusting the en-
semble spread of the forecast can be achieved by simply changing the classifier-free guid-
ance strength used at inference, providing a convenient method for calibrating ensem-
ble forecasts post-training.
–14–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
0 200 400 600 800
Ensemble Spread × N + 1
N  [m2/s2]
0
100
200
300
400
500
600
700
800Ensemble RMSE [m2/s2]
(a) Imperfect Initial Conditions
DLESyM10K
DLESyM T eacher Ensemble
Climatology
Well Calibrated (1-1)
0 200 400 600 800
Ensemble Spread × N + 1
N  [m2/s2]
0
100
200
300
400
500
600
700
800Ensemble RMSE [m2/s2]
(b) Perfect Initial Conditions
DLESyM10K
DLESyM T eacher Ensemble
Climatology
Well Calibrated (1-1)
0
2
4
6
8
10
DLESyM10K Classifier-Free
Guidance Weight
20
40
60
80
DLESyM Teacher Ensemble Z500
Initial Condition Perturbation [m2/s2]
Figure 6. Spread-skill plot for day 7 Z500 forecasts comparing distilled student models to
initial condition ensembles from the autoregressive teacher model. (a) Spread-skill obtained given
an imperfect initial condition (Section 3.1) using the distilled student model (solid black) and ini-
tial condition ensembles from the autoregressive teacher model (solid blue). The 1-1 calibration
line (grey dashed) and climatology RMSE (red dashed) are shown for reference. For the distilled
student model, the classifier-free guidance weight used is indicated by the color of the marker
whereas for the autoregressive teacher it indicates initial condition perturbation strength used to
generate the ensemble. (b) Same as (a) but for the idealized case of perfect initial conditions.
.
3.2.3 Distilled Models Are Skillful Across Lead Times
Medium range. We first assess medium-range (7-day) forecast skill under a re-
alistic setting where both models are initialized from an imperfect estimate of the at-
mospheric state that contains non-negligible error (Figure 6a). In this setting, the au-
toregressive teacher model (DLESyM) exhibits substantial ensemble RMSE because ini-
tial condition errors grow during the autoregressive rollout (Figure 2). Increasing ensem-
ble spread by further perturbing around the already-imperfect initial condition does not
meaningfully reduce forecast error, as the 7-day evolution remains tightly constrained
by the biased starting point. In contrast, DLESyM10K shows much greater robustness
to this initialization error: its day 7 Z500 ensemble RMSE increases by only 25 m 2/s2
due to the addition of initial condition error (comparing panels a & b), and its RMSE
is lower than that of the autoregressive teacher for moderate classifier-free guidance strengths.
This improved performance stems from the student model’s probabilistic formulation,
which represents a distribution of plausible future states and thereby expresses aleatoric
model uncertainty that can hedge over multiple potential trajectories consistent with an
imperfect initial condition. Equivalent benefits for the teacher model would require ex-
plicitly injecting model uncertainty, for example through a checkpoint ensemble (Weyn
et al., 2021) or probabilistic model design (Lang et al., 2024; Alet et al., 2025; Bonev et
al., 2025). By varying the classifier-free guidance strength, the distilled student model
is able to explore spread-skill space. When the guidance strength is ∼1 the distilled stu-
dent model achieves a well-calibrated forecast by intersecting the 1-1 line, whereas the
autoregressive teacher model is under-dispersive across the full range of initial condition
perturbation strengths explored here.
It is instructive to also examine forecast behavior in the idealized regime of per-
fect initial conditions (Figure 6b). When initialized exactly from the true atmospheric
–15–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
Figure 7. Distilled student model long-range forecast skill in perfect-model experiment.
(a) Global mean 2 m air temperature CRPS at 4-week lead time for the autoregressive teacher
(blue), distilled student (orange), deterministic climatology (light grey), and probabilistic clima-
tology (dark grey). (b) Same as (a) but at 12-week lead time. (c) Percent change in global mean
2 m air temperature CRPS with respect to probabilistic climatology at 4-week lead time with
error bars showing 95% confidence interval by bootstrapping over evaluation dates. (d) Same as
(c) but for 12-week lead time. (e) Global map of time mean difference between distilled model
CRPS and that of probabilistic climatology at 4-week lead time. (f) Same as (e) but for 12-week
lead time. In both (e) and (f) blue indicates an improvement with respect to climatology and
stippling indicates a difference that is significantly different from zero at significance level 0.05
(Appendix A).
state and run deterministically, the autoregressive teacher produces a perfect forecast
with zero RMSE since it is a perfect model of the DLESyM atmosphere. As perturba-
tions are added around the true state, its ensemble RMSE increases smoothly with per-
turbation amplitude. DLESyM10K behaves differently in this idealized setting: even when
initialized from the true state, it yields a non-zero ensemble RMSE due to its probabilis-
tic nature. Increasing perturbation amplitude does not significantly change its RMSE
(comparing panels a & b), reflecting the fact that uncertainty in DLESyM10K arises pre-
dominantly from its learned distribution over future states rather than from sensitivity
to initial conditions.
S2S and seasonal. Moving to long-range forecasting, we now evaluate the per-
formance of DLESyM10K at the more challenging S2S and seasonal time-scales in the
setting where we have an imperfect initial condition (Figure 7). At both S2S and sea-
sonal lead times, DLESyM10K shows substantially more skill than a deterministic cli-
matology (panels a & b), achieving global mean skill within 3-7% of an ensemble fore-
–16–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
cast using the autoregressive teacher model, constructed by further perturbing around
the already imperfect initial conditions provided to DLESyM10K (panels c & d). Com-
paring both DLESyM10K and the autoregressive teacher to a probabilistic climatology
highlights the significant challenge of long-range forecasting as they both only marginally
improve upon probabilistic climatology in terms of global mean CRPS (panels c & d).
Nonetheless, DLESyM10K shows statistically significant (Appendix A) skill relative to
climatology both in the global mean (panels c & d) and in many regions (panels e & f),
with the model showing most skill in the tropics and over oceans where the relatively
slow evolution of sea surface temperature increases the long-range predictability of sur-
face air temperature. At both S2S and seasonal lead times DLESyM10K appear to strug-
gle primarily over the continental Northern Hemisphere and over Antarctica where there
appear to be significant errors that warrant closer scrutiny in future work. Even with
these limitations, DLESyM10K exceeds climatology and closely matches the skill of its
autoregressive teacher in a single model timestep, which corresponds to 126 and 392 teacher
steps at S2S and seasonal timescales respectively.
4 Real-World S2S Forecasting
4.1 Setup
4.1.1 Fine-Tuning Distilled Models on ERA5
Ultimately, our goal is to apply DLESyM10K to real-world long-range forecasting
taking ERA5 reanalysis as initial condition. While DLESyM was trained on ERA5, the
model climate that emerges when it is run for long periods does not exactly match that
of the real-world (Cresswell-Clay et al., 2025), as is the case for any climate model. If
we are to apply DLESyM10K, which was trained on DLESyM simulations, for real-world
forecasting there is thus a domain shift to overcome.
We use two strategies to alleviate this domain shift. First, we calculate the clima-
tological bias of the DLESyM simulations compared to ERA5 and use this to shift both
the ERA5 initial conditions and forecast targets seen by the distilled model, ensuring
the large-scale mean and seasonal cycle of our target distribution matches that seen dur-
ing training. Second, we fine-tune DLESyM10K on ERA5 data. During fine-tuning, we
reduce the learning rate by a factor of ten compared to the original training and freeze
all weights except for: the first convolutional layer in the UNet encoder, the final UNet
block in the decoder, all UNet blocks with attention (which are near the middle of the
UNet), and all GroupNorm weights and biases. During early testing, we found this strat-
egy to achieve a good balance, providing enough capacity to adapt to ERA5 data while
freezing enough of the pre-trained weights to avoid overfitting to the short ERA5 record.
4.1.2 Bias Correcting Long-Range Forecasts Using Lead Time-Dependent
Model Climatology
For both physics-based and autoregressive weather models it is common practice
to perform bias correction when forecasting at S2S and seasonal time-scales to correct
for model drift caused by accumulating model errors (Vitart, 2004; Weigel et al., 2008;
Vitart et al., 2017; Weyn et al., 2021, 2024). In this study we use a lead time-dependent
model climatology to bias correct all real-world long-range forecasts. In this approach,
we take reforecasts for the same day of the year for the past 20 years and find the mean
bias of the reforecasts compared to ERA5 ground truth. This mean bias is then subtracted
from the forecast fields for the target year before scoring. Note while DLESyM10K does
not in theory suffer an accumulation of errors over long autoregressive rollouts, we found
in practice the same bias correction procedure to be helpful for our distilled models when
applied to real-world data. This is likely a result of the DLESyM-ERA5 domain shift
as bias correction was not found to be beneficial in our perfect-model experiment.
–17–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
4.1.3 Benchmarking Distilled Models Against Operational S2S Forecasts
We evaluate DLESyM10K’s ability to do S2S forecasting in the real world. As in
Section 3.1, we seek to predict a weekly average at 4-week lead time. To benchmark our
approach against existing operational forecasts, we use the ECMWF S2S ensemble fore-
casts which contain 50 ensemble members (Vitart et al., 2017). Specifically, we evalu-
ate the ECMWF real-time forecasts for the period 2018-2022 taking ERA5 to be the tar-
get. We bias correct (Section 4.1.2) all ECMWF forecasts using the reforecasts provided
for the preceding twenty years using the same model version as the real-time forecasts
and we bias correct DLESyM10K using the same procedure. DLESyM10K is fine-tuned
on ERA5 data from 1980-2016. To test the value of distilling the large DLESyM sim-
ulation, we also evaluate a long timestep model with the same architecture trained from
scratch on ERA5. All forecasts are evaluated using CRPS focusing on 2 m air temper-
ature. As in Section 3.1, all forecasts are benchmarked against a deterministic and prob-
abilistic climatological forecast taken here from the 20 preceding years of ERA5.
4.2 Results: Fine-Tuning Distilled Models on ERA5 Yields Competi-
tive Real-World S2S Forecasting
As outlined in Section 4.1.1, we fine-tune DLESyM10K on real-world data from ERA5
to allow it to adapt to distribution shifts between the DLESyM simulated climate and
the real world. Comparing the learning curves of our fine-tuned model to one with iden-
tical architecture but trained from scratch on ERA5 data (Figure 8) reveals the bene-
fit of pre-training on DLESyM simulations. Training from scratch on ERA5 leads to over-
fitting, whereas fine-tuning only a subset of pre-trained parameters on ERA5 acts as a
strong regularization, preventing overfitting. Importantly, the fine-tuned model is able
to achieve a lower validation loss than training from scratch on ERA5, suggesting trans-
ferability of the skill learned from the DLESyM simulations to real-world data.
To benchmark DLESyM10K against an operational baseline, we compare the week-
4 2 m temperature forecast skill to that of the ECMWF ensemble forecast system from
2018-2022 (Figure 9). First, the challenge of forecasting at S2S time-scales is highlighted
by the fact that a probabilistic climatology, taking the preceding 20 years as ensemble
members, achieves comparable global mean CRPS to all forecast models. The bias-corrected
ECMWF forecasts have the lowest CRPS, although our fine-tuned DLESyM10K model
achieves almost the same skill, with both achieving a statistically significant skill improve-
ment over probabilistic climatology. Based on the fact that DLESyM10K is competitive
with an operational physics-based ensemble forecasting system, it is logical to expect that,
with further refinements, long-range distillation is a viable path to state-of-the-art long-
range forecasting. DLESyM10K outperforms the long-timestep model trained from scratch
on ERA5, further highlighting the value of pre-training on a large DLESyM simulation.
Looking beyond the global means (Figure 10), both ECMWF and DLESyM10K
consistently outperform probabilistic climatology primarily over oceans, with predictabil-
ity likely attributable to the relatively slow evolution of sea surface temperature. In con-
trast, over land both models show limited skill compared to climatology, with skill mostly
confined to the tropics, highlighting that skillful S2S forecasting remains a challenging
frontier for both physics-based and AI weather forecasting systems. Comparing DLESyM10K
to ECMWF (Figure 10c), DLESyM10K shows statistically significant improvements com-
pared to ECMWF over the Americas and parts of central Africa, while ECMWF out-
performs in the tropics, and parts of Eurasia and Africa.
5 Conclusions
Achieving skillful long-range forecasts, from S2S to seasonal time-scales, remains
one of the most challenging and socioeconomically consequential goals in AI-driven weather
–18–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
Figure 8. Fine-tuning distilled student models on real-world ERA5 reanalysis data for S2S
forecasting. Orange curves: training (dashed) and validation (solid) loss for the DLESyM pre-
trained model during fine-tuning on ERA5. Blue curves: same as orange but for model trained
from scratch on ERA5. Note, the learning curves were smoothed for plotting purposes.
prediction. It remains to be seen whether the current paradigm of training autoregres-
sive models on reanalysis data can achieve breakthrough skill in forecasting the slower
modes of climate variability that drive S2S and seasonal predictability.
In this study, we proposed a novel approach to long-range weather modeling. Rather
than relying on ensemble autoregressive rollouts, we repurpose a reanalysis-trained au-
toregressive model as a generator of large volumes of synthetic data to train a separate
distilled model that predicts long-range forecasts in a single model timestep. This de-
sign leverages the ability of autoregressive models to produce realistic weather trajec-
tories while mitigating their limitations for ensemble forecasting at extended lead times.
To our knowledge, this is the first work to train an AI weather model on synthetic data
generated by another AI model, although prior studies have trained on physics-based sim-
ulations (Rasp & Thuerey, 2021). Our results show that replacing long autoregressive
rollouts with a single extended timestep and optimizing for a probabilistic long-range
objective yields well-calibrated forecasts across multiple time scales. We further demon-
strate that classifier-free guidance, commonly used in image generation, offers a simple
recipe for controlling ensemble spread in conditional diffusion models. Training with such
long timesteps (equivalent to up to 392 autoregressive steps) without overfitting required
a massive synthetic dataset, and we observed that S2S forecast skill scaled with the num-
ber of synthetic years, even when the dataset far exceeded the size of ERA5. Finally, fine-
tuning on ERA5 reanalysis allowed our distilled models to achieve real-world forecast
skill comparable to the operational ECMWF S2S ensemble forecast system.
Although our findings highlight the potential of distillation techniques for improv-
ing long-range weather prediction, several limitations remain that warrant attention in
future research. Firstly, while it is impressive that our model achieves competitive S2S
forecast skill compared to ECMWF, our model still slightly trails ECMWF in terms of
global mean CRPS and thus does not yet represent a breakthrough in real-world S2S fore-
–19–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
Figure 9. (a) Global averaged real-world CRPS of week 4 2m air temperature for all methods
evaluated against ERA5 ground truth. Dashed horizontal lines show the skill of climatology for
reference. (b) Percentage change in global mean with respect to probabilistic climatology with
error bars showing 95% bootstrapped confidence interval over the range of evaluation dates.
cast skill. Note that S2S time-scales are notoriously challenging for both physics-based
and data-driven weather models, and the current state of the art for AI S2S weather mod-
els is parity with, or at best marginal improvements upon, the ECMWF ensemble fore-
casts (L. Chen et al., 2024; Weyn et al., 2024; Lang et al., 2024). We hope that future
refinements to the long-range distillation approach outlined here could eventually yield
more substantial improvements in S2S forecasting.
The primary opportunity we see for improving the performance of long-range dis-
tilled models is by leveraging the rapid recent advances in coupled autoregressive Earth
System Models. One benefit of our distillation approach, is that it can be readily applied
to any autoregressive model, allowing us to bootstrap future refinements to the autore-
gressive teacher model into improved distilled models. While the version of DLESyM used
in this study generates realistic interrannual and intraseasonal variability (Cresswell-Clay
et al., 2025), it simulates only 8 atmospheric variables and only a single ocean variable.
It is thus likely that the synthetic climate our distilled models were trained on here does
not fully capture important modes of S2S and seasonal variability in the real world such
as the Madden-Julian Oscillation and ENSO, indeed the ENSO amplitude was observed
to be weak compared to observations (Cresswell-Clay et al., 2025). As increasingly so-
phisticated autoregressive Earth System Models emerge, we anticipate that applying our
framework to models such as SamudrACE (Duncan et al., 2025; Watt-Meyer et al., 2025;
Dheeshjith et al., 2025), NeuralGCM (Kochkov et al., 2024), and forthcoming enhance-
ments to DLESyM could further improve the forecast skill of long-range distilled mod-
els. By proposing training a separate model for long-range forecasting, we highlight that
autoregressive climate emulators can be useful as generators of huge synthetic training
datasets for long-range forecasting even if they are not themselves directly amenable to
ensemble forecasting from reanalysis. Finally, the ERA5 fine-tuning method for distilled
models presented here provides a crucial tool for ensuring the resulting forecast mod-
els are well calibrated against real-world observations while retaining the benefits of pre-
training on multi-centennial simulations.
This study provides the first demonstration that forecast performance can improve
with increasing volumes of AI-generated synthetic training data (Figure 4) and that these
improvements transfer to downstream real-world forecasts after ERA5 fine-tuning (Fig-
ure 9). This suggests a new scaling axis for AI weather models, which have to date only
been scaled in terms of model capacity, whereas results from large language modeling
–20–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
Figure 10. Comparison of the spatial patterns of real-world 4-week forecast skill between
ECMWF and distilled student models for 2 m air temperature. (a) Difference between ECMWF
and 20-year probabilistic climatology CRPS. (b) Same as (a) but for distilled student model. (c)
Difference between distilled student model and ECMWF CRPS. In all panels blue indicates an
improvement in forecast skill and stippling indicates a statistically significant difference between
the skill of the two methods under comparison (Appendix A).
indicate that model capacity and training dataset size should be scaled in tandem (Kaplan
et al., 2020). Here, S2S forecast skill scaled with diminishing returns as dataset size in-
creased, rather than following a power law, but dataset size was varied at fixed model
capacity. Future work could explore whether jointly scaling model capacity and dataset
size, as is done for large language models, yields stronger gains, potentially benefiting
from transformer-based architectures that scale more effectively with large datasets than
the convolutional UNet backbone used here (Kaplan et al., 2020). While this study fo-
cused on long-range forecasting, training on huge synthetic datasets could also improve
short- and medium-range forecasts, either by leveraging existing large ensemble simu-
lations (Mahesh et al., 2025, 2025) or by exploiting the low inference cost of AI mod-
els to generate training data from any teacher model of interest.
By an initial exploration of distilled AI models trained on large volumes of synthetic
data from autoregressive AI weather models, we hope to expand the design space of AI
weather modeling and inspire further exploration of synthetic training data approaches.
Departing from the autoregressive modeling framework opens up a broader range of cli-
–21–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
T able B1. Details about the huge DLESyM ensemble simulation used to generate training
data.
Parameter Value
Model timestep 6 hours
Output frequency saved Daily averages
Data volume 7 TB
Number of stable ensemble members 162
Initialization date range 2008-01-01 to 2016-12-31
Simulation duration 90 years
Spin-up time excluded First 2 years
Training-Validation Split 75% for training, 25% for validation
Hardware run on 96 H100 GPUs
Inference time 4 hours
Simulation throughput 1,100 SYPD per H100
mate informatics and scientific exploration applications beyond forecasting. Brenowitz,
Ge, et al. (2025) showed that training conditional generative models on ERA5 and ICON
simulations outside of an autoregressive framework enabled a diverse range of use cases
including downscaling, channel in-filling, and steerable sampling. While in this study,
our distilled models were tasked with long-range forecasting, one could envisage train-
ing similar conditional models on huge autoregressive AI simulations for other tasks such
as exploring the global drivers of local weather extremes or for conditioning sample gen-
eration on large-scale climate indices or other quantities of interest.
Appendix A Difference in Scores Significance Testing
Throughout this manuscript where we plot maps of differences in scores between
one forecasting model and another, we indicate statistical significance using a paired test
on the difference in similar to that used in Mardani et al. (2025). The purpose of this
test is to test whether observed differences between the time mean scores of two mod-
els are statistically significant given the large day-to-day variability of the atmosphere,
and hence of the scores. In each grid point, we perform a 2-tailed t-test on the differ-
ence between the scores of model A and model B and select grid points that are signif-
icant at the 0.05 level. We finally apply the Benjamini–Hochberg procedure to control
for the false discovery rate from running multiple tests across grid points.
In Figures 7 and 9 we present bar plots of percentage improvement in global mean
scores with respect to probabilistic climatology with error bars. These error bars were
calculated by taking a time-series of percentage improvement, calculating percentage im-
provement at each timestep separately, then using bootstrapping over the time samples
to construct the 95% confidence interval.
Appendix B Hyperparameters
Appendix C Early Exploration of Quantile Regression Approach
In this manuscript we presented results from formulating our distilled student model
as a conditional diffusion model. In early explorations for this project we explored an
alternative approach where we used quantile regression instead of conditional diffusion
for the probabilistic forecasting. The experiments conducted using this method were fo-
–22–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
T able B2. Training configurations for distilled student models.
Parameter DLESyM Training ERA5 Fine-Tuning ERA5 From Scratch
Distilled student architecture Song UNet HPX64 Song UNet HPX64 Song UNet HPX64
Number of parameters 149M 149M 149M
Batch size 64 64 64
Learning rate 10 −4 10−5 10−4
Condition dropout fraction 0.1 0.1 0.1
Optimizer Adam Adam Adam
Number of training steps 156,000 18,750 18,750
Training Time on 16 H100 GPUs 20 hours 2.4 hours 2.4 hours
T able B3. Diffusion sampler settings used for all distilled student forecasts presented in this
study except where stated otherwise.
Parameter Value
σmin 0.002
σmax 200
Training σ distribution Log uniform
Number of sampler steps 18
Schurn 0
Sampler scheme EDM ODE
Classifier-free guidance strength 1.0
Ensemble members 32
–23–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
cused on quickly exploring different methods within our compute budget rather than sys-
tematic ablations. Below we include informal observations and our interpretations from
these explorations in the hope they may benefit future researchers.
C1 Quantile Regression Formulation
To obtain a probabilistic forecast in a single model timestep using quantile regres-
sion, we discretized our forecast into climatological quintile bins from the preceding 20
years and tasked a neural network with directly forecasting the quintile probabilities rather
than generating ensemble member forecasts. We used the same UNet backbone archi-
tecture as was presented in the manuscript but removed the σ level conditioning and used
a cross-entropy loss function to classify which quintile bin the target falls in. These ex-
periments were primarily focused on S2S forecasting.
C2 Findings
Observation 1. Training the quantile regression method on 11,000 years of DLESyM
simulation data for S2S forecasting led to very weak learning, with slowly converging loss
curves even after exploring a wide range of hyperparameters.
Interpretation. S2S forecasting is a challenging task with very limited prediction
skill. The quantile regression framing with a cross-entropy loss function has the seem-
ingly desirable property that a randomly initialized network starts with the same skill
as probabilistic climatology (predicting equal quintile probabilities). However, in a weak
predictability regime like S2S this likely makes it challenging for the network to learn
powerful representations since it gets only very weak signals from the loss function.
Observation 2. Using curriculum learning (Bengio et al., 2009) on lead times by
fine-tuning a network initially trained for 7-day lead time quantile regression on S2S lead
times improves skill beyond training from scratch at S2S. Training on an equal mix of
different lead times achieves a similar effect.
Interpretation. This supports our interpretation of observation 1 that the S2S
forecasting challenge provides too challenging an initial task for the randomly initialized
network to learn meaningful data representations.
Observation 3. Training a S2S quantile regression model from scratch on ERA5
achieves better skill than the mdoel trained on 11,000 years of DLESyM data on with-
held DLESyM data. Further, fine-tuning the DLESyM pre-trained quantile regression
model on ERA5 leads to the same performance as training from scratch on ERA5 but
does not improve over training from scratch.
Interpretation. Training on a smaller dataset allows the network to overfit, with-
out the implicit regularization of training on 11,000 years of simulation. This leads to
some initial skill on the validation set compared to the network trained on 11,000 years
which should be thought of as an almost randomly initialized network due to its weak
learning. But the network quickly overfits and can’t be improved beyond a certain point
using the limited ERA5 dataset. Fine-tuning the DLESyM pre-trained network on ERA5
essentially reverts to training from scratch on ERA5 since the network was unable to learn
meaningful representations on the large DLESyM dataset.
Observation 4. Despite being presented with the same training dataset and task,
conditional diffusion model shows real-world benefit of pre-training on DLESyM and per-
formance scaling with increasing synthetic data.
Interpretation. The diffusion objective allows the network to learn meaningful
data representations even in challenging predictability regimes since it focuses on grad-
ually de-noising corrupted examples from the training set. This pushes the network past
–24–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
the early training problems observed for quantile regression and allows it to properly ex-
ploit the large simulation dataset.
Open Research
Our code for long-range distillation will be released in a public GitHub repository
upon publication. The DLESyM teacher model code used in this manuscript is available
in the NVIDIA Earth2Studio package (NVIDIA, 2025a).
Acknowledgments
S.M. thanks Peter Harrington, David Pruitt, and Nathaniel Cresswell-Clay for dis-
cussions.
–25–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
References
Alet, F., Price, I., El-Kadi, A., Masters, D., Markou, S., Andersson, T. R., . . . others
(2025). Skillful joint probabilistic weather forecasting from marginals. arXiv
preprint arXiv:2506.10772 .
Bengio, Y., Louradour, J., Collobert, R., & Weston, J. (2009). Curriculum learning.
In Proceedings of the 26th annual international conference on machine learning
(pp. 41–48).
Bi, K., Xie, L., Zhang, H., Chen, X., Gu, X., & Tian, Q. (2023). Accurate medium-
range global weather forecasting with 3d neural networks. Nature, 619(7970),
533–538.
Bonev, B., Kurth, T., Mahesh, A., Bisson, M., Kossaifi, J., Kashinath, K.,
. . . Keller, A. (2025). Fourcastnet 3: A geometric approach to prob-
abilistic machine-learning weather forecasting at scale. arXiv preprint
arXiv:2507.12144 .
Brenowitz, N. D., Cohen, Y., Pathak, J., Mahesh, A., Bonev, B., Kurth, T., . . .
Pritchard, M. S. (2025). A practical probabilistic benchmark for ai weather
models. Geophysical Research Letters, 52(7), e2024GL113656.
Brenowitz, N. D., Ge, T., Subramaniam, A., Manshausen, P., Gupta, A., Hall,
D. M., . . . Pritchard, M. S. (2025). Climate in a bottle: Towards a generative
foundation model for the kilometer-scale global atmosphere. arXiv preprint
arXiv:2505.06474 .
Chen, K., Han, T., Gong, J., Bai, L., Ling, F., Luo, J.-J., . . . others (2023). Fengwu:
Pushing the skillful global medium-range weather forecast beyond 10 days
lead. arXiv preprint arXiv:2304.02948 .
Chen, L., Zhong, X., Li, H., Wu, J., Lu, B., Chen, D., . . . others (2024). A ma-
chine learning model that outperforms conventional global subseasonal forecast
models. Nature Communications, 15(1), 6425.
Chen, L., Zhong, X., Zhang, F., Cheng, Y., Xu, Y., Qi, Y., & Li, H. (2023). Fuxi: a
cascade machine learning forecasting system for 15-day global weather forecast.
npj climate and atmospheric science , 6(1), 190.
Cresswell-Clay, N. (2025). personal communication.
Cresswell-Clay, N., Liu, B., Durran, D. R., Liu, Z., Espinosa, Z. I., Moreno, R. A.,
& Karlbauer, M. (2025). A deep learning earth system model for efficient
simulation of the observed climate. AGU Advances, 6(4), e2025AV001706.
Dheeshjith, S., Subel, A., Adcroft, A., Busecke, J., Fernandez-Granda, C., Gupta,
S., & Zanna, L. (2025). Samudra: An ai global ocean emulator for climate.
Geophysical Research Letters, 52(10), e2024GL114318.
Dueben, P. D., & Bauer, P. (2018). Challenges and design choices for global weather
and climate models based on machine learning. Geoscientific Model Develop-
ment, 11(10), 3999–4009.
Duncan, J. P., Wu, E., Dheeshjith, S., Subel, A., Arcomano, T., Clark, S. K., . . .
others (2025). Samudrace: Fast and accurate coupled climate modeling with
3d ocean and atmosphere emulators. arXiv preprint arXiv:2509.12490 .
Hersbach, H. (2000). Decomposition of the continuous ranked probability score for
ensemble prediction systems. Weather and Forecasting, 15(5), 559–570.
Hersbach, H., Bell, B., Berrisford, P., Hirahara, S., Hor´ anyi, A., Mu˜ noz-Sabater, J.,
. . . others (2020). The era5 global reanalysis. Quarterly journal of the royal
meteorological society, 146(730), 1999–2049.
Ho, J., & Salimans, T. (2022). Classifier-free diffusion guidance. arXiv preprint
arXiv:2207.12598 .
Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., . . .
Amodei, D. (2020). Scaling laws for neural language models. arXiv preprint
arXiv:2001.08361 .
Karlbauer, M., Cresswell-Clay, N., Durran, D. R., Moreno, R. A., Kurth, T., Bonev,
B., . . . Butz, M. V. (2024). Advancing parsimonious deep learning weather
–26–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
prediction using the healpix mesh. Journal of Advances in Modeling Earth
Systems, 16(8), e2023MS004021.
Karras, T., Aittala, M., Aila, T., & Laine, S. (2022). Elucidating the design space
of diffusion-based generative models. Advances in neural information process-
ing systems , 35, 26565–26577.
Keisler, R. (2022). Forecasting global weather with graph neural networks. arXiv
preprint arXiv:2202.07575 .
Kochkov, D., Yuval, J., Langmore, I., Norgaard, P., Smith, J., Mooers, G., . . . oth-
ers (2024). Neural general circulation models for weather and climate. Nature,
632(8027), 1060–1066.
Lam, R., Sanchez-Gonzalez, A., Willson, M., Wirnsberger, P., Fortunato, M., Alet,
F., . . . others (2023). Learning skillful medium-range global weather forecast-
ing. Science, 382(6677), 1416–1421.
Lang, S., Alexe, M., Clare, M. C., Roberts, C., Adewoyin, R., Bouall` egue, Z. B., . . .
others (2024). Aifs-crps: ensemble forecasting using a model trained with a
loss function based on the continuous ranked probability score. arXiv preprint
arXiv:2412.15832 .
Leutbecher, M., & Palmer, T. N. (2008). Ensemble forecasting. Journal of computa-
tional physics , 227(7), 3515–3539.
Mahesh, A., Collins, W. D., Bonev, B., Brenowitz, N., Cohen, Y., Elms, J., . . .
Willard, J. (2025). Huge ensembles – part 1: Design of ensemble weather
forecasts using spherical fourier neural operators. Geoscientific Model Devel-
opment, 18(17), 5575–5603. Retrieved from https://gmd.copernicus.org/
articles/18/5575/2025/ doi: 10.5194/gmd-18-5575-2025
Mahesh, A., Collins, W. D., Bonev, B., Brenowitz, N., Cohen, Y., Harrington,
P., . . . Willard, J. (2025). Huge ensembles – part 2: Properties of a
huge ensemble of hindcasts generated with spherical fourier neural oper-
ators. Geoscientific Model Development , 18(17), 5605–5633. Retrieved
from https://gmd.copernicus.org/articles/18/5605/2025/ doi:
10.5194/gmd-18-5605-2025
Mardani, M., Brenowitz, N., Cohen, Y., Pathak, J., Chen, C.-Y., Liu, C.-C., . . . oth-
ers (2025). Residual corrective diffusion modeling for km-scale atmospheric
downscaling. Communications Earth & Environment , 6(1), 124.
Nguyen, T., Shah, R., Bansal, H., Arcomano, T., Maulik, R., Kotamarthi, R., . . .
Grover, A. (2024). Scaling transformer neural networks for skillful and reliable
medium-range weather forecasting. Advances in Neural Information Processing
Systems, 37, 68740–68771.
NVIDIA. (2025a). Earth2Studio. https://github.com/NVIDIA/earth2studio/
tree/0.8.0. (Accessed: 2025-06-20)
NVIDIA. (2025b). Earth2Studio Gaussian Initial Condition Pertur-
bation Code. https://github.com/NVIDIA/earth2studio/blob/
b40c253a9bc903d6f7cabe835be9a75024dfa48b/earth2studio/
perturbation/gaussian.py. (Accessed: 2025-06-20)
NVIDIA. (2025c). PhysicsNeMo Checkpoints: DLESyM-V1-ERA5. https://
catalog.ngc.nvidia.com/orgs/nvidia/teams/earth-2/models/dlesym-v1
-era5?version=1.0.1. (Accessed: 2025-06-20)
Pathak, J., Subramanian, S., Harrington, P., Raja, S., Chattopadhyay, A., Mardani,
M., . . . others (2022). Fourcastnet: A global data-driven high-resolution
weather model using adaptive fourier neural operators. arXiv preprint
arXiv:2202.11214 .
Price, I., Sanchez-Gonzalez, A., Alet, F., Andersson, T. R., El-Kadi, A., Masters, D.,
. . . others (2025). Probabilistic weather forecasting with machine learning.
Nature, 637(8044), 84–90.
Rasp, S., Hoyer, S., Merose, A., Langmore, I., Battaglia, P., Russell, T., . . . others
(2024). Weatherbench 2: A benchmark for the next generation of data-driven
–27–
manuscript submitted to Journal of Advances in Modeling Earth Systems (JAMES)
global weather models. Journal of Advances in Modeling Earth Systems , 16(6),
e2023MS004019.
Rasp, S., & Thuerey, N. (2021). Data-driven medium-range weather prediction with
a resnet pretrained on climate simulations: A new model for weatherbench.
Journal of Advances in Modeling Earth Systems , 13(2), e2020MS002405.
Selz, T., & Craig, G. C. (2023). Can artificial intelligence-based weather prediction
models simulate the butterfly effect? Geophysical Research Letters, 50(20),
e2023GL105747.
Sønderby, C. K., Espeholt, L., Heek, J., Dehghani, M., Oliver, A., Salimans, T., . . .
Kalchbrenner, N. (2020). Metnet: A neural weather model for precipitation
forecasting. arXiv preprint arXiv:2003.12140 .
Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B.
(2020). Score-based generative modeling through stochastic differential equa-
tions. arXiv preprint arXiv:2011.13456 .
Toth, Z., & Kalnay, E. (1993). Ensemble forecasting at nmc: The generation of
perturbations. Bulletin of the american meteorological society , 74(12), 2317–
2330.
Vitart, F. (2004). Monthly forecasting at ecmwf. Monthly Weather Review , 132(12),
2761–2779.
Vitart, F., Ardilouze, C., Bonet, A., Brookshaw, A., Chen, M., Codorean, C., . . .
others (2017). The subseasonal to seasonal (s2s) prediction project database.
Bulletin of the American Meteorological Society , 98(1), 163–173.
Watt-Meyer, O., Henn, B., McGibbon, J., Clark, S. K., Kwa, A., Perkins, W. A., . . .
Bretherton, C. S. (2025). Ace2: accurately learning subseasonal to decadal
atmospheric variability and forced responses. npj Climate and Atmospheric
Science, 8(1), 205.
Weigel, A. P., Baggenstos, D., Liniger, M. A., Vitart, F., & Appenzeller, C. (2008).
Probabilistic verification of monthly temperature forecasts. Monthly Weather
Review, 136(12), 5162–5182.
Weyn, J. A., Durran, D. R., & Caruana, R. (2019). Can machines learn to predict
weather? using deep learning to predict gridded 500-hpa geopotential height
from historical weather data. Journal of Advances in Modeling Earth Systems ,
11(8), 2680–2693.
Weyn, J. A., Durran, D. R., & Caruana, R. (2020). Improving data-driven
global weather prediction using deep convolutional neural networks on a
cubed sphere. Journal of Advances in Modeling Earth Systems , 12(9),
e2020MS002109.
Weyn, J. A., Durran, D. R., Caruana, R., & Cresswell-Clay, N. (2021). Sub-seasonal
forecasting with a large ensemble of deep-learning weather prediction models.
Journal of Advances in Modeling Earth Systems , 13(7), e2021MS002502.
Weyn, J. A., Kumar, D., Berman, J., Kazmi, N., Klocek, S., Luferenko, P., & Tham-
biratnam, K. (2024). An ensemble of data-driven weather prediction models
for operational sub-seasonal forecasting. arXiv preprint arXiv:2403.15598 .
–28–