OmniCast: A Masked Latent Diffusion Model for
Weather Forecasting Across Time Scales
Tung Nguyen1 Tuan Pham2 Troy Arcomano3,4 V eerabhadra Kotamarthi3
Ian Foster3 Sandeep Madireddy3 Aditya Grover1
1UCLA 2UCI 3Argonne National Laboratory 4Allen Institute for AI
Abstract
Accurate weather forecasting across time scales is critical for anticipating and
mitigating the impacts of climate change. Recent data-driven methods based on
deep learning have achieved signiﬁcant success in the medium range, but struggle
at longer subseasonal-to-seasonal (S2S) horizons due to error accumulation in
their autoregressive approach. In this work, we propose OmniCast, a scalable
and skillful probabilistic model that uniﬁes weather forecasting across timescales.
OmniCast consists of two components, a V AE model that encodes raw weather
data into a continuous, lower-dimensional latent space, and a diffusion-based
transformer model that generates a sequence of future latent tokens given the initial
conditioning tokens. During training, we mask random future tokens and train
the transformer to estimate their distribution given conditioning and visible tokens
using a per-token diffusion head. During inference, the transformer generates the
full sequence of future tokens by iteratively unmasking random subsets of tokens.
This joint sampling across space and time mitigates compounding errors from
autoregressive approaches. The low-dimensional latent space enables modeling
long sequences of future latent states, allowing the transformer to learn weather
dynamics beyond initial conditions. OmniCast performs competitively with leading
probabilistic methods at the medium-range timescale while being 10 → to 20 →
faster, and achieves state-of-the-art performance at the subseasonal-to-seasonal
scale across accuracy, physics-based, and probabilistic metrics. Furthermore, we
demonstrate that OmniCast can generate stable rollouts up to 100 years ahead.
Code and model checkpoints are available at https://github.com/tung-nd/omnicast.
1 Introduction
Accurate weather forecasting across time scales is essential for anticipating extreme events, managing
resources, and mitigating the impacts of climate change. While medium-range forecasting, which
encompasses predictions up to approximately two weeks, has seen remarkable progress with both
numerical and data-driven approaches, extending prediction skill beyond this horizon remains a
signiﬁcant challenge. Subseasonal-to-seasonal (S2S) forecasting, which aims to predict atmospheric
conditions from two to six weeks ahead, represents this next frontier. This timescale bridges the gap
between short-term weather forecasts and longer-term climate projections, enabling more informed
decision-making for extreme weather events such as droughts, ﬂoods, and heatwaves [ 51, 36, 52, 8].
S2S prediction is particularly challenging due to the interplay between atmospheric initial conditions,
essential for short-term and medium-range forecasting, and boundary conditions dominating seasonal
and climate predictions [ 27, 28]. Traditional numerical weather prediction (NWP) models, built
upon solving differential equations of ﬂuid dynamics and thermodynamics, have been instrumental
in advancing S2S weather prediction [ 36, 47, 48]. However, numerical methods incur substantial
computational costs due to the complexity of integrating large systems of differential equations,
39th Conference on Neural Information Processing Systems (NeurIPS 2025).
arXiv:2510.18707v1  [cs.LG]  20 Oct 2025
particularly at ﬁne spatial and temporal resolutions. This computational bottleneck also constrains
the ensemble size of ensemble systems, which is crucial for achieving accurate S2S predictions.
To overcome the challenges of NWP systems, there has been a growing interest in data-driven
approaches based on deep learning for weather forecasting [ 10, 43, 50]. These approaches involve
training deep neural networks on historical datasets, such as ERA5 [ 14, 15, 39, 40], to learn the
underlying weather patterns. Once trained, they can produce forecasts in seconds compared to
the hours required by NWP models. Recent deep learning methods such as PanguWeather [ 2],
Graphcast [ 22], and Stormer [ 33] have also shown superior accuracy in medium-range weather
forecasting, surpassing operational IFS [ 49], the state-of-the-art NWP system. However, their
application to the S2S timescale has been limited [ 31]. One possible explanation for this limitation is
the rapid error compounding in their autoregressive designs, in which a model learns to forecast the
future weather state at a small interval and iteratively feeds its prediction back as input to achieve
longer-horizon forecasts. Even though previous works have proposed multi-step ﬁnetuning to mitigate
this issue, back-propagation through a large number of forward passes required for S2S timescales
is computationally prohibitive. Moreover, training a neural network to forecast at a small interval
only allows the model to learn the initial conditions problem, ignoring boundary conditions that are
critical for prediction at S2S timescales.
In this work, we propose OmniCast, a novel latent diffusion model for skillful probabilistic weather
forecasting across time scales. OmniCast follows a two-stage training process. In the ﬁrst stage,
we train a V AE model [19] that compresses raw weather data into a continuous, lower-dimensional
latent space. In the second stage, we train a transformer to model the distribution of a sequence of
future latent tokens given the initial conditioning tokens using a masked generative framework [ 3, 55].
Speciﬁcally, during training, we randomly mask a subset of future tokens, and task the transformer
to unmask these tokens based on the conditioning tokens and the visible tokens. Since the latent
tokens lie in a continuous space, we use a small diffusion network on top of the transformer model to
estimate the per-token distribution of unmasked tokens. In addition to the diffusion loss, we apply a
mean-squared error (MSE) objective to enforce the model to accurately predict the ﬁrst few latent
frames deterministically. After training, OmniCast generates forecasts for the full sequence of future
tokens through an iterative process. In each iteration, the model selects a subset of future tokens
to unmask given the conditioning tokens and previously unmasked tokens, continuing this process
until all future tokens are generated. The unmasking operation involves sampling from the diffusion
model, with the number and positions of tokens selected to unmask in each iteration determined by a
predeﬁned schedule and unmasking order. This joint generation of future tokens across time and space
signiﬁcantly mitigates the compounding errors issue of an autoregressive approach. Furthermore,
training on the full sequence of future frames enables OmniCast to address both initial condition
problems and boundary condition challenges, which are critical for S2S prediction.
We evaluate OmniCast on ChaosBench [ 31], a recent benchmark for subseasonal-to-seasonal predic-
tion. OmniCast achieves state-of-the-art performance on key atmospheric variables across various
accuracy, physics-based, and probabilistic metrics. Additionally, we carefully study the impact of
different design choices, including the auxiliary MSE loss, training sequence lengths, unmasking
order, and diffusion sampling temperature, on the forecasting performance of OmniCast.
2 Related Work
Data-driven weather forecasting Deep learning has become a promising approach in the ﬁeld of
weather forecasting. Recent advancements with powerful architectures have achieved signiﬁcant
successes, providing faster inference and superior forecasting accuracy compared to IFS, the gold-
standard numerical weather prediction system. Notable methods include FourCastNet [ 35], which
utilizes an adaptive neural operator architecture; Keisler [17]’s, GraphCast [ 22], and AIFS [ 24],
which leverage graph neural networks; and a series of transformer-based models such as Pan-
guWeather [2], Stormer [ 33], and others [ 32, 6, 4, 7]. Beyond deterministic predictions, the ﬁeld has
increasingly focused on probabilistic forecasting to better account for forecast uncertainty. Common
approaches involve integrating existing architectures with generative frameworks, including diffusion
models [37, 30], normalizing ﬂows [ 7], and latent variable models [ 34]. Others explore ensemble
predictions through initial condition perturbations, exempliﬁed by methods like AIFS-CRPS [ 24] and
NeuralGCM [20].
2
Data-driven S2S prediction Recent benchmarks have emerged to evaluate data-driven methods at
S2S timescales. While many focus on regional forecasts such as the US [ 16, 29], ChaosBench [31]
offers a comprehensive framework for global S2S prediction, providing extensive numerical baselines
and physics-based metrics. A key ﬁnding from ChaosBench shows that state-of-the-art deep learning
methods struggle to extend to S2S timescales. These methods predominantly rely on autoregressive
approaches that generate predictions iteratively at short time intervals, leading to error accumulation
with increasing lead times. While multi-step ﬁnetuning helps mitigate this issue for medium-range
forecasts, it becomes computationally prohibitive for S2S predictions due to the extensive number
of required forward passes. Moreover, training models with short time intervals fails to capture
boundary conditions essential for long-term weather patterns. While Fuxi-S2S [ 5] was proposed for
S2S prediction, it focuses on forecasting daily averaged statistics, which fundamentally alters the
underlying weather dynamics and makes it inapplicable to forecasting at instantaneous time steps.
3 Background and Preliminaries
3.1 Weather forecasting
The goal of weather forecasting is to forecast future weather conditions XT ↑ RV →H→W based on
initial conditions X0 ↑ RV →H→W , where T represents the target lead time, V denotes the number of
input and output physical variables (e.g., temperature and geopotential), and H → W corresponds
to the spatial resolution of the data, determined by the density of the global grid. In subseasonal-
to-seasonal (S2S) forecasting, we focus on lead times ranging from 2 to 6 weeks. Autoregressive
modeling is a dominant paradigm in data-driven weather forecasting, where a model iteratively
produces forecasts Xωt at a short interval ωt to reach the target lead time T . In this work, we propose
an alternative approach: training a generative model to estimate the distribution of the entire sequence
of future weather states X1:T given initial conditions X0. This approach mitigates error accumulation
and enables the model to learn both initial and boundary condition dynamics by considering the
complete sequence of weather states.
3.2 Masked generative modeling
Masked generative modeling is an efﬁcient and powerful approach for image and video generation in
computer vision [3, 55, 25]. In this framework, visual data X1:T ↑ RT →V →H→W (T =1 for images)
is ﬁrst embedded by a V AE encoder into a sequence of tokens x ↑ RN →D , where N represents
the length of the ﬂattened token sequence. During training, we apply a binary mask to randomly
select a subset of tokens to be predicted, creating a corrupted sequence. We then train a transformer
model to recover the original tokens at masked positions based on both the visible tokens and any
additional conditioning information such as initial frames. For generation, the framework employs an
iterative decoding process that starts with a fully masked sequence of future tokens. In each iteration,
the model predicts a random subset of masked tokens in parallel, where the number and positions
of the unmasked tokens follow a predeﬁned schedule and order. This process continues until all
tokens are unmasked, at which point the generated tokens are decoded back to the original domain
through a V AE decoder. This framework offers key advantages for weather forecasting: it allows
the model to capture long-range dependencies across the entire sequence while avoiding the error
accumulation typical in autoregressive approaches, and the iterative reﬁnement process enables the
model to maintain consistency across both spatial and temporal dimensions.
3.3 Modeling continuous tokens with diffusion models
In the masked generative modeling framework, a common practice is to embed the raw visual data into
a discrete latent space and train the transformer model using a cross-entropy objective. However, this
approach relies on vector-quantized V AE models [45], which are sensitive to gradient approximation
strategies [41, 38, 21] and typically achieve lower reconstruction quality than continuous-valued
V AEs. Recent works [44, 26] have demonstrated that discretization can be eliminated by directly
modeling the per-token probability distribution in a continuous latent space. In this work, we adopt
diffusion models for continuous distribution modeling.
Given data x ↑ RD and its conditioning information z ↑ RD , we model the conditional distribution
p(x | z) using a diffusion process that gradually transforms a Gaussian prior into the target distribution.
3
Transformer backbone
Figure 1: OmniCast processes the latent tokens through a trans-
former backbone that outputs a vector zi for each position i in
the sequence.
Figure 2: The denoising network
eε predicts the noise ε from zi and
xs
i .
Figure 3: The deterministic net-
work predicts directly xi from zi.
The forward diffusion process progressively adds Gaussian noise to the data x following:
xs = ↓ ϑ sx +
↓
1 ↔ ϑ sε, (1)
where s indicates the diffusion step, ϑ s determines the noise schedule, and ε ↗N (0, I) represents
Gaussian noise. The reverse process employs a denoising network εε (xs,s ,z ) parameterized by ϖ to
predict the noise component from the noisy input xs and condition z:
Ldiff(ϖ)= Eϑ,x
[
↘εε (xs,s ,z ) ↔ ε↘2]
. (2)
At inference time, conditional sampling begins with a random Gaussian noise xS ↗N (0, I) and
iteratively applies the reverse diffusion process:
xs↑1 = 1↓ ϑ s
(
xs ↔ 1 ↔ ϑ s↓ 1 ↔ ¯ϑ s
εε (xs,s ,z )
)
+ ϱς sω, (3)
where ¯ϑ s = ∏s
k=1 ϑ k, ω ↗N (0, I) and ςs controls the magnitude of noise added at each step. This
iterative process generates samples from the learned conditional distribution pε (x | z). Following [26],
we additionally scale the noise ςsω by the temperature ϱ that controls the sample diversity from the
diffusion model.
4 Methodology
We present OmniCast, a novel method for subseasonal-to-seasonal prediction. Similar to previous
works in video generation, OmniCast consists of two components: a V AE model that compresses the
raw weather data into a lower-dimensional space, and a masked generative transformer model in this
latent space. We present the two components and their key design choices in this section.
4.1 V AE for weather data embedding
A V AE encoder embeds a weather state X ↑ RV →H→W into a map of h → w latent tokens, where
h<H and w<W . In vector-quantized V AEs, each entry in the latent map is an integer index from a
ﬁxed-size vocabulary, representing a discrete latent space. While this discretization is widely adopted
in computer vision due to its compatibility with cross-entropy training and straightforward sampling
from softmax distributions, it presents signiﬁcant challenges for weather data. Unlike RGB images
with three channels, weather states can contain hundreds of physical variables, resulting in an extreme
compression requirement. For instance, consider compressing weather data with 100 variables (32 bits
per value) by a factor of 4 in each spatial dimension, using a vocabulary size of 213 = 8192 (13 bits
per latent token). This results in a compression ratio of (32→100→H →W )/(13→(H/4)→(W/4)) ≃
3938. Such aggressive compression leads to substantial reconstruction errors, ultimately degrading
the performance of the second-stage generative modeling.
Therefore, we adopt a continuous V AE model for OmniCast, where each token in the h→ w latent map
is a continuous vector of D dimensions. With D = 16, for example, the compression ratio becomes
(32 → 100 → H → W )/(32 → 16 → (H/4) → (W/4)) = 100 , substantially lower than the discrete
approach. While it is also possible to compress a sequence of weather states X1:T ↑ RT →V →H→W in
both temporal and spatial dimensions, our preliminary experiments showed no clear beneﬁts from
temporal compression, leading us to adopt per-frame embedding.
4
4.2 Masked generative modeling for S2S prediction
After training the V AE, we embed the initial condition into a sequence of tokens c =
(c1,c 2,...,c h→w). Similarly, each future weather state is embedded into a sequence of tokens,
which are concatenated to form the complete sequence of future tokens x =( x1,x 2,...,x N ), where
N = T → h → w represents the total number of future tokens. Each latent token is a continuous
vector of dimension D. Our generative modeling objective is to estimate the conditional distribution
p(x | c) from the training data.
We achieve this using a masked generative framework, as illustrated in Figure 1. During training,
we sample a binary mask m =[ mi]N
i=1 ↗ pU and replace tokens xi with a learnable, continuous
[MASK] token where mi =1 , creating a corrupted sequence x = m(x). The generative objective is
to estimate the distribution of masked tokens conditioned on the visible and conditioning tokens:
Lgen(ϖ)= E
m↓pU
[ ∑
i s.t. mi =1
↔ log pε (xi | c, x)
]
. (4)
The model processes the input by concatenating the conditioning tokens c with the corrupted future
tokens x, adding positional encodings to the embedded sequence, and passing it through a bi-
directional transformer backbone to obtain vectors zi for each masked position. Given these vectors,
the per-token objective log pε (xi | c, x) in Equation 4 simpliﬁes to log pε (xi | zi). To model this
continuous distribution, we employ a diffusion model where zi serves as conditional information
for a denoising network – implemented as a small MLP on top of the transformer (Figure 2). We
train the denoising network and the transformer backbone jointly using the diffusion loss speciﬁed in
Equation 2. Conceptually, this diffusion objective encourages the model to produce representations
zi that facilitate effective denoising.
Auxiliary deterministic objective To encourage accurate predictions of near-term future tokens,
we incorporate an auxiliary mean-squared error loss in the latent space. We implement this through
a separate MLP head that produces deterministic predictions ˆxi from zi, training it jointly with the
transformer backbone. Since weather dynamics become increasingly chaotic beyond day 10, making
deterministic predictions progressively less meaningful, we apply this loss only to the ﬁrst 10 future
frames. Furthermore, we employ an exponentially decreasing weighting scheme to emphasize the
importance of accurate predictions for earlier frames. The deterministic objective is thus:
Ldeter(ω)= E
m→pU
[ ∑
mi =1
w(i)||xi → ˆxi||2
2
]
. (5)
Appendix A.2 presents the details of this objective. The complete training objective combines both
losses: L(ϖ)= Lgen(ϖ)+ Ldeter(ϖ).
Sampling from OmniCast At inference time, we generate samples from p(x | c) through an iterative
decoding process, starting from a sequence of fully masked future tokens. Each iteration consists
of three steps: ﬁrst, the transformer backbone processes the conditioning tokens and corrupted
future tokens to produce vectors zi for each masked position; second, a subset of masked positions
is randomly selected according to a predeﬁned schedule for unmasking; third, for each selected
position, the diffusion model generates token xi by conditioning on zi and performing a ﬁxed number
of diffusion steps. This process iterates until all future tokens are revealed, at which point the
V AE decoder maps the generated tokens back to the weather domain. To generate an ensemble of
forecasts, we simply replicate the initial tokens and perform independent sampling for each copy. Four
hyperparameters affect the sampling procedure: the number of unmasking iterations, the unmasking
order, the number of diffusion steps, and the diffusion temperature.
4.3 Implementation details
Architectural details For the transformer backbone, we adopt the encoder-decoder architecture
from Masked Autoencoder (MAE) [ 13]. The model processes an input sequence in two stages:
ﬁrst, the encoder processes the conditioning and visible tokens; second, the encoded sequence is
augmented with learnable [MASK] tokens at appropriate positions and passed through the decoder
to produce zi for each position i. Both the encoder and decoder are bidirectional, employing full
attention. Before feeding to either the encoder or decoder, we add the input sequences with positional
5
embeddings that combine two components: temporal embeddings to distinguish different frames, and
spatial embeddings to differentiate tokens within each frame. The encoder and decoder follow the
Transformer [46] implementation in ViT [ 9], each having 16 layers with 16 attention heads, a hidden
dimension of 1024, and a dropout rate of 0.1.
Mask sampling During training, we sample a masking ratio φ ↗U [0.5, 1.0] and generate a
corresponding binary mask m, where φ =0 .75 indicates that 75% of entries in m are 1. For
inference, we start with full masking ( φ =1 .0) and gradually reduce it to 0.0 following a cosine
schedule [3]. We set the number of unmasking iterations to match the number of future weather states
T by default. We employ random masking orders across both spatial and temporal dimensions for
training and inference.
Diffusion loss details We use a linear noise schedule with 1000 steps at training time that are
resampled to 100 steps at inference. The denoising network εε is implemented as a small MLP
following Li et al. [26]. Speciﬁcally, the network consists of six residual blocks, each comprising a
LayerNorm (LN), a linear layer, a SiLU activation, and another linear layer, with a residual connection
around the block. Each block maintains a width of 2048 channels. The network takes the vector zi
from the transformer as conditioning information, which is combined with the time embedding of the
diffusion step s through adaptive layer normalization (AdaLN) in each block’s LN layers.
5 Experiments
We compare OmniCast with state-of-the-art deep learning and numerical methods on both medium-
range and S2S time scales, using WeatherBench2 [ 40] (WB2) and ChaosBench [ 31] as benchmarks,
respectively, and conduct extensive ablation studies to assess the contribution of each component in
OmniCast. We further test the stability of OmniCast up to 100 years ahead in Appendix B.5.
Across both tasks, we train and evaluate OmniCast on 69 variables from the ERA5 reanalysis
dataset [15], including four surface-level variables – 2-meter temperature (T2m), 10-meter U and
V wind components (U10, V10), and mean sea-level pressure (MSLP), as well as ﬁve atmospheric
variables – geopotential (Z), temperature (T), U and V wind components, and speciﬁc humidity (Q),
each at 13 pressure levels {50, 100, 150, 200, 250, 300, 400, 500, 600, 700, 850, 925, 1000} hPa.
For medium-range forecasting, we use native 0.25↔ resolution (721 → 1440 grids) and follow WB2
to train on years 1979–2018, validate on 2019, and test on 2020 using initial conditions at 00UTC
and 12UTC. For S2S prediction, we downsample the data to 1.40625↔ (128 → 256 grids) and follow
ChaosBench to train on 1979–2020, validate on 2021, and test on 2022 using 00UTC initializations.
5.1 OmniCast for S2S prediction
Training and inference details We train a V AE that embeds each weather state of shape 69 →
128 → 256 into a latent map of shape 1024 → 8 → 16, reducing spatial dimensions by a factor of
16. The architectural details and training process of the V AE are described in Appendix A.1. We
train OmniCast to forecast a sequence of T = 44 future weather states at 24hr intervals, covering
lead times from 1 to 44 days. Each training example consists of 45 → 8 → 16 = 5760 latent tokens,
including the initial condition. During inference, we generate the complete future sequence in 44
iterations (1 iteration per frame) using a diffusion temperature of ϱ =1 .3. We produce an ensemble
of 50 forecast sequences for each initial condition.
Baselines We compare OmniCast with PanguWeather (PW) [2] and GraphCast (GC) [22], two leading
open-sourced deep learning methods, and ensemble systems of four numerical models from different
national agencies: UKMO-ENS (UK) [ 53], NCEP-ENS (US) [ 42], CMA-ENS (China) [ 54], and
ECMWF-ENS (Europe) [11]. We refer to ChaosBench for details about these baselines. Following
ChaosBench, we report results on T850, Z500, and Q700 at lead times from 1 to 44 days. We
additionally compare OmniCast with ClimaX [ 32] and Stormer [ 33] in Appendix B.2. We do not
compare against Fuxi-S2S [ 5] as Fuxi-S2S forecasts daily average values from past daily averages,
making it incomparable with OmniCast and the rest of the methods, which perform point-in-time
weather forecasting based on an initial condition. We are also not able to run Gencast [ 37] and
NeuralGCM [20] for S2S due to their signiﬁcant computational demands.
Results Figure 4 compares different methods on three deterministic metrics: Root Mean-Squared
Error (RMSE), Absolute Bias (ABS BIAS), and Multi-scale Structural Similarity (SSIM). At shorter
6
Figure 4: Deterministic performance of different methods at lead times from 1 to 44 days across three
key variables. Solid curves are deep learning methods and dashed curves are numerical methods.
Figure 5: Physics-based metrics of different methods at lead times from 1 to 44 days across three key
variables. Solid curves are deep learning methods and dashed curves are numerical methods.
lead times, OmniCast shows slightly worse performance on RMSE and SSIM than other baselines,
which is expected since we train OmniCast to model a full sequence of future weather states rather
than optimizing for short- and medium-range predictions. However, OmniCast’s relative performance
improves with increasing lead time, ultimately matching ECMWF-ENS as one of the top two
performing methods beyond day 10. Notably, OmniCast demonstrates the lowest bias among all
baselines, maintaining near-zero bias across all three target variables.
Physical consistency also plays a crucial role in S2S prediction, particularly for ensemble systems.
We evaluate this aspect using two physics-based metrics: Spectral Divergence (SDIV) and Spectral
Residual (SRES), which measure how closely the power spectra of predictions match those of
ground-truths. As shown in Figure 5, OmniCast achieves substantially better physical consistency
than other deep learning methods, and often outperforms all baselines on these metrics. These results
demonstrate how OmniCast effectively preserves signals across the frequency spectrum.
7
Figure 6: Probabilistic performance of different methods at lead times from 1 to 44 days across three
key variables. Solid curves are deep learning methods and dashed curves are numerical methods.
Finally, we compare OmniCast with the four numerical ensemble systems on two probabilistic metrics:
Continuous Ranked Probability Score (CRPS) and Spread/Skill Ratio (SSR) (closer to 1 is better).
Figure 6 shows that OmniCast and ECMWF-ENS are the two leading methods across variables and
lead times. Similar to deterministic results, OmniCast performs worse than ECMWF-ENS at shorter
lead times but outperforms this baseline beyond day 15.
5.2 OmniCast for medium-range forecasting
Figure 7: Probabilistic performance of different methods in medium-range forecasting. Solid curves
are deep learning methods and dashed curves are numerical methods.
In addition to its strong performance on the S2S task, we demonstrate that OmniCast also performs
competitively at the medium-range timescale. We train a V AE model with a spatial downsampling
ratio of 16, compressing each weather state of shape 69 → 721 → 1440 into a latent representation of
size 256 → 45 → 90. We then train OmniCast to predict two steps ahead at 12-hour intervals, following
8
the setup of Gencast [ 37]. During inference, we use autoregressive sampling, recursively feeding
the most recent predicted frame as the new initial condition until the target lead time is reached. We
generate forecasts using a single sampling iteration per frame with a diffusion temperature ϱ =1 .0,
and produce an ensemble of 50 members.
We compare OmniCast against Gencast [ 37], a leading deep learning method for probabilistic fore-
casting, and IFS-ENS [23], the gold-standard numerical ensemble system. Following WeatherBench2,
we use ensemble RMSE, CRPS, and spread-skill ratio (SSR) as evaluation metrics. As shown in
Figure 7, OmniCast performs comparably with IFS-ENS across all variables and metrics, and is only
slightly behind Gencast. These results indicate that OmniCast achieves strong performance across
both medium-range and S2S timescales.
5.3 Efﬁciency of OmniCast
Figure 8: Runtime vs resolution to produce a 15-day forecast.
Beyond its strong empirical perfor-
mance, OmniCast offers substantial
efﬁciency gains over existing meth-
ods. We trained OmniCast for 4 days
using 32 NVIDIA A100 GPUs. In
comparison, Gencast requires 5 days
of training on 32 TPUv5e devices –
hardware signiﬁcantly more powerful
than A100s, and NeuralGCM [ 20] re-
quires 10 days on 128 TPUv5e de-
vices. Additionally, Gencast employs
a two-stage training pipeline, ﬁrst pre-
training on 1.0↔ resolution and then
ﬁnetuning on 0.25↔, while we trained
OmniCast in a single stage.
At inference time, OmniCast is orders of magnitude faster than Gencast, NeuralGCM, and IFS-ENS.
Figure 8 compares the runtime (in seconds) required to generate a 15-day forecast across different
resolutions. At 0.25↔ resolution, Gencast requires 480 seconds on TPUv5, whereas OmniCast
achieves the same forecast in just 29 seconds on an A100. At 1.0↔, OmniCast completes inference in
only 11 seconds, compared to 224 seconds for Gencast on the same hardware. These results highlight
the scalability and practicality of OmniCast for operational forecasting.
The efﬁciency of OmniCast stems from two key architectural innovations. First, OmniCast operates in
a much lower-dimensional latent space ( 45 → 90 latent grid vs 721 → 1440 original grid), signiﬁcantly
reducing the computational cost of training and inference. Second, OmniCast employs a highly
efﬁcient sampling mechanism. Unlike Gencast, which performs 50 full forward passes through
the entire network for 50 diffusion steps, OmniCast requires only a single forward pass through
the transformer backbone. The subsequent diffusion steps involve only lightweight forward passes
through a compact MLP diffusion head, resulting in orders-of-magnitude lower inference time.
Together, these design choices enable OmniCast to deliver fast and scalable forecasts.
5.4 Ablation studies
We analyze four key factors that inﬂuence OmniCast’s performance: the auxiliary deterministic
objective, training sequence length T , unmasking order during sampling, and diffusion sampling
temperature ϱ. We present results for T850 on RMSE, CRPS, and SSR. We additionally study the
impact of IC perturbations in Appendix B.3.
Impact of the deterministic objective Figure 9a demonstrates the important role of the deterministic
loss in OmniCast’s performance. Removing the MSE objective (No-MSE) degrades both RMSE and
CRPS scores, with particularly noticeable impact at short lead times. However, naively applying
MSE to all future frames (MSE-All-Frames) also proves counterproductive, as it forces deterministic
predictions even for S2S timescales where weather systems become inherently chaotic. Our approach
of applying MSE only to the ﬁrst 10 frames achieves the best RMSE and CRPS scores across
medium-range and S2S timescales.
9
(a) Impact of the deter-
ministic objective.
(b) Impact of the train-
ing sequence length.
(c) Comparison of differ-
ent unmasking strategies.
(d) Impact of diffusion
sampling temperature ε .
Figure 9: Ablation studies showing the impact of different components in OmniCast.
Impact of training sequence length In the main S2S experiment, we train OmniCast to generate
44 future weather states at 24 hour intervals. One could alternatively train the model on shorter
sequences and/or smaller intervals, then apply multiple roll-outs during inference to reach longer
horizons. Figure 9b shows that models trained on shorter sequences or smaller intervals excel at short-
and medium-range forecasting but underperform at S2S timescales. This trade-off emerges because
shorter sequences allow models to specialize in near-term predictions, leading to better performance
at shorter lead times. However, these models suffer from error accumulation at longer horizons,
ultimately performing worse than the model trained on full sequences.
Impact of unmasking orders While our approach randomly masks tokens across both space and
time during training, one may try more structured masking strategies at inference. We evaluate two
such alternatives: an autoregressive strategy that unmasks entire frames sequentially, and a random
framewise approach that unmasks complete frames in random order. Figure 9c shows that our fully
randomized strategy achieves the best SSR scores, while both alternatives produce under-dispersive
ensembles. The superior performance of the fully randomized approach stems from its introduction
of additional randomness through the unmasking order, generating more diverse ensemble forecasts.
This greater diversity consequently leads to better performance across other metrics.
Impact of diffusion sampling temperature Higher values of the temperature ϱ produce more
diverse forecasts. Figure 9d demonstrates this empirically. Setting ϱ< 1 produces under-dispersive
ensembles, degrading performance across other metrics. Increasing ϱ boosts sample diversity,
improving SSR scores and overall better performance. However, pushing ϱ too high (e.g., ϱ =1 .5)
causes samples to deviate from the mean prediction, compromising RMSE and CRPS performance.
We identify ϱ =1 .3 as the optimal value, providing the best balance between ensemble diversity and
forecast quality, which we adopt for our main experiments.
6 Conclusion
We present OmniCast, a novel latent diffusion model for S2S prediction. By combining the masked
generative framework with a diffusion objective, our approach enables direct modeling of long
sequences of future weather states while avoiding error accumulation inherent in autoregressive meth-
ods. OmniCast achieves state-of-the-art performance in deterministic and probabilistic metrics while
maintaining exceptional physical consistency. In medium-range forecasting, OmniCast performs
competitively with existing methods while being signiﬁcantly more efﬁcient. Future work could study
the fundamental trade-off between V AE reconstruction quality and transformer modeling capacity,
and explore more sophisticated generative frameworks to enhance the diffusion objective.
10
References
[1] Niket Agarwal, Arslan Ali, Maciej Bala, Y ogesh Balaji, Erik Barker, Tiffany Cai, Prithvijit
Chattopadhyay, Y ongxin Chen, Yin Cui, Yifan Ding, et al. Cosmos world foundation model
platform for physical ai. arXiv preprint arXiv:2501.03575, 2025.
[2] Kaifeng Bi, Lingxi Xie, Hengheng Zhang, Xin Chen, Xiaotao Gu, and Qi Tian. Accurate
medium-range global weather forecasting with 3D neural networks. Nature, 619(7970):533–
538, 2023.
[3] Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, and William T Freeman. Maskgit: Masked
generative image transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pages 11315–11325, 2022.
[4] Kang Chen, Tao Han, Junchao Gong, Lei Bai, Fenghua Ling, Jing-Jia Luo, Xi Chen, Leiming
Ma, Tianning Zhang, Rui Su, et al. Fengwu: Pushing the skillful global medium-range weather
forecast beyond 10 days lead. arXiv preprint arXiv:2304.02948, 2023.
[5] Lei Chen, Xiaohui Zhong, Jie Wu, Deliang Chen, Shangping Xie, Qingchen Chao, Chensen
Lin, Zixin Hu, Bo Lu, Hao Li, et al. Fuxi-s2s: An accurate machine learning model for global
subseasonal forecasts. arXiv preprint arXiv:2312.09926, 2023.
[6] Lei Chen, Xiaohui Zhong, Feng Zhang, Y uan Cheng, Yinghui Xu, Y uan Qi, and Hao Li. FuXi:
A cascade machine learning forecasting system for 15-day global weather forecast. arXiv
preprint arXiv:2306.12873, 2023.
[7] Guillaume Couairon, Christian Lessig, Anastase Charantonis, and Claire Monteleoni. Arch-
esweather: An efﬁcient ai weather forecasting model at 1.5 {\deg} resolution. arXiv preprint
arXiv:2405.14527, 2024.
[8] Daniela IV Domeisen, Christopher J White, Hilla Afargan-Gerstman, Ángel G Muñoz,
Matthew A Janiga, Frédéric Vitart, C Ole Wulff, Salomé Antoine, Constantin Ardilouze,
Lauriane Batté, et al. Advances in the subseasonal prediction of extreme events: Relevant case
studies across the globe. Bulletin of the American Meteorological Society, 103(6):E1473–E1501,
2022.
[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,
Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly,
Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image
recognition at scale. arXiv preprint arXiv:2010.11929, 2020.
[10] P . D. Dueben and P . Bauer. Challenges and design choices for global weather and climate
models based on machine learning. Geoscientiﬁc Model Development , 11(10):3999–4009,
2018. doi: 10.5194/gmd-11-3999-2018. URL https://gmd.copernicus.org/articles/
11/3999/2018/.
[11] ECMWF. IFS Documentation CY41R1 - Part V: The Ensemble Prediction System . Number 5.
ECMWF, 2015 2015. doi: 10.21957/eow1lonc. URL https://www.ecmwf.int/node/9212.
<p> Operational implementation 12 May 2015</p>.
[12] Jayesh K Gupta and Johannes Brandstetter. Towards multi-spatiotemporal-scale generalized
pde modeling. arXiv preprint arXiv:2209.15616, 2022.
[13] Kaiming He, Xinlei Chen, Saining Xie, Y anghao Li, Piotr Dollár, and Ross Girshick. Masked
autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF conference on
computer vision and pattern recognition , pages 16000–16009, 2022.
[14] Hans Hersbach, Bill Bell, Paul Berrisford, Gionata Biavati, András Horányi, Joaquín
Muñoz Sabater, Julien Nicolas, Carole Peubey, Raluca Radu, Iryna Rozum, Dinand Schepers,
Adrian Simmons, Cornel Soci, Dick Dee, and Jean-Noël Thépaut. ERA5 hourly data on single
levels from 1979 to present. Copernicus Climate Change Service (C3S) Climate Data Dtore
(CDS), 10(10.24381), 2018.
11
[15] Hans Hersbach, Bill Bell, Paul Berrisford, Shoji Hirahara, András Horányi, Joaquín Muñoz-
Sabater, Julien Nicolas, Carole Peubey, Raluca Radu, Dinand Schepers, , Adrian Simmons,
Cornel Soci, Saleh Abdalla, Xavier Abellan, Gianpaolo Balsamo, Peter Bechtold, Gionata
Biavati, Jean Bidlot, Massimo Bonavita, Giovanna De Chiara, Per Dahlgren, Dick Dee, Michail
Diamantakis, Rossana Dragani, Johannes Flemming, Richard Forbes, Manuel Fuentes, Alan
Geer, Leo Haimberger, Sean Healy, Robin J. Hogan, Elías Hólm, Marta Janisková, Sarah
Keeley, Patrick Laloyaux, Philippe Lopez, Cristina Lupu, Gabor Radnoti, Patricia de Rosnay,
Iryna Rozum, Freja V amborg, Sebastien Villaume, and Jean-Noël Thépaut. The ERA5 global
reanalysis. Quarterly Journal of the Royal Meteorological Society , 146(730):1999–2049, 2020.
[16] Jessica Hwang, Paulo Orenstein, Judah Cohen, Karl Pfeiffer, and Lester Mackey. Improving
subseasonal forecasting in the western us with machine learning. In Proceedings of the 25th
ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , pages
2325–2335, 2019.
[17] Ryan Keisler. Forecasting global weather with graph neural networks. arXiv preprint
arXiv:2202.07575, 2022.
[18] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
[19] Diederik P Kingma and Max Welling. Auto-encoding variational bayes, 2013. URL https:
//arxiv.org/abs/1312.6114.
[20] Dmitrii Kochkov, Janni Y uval, Ian Langmore, Peter Norgaard, Jamie Smith, Grifﬁn Mooers,
Milan Klöwer, James Lottes, Stephan Rasp, Peter Düben, et al. Neural general circulation
models for weather and climate. Nature, 632(8027):1060–1066, 2024.
[21] Alexander Kolesnikov, André Susano Pinto, Lucas Beyer, Xiaohua Zhai, Jeremiah Harmsen,
and Neil Houlsby. Uvim: A uniﬁed modeling approach for vision with learned guiding codes.
Advances in Neural Information Processing Systems , 35:26295–26308, 2022.
[22] Remi Lam, Alvaro Sanchez-Gonzalez, Matthew Willson, Peter Wirnsberger, Meire Fortunato,
Ferran Alet, Suman Ravuri, Timo Ewalds, Zach Eaton-Rosen, Weihua Hu, Alexander Merose,
Stephan Hoyer, George Holland, Oriol Vinyals, Jacklynn Stott, Alexander Pritzel, Shakir
Mohamed, and Peter Battaglia. Learning skillful medium-range global weather forecasting.
Science, 0(0):eadi2336, 2023. doi: 10.1126/science.adi2336. URL https://www.science.
org/doi/abs/10.1126/science.adi2336.
[23] Simon Lang, Mark Rodwell, and Dinand Schepers. Ifs upgrade brings many improvements and
uniﬁes medium-range resolutions. ECMWF Newsletter, 176:21–28, 2023.
[24] Simon Lang, Mihai Alexe, Matthew Chantry, Jesper Dramsch, Florian Pinault, Baudouin
Raoult, Mariana CA Clare, Christian Lessig, Michael Maier-Gerber, Linus Magnusson, et al.
Aifs-ecmwf’s data-driven forecasting system. arXiv preprint arXiv:2406.01465, 2024.
[25] Tianhong Li, Huiwen Chang, Shlok Mishra, Han Zhang, Dina Katabi, and Dilip Krishnan.
Mage: Masked generative encoder to unify representation learning and image synthesis. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages
2142–2152, 2023.
[26] Tianhong Li, Y onglong Tian, He Li, Mingyang Deng, and Kaiming He. Autoregressive image
generation without vector quantization. arXiv preprint arXiv:2406.11838, 2024.
[27] Edward N Lorenz. Forced and free variations of weather and climate. Journal of Atmospheric
Sciences, 36(8):1367–1376, 1979.
[28] Annarita Mariotti, Paolo M Ruti, and Michel Rixen. Progress in subseasonal to seasonal
prediction through a joint weather and climate community effort. Npj Climate and Atmospheric
Science, 1(1):4, 2018.
12
[29] Soukayna Mouatadid, Paulo Orenstein, Genevieve Flaspohler, Miruna Oprescu, Judah Cohen,
Franklyn Wang, Sean Knight, Maria Geogdzhayeva, Sam Levang, Ernest Fraenkel, et al.
Subseasonalclimateusa: a dataset for subseasonal forecasting and benchmarking. Advances in
Neural Information Processing Systems, 36, 2024.
[30] Congyi Nai, Xi Chen, Shangshang Y ang, Y uan Liang, Ziniu Xiao, and Baoxiang Pan. Boosting
weather forecast via generative superensemble. arXiv preprint arXiv:2412.08377, 2024.
[31] Juan Nathaniel, Y ongquan Qu, Tung Nguyen, Sungduk Y u, Julius Busecke, Aditya Grover, and
Pierre Gentine. Chaosbench: A multi-channel, physics-based benchmark for subseasonal-to-
seasonal climate prediction. arXiv preprint arXiv:2402.00712, 2024.
[32] Tung Nguyen, Johannes Brandstetter, Ashish Kapoor, Jayesh K Gupta, and Aditya Grover.
ClimaX: A foundation model for weather and climate. arXiv preprint arXiv:2301.10343, 2023.
[33] Tung Nguyen, Rohan Shah, Hritik Bansal, Troy Arcomano, Romit Maulik, V eerabhadra Kota-
marthi, Ian Foster, Sandeep Madireddy, and Aditya Grover. Scaling transformer neural networks
for skillful and reliable medium-range weather forecasting. arXiv preprint arXiv:2312.03876,
2023.
[34] Joel Oskarsson, Tomas Landelius, Marc Peter Deisenroth, and Fredrik Lindsten. Probabilistic
weather forecasting with hierarchical graph neural networks. arXiv preprint arXiv:2406.04759,
2024.
[35] Jaideep Pathak, Shashank Subramanian, Peter Harrington, Sanjeev Raja, Ashesh Chattopadhyay,
Morteza Mardani, Thorsten Kurth, David Hall, Zongyi Li, Kamyar Azizzadenesheli, Pedram
Hassanzadeh, Karthik Kashinath, and Animashree Anandkumar. FourCastNet: A global data-
driven high-resolution weather model using adaptive Fourier neural operators. arXiv preprint
arXiv:2202.11214, 2022.
[36] Kathy Pegion, Ben P Kirtman, Emily Becker, Dan C Collins, Emerson LaJoie, Robert Burgman,
Ray Bell, Timothy DelSole, Dughong Min, Y uejian Zhu, et al. The subseasonal experiment
(subx): A multimodel subseasonal prediction experiment. Bulletin of the American Meteorolog-
ical Society, 100(10):2043–2060, 2019.
[37] Ilan Price, Alvaro Sanchez-Gonzalez, Ferran Alet, Timo Ewalds, Andrew El-Kadi, Jacklynn
Stott, Shakir Mohamed, Peter Battaglia, Remi Lam, and Matthew Willson. Gencast: Diffusion-
based ensemble forecasting for medium-range weather. arXiv preprint arXiv:2312.15796 ,
2023.
[38] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea V oss, Alec Radford, Mark
Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International conference on
machine learning, pages 8821–8831. Pmlr, 2021.
[39] Stephan Rasp, Peter D Dueben, Sebastian Scher, Jonathan A Weyn, Soukayna Mouatadid, and
Nils Thuerey. WeatherBench: a benchmark data set for data-driven weather forecasting. Journal
of Advances in Modeling Earth Systems , 12(11):e2020MS002203, 2020.
[40] Stephan Rasp, Stephan Hoyer, Alexander Merose, Ian Langmore, Peter Battaglia, Tyler Russel,
Alvaro Sanchez-Gonzalez, Vivian Y ang, Rob Carver, Shreya Agrawal, Matthew Chantry,
Zied Ben Bouallegue, Peter Dueben, Carla Bromberg, Jared Sisk, Luke Barrington, Aaron Bell,
and Fei Sha. WeatherBench 2: A benchmark for the next generation of data-driven global
weather models. arXiv preprint arXiv:2308.15560, 2023.
[41] Ali Razavi, Aaron V an den Oord, and Oriol Vinyals. Generating diverse high-ﬁdelity images
with vq-vae-2. Advances in neural information processing systems , 32, 2019.
[42] Suranjana Saha, Shrinivas Moorthi, Xingren Wu, Jiande Wang, Sudhir Nadiga, Patrick Tripp,
David Behringer, Y u-Tai Hou, Hui-ya Chuang, Mark Iredell, et al. The ncep climate forecast
system version 2. Journal of climate, 27(6):2185–2208, 2014.
[43] Sebastian Scher. Toward data-driven weather and climate forecasting: Approximating a simple
general circulation model with deep learning. Geophysical Research Letters, 45(22):12–616,
2018.
13
[44] Michael Tschannen, Cian Eastwood, and Fabian Mentzer. Givt: Generative inﬁnite-vocabulary
transformers. In European Conference on Computer Vision, pages 292–309. Springer, 2025.
[45] Aaron V an Den Oord, Oriol Vinyals, et al. Neural discrete representation learning. Advances in
neural information processing systems, 30, 2017.
[46] Ashish V aswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
!ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in Neural Information
Processing Systems, 30, 2017.
[47] Frédéric Vitart. Evolution of ecmwf sub-seasonal forecast skill scores. Quarterly Journal of the
Royal Meteorological Society, 140(683):1889–1899, 2014.
[48] Frederic Vitart, Constantin Ardilouze, Axel Bonet, Anca Brookshaw, M Chen, C Codorean,
M Déqué, L Ferranti, E Fucile, M Fuentes, et al. The subseasonal to seasonal (s2s) prediction
project database. Bulletin of the American Meteorological Society , 98(1):163–173, 2017.
[49] NP Wedi, P Bauer, W Denoninck, M Diamantakis, M Hamrud, C Kuhnlein, S Malardel,
K Mogensen, G Mozdzynski, and PK Smolarkiewicz. The modelling infrastructure of the
Integrated F orecasting System: Recent advances and future challenges. European Centre for
Medium-Range Weather Forecasts, 2015.
[50] Jonathan A Weyn, Dale R Durran, and Rich Caruana. Can machines learn to predict weather?
Using deep learning to predict gridded 500-hPa geopotential height from historical weather
data. Journal of Advances in Modeling Earth Systems , 11(8):2680–2693, 2019.
[51] Christopher J White, Henrik Carlsen, Andrew W Robertson, Richard JT Klein, Jeffrey K Lazo,
Arun Kumar, Frederic Vitart, Erin Coughlan de Perez, Andrea J Ray, Virginia Murray, et al.
Potential applications of subseasonal-to-seasonal (s2s) predictions. Meteorological applications,
24(3):315–325, 2017.
[52] Christopher J White, Daniela IV Domeisen, Nachiketa Acharya, Elijah A Adeﬁsan, Michael L
Anderson, Stella Aura, Ahmed A Balogun, Douglas Bertram, Sonia Bluhm, David J Brayshaw,
et al. Advances in the application and utility of subseasonal-to-seasonal predictions. Bulletin of
the American Meteorological Society, 103(6):E1448–E1472, 2022.
[53] KD Williams, CM Harris, A Bodas-Salcedo, J Camp, RE Comer, D Copsey, D Fereday,
T Graham, R Hill, T Hinton, et al. The met ofﬁce global coupled model 2.0 (gc2) conﬁguration.
Geoscientiﬁc Model Development, 88(55):1509–1524, 2015.
[54] Tongwen Wu, Yixiong Lu, Y ongjie Fang, Xiaoge Xin, Laurent Li, Weiping Li, Weihua Jie, Jie
Zhang, Yiming Liu, Li Zhang, et al. The beijing climate center climate system model (bcc-csm):
The main progress from cmip5 to cmip6. Geoscientiﬁc Model Development, 12(4):1573–1600,
2019.
[55] Lijun Y u, Y ong Cheng, Kihyuk Sohn, José Lezama, Han Zhang, Huiwen Chang, Alexander G
Hauptmann, Ming-Hsuan Y ang, Y uan Hao, Irfan Essa, et al. Magvit: Masked generative video
transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pages 10459–10469, 2023.
14