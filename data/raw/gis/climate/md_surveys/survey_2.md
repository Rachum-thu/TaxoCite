# Foundation Models for Weather and Climate Data Understanding: A Comprehensive Survey

## Abstract—
As artificial intelligence (AI) continues to rapidly evolve, the realm of Earth and atmospheric sciences is increasingly adopting data-driven models, powered by progressive developments in deep learning (DL). Specifically, DL techniques are extensively utilized to decode the chaotic and nonlinear aspects of Earth systems, and to address climate challenges via understanding weather and climate data. Cutting-edge performance on specific tasks within narrower spatio-temporal scales has been achieved recently through DL. The rise of large models, specifically large language models (LLMs), has enabled fine-tuning processes that yield remarkable outcomes across various downstream tasks, thereby propelling the advancement of general AI. However, we are still navigating the initial stages of crafting general AI for weather and climate. In this survey, we offer an exhaustive, timely overview of state-of-the-art AI methodologies specifically engineered for weather and climate data, with a special focus on time series and text data. Our primary coverage encompasses four critical aspects: types of weather and climate data, principal model architectures, model scopes and applications, and datasets for weather and climate. Furthermore, in relation to the creation and application of foundation models for weather and climate data understanding, we delve into the field’s prevailing challenges, offer crucial insights, and propose detailed avenues for future research. This comprehensive approach equips practitioners with the requisite knowledge to make substantial progress in this domain. Our survey encapsulates the most recent breakthroughs in research on large, data-driven models for weather and climate data understanding, emphasizing robust foundations, current advancements, practical applications, crucial resources, and prospective research opportunities.

## 1 INTRODUCTION
Concept 1. Weather and Climate are distinct concepts with notable differences in spatial and temporal scales, variability, and predictability. The dissimilarities between the two can be elucidated as follows:
• Temporal Scale. Weather pertains to the immediate state of atmospheric conditions, typically within a short-term timeframe. Conversely, climate represents a statistical summary of long-term weather patterns.
• Spatial Scale. Weather represents atmospheric conditions at a specific location, whereas climate encompasses a comprehensive summary of typical weather patterns within a region over an extended period.
• Variability. Weather exhibits rapid and frequent changes, while climate change occurs at a slower pace and encompasses long-term shifts in weather patterns.
• Predictability. Weather prediction focuses on forecasting weather conditions in the next few days or shorter time scales. In contrast, climate prediction aims to forecast climate trends over the following months to decades.

Climate change delineates noticeable alterations in global temperature and weather patterns over protracted periods. Currently, our planet is experiencing a proliferation in extreme natural phenomena, such as droughts [1], [2], floods [1], earthquakes [3], heatwaves [4], and intense rainfall [5], propelled by escalating climate change. Further amplifying these challenges are the alarming threats to ecosystems from mounting global warming and sea-level reductions [6], [7]. Given the projected augmentation in surface temperatures this century, we foresee an intensification in the harshness and frequency of these extreme phenomena [8].

Leveraging advanced climate modeling and prediction techniques, which integrate a plethora of atmospheric and surface variables - encompassing atmospheric conditions, ocean currents, terrestrial ecosystems, and biosphere interactions - can enhance our comprehension of climate change [9], [10]. These insights can guide the formulation of bespoke mitigation strategies [11]. Long-term, accurate predictions of sea level changes can strengthen urban planning and disaster preparedness in coastal cities [12], [13], [14]. In the short term, precise forecasts of rainfall, temperature, and humidity can heighten the safety of human activities, including agricultural planning and transportation scheduling [15], [16], [17].

Traditionally, general circulation models (GCMs) [18] and numerical weather prediction models (NWPs) [19], [20], [21] have been favored tools for studying climate change trends and predicting future weather and climate scenarios. These models assimilate major Earth system components, including the atmosphere, surface, and oceans, to emulate the multidimensional dynamics of the Earth system. They identify potential nonlinear correlations between these components through complex physical equations, such as atmospheric dynamics, to generate predictions within a wide spectrum of physical parameters [22]. However, despite their considerable maturation, numerically constrained weather prediction models still encounter numerous challenges and limitations. One of these is their oversimplified representation of local geographical features [23], as they often fail to capture the intricate nuances of local topography, which exerts a critical influence on regional weather and climate patterns. Another obstacle is the effective integration of observational data from disparate sources, such as weather stations, radars, and satellites [8]. Traditional models often struggle with incorporating these data, with varying spatial and temporal resolutions, into their modeling frameworks. Moreover, they require substantial computational resources to manage the myriad of physical constraints [24]. The complexity and scale of the Earth system demand extensive calculations, presenting challenges to computational capacity and efficiency.

The rapid advancement of AI technology has introduced cost-effective, direct, and simplified solution strategies for weather and cliamte modeling. In particular, Machine Learning (ML) and Deep Learning (DL) technologies can discern potential trend representations in weather and climate data, bypassing the need for intricate physical relationships. Initially, ML techniques were sparingly used for short-term, localized forecasts of weather and climate conditions, given their limited capabilities compared with large-scale, time-extensive physical models. However, the past decade has witnessed an exponential surge in the application of data-driven deep learning methods in weather and climate research, propelled by the explosive expansion of global weather and climate data [25], [26]. Capitalizing on abundant data resources and advancements in computational technology [27], [28], these models are revolutionizing climate science [29]. Employing voluminous data, deep learning models unravel the intricate nonlinear relationships concealed within climate variables, thereby capturing the dynamism and complexity of the climate system with enhanced precision [30], [31]. However, these models are often designed for specific tasks and trained with data in particular formats, such as regional weather forecasting or downscaling on a microscale. Differences in the representations of training data sources have resulted in an overly compartmentalized functionality of data-driven deep learning models for understanding weather and climate data. Consequently, it poses a significant challenge to develop a versatile climate model that can be fine-tuned for simulating the global weather and climate system.

The recent emergence and swift advancement of large models have yielded significant gains across various fields, including natural language processing (NLP), computer vision (CV) [32], robotics [33], and a range of interdisciplinary areas encompassing life sciences [34], [35], [36], [37], [38]. Particularly in the NLP field, large models, or large language models (LLMs), are evolving rapidly, trained on large-scale corpora and fine-tuned for various downstream tasks [39], [40], [41]. In computer vision, large vision models trained on substantial natural images [42], [43], [44] demonstrate exceptional zero-shot capabilities [45], [46]. The impressive performance of these models across tasks arises from their substantial parameter counts and large-scale pre-training data. For instance, GPT-3 [47], [48] possesses nearly 120 times the parameters of GPT-2 [49], enabling it to learn more powerfully from fewer samples, while GPT-4 [50] has less than ten times the parameters of GPT-3, yet excels in text generation and image understanding. The rapid ascension of LLMs has redefined the path forward for deep learning, despite long-standing developments in areas such as unsupervised/semi-supervised and transfer learning. A notable example is the vision-language large model [46], [51], [52], [53], such as CLIP [46], which is trained on numerous natural image-text pairs and fine-tuned to achieve promising results in tasks like image segmentation [54], [55], [56] and video subtitle generation [57], [58]. Recently, the extension of large models into domains such as speech [59], [60], physics [61], and mathematical analysis [62] has catalyzed advancements in fundamental science and specialized areas.

The groundbreaking success of pre-trained foundation models has propelled the domains of NLP and CV significantly closer to the realization of versatile AI. This advancement prompts an intriguing question: The success of pre-trained foundation models has allowed the fields of NLP and CV to take a meaningful step towards realizing general-purpose AI, which not only leads one to wonder: Is it possible to develop a universal foundation model for weather and climate data understanding that effectively addresses a myriad of related tasks?

Building upon the theory of pre-trained models, ClimaX [25] introduces an innovative approach towards the development of a weather and climate base model. It leverages the Transformer to pre-train large-scale weather and climate data, yielding a flexible foundation model proficient in short- to medium-term forecasting, climate projection, and downscaling. Both PanGu-Weather [63] and W-MAE [64] exhibit robust climate prediction capabilities by modeling the global climate system using copious data. However, the quest for large-scale, universal climate models faces significant obstacles. A primary challenge is the scarcity of large, diverse, and high-quality training datasets. Existing datasets (refer to Table. 4 for more details) struggle with inconsistent measurements, spatial-temporal biases, and limited functionality, hampering the progression of all-encompassing, multipurpose large-scale foundation models. Additionally, the computational demands of these models add another dimension of complexity, with the required infrastructure potentially unachievable in resource-limited settings. Ideally, a weather/climate foundation model should seamlessly handle multi-source observations and incorporate detailed representations of geographic features to generate more precise simulations of weather and climate trends. Unfortunately, this remains a largely uncharted territory for current weather and climate base models. Moreover, the interpretability of these models, often perceived as "black boxes," is a significant concern. In tasks related to weather and climate, where erroneous predictions can wreak havoc on ecosystems and societies, the need for interpretability is especially accentuated [36], [65], [66]. Despite the remarkable strides and potential in understanding weather and climate data, the distinct challenges associated with the development of large-scale foundation models, as outlined above, necessitate concentrated research (refer to Sec. 9 for more details). This emphasizes the need for a thorough review of advancements in this nascent field.

In this paper, we conduct a comprehensive review of data-driven models explicitly designed for weather and climate data. Our survey encompasses a wide array of large foundation models/task-specific models spanning various data types, model architectures, application domains, and representative tasks. This review amplifies the scope of insights derived from weather and climate data, encouraging novel strategies and fostering the cross-application of large models in the weather and climate. By leveraging the power of DL in large-scale models, we aim to reveal complex climate patterns, augment predictions, and deepen our comprehension of the climate system, thereby empowering society to more effectively adapt to the challenges posed by climate change. Our contributions are summarized as follows:
• First Comprehensive and Contemporary Survey. To the best of our knowledge, this paper constitutes the inaugural comprehensive survey that thoroughly encapsulates the state-of-the-art developments of large, and task-specific models for weather and climate data understanding, spanning across time series, video streams, and text sequences. We furnish an in-depth and current panorama that covers the broad spectrum of the domain, simultaneously delving into the subtleties of distinct methodologies, thereby providing the reader with a comprehensive and current apprehension of this field.
• Systematic and In-depth Categorization. We introduce and discuss an organized and detailed categorization, dividing existing related research into two main categories: large climate foundation models and task-specific climate models. Furthermore, we further classify them based on the underlying model architectures, including RNNs, Transformers, GANs, Diffusion models, and Graph Neural Networks. Subsequent divisions are made based on the models’ application domains and specific tasks, with detailed explanations of these task definitions. This multidimensional categorization provides readers with a coherent roadmap.
• Abundant Resource Compilation. We have assembled a substantial collection of datasets and open-source implementations pertinent to the field of weather and climate science. Each dataset is supplemented with an exhaustive description of its structure, pertinent tasks, and direct hyperlinks for expedient access. This compilation serves as an invaluable resource for prospective research and developmental endeavors in the domain.
• Future Outlook and Research Opportunities. We have delineated several promising trajectories for future exploration. These viewpoints span across various domains, including data post-processing, model architectures, interpretability, privacy, and training paradigms, among others. This discourse equips the readers with an intricate understanding of the current status of the field and potential avenues for future exploration.
• Insights for Designing. We discuss and pinpoint crucial design elements for promising weather and climate foundation models. These design components incorporate the selection of temporal and spatial scales, dataset choice, data representation and model design, learning strategies, and evaluation schemes. Adherence to this systematic design pipeline enables practitioners to rapidly comprehend the design principles and construct robust weather and climate foundation models, thereby fostering the expeditious advancement of the weather and climate domain.

Paper Organization. The remainder of this survey is structured as follows: Section 2 delineates the distinctions between our survey and other corresponding studies. Section 3 instills the reader with fundamental knowledge on foundational models, primary depictions of weather and climate data, and related tasks. Section 4 expounds upon the core architecture of paramount models for weather and climate tasks. In Section 6, we present a synopsis of the principal model classifications currently in use for weather and climate tasks, encompassing climate basic models and task-specific models. This section furnishes a holistic view of the field prior to probing into the complexities of individual methodologies. Section 5 imparts a concise introduction to climate basic models and task-specific models, further stratifying task-specific models based on dissimilar model architectures. Subsequently, Section 7 undertakes an extensive exploration of data-driven deep learning models for specific weather and climate tasks. Considering the lack of a unified and comprehensive index for weather and climate datasets, Section 8 presents an exhaustive collection of dataset resources and introductions, aiming to impart convenience and efficiency for readers. Section 9 delineates the challenges currently impeding the evolution of weather and climate basic models, as well as prospective future directions in this field. Section 10 proposes a potential blueprint for the construction of weather and meteorological basic models, aiding contemplation and execution by practitioners, and fostering the development of climate foundation models. Finally, Sec. 11 provides a summary and concluding remarks on the content of the survey.

## 2 RELATED WORK AND DIFFERENCES
While numerous expansive surveys have been executed to model weather and climate-related data from various vantage points, none of them emphasize the broad-spectrum scope of weather data. For example, Ren et al. [31] undertook a survey on deep learning-based weather forecasting, focusing on neural network architecture design and spatial and temporal scales, yet it omitted models pertinent to the era of the weather data explosion. Both Fang et al. [67] and Jones et al. [71] reviewed deep learning-based weather forecasting within the confines of specific scenarios, namely extreme weather conditions and climate impacts on flood risk. Conversely, Bochenek et al. [68] and Jaseena et al. [74] exclusively addressed and summarized machine learning/deep learning-based works concerning ordinary time series. Chen et al. [70] provided a survey of machine learning methodologies in weather and climate, but the focus remained restricted to forecasting tasks. Furthermore, Molina et al. [72] primarily emphasized the application of machine learning in climate modeling, such as sources of predictability in climate variability models, feature detection, extreme weather and climate prediction, observational model integration, downscaling, and bias correction. Materia [8] primarily centered on reviewing literature that employed machine learning techniques for extreme weather detection and understanding. These aforementioned surveys lack thorough investigation into the applications of foundational models in weather data understanding. Mukkavilli et al. [73] discussed the application of large models to weather and climate tasks and the architectural design, which bears similarity to our endeavor, but does not include more detailed task-specific models and a wider range of data modalities. Globally, these surveys also lack a structured delineation and an exhaustive discussion of deep learning-based models for weather data understanding, as well as adequate resources (datasets, open-source models and tools, etc.) that are either not provided or are limited in their availability. Given the recent multiplication of large-scale models in domains such as vision [45], [75], audio [50], and text [56], our intention with this survey is to provide an exhaustive and up-to-date overview of large-scale models for weather data understanding, as well as a structured delineation, synthesis, and discussion of pertinent task-specific models, with the objective of establishing a robust foundation for the design of weather and climate base models. Our aim surpasses merely documenting recent advances; we also focus on available resources, practical applications, and potential research directions.

## 3 BACKGROUND AND PRELIMINARY
This study aims to review the recent progress in implementing data-driven models, with a primary emphasis on DL techniques, to address weather and climate tasks. The objective is to illuminate potential pathways for developing foundation models dedicated to weather and climate data understanding. We direct our attention towards two principal categories of models in the weather and climate domains: large-scale foundational models and task-specific models. In this section, we commence by discussing these two model types and elucidate their distinctions and connections. Subsequently, we delineate weather and climate-related data types and representative tasks across diverse domains. We conclude with an introduction to four prevalent base model architectures employed in weather and climate tasks.

### 3.1 Foundation Models
Foundation Models (FMs) originated as pre-trained LLMs with a broad capability to undertake a myriad of downstream tasks through fine-tuning strategies. These models constitute a versatile class, separate from task-specific models, due to their capacity to accommodate a range of downstream tasks and integrate heterogeneous representations. The prowess of FMs can be classified into two categories: (1) Cross-Modal Representation and (2) Reasoning and Interaction.

Cross-Modal Representation. This category involves multi-modal models, including vision-language models (VLMs) [46], [51], [76], [77]. These models merge and align linguistic and visual modalities, demonstrating a significant potential for modal unification. A prime example is CLIP (Contrastive Language-Image Pre-training) [46], which concurrently trains on text and image data using the contrastive learning method. It displays substantial Zero-Shot Learning (ZSL) and Few-Shot Learning (FSL) abilities on downstream tasks. Another innovative model, SAM (Segment Anything Model) [45], integrates the concept of prompting into visual tasks, yielding remarkable zero-shot segmentation performance. Models like InstructBLIP [78], CoCa [79], BEIT-3 [80], InstructGPT [81], and LLaMa [82], [83] further expand the reach of cross-modal foundation models, accommodating a broader spectrum of tasks and modal representations. In weather prediction and climate change applications, data typically exhibit large-scale and multimodal characteristics, such as radar observations [84], [85], satellite images [86], ground-based observatories [24], [87], and organized gridded data [88], [89], [90]. These characteristics provide impetus for the development of data-driven FMs for weather and climate tasks.

Reasoning and Interaction. FMs demonstrate exceptional reasoning and planning abilities, exemplified by models like CoT [91], ToT [92], and GoT [93], in addition to task planning agents. This category also involves interaction abilities, encompassing operations and communication. This study emphasizes the application of data-driven FMs for weather and climate tasks. Nonetheless, this area remains uncharted, offering abundant opportunities for innovation.

### 3.2 Task-Specific Models
Contrary to previously mentioned FMs, the majority of DL models for weather and climate are mainly domain-specific (e.g., global/regional precipitation forecasting, extreme weather comprehension, climate model downscaling). This survey classifies these task-specific models into two categories based on the nature of task for time series: (1) Time Series-based Weather and Climate Analysis; (2) Spatio-Temporal Series-based Weather and Climate Analysis. We also delineate an area for climate text data: Climate Text Analysis Tasks.

Time Series-based Weather and Climate Analysis. This category primarily comprises DL models for weather and climate analysis that leverage time series data. These models typically utilize weather time series data obtained from a single weather station to determine sequential relationships between one or multiple variables from past observations, thereby facilitating future trend predictions for specific weather variables.

A classic example of a data-driven model for weather forecasting is the Auto Regressive Integrated Moving Average (ARIMA) [94], which enables non-stationary data to become stationary through a differencing operation, and subsequently employs a combination of auto-regression and moving averages to model the time series. Given the significant seasonality often present in weather data, such as fluctuations in temperature and rainfall, Seasonal ARIMA (SARIMA) [95] and Seasonal ARIMA with eXogenous variables (SARIMAX) [96] have been developed to model weather series, building upon seasonal auto-regression/moving average principles. Vector Autoregression (VAR) serves as an alternate method capable of modelling and predicting multiple correlated variables concurrently. Deep Learning-based models, such as families of Recurrent Neural Networks (RNNs) [97], [98], [99], convolutional neural network (CNN)-based architectures, and models based on the Transformer (e.g., Informer [100], Autoformer [101], Crossformer [102], ETSFormer [103], Reformer [104], FEDformer [105]), have exhibited superior performance when dealing with non-stationary time series. These models are particularly useful due to their lack of reliance on additional statistical knowledge and their efficiency in long-term forecasting.

Spatio-Temporal Series-based Weather and Climate Analysis. Another focal area is DL models for weather and climate analysis that employ spatio-temporal series. Unlike time-series data, spatio-temporal data covers weather variable observations across multiple locations over time, allowing for the extraction of intricate spatio-temporal patterns. In this context, continuous radar echoes or satellite images that represent independent weather times are also considered as spatio-temporal sequences.

Data-driven models designed for analysing spatio-temporal series for weather and climate analysis are often required to capture both temporal and spatial correlations. For instance, the convolutional LSTM [97], a variant of the LSTM, incorporates convolutional operations to the LSTM to capture additional spatial correlations. 3D Convolutional Neural Networks (3D-CNNs) are frequently employed to consider spatio-temporal correlations of sequences simultaneously. Spatio-Temporal Graph Neural Networks [106], and other graph-based structures, effectively encode different spatial information into graphs that capture spatial correlations as well as temporal trends of weather variables. Transformer models utilize self-attention mechanisms to assess the importance of different locations and time points when making predictions [107]. Recent advancements in the field have also seen the exploration of generative AI, such as generative adversarial networks [108] and diffusion models [109], for weather prediction and climate change based on spatio-temporal sequences, owing to their excellent generative quality.

### 3.3 Types of Weather and Climate Data
Investigations into weather and climate typically necessitate the exploration of both temporal and textual data. The primary objectives of these tasks involve discerning the relationships between historical weather patterns — often characterized by numerous meteorological variables — and future changes. This process also includes the extraction of specific features from textual sequences to aid detailed subsequent analysis. In these scenarios, our discussion mainly revolves around three primary data types: time series, spatio-temporal, and textual data. In the context of weather and climate analysis, time series can be broadly divided into two types: univariate and multivariate. A univariate time series might be represented by the daily mean temperature at a single observation point, while a multivariate time series may include daily precipitation and humidity data collected from the same observation point. Here, we first discuss the definition of univariate/multivariate time series. Formally, we follow the definitions of time series data in Ref. [110], which we summarize below.

Definition 3.1 (Time Series Data). For a single point observation, a univariate time series sole weather variables (such as temperature) x = {x1, x2, x3, ..., xT } ∈ RT is a sequence of T time step indexed in time order, where xt ∈ R is the variable value of the time series at time t. A multivariate time series including different climate variables (i.e., temperature, humidity, precipitation, etc.) X = {x1, x2, x3, ..., xT } ∈ RT ×D is a sequence of T time steps indexed in time order but with D dimensions (variables), in which x ∈ RD denotes the values of the time series at time t along D channels.

Global climate data are often represented as spatio-temporal series, i.e., chaotic correlations with both temporal (change trend) and spatial dimensions (geographic location). We define two distinct Spatio-Temporal Series: univariate spatio-temporal series and multivariate spatio-temporal series. They are both sequence of data points organized by both temporal and spatial dimensions.

Definition 3.2 (Spatio-Temporal Series). For univariate spatio-temporal series, follow Definition 2.1, there exist N points on the Earth system, at each point there exists a time series x = {x1, x2, x3, ..., xT } ∈ RT , where xt ∈ R, the spatio-temporal series is formulated as Xu = {x1, x2, x3, ..., xN } ∈ RT ×N . Similarly, for multivariate spatio-temporal sequences, the series can be formulated as Xmu = {X1, X2, X3, ..., XN } ∈ RT ×D×N , where XN denote the multivariate time series at the N space point. Notably that graph-based structure usually utilized to construct a spatio-temporal series, such as spatio-temporal graphs (STGs), temporal knowledge graphs (TKGs), video streams, and others. In this survey, we mainly focus above-mentioned classes, which are highly representative and align closely with the current spatio-temporal series-based weather forecasting and climate analysis tasks. And we follow the Ref. to define STGs and TKGs firstly, as follows.

Definition 3.3 (Spatio-Temporal Graphs). A spatio-temporal graph G = {G1, G2, G3, ..., GT } denotes a sequence of T static graph snapshots (also named time steps) indexed in time order, in which Gt = ( Vt, ϵt) presents a snapshot at t-th time step; Vt and ϵt are sets of nodes and edges at time t. The adjacent matrix represents the correlation between nodes in the graph and node feature matrices are defined as At ∈ RN ×N and Xt ∈ RN ×D, where At = {at i,j} and at i,j ̸= 0 if there is an edge between node i and j. In addition, N = |Vt| is the number of nodes and D is the dimension of node features.

Definition 3.4 (Temporal Knowledge Graphs). Follow the definition of STGs, a temporal knowledge graph G = {G1, G2, G3, ..., GT } is a sequence of T knowledge graph snapshots indexed in time order, where Gt = ( ϵt m Rt) is a snapshot consisting of the entity and relation sets at time t. Specifically, ϵt encapsulates both subject and object entities, and Rt presents the set of relations between them. In a temporal knowledge graph, entities and relations may posses different features, denoted by X ∈ R|ϵt|×De and Xr t ∈ R|R|×Dr, where De and Dr are feature dimensions.

Spatio-temporal video streams belong to a species of spatio-temporal series, which are represented as regular spatial shapes and sequences organized in time order. In weather forecasting and climate analysis tasks, regional contiguous weather radar echoes and satellite images that symbolize specific climate events belong to this type, and we define spatio-temporal video streams based on the definition of spatio-temporal sequences as follows.

Definition 3.5(Spatio-Temporal Video Streams). Assume a spatio-temporal video streams V = {F1, F2, F3, ..., FT } is a set of continue frames that cover T time steps indexed in time order, where Ft denotes the t-th frame (or time step). Each frame is viewed as a matrix of pixels 1 can be formulated as Ft ∈ RC×H×W , where C, H, W denote the channels, height, and width of the frame, respectively.

Definition 3.6 (Text Sequence). Let S be a text sequence, where each element in the sequence represents a word or character. The text sequence can be represented as S = {x1, x2, . . . , xn}, where xi represents the i-th element in the sequence. The length of the text sequence, denoted as (N), can be defined as N = |S|, where | · | represents the cardinality or number of elements in the sequence. Furthermore, each element in the text sequence can be represented as a one-hot encoded vector, denoted as X. The one-hot encoded vector Xi for the i-th element in the sequence is a binary vector of length M, where M represents the total number of unique words or characters in the text corpus. The one-hot encoded vector Xi has a value of 1 at the position corresponding to the index of the word or character in the vocabulary, and 0 elsewhere.

### 3.4 Mainstream Tasks for Weather and Climate
Based on the above definitions, we will present representative weather and climate analysis tasks associated with the above data types and structures.

• Weather/Climate Time Series Tasks. Time series analysis forms the bedrock of weather and climate studies. Researchers frequently harness this methodology to extract meteorological trends from sequential data, projecting these tendencies onto multiple variable values across a specified temporal span for granular analysis. This overarching task encompasses three subtasks: Forecasting, Classification, and Imputation. In the forecasting task, the primary goal in to precisely predict a specific variable for a designated future temporal window grounded on historical observation. This task can be bifurcated, based on the magnitude of the prediction window, into short-term forecasting (typically spanning several hours to a few days) and long-term forecasting (generally a week or beyond). Short-term weather forecasting is often employed in immediate weather prediction and urban planning, whereas long-term forecasting predominantly serves climate studies, agriculture, and energy sectors. Subsequently, the classification task is aimed at mapping distinct meteorological phenomena, such as drought intensities, based on a historical chronology of atmospheric observations. Finally, the imputation task is structured to fill missing values in the series. This task exploits potential information embedded in the series, accounting for data gaps that might emanate from sensor malfunctions or severe climate events, among other factors.

• Graph Structure-based Tasks. The mainstream task of graph structure-based for climate change is forecasting. We explore graph structure-based tasks in terms of both STGs and TKGs, as previously mentioned. STGs and TKGs is extensions for representing and reasoning about spatio-temporal information, fusing the relationships between time, space, and entities into a unified graph structure. Forecasting tasks aim to infer weather conditions at future spatio-temporal points based on historical observations and model predictions. Such tasks involve multiple variables, such as temperature, humidity, and barometric pressure, as well as temporal and spatial dimensions. The key challenges of spatio-temporal map prediction tasks are how to effectively capture and model spatio-temporal dependencies and how to cope with data uncertainty and missingness.

• Spatio-Temporal Video Streams Tasks. Video data stands as a crucial asset in the examination of climate change and weather forecasting. In meteorological contexts, spatio-temporal video streams typically manifest as sequences of frames that depict weather fluctuations over a fixed period. These sequences may include regularly shaped radar images, satellite images, and other types of weather-related visual data. Therefore, the primary interest in spatio-temporal video stream data lies in prediction tasks—namely, the forecasting of future images based on a series of past consecutive frames. The quintessential task in this context involves the prediction of imminent rainfall based on radar echoes or the extrapolation of satellite imagery.

• Climate Text Tasks. The analysis of climate textual data, or climate text analysis, aspires to distill significant patterns and insights. This process encapsulates several subtasks including Sentiment Analysis, Topic Modeling, Information Extraction, and Trend Analysis. Sentiment analysis endeavors to perceive the sentiment or perspectives encapsulated in climate text data (e.g., public perceptions of climate change). Topic modeling, conversely, strives to identify and classify the cardinal themes or subjects broached within climate texts, thereby fostering a comprehensive understanding of pivotal focus areas. Information extraction constitutes the extraction of specific details from climate texts, such as instances of extreme weather events or particulars of climate policy. Finally, trend analysis concentrates on pinpointing and examining trends within climate texts, aiding in the monitoring of shifts in public dialogue, scientific research, or policy discussions over time. Collectively, these tasks converge to a deeper discernment of climate issues. The insights harvested can enlighten decision-making mechanisms, policy development, and initiatives to amplify public cognizance.

Considering the aforementioned types of weather and climate data, we will now expound on a variety of tasks pertinent to weather and climate analysis. Note that we have omitted the explicit outline and definition of the Climate Text Analysis task due to its closely related subtasks, and instead adopted the aforementioned Climate Task as a proxy for the Climate Text Analysis definition. A succinct description of each task is as follows:

• Forecasting Tasks. These tasks span from a few hours (nowcasting) to days and weeks (short- and medium-range forecasting). They may include regional forecasting for continental states, counties, or cities. Subseasonal to seasonal prediction involves forecasting weather between 2 weeks and 2 months in advance, bridging the gap between weather forecasts and seasonal climate predictions, which is imperative for disaster mitigation.

• Precipitation nowcasting tasks. Precipitation Nowcasting is a weather forecasting technique designed to predict precipitation over the next few hours. Unlike traditional weather forecasting, it focuses on short-term changes in precipitation, usually predicted on time scales of minutes to hours. This task employs data from radar systems, satellites, weather observation facilities, and numerical models, combined with image processing techniques, to predict the distribution, intensity, and movement of precipitation over a brief future period via real-time monitoring and analysis of atmospheric clouds and precipitation systems. Therefore, we have isolated it from the general forecasting task.

• Downscaling tasks. Given the coarse spatial resolution of global climate models, they can only offer general estimates of climate conditions at local or regional scales. Simulations often exhibit systematic biases that diverge from trends in observed data. Downscaling climate models aims to generate locally precise climate information from global climate projections by correlating this climate information to observed local climate conditions. This process enhances the data’s spatial and temporal resolution, rendering it more suitable for local and regional analysis.

• Bias correction tasks. Bias correction is vital in weather and climate applications. It aims to minimize or eliminate systematic biases in model outputs and observational data, which emerge due to uncertainties in weather models and measurement errors. In weather forecasting, bias correction enhances the accuracy of model predictions by adjusting variables such as temperature and precipitation to match actual observations. In climate research, bias correction is crucial for aligning climate model outputs with observational data, facilitating accurate analysis of climate change trends, evaluation of model performance, and reliable predictions of future climate changes. Various methods, including statistical, machine learning, and deep learning techniques, can be employed for bias correction, tailoring the approach based on the specific application and data characteristics. By minimizing or eliminating systematic biases, bias correction improves the quality and reliability of weather and climate data.

• Weather pattern understanding tasks. This task strives to analyze weather data to comprehend the variations and trends in weather patterns and the climate system. It involves modeling and analyzing various elements of the weather system, such as pressure, temperature, humidity, wind speed, and wind direction, to disclose their relationships and interactions. The objective is to identify and interpret different weather patterns, such as cyclones, fronts, and high-pressure systems, and deduce their impacts on weather changes and extreme weather events. By gaining a deeper understanding of weather patterns, we can enhance our knowledge of weather forecasting and climate change, providing decision-makers and researchers with more accurate and comprehensive information about the weather system.

## 4 BASIC STRUCTURE FOR WEATHER & CLIMATE
Considering the different types of data present in weather and climate tasks, we mainly consider the use of Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Graph Neural Networks (GNNs), Transformers, Generative Adversarial Networks (GANs), and Diffusion Models to mine complex correlations from these data. In this survey, we mainly focus on Recurrent Neural Networks, Transformers, Generative Adversarial Networks, Graph Neural Networks, and Diffusion Models. Considering the particular representations of weather and climate data, we focus on spatio-temporal graphical neural networks in our discussion of GNNs.

### 4.1 Recurrent Neural Networks
Recurrent Neural Networks [111] (RNNs) are a neural network architecture specialized in processing sequential data. In RNNs, information is passed on all the time, enabling the RNN to utilize previous information to influence subsequent outputs. RNNs are fundamental modules in deep learning and are widely used in language modeling [112], [113], [114], time series analysis [98], [115], [116], and many other sequence-related tasks. RNNs have also pioneered the use of deep learning techniques to deal with weather and climate modeling [97]. The update rule for a general RNN can be expressed as:
ht = σ(Whxt + Uhht−1 + bh), (1)
where ht is the hidden state at t-th time step, xt is the input at t-th time step, Wh and Uh are the weight matrices, bh is the bias, and σ is a nonlinear activation function such as tanh or ReLU.

However, ordinary RNNs often encounter the problems of gradient vanishing and gradient explosion in practice, making it difficult to handle long sequences. To solve this problem, some improved RNN structures have been proposed, such as Long Short-Term Memory [99] (LSTM) and Gated Recurrent Unit [117] (GRU). ConvLSTM [97] and ConvGRU [97] are variants that introduce convolutional operations into LSTM and GRU, allowing them to process spatially structured data such as images or videos, they usually have utilized to process weather spatio-temporal series data such as radar echo or satellite image sequences. In these models, fully connected operations are replaced by convolutional operations. For example, the update rule of ConvLSTM can be expressed as:
ft = σ(Wxf ∗ xt + Whf ∗ ht−1 + bf )
it = σ(Wxi ∗ xt + Whi ∗ ht−1 + bi)
ot = σ(Wxo ∗ xt + Who ∗ ht−1 + bo)
˜Ct = tanh(Wxc ∗ xt + Whc ∗ ht−1 + bc)
Ct = ft ◦ Ct−1 + it ◦ ˜Ct
ht = ot ◦ tanh(Ct)
(2)
where ft, it, ot, and ˜Ct are forgetting gates, input gates, output gates, and candidate memory cells, respectively, ∗ denotes the convolution operation, and ◦ denotes the Hadamard product. The ConvGRU update rules can be represented as follows:
rt = σ(Wxr ∗ xt + Whr ∗ ht−1 + br)
zt = σ(Wxz ∗ xt + Whz ∗ ht−1 + bz)
˜ht = tanh(Wxh ∗ xt + rt ◦ (Whh ∗ ht−1) + bh)
ht = (1 − zt) ◦ ht−1 + zt ◦ ˜ht
(3)
where rt and zt are the reset and update gates, respectively. These gating mechanisms allow ConvGRU to handle long time dependencies more efficiently. These formulas show that ConvGRU first computes the reset and update gates at each time step, then computes the candidate hidden state˜ht, and finally computes the new hidden state ht. The update gate zt plays a role in determining how many new candidate hidden states to use when computing new hidden states.

### 4.2 Diffusion Models
Diffusion Models (DMs) [118], [119] have achieved promising achievements in extensive applications across a range of fields including computer vision [109], [120], [121], [122], natural language processing [123], [124], [125], due to their efficacy in emulating intricate, high-dimensional data distributions. DMs comprise a category of probabilistic generative models and the core of these lie the principles of diffusion process, which are stochastic procedures delineating the continuous stochastic motion of particles over time. At the core of these models lie the principles of diffusion processes, which are stochastic procedures delineating the continuous stochastic motion of particles over time. These processes model spatial or temporal diffusion wherein particles incline towards transitioning from zones of high concentration to those with lower densities, facilitating a gradual assimilation or blending of quantities. The principal concept involves conducting a sequence of diffusion steps, with each step updating the data’s probability distribution. This is accomplished by incorporating Gaussian noise into the current data samples and iteratively refining them. The noise addition in each diffusion step perturbs the data points, and the iterative refinement guides these perturbed points to gradually converge to the target distribution. This iterative process is akin to a random walk in the data space, where the random perturbations, guided by the model, eventually lead to the generation of new data points following the target distribution.

Mathematically, a diffusion model describes a Markov chain that begins with the data and ends with noise. Let’s denote the data as x and the noise as z. The Markov chain has the following form:
xt = sqrt((1 − dt)) * x(t − 1) + sqrt(dt) * zt (4)
where zt is sampled from a standard Gaussian distribution, dt is a small time step and t is the current step. The goal of the diffusion model is to learn the reverse transition of this Markov chain, i.e., to generate data from noise. This is done by estimating the conditional distribution p(x(t − 1)|xt) and sampling from it. With enough steps, the chain will transform the noise z into the data x.

### 4.3 Transformers
Transformer is a DL model and has become a key infrastructure for existing state-of-the-art (SOTA) large models applied to NLP and other sequence-to-sequence tasks (i.e., weather forecasting) [126]. The key to this is its ability to handle dependencies between any part of the input sequence and any part of the output sequence without having to rely on the order of the sequences as in RNNs [127]. Vanilla Transformer utilizes an encoder-decoder architecture, where both the encoder and decoder are comprised of a series of stacked blocks. Each Transformer layer is composed of a self-attention layer and a fully-connected feed-forward network (FFN). Additionally, the decoder block incorporates an additional cross-attention layer on top of the self-attention layer to capture information from the encoder. To facilitate information flow and alleviate the vanishing gradient problem, residual connections [128] and layer normalization modules are implemented between each layer.

Multi-Head Self-Attention. At the heart of the Transformer architecture lies in the self-attention mechanism. This mechanism plays a pivotal role in capturing relationships within an input sequence. It accomplishes this by calculating attention scores for each element in the sequence in relation to the other elements. These scores are then utilized to assign weights to the input sequence, resulting in the generation of a new weighted sequence. The formula for the self-attention mechanism is as follows:
H = Attention(Q, K, V) = softmax( Q K^T / sqrt(dk) ) V, (5)
where the dk denotes the dimension of the key, Q ∈ Rn×dk, K ∈ Rm×dk, V ∈ Rm×dv are the query matrix, key matrix and value matrix respectively, which are linear transformations of the same input sequence X ∈ Rn×d (or feature matrix from the previous layer) based on three weight matrices Wq ∈ Rd×dk, Wk ∈ Rd×dk, Wv ∈ Rd×dv, as Q = XWq, K = XWk, V = XWv, (6) The attention score is obtained by computing the dot product of the query matrix and key matrix, then dividing by sqrt(dk) for scaling, and finally normalizing by softmax.

Transformer uses multi-head self-attention with multiple sets of Q(i), K(i), V(i), each set corresponding to a distinct set of linear transformation matrix W(i) q ∈ Rd×dk, W(i) k ∈ Rd×dk, W(i) v ∈ Rd×dh, where dh is set to dv / h, h is the number of heads. The final output of the multi-head self-attention is obtained by projecting the concatenation of a series of Hi into a new feature space with a new weight matrix Wproj ∈ Rdv×dproj, as follows:
H = Multi-Head Self-Attention(Q, K, V) = Concat(H1, H2, ..., Hh) Wproj, Hi = Attention(Q(i), K(i), V(i)). (7)

For decoder, there is an additional mask mechanism that prevents query vectors from attending to the future positions yet to be decoded. In addition, an extra cross-attention following the self-attention, where the Q is derived from the output of the previous layer in the decoder, and the K and V are transformed from the output of the last layer of the encoder. It is designed to avoid foreseeing the true label while considering information from the encoder when encoding.

Fully-connected Feed-Forward Layer. Fully-connected feed-forward Layers following the attention layer is consists of linear transformation and a non-linear activation function. Denote the input matrix X ∈ Rn×di, the output of the feed-forward layer is
F = FFN(X) = σ(W1X + b1) + b2, (8)
where σ(·) presents the activation function, and W1 ∈ Rdi×dm, b1 ∈ Rdm, W2 ∈ Rdm×do, b2 ∈ Rdo are all learnable parameters.

Residual Connection and Normalization. Following each attention layer and each feed-forward layer, residual connection and layer normalization are applied. They conduct to retaining information when the model is considerably deep and thus guarantees the model performance. Formally, given a neural layer f (·), the residual connection and normalization layer is defined as
Add & Norm(X, f) = LayerNorm(X + f (X)). (9)

Transformer Layer. The design of the Transformer model enables parallel processing of the entire sequence, eliminating the need for sequential processing of elements as in RNNs. This parallel processing enhances its efficiency in handling long sequences. By utilizing a multi-layer self-attention mechanism, the Transformer model effectively captures long-distance dependencies in sequences, which is crucial for tasks involving translation, summarization, and other sequence-to-sequence operations.

### 4.4 Generative Adversarial Networks
Generative Adversarial Networks (GANs) [108] aim to train a generative model via adversarial processes, it have widely used to image generation [29], [129], [130], super-resolution [131], [132], style transferring [133], [134], and image-based weather forecasting [135]. The fundamental concept of GANs involves training two NNs adversarially: a Generator G and a Discriminator D. The objective of the Generator G is to learn the underlying data distribution and generate novel samples accordingly. The discriminator (D)’s objective is to differentiate between the samples generated by the generator and the real samples. During training, the generator aims to produce samples that can effectively fool the discriminator, while the discriminator strives to enhance its ability to differentiate between real and generated samples. This process can be regarded as a two-player zero-sum game, ultimately leading to an equilibrium where the discriminator cannot distinguish between the generator-generated samples and the real samples.

The objective function of GANs can be expressed as the following optimization problem:
min_G max_D V(D, G) = Ex∼pdata(x)[log D(x)] + Ez∼pz(z)[log(1 − D(G(z)))], (10)
where x is a sample from the true data distribution pdata, z is a sample from some a prior noisy distribution pz, G(z) is the sample generated by the generator using the noisy sample z, and Dx is the discriminator’s estimate of whether the sample x (either the true sample or the generated sample) is the true sample. Training of GANs typically involves alternately optimizing two of this objective function. First, the generator is fixed and the discriminator is optimized. Then, fix the discriminator and optimize the generator. This process is repeated until some equilibrium is reached, at which point the samples generated by the generator should be indistinguishable from the true samples by the discriminator.

### 4.5 Spatio-Temporal Graph Neural Networks
Spatio-Temporal Graph Neural Networks (STGNNs) [106] is a concept in machine learning that combines spatial and temporal information using graph structures. It is particularly useful for analyzing data with both spatial and temporal dependencies. In STGNN, the basic concept involves representing the data as a graph, where each node represents a spatial location and the edges capture the spatial connectivity. Additionally, each node also contains temporal information, representing the state of the variable at different time steps.

Spatial Graph Structure. Let G = ( V, E) be the graph representing the spatial connections, where V is the set of nodes representing spatial locations, and E is the set of edges representing the spatial relationships. Each node vi represents the feature vector xi of the corresponding location i.

Temporal Information. Let X = xt i be the set of feature vectors for all locations at time t. Each feature vector xt i represents the state of the variable at location i and time t.

Spatio-temporal Graph Convolution. STGNN incorporates both spatial and temporal information through graph convolution operations, which capture the relationships between variables at different locations and time steps. The spatio-temporal graph convolution can be represented as:
ht+1 i = f ( Σ j∈N (i) wij · ht j + bt i ). (11)
Here, ht+1 i represents the updated feature vector of node i at time t + 1, N (i) denotes the set of neighbors of node i, capturing the spatial connections between locations, wij represents the weight between node i and its neighbor j, indicating the strength of their relationship, ht j represents the feature vector of the neighboring node j at time t. bt i is a bias term for node i at time t. f (·) represents an activation function, such as ReLU or Sigmoid, applied element-wise to the sum of weighted inputs. The spatio-temporal graph convolution operation combines the spatial connectivity and temporal dependencies to effectively capture the evolving patterns and relationships in the data.

## 5 OVERVIEW AND CATEGORIZATION
In this section, we provide an overview and categorization of DL models for weather and climate. Our survey is structured along three main dimensions: data types, model architectures, and application domains. Based on the scope of application, we primarily divide the existing literature into two main categories: Large Foundation Models and Task-Specific Weather and Climate Models. Considering the task generality of weather/climate foundation models, we discuss them at a high level without further subdivisions. For task-specific weather/climate models, we categorize them based on specific underlying architectures to facilitate readers in indexing and referencing specific works according to model architectures, including Recurrent Neural Networks, Generative Adversarial Networks, Transformers, Diffusion Models, and Graph Neural Networks. Subsequently, at the application level, we divide the existing literature into two main categories based on specific data categories: Time Series for Weather and Climate and Text for Weather and Climate. In the first category, we further dissect the existing literature into six primary classes predicated on the domains of application: Forecasting, Precipitation Nowcasting, Downscaling, Data Assimilation, Bias Correction, and Weather Pattern Understanding. For the second category, we explore it as a general subject (Climate Text Analysis), refraining from subdividing it into different subtasks. This is because these often originate from pre-trained LLMs, and the specific task characteristics are typically delineated based on downstream datasets rather than the model itself.

## 6 MODELS FOR WEATHER & CLIMATE
In this section, we will delve into the advancements of Foundation Models and Task-Specific Models for weather and climate data understanding. A categorization of representative methods and detailed information can be found in Table. 3.

### 6.1 Foundation Models for Weather & Climate
The burgeoning development of foundation models in NLP [47], [82], [200] and CV [45], [46] has piqued research interest in foundation models for weather and climate data understanding. Large Foundation Models, created through pre-training strategies, can substantially enhance the generalization capability of AI-based climate models and can be fine-tuned for specific downstream tasks. Pre-training of such models necessitates large-scale sequence data, not typically sourced from ordinary time-series data.

Mindful of computational efficiency and the demand for timely climate predictions, Pathak et al. proposed FourCastNet [136], a climate pre-trained foundation model based on Vision Transformer and Adaptive Fourier Neural Network Operator (AFNO) [201], for high-resolution predictions and rapid inference. Its training process consists of self-supervised pre-training and autoregressive fine-tuning based on the pre-trained model. PanGu-Weather [63], a data-driven model leveraging the 3D Earth-specific Transformer, is notable for its swift, precise global predictions and superior performance. It predicts atmospheric states over time based on the current state, described by five upper-air variables and four surface variables on a 0.25° horizontal grid with 13 vertical layers for the upper-air variables. On the other hand, ClimaX [25] introduces the concept of fundamental modeling to weather prediction with its fully supervised pre-training based on the Transformer. It proposes variable disambiguation and variable aggregation strategies for merging and revealing potential relationships between different weather variations at various altitudes, offering promising flexibility for adapting to diverse downstream tasks, including global/regional/seasonal forecasting, climate mapping, and downscaling tasks. FengWu [138] tackles the medium-term forecasting problem from a multimodal, multitask perspective with a uniquely designed deep learning architecture. It features a model-specific decoder and a cross-modal fusion Transformer that balances the optimization of different predictors in a regionally adaptive manner under the supervision of uncertainty loss. Given that the aforementioned large-scale models are trained via a fully supervised approach, W-MAE [64] implements unsupervised training of weather prediction models using a Masked Auto-Encoder (MAE)-based [202], [203] approach, which can be fine-tuned for downstream tasks through various data sources. MetePFL [24] and FedWing [154] also propose a Prompt-based federated learning [204] for training large foundation models, considerably reducing the cost of collaborative model training across regions while safeguarding data privacy. The rapid advancement of LLMs has led to the processing of weather and climate tasks that are no longer restricted to visual or time-series models. OceanGPT [197], based on LLMs, proposes a methodology for processing a wide range of ocean-related tasks. Beyond the foundation models used for forecasting and simulation, ClimateBert [195] is an NLP-based foundation model for processing climate-related texts. It is trained on over 2 million climate-related paragraphs from diverse sources such as news articles, research papers, and company climate reports [205].

### 6.2 Task-specific Models for Weather & Climate
In the realm of weather and climate analysis, task-specific models have been utilized for a myriad of specific tasks. This section will delve into the progress made in task-specific models for weather and climate, focusing on these principal architectures: RNNs, Transformers, GANs, Diffusion Models, and Graph Neural Networks (GNNs).

• Recurrent Neural Networks (RNNs). RNNs serve as the backbone of numerous weather forecasting models [85], [97], [145], [175], [206], [207], [208], [209], [210], [211], [212], [213]. In addition to weather and climate prediction models built on RNN architectures, hybrid models fusing RNN with other mechanisms have also gained traction [146], [147], [214], [215], [216], [217]. For instance, the amalgamation of Swin Transformer [218] with RNN has given birth to models like SwinLSTM [147], which capitalize on the advantages of both architectures. Moreover, the fusion of SwinRNN with generative models has led to models for the diffusion model SwinRDM [146] and for GAN [216], [217]. Added to this, physical-informed based approaches have been introduced [219]. Concurrently, with the evolution of Transformer-based spatio-temporal extraction, the integration of RNN architecture and Transformer models to address this problem has been on the rise [214], [215].

• Diffusion Models. Standard diffusion models, comprising forward noisy processes and backward denoising processes, are widely employed for learning data distribution and generating data representations in meteorological and climatic contexts [146], [147], [150], [152], [177], [220], [221], [222], [223], [164], [224]. For instance, SwinRDM [146] amalgamates SwinRNN [147] and diffusion models to attain high-resolution weather forecasting. However, it is important to note that the application of diffusion models in weather and climate studies is still in its nascent stage.

• Generative Adversarial Networks (GANs). GANs have widely used in image generation tasks, ranging from generating handwritten digits [225] to generating large-scale image datasets [226], [227]. They are commonly employed in weather and climate tasks for spatiotemporal video stream prediction [228], [229], aiming to generate realistic and temporally coherent sequences and match high-dimensional data distributions between them. Therefore, GAN-based architecture is common in weather and climate prediction tasks aims to generate predicted future frames like ground-truth as same as possible [84], [230], [231], [232], [167], [170], [216], [217], [233], [234], [235], [236], [237], [238], [239]. Additional physical constraints are often introduced to improve the accuracy of weather and climate modeling in these hybrid models [229], [240], [241], [242], [243], [244], [245], [246], [247], [248].

• Transformers. Transformer-based models are widely used for tasks related to time series analysis due to its powerful long series modeling capabilities, which also include responding to weather and climate change [149]. It focuses on short-term/long-term forecasting tasks in weather and climate applications and can be categorized into two types, the former focusing on one-/two-dimensional forecasts of weather and climate, such as predicting trends in relevant weather variables globally or regionally on single atmosphere level, and the latter focusing on multidimensional forecasts, such as extrapolations based on radar-echo imagery [249], satellite cloud images [250] and multi-layer atmosphere status, thus contributing to the understanding of weather patterns in the region. For the first category, the Transformer is used to perform short- and long-term forecasts, modeling dependencies on variables at different points in time through positional coding as well as self-attention mechanisms [178], [251], [252], [253], [254], [255]. As for the second category, Transformers are expected to establish complex multi-layered spatio-temporal relationships of meteorological variables at different atmospheric pressures, and the results of this type of Transformer are usually challenged based on the characteristics of the data itself (atmospheric pressures, spatio-temporal correlations, variable correlations), and so on [25], [63], [64], [138], [148]. Inspired by the fields of NLP and CV, the Transformer structure has also been redesigned for the development of large-scale weather and climate foundation models [25], [63], [138]. In addition, in the field of NLP-based climate text analysis, Transformers is a general architecture [196], [196], [198], [199], [256], [257], [258], [259].

• Graph Neural Networks. In the field of weather and climate, numerous studies have explored the application of graph neural networks, particularly spatial-temporal graph neural networks, due to their ability to establish potential spatial-temporal relationships of the Earth system [181]. Two common applications include spatial-temporal sequence prediction [137], [142], [143], [144], [183], [184], [221], [260], [261], [262], [263], [264], [265] and spatial-temporal video stream prediction in weather forecasting [168]. In spatial-temporal sequence prediction, graph neural networks are used to model the spatio-temporal dependencies and correlations in weather data. This involves predicting future weather conditions based on historical observations at different locations [24], [154]. The graph structure is used to capture the spatial relationships between nodes, and the temporal dependencies are modeled using recurrent [264], [265] or convolutional layers [144], [183]. In spatial-temporal video stream prediction, graph neural networks are employed to predict future weather conditions in the form of video-like sequences [168]. This involves predicting the evolution of weather patterns over time, taking into account both spatial and temporal dependencies.

## 7 APPLICATIONS
This section presents an overview of prevalent DL models, categorized by their applications in weather and climate analysis. These applications include forecasting, precipitation nowcasting, downscaling, bias correction, data assimilation, climate text analysis, and weather pattern understanding.

### 7.1 Forecasting
Accurate weather and climate forecasting is critical for environmental and societal planning. Significant strides have been made in developing robust DL methods that model the nonlinear associations between historical and future weather patterns. This section mainly focuses on discuss the advancement in the task of weather and climate forecasting based on time series and spatio-temporal series. The most common in such tasks are RNNs-based architecture, which are widely used due to their autoregressive (AR) architecture [145], [146], [147], [212], [213]. For instance, DWFH introduces conductive long and short-term memory models to enhance data-driven deep weather prediction models [145]. Ref. [212] merges the LSTM and an adaptive neuro-fuzzy inference system (ANFIS) for atmospheric pressure forecasting. SwinRDM introduces the SwinRNN as a fundamental component for high-resolution weather forecasting [146], and diffusion models to achieve high-resolution weather forecasting at 0.25 degrees using a two-step training strategy: first, cyclic prediction of future atmospheric fields is performed at low resolution, followed by high-resolution and fine-grained atmospheric detail reconstruction based on the diffusion-based super-resolution model. Moreover, SWINVRNN employs a Recurrent Neural Network-based architecture with variations loss to improve long-lead weather forecasts [147]. In addition, Transformer, especially Vision Transformer, is also widely used in weather and climate prediction based on spatio-temporal series due to its bright performance in modeling potential representational associations between image regions using Patch mechanism and self-attention mechanism. FourCastNet [136] delivers impressive performance in various weather forecasting tasks using 0.25° resolution. This achievement is based on the Vision Transformer (ViT) [266] and Adaptive Fourier Neural Network Operators (AFNO). PoET [148] introduces hierarchical ensemble transformers to enhance medium-range ensemble weather forecasts on a global scale. TeleViT [153] integrates fine-grained local-scale and global-scale inputs, treating the Earth as one interconnected system for seasonal wildfire forecasting. Large models came out of nowhere when considering the ultra-large-scale, high-resolution global medium-term forecasting task. PanGu-Weather [63], a data-driven model based on 3D Earth-specific transformers, is lauded for its rapid and accurate global forecasts. This model predicts the atmospheric state at a given time based on the current state, described by five upper-air variables on a 0.25° horizontal grid and four surface variables, with 13 vertical levels for the upper-air variables. Feng Wu [138] addresses the medium-range forecasting problem from a multi-modal, multi-task perspective, with its elaborate deep learning architecture with model-specific decoders and cross-modal fusion transformers that learn under the supervision of uncertainty loss to balance the optimization of different predictors in a regionally adaptive manner. FuXi [139] cascades cubic embeddings and U-transformers and is trained using 39 years of high-resolution in-analysis data. It delivers forecast performance comparable to that of the ECMWF EM with a temporal resolution of 6 hr and a spatial resolution of 0.25° in a 15-day forecast. The FuXi-Extreme model [155] employs a denoising diffusion probabilistic model (DDPM) [118] to refine the surface forecast data generated by the FuXi model [139] in 5-day forecasts, thereby enhancing extreme rainfall/wind forecasting. As an all-purpose foundation model, ClimaX [25] introduces the concept of foundation modeling to the field of weather prediction, with its fully supervised pre-training based on the Transformer, and proposes variable tokenization and variable aggregation strategies for fusing and mining the potential relationships of different weather variations at different heights, which gives it very promising flexibility to adapt to different downstream tasks, including global/regional/seasonal prediction, as well as the tasks of climate mapping, and downscaling. While the aforementioned models are trained in a fully supervised-based pre-training, W-MAE [64] leverages a Masked Auto-Encoder (MAE)-based approach [202], [203] for self-supervised training in weather forecasting models, potentially allowing fine-tuning by different data sources to adapt to downstream tasks.

Generative AI are carving a niche in the field of climate and weather forecasting, with several promising approaches recently reported. SEEDS [150], for instance, employs an array of finely-tuned ensemble simulators to generate probabilistic weather forecasts. These forecasts are akin to the “seeds“ of weather states provided during the inference process, with two different ensemble simulators generating two distinct event predictions. However, the self-regression mechanism underpinning this approach, similar to the RNN architecture used in diffusion model training, is susceptible to instability and feature dissipation over time, particularly in long-range forecasting tasks. Contrastingly, Dyfussion [151] uses pristine initial conditions, while the PDE-Refiner [222] enhances the diffusion process-based predictions by iteratively observing them to capture low-amplitude information that may not be immediately evident in the data. DITTO [152] adopts a unique approach, generating a continuous interpolation between the initial and final time steps, and using time fireworks instead of incremental noise in the forward process. TemperatureGAN [242], a conditional GAN, considers factors such as the month, location, and time period to generate atmospheric temperature predictions at an hourly resolution above ground level. Furthermore, GANs that integrate physical information constraints are being deployed to emulate ocean systems, thereby enhancing climate prediction capabilities [244], [245], [246], [247], [248]. For instance, Refs. [244], [245] describe GAN-based models that learn underlying physical relationships between surface and subsurface temperatures in numerical models. Subsequent calibration of model parameters using observational data leads to enhanced predictions. PGnet [248] is a generative neural network model that uses a mask matrix to identify regions of low-quality prediction generated during the initial physical stage. The generative neural network then uses this mask as a prior for the second stage of fine prediction. WGC-LSTM [260] harnesses graph convolutions to capture spatial relationships and amalgamates these with LSTM to concurrently consider both spatial and temporal relationships.

Reflecting upon the intricate interconnections between atmospheric elements, surface variables, and precise terrestrial coordinates within the Earth system, a substantial amount of research has utilized graph-based methodologies for weather and climate prediction tasks. For instance, Keisler Graph Neural Network [142] leverages a graph neural network architecture [267] to achieve weather forecasting. It uses an encoder that maps the original 1° latitude/longitude mesh to an icosahedral mesh, performs message passing computations on this mesh, and then decodes back into latitude/longitude space. GraphCast [137], on the other hand, also utilizes a GNN-based framework for weather prediction, albeit with a much higher resolution and flexibility. It stands as the inaugural large-scale foundation model for weather and climate predictions based on graph methodology. Graphino [140], a globally spatial GNN, is specifically designed for seasonal forecasting tasks, including prediction of the El Niño-Southern Oscillation (ENSO) phenomenon [268]. The model begins by constructing an initial graph with grid cells as nodes and learns the edges based on the connectivity between geographical locations. In addition, GE-STDGN [143] employs a graph structure learning and optimization method underpinned by the evolutionary multi-objective optimization (EMO) algorithm known as graph evolution [269]. This augments the model’s ability to analyze intricate node correlations for spatio-temporal weather sequence prediction. HiSTGNN [144] features an adaptive graph learning module that builds a self-learning hierarchical graph [270]. This graph is comprised of a global graph that represents region-specific information and a local graph that encapsulates meteorological variables within each region. The model effectively identifies hidden spatial dependencies and diverse long-term weather patterns using graph convolution and gated temporal convolution with a dilated initial as its core structure. Lastly, WeKG-MF [261] presents an innovative approach by constructing a knowledge graph from open weather observations published by Météo-France. This model is built upon a semantic schema that encapsulates the knowledge of meteorological observations for an array of downstream scenarios.

### 7.2 Precipitation Nowcasting
The domain of precipitation nowcasting has garnered substantial advancements through the application of DL techniques, including CNNs [84], [271], [272], [273], [274], RNNs [85], [97], [238], [274], [276], [277], and Transformers [107], [166], [171], [173], [176], [278]. These methodologies have demonstrated remarkable proficiency in managing spatio-temporal data, a prevalent format in Earth system observation.

ConvLSTM [97] was pioneering in its integration of deep learning for processing precipitation proximity forecasts, effectively amalgamating CNN and LSTM to manage spatio-temporal radar data. Successive models, such as PredRNN [209] and E3D-LSTM [210], similarly incorporate spatio-temporal data within LSTM and CNN architectures to extract long-term higher-order correlations. PhydNet [279] introduces partial differential equation (PDE) [280] constraints into its theoretical space. MetNet [165] and its subsequent iterations, MetNet-2 and MetNet-3 [281], proposed an architecture based on ConvLSTM and advanced CNNs, thereby enabling proficient precipitation forecasting up to 12 hours ahead.

The ascension of Transformers in the visual realm has benefited the spatio-temporal video streaming data-based approach to rainfall prediction. For instance, PTCT [173] divides original frames into multiple patches to eliminate inductive bias constraints. It also applies 3D temporal convolutions to effectively capture short-term dependencies. The Preformer [176] model proposes an encoder-translator-decoder architecture where the encoder integrates spatial features from multiple elements, the translator models spatio-temporal dynamics, and the decoder combines temporal and spatial information for future precipitation prediction. Rainformer [171] introduces global feature extraction units and gate fusion units (GFUs) to balance the fusion of local and global features, thereby enabling efficient rainfall prediction. TEMPEE [107] proposes a parallel use of spatio-temporal encoders and decoders based on the Transformer architecture, achieving promising results in the egoless regression strategy for handling non-stationary spatio-temporal sequences. This significantly improves the accuracy of precipitation nowcasting. EarthFormer [172], based on Cuboid Attention, is utilized for Earth system forecasting, including precipitation nowcasting and ENSO [282].

Taking into account the instructive role of knowledge from other modes, multimodal spatial-temporal tasks have been introduced [174], [175], [276]. The MM-RNN [174] introduces elemental knowledge to guide precipitation nowcasting, enforcing a constraint that requires the movement of precipitation to follow basic atmospheric laws of motion for accurate forecasting. STIN [175] utilizes spatio-temporally specific filters to generate precipitation forecasts from multimodal meteorological data. Recently, precipitation nowcasting, viewed as an uncertainty assessment problem, has also benefited from the successful application of diffusion modeling.

Recently, precipitation nowcasting, viewed as an uncertainty assessment problem, has also benefited from the successful application of generative modeling. DGMR employs an adversarial training methodology to generate sharp and accurate proximity forecasts, which solves the problem of fuzzy prediction. DMSF-GAN [84], on the other hand, completely eschews autoregressive strategies and is based on adversarial training and pure CNN architectures to address the problem of feature dispersion over time. PCT-CYCLE GAN [170] generates temporal causality using two generator networks with forward and backward temporal dynamics. Each generator network learns a multitude of one-to-one mappings on precipitation data based on time-dependent radar to approximate a mapping function representing the temporal dynamics in each direction. The MPL-GAN [167] utilizes a multi-path learning strategy to improve the diversity of generated sequences while providing accurate predictions. In addition, to simultaneously handle uncertainty and enhance domain-specific standards, PreDiff [177] adopts a two-stage probabilistic spatiotemporal prediction pipeline, incorporating explicit knowledge control mechanisms to enforce predictions conforming to specific domain’s physical constraints. This is achieved by estimating the bias of the constraints imposed in each denoising step and correspondingly challenging the overfitting distribution. GED [169], known as Generative Ensemble Diffusion, utilizes a diffusion model to generate a set of possible weather scenarios which are then amalgamated into a probable prediction via the use of a post-processing network. Ref. [231] utilizes radar-based deep learning models for skillful short-term precipitation forecasting, achieving display-consistent predictions over a 1536x1280 km region.

The introduction of physical constraints and graph relations can improve the efficiency and accuracy of the model. Ref. [240] introduces a generative adversarial network with physical information constraints to improve both local distribution and spatial structure for daily precipitation field improvement. CNGAT [168] fuses spatial and temporal information for improved Radar quantitative precipitation estimate (RQPE) [283]. The precipitation estimation area was partitioned into subareas that were treated as nodes to form an input graph. All nodes were then categorized according to the temporal mean radar reflectivity for precipitation estimation with an attention mechanism.

### 7.3 Downscaling
Achieving precise, fine-grained weather predictions necessitates high spatial resolution data. However, most global weather forecasting models are restricted by the availability and scale of data, resulting in an over-reliance on data with approximately a 5.625° spatial resolution, equivalent to a grid point spacing of about 625 kilometers. Despite these limitations, the data volume is significant. For instance, the data scale of the ERA5 system at a 0.25° spatial resolution is several tens of times larger—around 15 terabytes—compared to the 5.625° spatial resolution data. High spatial resolution data offer a more granular representation of complex atmospheric processes and the interplay between different weather systems. One strategy to tackle this issue is the enhancement of weather data’s spatial resolution, a process referred to as super-resolution (SR) [284], [285]. SR can bolster the resolution of gridded data, surpassing conventional interpolation methods in effectiveness.

A popular DL-based SR model, U-Net, leverages a synergistic encoder-decoder structure to produce high-resolution outputs from low-resolution inputs [286], [287], [288]. Within the realm of semi-supervised learning, generative adversarial networks (GANs) have demonstrated potential in enhancing the representation of more intricate structures and details [164], [217], [236], [237], [289], [290], [291], [292]. The typical procedure involves training the generator to learn the potential mapping between low- and high-resolution grid data or images. For example, Stengel et al. presented an adversarial DL approach that super-resolves the predictions of wind speed and solar irradiance in global climate models to a sufficient scale for renewable energy resource assessment, thereby improving the resolution of wind and solar energy data nearly fiftyfold [292].

Recent research has deployed diverse strategies such as normalizing flows and neural operators. Self-supervised learning-based methods have also been investigated for downscaling low-resolution grid weather data. For instance, the pre-trained foundation model, ClimaX [25], allows fine-tuning for resolution downscaling. González et al. introduced a downscaling strategy based on multi-variable physical hard constraints, ensuring the physical relationships between variable sets [161].

Physics-constrained DL-based methods have also been proposed to improve the model’s performance via external adjustment [156], [157], [158], [162], [163], [293], [294]. For example, MeshfreeFlowNet [156] employs a physics-informed model which incorporates Partial Differential Equations (PDEs) as regularization terms into the loss function, achieving spatio-temporal downscaling. Harder et al. [158] were the first to apply hard-constraining to achieve fine-grained downscaling outputs in climate change datasets. Furthermore, strategies such as contrastive learning [285] and Bayesian DL models [159] were adopted.

In response to the lack of interpretability of DL-based downscaling methods, Gong et al. explored the interpretability of fundamental CNNs in climate model downscaling strategies, thus paving the way for trustworthy artificial intelligence in downscaling models [273]. Bano et al. analyzed the downscaling issue from a multimodel perspective, developing a CNN-based downscaling prediction ensemble (DeepESD) for temperature and precipitation in the European EUR-44i (0.5°) domain based on eight global circulation models [160]. This represents the first application of CNNs in generating a downscaled multimodel ensemble based on perfect prognosis methods, allowing for the quantification of model uncertainty in climate change signals.

The introduction of uncertainty modeling also allows downscaling gains in DL-based models, significantly improving efficiency as well as reconstruction resolution. ResDiff [164] employs a two-step diffusion model-based approach. In the first step, U-Net regression predicts the mean values, while in the second step, the diffusion model predicts the residuals, thereby achieving kilometer-scale atmospheric downscaling. However, it should be noted that the use of diffusion models in the field of weather and climate is still in the exploratory stage. Ref. [223] also employs similar operations, utilizing diffusion models for cloud cover and super-resolution diffusion models for high-resolution solar energy forecasting.

### 7.4 Bias Correction
Bias correction in weather predictions has traditionally relied on statistical methods [186]. Over time, these techniques have evolved, embracing machine learning strategies such as Deep Belief Networks and Support Vector Machines. The advent and proliferation of data availability have further catalyzed the shift towards deep learning methodologies, including Long Short-Term Memory (LSTM) [187], [188], [189] and Convolutional Neural Networks (CNN) [185], [190], [191]. These methodologies have been instrumental in mitigating common weather-related biases.

A notable approach is the DL-Corrector-Remapper technique [192], which stands apart in its ability to correct, remap, and fine-tune gridded uniform forecasts from the FourCastNet system. This process enables a direct comparison with non-uniform, sparse observational ground truth data via the AFNO method. The Super Resolution Deep Residual Network (SRDRN) [191] has been employed for climate downscaling and bias correction. This network utilizes stacked general circulation models and extracts spatial features, effectively diminishing biases and correcting spatial dependencies relative to observational data.

In an intriguing application, the Unsupervised Image-to-Image Translation (UNIT) network [193] capitalizes on unpaired image translation for bias correction. This method offers a novel perspective on bias mitigation. Hess et al. [240] have proposed a post-processing technique that employs a physics-constrained Generative Adversarial Network (cGAN) to concurrently correct biases in local frequency distribution and spatial patterns of state-of-the-art CMIP6-level Earth System Models.

Recently, the WeatherGNN model [194] has been developed, which leverages a Graph Neural Network within a comprehensive framework. This model learns the intricate relationships between weather and geography, capturing meteorological interactions and spatial dependencies between grids. This approach provides a robust and sophisticated tool for bias correction. These advancements illustrate the potential of deep learning methodologies in refining weather prediction systems.

### 7.5 Data Assimilation
Data assimilation (DA) is a key component of high-level NWP systems. These systems not only forecast future states, but also integrate observational data to establish the initial state, guiding the model’s trajectory to future states. This complex process is computationally demanding, making it an active area of research. Existing approaches often rely on simplifying assumptions, such as linearity, which adds to the challenges in the field. However, the integration of deep learning into DA is gaining recognition, with encouraging research outcomes. For instance, OceanFourCast [149] employs neural operators alongside a Transformer-based architecture, inspired by FourCastNet [136], to support adjoint-based data assimilation in ocean modeling. Furthermore, Bocquet et al. [295] innovatively combine DA, machine learning, and expectation maximization to perform Bayesian inference of chaotic dynamics, enabling the assimilative reconstruction of observational data for geophysical flows. For an in-depth review of DA, we refer readers to Geer’s work [296].

### 7.6 Climate Text Analysis
The rapid development of LLMs has provided new insights for climate text analysis. Hershcovich et al. introduced a climate performance model card, designed with the intent of practical application requiring minimal information on the experimental setup and associated computer hardware [297]. A language model, known as ClimateBert [195], was developed with a foundation in DistilRoBERTa, specifically designed for analyzing climate-orientated text. This versatile model can be employed in a variety of tasks, such as detecting climate-related content, discerning sentiment in climate-related paragraphs, identifying commitment and action-related content, distinguishing specific from non-specific climate-related text, and assigning climate-related content to one of four categories as per the recommendations of the Task Force on Climate-related Financial Disclosures (TCFD). Further refinement of ClimateBert is seen in the work of Garrido-Merchán et al. [199], who utilized ClimaText [205] to fine-tune the model for the specific task of analyzing disclosures relating to financial risks connected with climate change. An extension, ClimateBert-NetZero [198], was designed to classify whether a given text contains a net zero or reduction target. Krishnan et al. employed ClimateBert in their Climate NLP project, analyzing public sentiment towards climate change using data gathered from Twitter and Facebook [257]. Auzepy et al. proposed the use of pretrained LLMs’ zero-shot capabilities to evaluate TCFD reporting [258]. However, this approach is not without its challenges. Pre-trained LLMs often lack up-to-date information and tend to use imprecise language, a significant disadvantage in the field of climate change where accuracy is paramount. To mitigate this, Kraus et al. incorporated emission data from ClimateWatch and utilized a general Google search to enhance the language model [259]. Vaghefi et al. integrated information from the Intergovernmental Panel on Climate Change’s Sixth Assessment Report (IPCC AR6) into GPT-4 [298], laying the groundwork for the implementation of conversational AI in the realm of climate science [256]. In the intersection of climate and health, CliMedBert [196] was developed for diverse applications, including understanding climate and health-related concepts, fact-checking, relationship extraction, and generating evidence on the impact of health on policy text generation. Additionally, Bi et al. have proposed OceanGPT [197], based on LLM (e.g., Llama [82] and GPT3.5 [48]), to handle specific tasks related to the ocean, such as ocean text analysis and intelligent underwater agent instructions.

### 7.7 Weather Patterns Understanding
Weather pattern understanding, as opposed to forecasting, tends to lean towards a qualitative analysis of climate change. By integrating predictions derived from reanalysis datasets, we can more effectively quantify the potential impact of future weather events. Traditional numerical methods, though costly, rely on manually crafted features such as fronts, tropical cyclones [299], extratropical cyclones, and atmospheric rivers, using heuristic detection algorithms based on empirical knowledge. However, weather patterns with more distinct features, like tornadoes and typhoons, may be more amenable to pattern detection and prediction due to their characteristic features. For instance, a typhoon’s eye and surrounding rainbands present distinct patterns. This pattern detection and prediction could potentially prove more advantageous than predicting the general atmospheric state in standard training. One approach might be to employ spatio-temporal video stream data, such as radar reflectivity data [107] and weather satellite cloud imagery [300]. This transition from spatio-temporal weather video stream data to predictions offers a more dynamic and visually intuitive method for weather pattern understanding.

Weather pattern understanding based on DL techniques often requires large-scale, well-annotated samples. In one study, Kashinath et al. [301] created a dataset suitable for tropical cyclone (TC) detection in the 25km CAM5.1 model. They achieved fine-grained and rapid segmentation of TCs and atmospheric rivers (ARs) using DL-based segmentation algorithms. Racah et al. [302] extended this dataset to detect and precisely locate TCs, extra-tropical cyclones (ETC), ARs, and tropical low-pressure systems using a 3D-CNN. Furthermore, Sobash et al. [303] combined CNNs and logistic regression (LR) to detect tornadoes in six-hourly dynamical forecasts and turbulence conditions in regional or high-resolution weather forecasts. In addition to detecting different weather patterns from large-scale reanalysis datasets, advanced AI models are frequently used to study the evolutionary processes of meteorological phenomena. These include the genesis and dissipation of typhoons in a regional context, as well as the movement trajectories of TCs. Next, we will proceed to conduct a literature review and discussion on the field of weather pattern understanding, focusing on climate phenomena and extreme weather events.

#### 7.7.1 Climate Phenomena Understanding and Prediction
We mainly focus on discussing three primary climate phenomena/representation in the global scale, including El Niño-Southern Oscillation, Climate Tipping Points, and Madden-Julian Oscillation.

• El Niño-Southern Oscillation. The El Niño phenomenon, arising from intense ocean-atmosphere interactions, is marked by heightened sea surface temperatures (SST), a levelled equatorial Pacific thermocline, and a diminished tropical Pacific Walker circulation [304]. Together with its inverse phase, La Niña, it constitutes the El Niño-Southern Oscillation (ENSO) cycle. This cycle, with a duration of 2 to 7 years, is the principal driver of global climate interannual variability, frequently correlating with significant global climatic and socio-economic repercussions [305]. Consequently, accurate ENSO forecasting is of paramount scientific and practical significance. Several methods have been proposed to enhance ENSO forecasting. Ref. [178] incorporates a Transformer-based architecture, considering long-term correlations among meteorological variables. A spatial-temporal Transformer for multi-year ENSO prediction is suggested by Ref. [306]. ENSO-GTC [181] applies the Global Teleconnections Coupler (GTC) for potential teleconnections between global SST. Ref. [65], [66] develop an interpretable deep learning model for ENSO forecasting. Ref. [179] introduces a holistic deep learning model for ENSO that integrates seasonality in climate data to enhance forecast fluctuation. Comprehensive reviews and surveys on deep learning-based ENSO forecasting can be found in Refs. [268], [307].

• Climate Tipping Points. Climate tipping points denote crucial thresholds within the climate system where the system undergoes significant and irreversible alterations in response to certain changes or external forcings [281], [308], [309]. These transitions can instigate major climate system shifts, including modifications in oceanic circulation patterns, accelerated glacier melting, and climate zone migration. The transgression of these tipping points can destabilize the long-term equilibrium of the climate system, inciting more severe climate transformations. TIP-GAN [243] is a Generative Adversarial Network (GAN)-based model designed to identify potential climate tipping points in Earth system models, with a particular emphasis on precipitating the collapse of the Atlantic Meridional Overturning Circulation (AMOC). Additionally, a neural-symbolic question answering program translator, NS-QAPT, is presented as a neural-symbolic approach to enhance the interpretability and explainability of deep learning climate simulations applied to climate tipping point detection [281]. Further relevant works can be explored in Refs. [310], [311].

• Madden-Julian Oscillation. The Madden-Julian Oscillation (MJO) [312], [313] is a substantial atmospheric circulation phenomenon predominantly observed near the equator. It is characterized by regular oscillations in convection activity and precipitation in equatorial regions, with a typical duration spanning 20 to 90 days. The MJO exerts substantial influence on global weather and climate systems, impacting precipitation patterns, wind fields, and the origination and evolution of tropical cyclones. Consequently, comprehension and prediction of the MJO are vital for accurate precipitation forecasting and disaster prevention, thereby effectively managing and mitigating potential risks. DK-STN [184], leveraging spatio-temporal knowledge embedding, has notably enhanced the prediction accuracy of the ANN method, while preserving high levels of efficiency and stability. For further related works, refer to Ref. [8].

#### 7.7.2 Extreme Weather Prediction and Understanding
This discussion primarily centers around the application of DL models for the prediction and understanding of four pivotal extreme weather events: Extreme Temperatures, Drought, Cyclones, and Extreme Precipitation.

• Extreme temperatures. Extreme Temperatures. These often present as intense, prolonged, and frequent heatwaves [74], imposing substantial challenges to human activities and the ecological environment. Extreme temperature events are typically defined as a series of days with temperature variables surpassing a specific threshold or evaluated using accumulation indices composed of amplitude, duration, and frequency. Data-driven climate models rooted in machine learning/deep learning have demonstrated effectiveness in extreme temperature prediction tasks. Techniques such as random forest and XGBoost have offered promising results. Furthermore, convolutional neural networks, recurrent neural networks, and Transformers have seen extensive use in extreme temperature prediction due to their capacity to capture spatiotemporal representations.

• Drought. Droughts occur at various spatiotemporal scales and involve multiple triggering mechanisms, which complicates a clear and comprehensive definition [314]. They represent an extremely complex natural disaster. Recent research has gravitated towards using AI algorithms [315] based on geospatial weather data for long-term drought prediction, such as in [180], [182], [316]. For example, Ref. [180] proposed a one-dimensional CNN combined with a GRU for evapotranspiration prediction, enabling the model to better capture dependencies in time series data. Meanwhile, Ref. [316] combined CNN and LSTM for drought prediction one month in advance. A more comprehensive review of AI applications in drought prediction can be found in Refs. [180], [317]. However, most existing studies are geographically focused, causing the model performances to heavily depend on specific research conditions such as the study area, drought index, or considered input variables. This dependency makes it difficult to generalize major findings from one study to another.

• Cyclones & Extreme Precipitation. In tropical and mid-latitude regions, weather-scale cyclones represent some of the most extreme events causing significant economic damage due to heavy rainfall, strong winds, and storm surges [318]. Evidence suggests that climate change may amplify the severity of these extreme events, even if not their frequency [299]. However, predicting their variability on sub-seasonal to decadal timescales remains a challenge [319]. Heavy precipitation events are not always linked with large-scale weather systems such as cyclones or fronts; many impactful events are tied to brief, small-scale severe convective events. These extremes pose a greater challenge for operational climate prediction systems as their spatial resolution is too coarse to capture the explicit representation of convection. In most regions where extreme precipitation is analyzed, the skill of numerical climate prediction systems for extreme precipitation decreases significantly after a few days. AI techniques have been applied to improve the prediction of cyclones and heavy precipitation events from various perspectives. The objective is to enhance the skill of numerical prediction systems (e.g., seasonal forecasting) in representing extreme weather events by identifying the relationship between large-scale driving factors and the occurrence of extreme events. This approach has been applied to large-scale extreme events, such as tropical or extratropical cyclones, or directly to precipitation fields [320], [321]. De Burgh-Day & Leibnberg [322] proposed a systematic model ablation study as a potential approach to address the interpretability issue of DL models while maintaining their good skill. Additionally, some DL-based strategies aim to handle cyclones and extreme precipitation forecasting via meteorological image extrapolation (refer to Section Precipitation Nowcasting), and others focus on improving model outputs by achieving high-resolution observations to enhance the representation of precipitation or wind patterns associated with cyclones rather than directly performing the prediction task [323], [324] (refer to Sec. 7).

## 8 RESOURCES
In this section, we catalog the prevalent datasets and tools pertinent to weather and climate change analysis, aspiring to streamline their accessibility for practitioners.

### 8.1 Dataset
This segment classifies datasets employed in data-driven weather and climate studies. These datasets facilitate weather time-series analysis, weather spatio-temporal series analysis, weather spatio-temporal video stream analysis, and climate text analysis. We bifurcate them into two categories: weather and climate series data and climate text data. It’s noteworthy that the datasets are unordered.

#### 8.1.1 Weather and Climate Series Data
This subsection concentrates on datasets related to weather and climate sequences, encompassing time series, spatio-temporal sequences, spatio-temporal video streams, and multimodal sequence data.

CMIP6 [88], [89], [90] is a compendium of simulated data from Phase 6 of the Coupled Model Comparison Project (CMCP). It encompasses a wide array of different climate variables within the Earth system, such as precipitation, temperature, evapotranspiration, and others. The data, derived from over 150 climate models, spans more than 150 years (1850-2015). It can be utilized to predict the ENSO phenomenon and common climate variables.

ERA5 [88], [89], [90] is widely used for training and benchmarking data-driven weather and climate forecasting, down-scaling, and projection models. Managed by the European Center for Medium-Range Weather Forecasting (ECMWF) [343], it is regularly updated. ERA5 contains hourly data on a 0.25° grid from 1979 till present, at 37 different pressure levels, as well as various surface climate variables, resulting in nearly 400,000 data points at a resolution of 721 × 1440.

HCOSD is provided by the Institute for Climate and Applied Frontier Research (ICAR), is a refined subset of the CMIP dataset. Standing for Historical Climate Observation and Stimulation Dataset, it includes historical simulated data from the CMIP5/6 model and assimilated data from nearly a century of historical observations, reconstructed from the US SODA model [344]. Each sample encapsulates meteorological and spatial variables, such as sea surface temperature anomalies, heat content anomalies (T300), latitudinal wind anomalies, and longitudinal wind anomalies, with data dimensions (year, month, lat, lon). The training data offers Nino3.4 index-labeled data for the corresponding month. The testing data comprises 12 randomly selected time series from multiple international oceanographic data assimilation results.

Extreme-ERA5 [90] is a subset constructed by ClimateLearn from ERA5 to evaluate the prediction capability of data-driven models under extreme weather conditions. It comprises various extreme weather events, defined by climate variables exceeding localized thresholds (e.g., heatwaves and cold breaks due to sea level temperature anomalies). The dataset covers the period 1979-2018, with 1979-2015 considered the training dataset.

PRISM [90] is a dataset contains myriad observed atmospheric variables, including but not limited to temperature and precipitation for the conterminous U.S. region. Maintained by the PRISM Climate Organization at Oregon State University, the dataset spans from 1895 to the present. At its highest resolution, it provides daily data based on 4 km x 4 km grid cells, forming a matrix of shape 621 x 1405.

DroughtED [314] is a drought forecast data that combines 180 daily weather observations for the continental United States and geospatial location metadata for all 3,108 counties. It includes meteorological real-time and historical data from NASA’s Global Energy Resources (Electricity) Prediction Program, and variables include measurements of precipitation, surface pressure, relative humidity dew/frost point, wind speed, and daily resolution temperature. Past drought observations were also included and given a parallel categorization of USDM drought levels, including no drought (none), abnormally dry (D0), moderate (D1), severe (D2), extreme (D3), and abnormal (D4). Additionally considering that drought is a seasonal phenomenon, seasonal characteristics were also included within the dataset. In addition, a location metric was included, including topographic slope, gradient, and elevation for each site, as well as land use (e.g., rain-fed cropland or forested land) for each site, and soil quality, such as toxicity or nutrient utilization.

Digital Typhoon [327] is an image-based dataset utilized to long-term spatio-temporal modeling for tropical cyclones. It is created from the comprehensive satellite image archive of the Japanese geostationary satellites series, Himawari, from Himawari-1 to Himawari-9. The dataset consists of 1,099 typhoons and 189,364 images. Geographically, it covers the complete record of typhoons occurring in the Northwestern Pacific region, with a time span from 1978 to 2022. The dataset has a temporal resolution of one hour and a spatial resolution of 5km.

EarthNet2021 [332] is large dataset for Earth surface prediction, extreme summer prediction and seasonal cycle prediction. It contains more than 32,000 samples of Sentinel 2 (high temporal and spatial resolution Earth satellite) Class 2A imagery, as well as daily climate data derived from the E-OBS observational dataset containing interpolated ground-truth observations of weather from multiple stations across Europe for the full year 2018.

ClimateNet [301] is an open and expert-labeled dataset designed for high-precision analyses of extreme weather events. It focuses on capturing tropical cyclones and atmospheric rivers in high-resolution climate model outputs, simulating the recent historical period from 1996 to 2010. This dataset is valuable for various applications in machine learning and climate research, such as transfer learning, curriculum learning, active learning, spatiotemporal segmentation, probabilistic segmentation, and hypothesis testing.

IowaRain [328] is primarily derived from the Quantitative Precipitation Estimation System (QPES) based on the National Weather Service’s Weather Detection Radar Network Iowa Flood Center. It covers the region of Iowa and spans the period from 2016 through the end of 2019. Each event in the dataset includes a collection of 2D rainfall rate maps, along with information about the size of the event (i.e., the number of rainfall rate maps in the set) and the start date of the event. This dataset is specifically designed for predicting regional rainfall events.

ExtremeWeather [302] is a comprehensive dataset that aims to facilitate the detection, localization, and understanding of extreme weather events. It is based on post-processed simulations of CAM5, a widely used atmospheric 3D model for global climate simulations. The dataset focuses on extreme weather events and provides a spatial resolution of 25-km. Each snapshot of the global atmospheric state is represented as a 768 × 1152 grid, with 16 simulated climate variables including surface temperature, surface pressure, precipitation, latitudinal winds, meridional winds, humidity, cloud fraction, and water vapor. The dataset covers a time span from 1979 to 2005, with a temporal resolution of 3 hours. It consists of a total of 78,840 samples, capturing four types of extreme weather events: Tropical Depression (TD), Tropical Cyclone (TC), Extratropical Cyclone (ETC), and Atmospheric Rivers (AR). The center of each storm is considered as the reference point for marking the bounding box coordinates. Notably, the dataset includes 39,420 labeled images, providing valuable annotations for training and analysis purposes.

KoMet [333] is a collection of data specifically gathered in Korea. It utilizes input data from GDAPS-KIM, a global numerical weather prediction model that offers hourly forecasts for various atmospheric variables. The dataset focuses on precipitation prediction and has a spatial resolution of 12 × 12 kilometers, resulting in a spatial size of 65 × 50. The dataset includes two types of variables: pressure level variables and surface variables. These variables provide valuable information for predicting and understanding precipitation patterns in Korea. In terms of the distribution of samples, approximately 87.24% of the samples in the dataset are classified as ”no rain,” indicating instances where precipitation is not observed. Around 11.57% of the samples correspond to rainy conditions, while 1.19% represent extreme rainfall events.

Germany [334] is a precipitation forecasting dataset collected in West Germany. It spans the period from 2011 to 2018 and focuses on precipitation forecasting. The input data for this dataset are derived from the COSMO-DE-EPS forecast, which provides 143 variables representing different atmospheric states. The dataset has a spatial resolution of 36 × 36 for the input data, indicating the grid size used to represent the atmospheric conditions. The output data, representing the precipitation forecasts, have a higher resolution of 72 × 72. In terms of the distribution of samples, approximately 85.10% of the samples in the dataset are classified as “no rain“ indicating instances where precipitation is not observed. Around 13.80% of the samples correspond to rainy conditions, while 1.10% represent extreme rainfall events.

China [335] is a precipitation forecasting dataset collected in China, provided hourly, 1 km × 1 km resolution, 3-hourly grid-point precipitation data for the rainy season. This dataset lasts from April through October for the 2020 and 2021 seasons. In addition, it includes 3-hour lead time projections from the regional NWP model, including 28 surface and pressure level variables such as 2-meter temperature, 2-meter dew point temperature, 10-meter u and v wind components, and CAPE (Convective Available Potential Energy) values. Each time frame in this dataset covers a sizable spatial region with a grid size of 430 × 815.

China-Precipitation/Temperature [326] is a high-spatial-resolution monthly precipitation and temperature dataset for China, covering the period from 1901 to 2017. The dataset includes monthly minimum, maximum, and mean temperatures, as well as precipitation data, at a spatial resolution of 0.5 arcminutes (approximately 1 kilometer) for the main land area of China. The dataset was downscaled using the Delta spatial downscaling method from the 30 arcminute Climatic Research Unit (CRU) time series dataset and the WorldClim climatology dataset. It was evaluated using observations collected from 496 weather stations across China during the period from 1951 to 2016.

ClimART [221] is a dataset for emulating atmospheric radiative transfer in weather and climate models, with more than 10 million samples from present, pre-industrial, and future climate conditions, based on the Canadian Earth System Model. This dataset of global snapshots of the current atmospheric state from CanESM5 was simulated every 205 hours from 1979 to 2014. CanESM5 has a horizontal grid discretizing longitude to 128 columns of the same size and latitude to 64 columns using a Gaussian grid (8192 = 128 x 64 columns). This resulted in 43 global snapshots per year for the period 1979-2014, totaling over 12 million columns and a raw dataset size of 1.5 TB.

MeteoNet [336] is a multimodal dataset for regional precipitation nowcasting covering a geographical area of 550 × 550 km in the northwestern quarter of France, spanning the years 2016 to 2018. The modalities of the dataset include radar echo observations, earth-observing satellite imagery, ground station observations, weather forecast model data and topographic maps. The ground observation data has a temporal resolution of six minutes and includes meteorological variables such as temperature, humidity, atmospheric pressure, and wind speed measured by 500 ground stations. The radar echoes, on the other hand, are precipitation radar records with a five-minute time resolution, i.e., 12 frames recorded in one hour, including radar reflectivity and rainfall estimates. The satellite data are recorded every 15 min for Cloud Type (CT) and every 1 hour for Channels (visible, infrared). Weather models are also included forecasts from 2 weather models with 2D parameters, generated once a day.

RAIN-F [345] is a pre-processed spatio-temporally aligned multimodal dataset for short-advance rainfall forecasting, which includes radar, ground-based observations, and a variety of summed satellite data, for the time period from 2017 to 2019, with a coverage of the Korean Peninsula. Specifically, nine different atmospheric state variables (one radar, seven ground observations, and one satellite) associated with precipitation variables are included with a temporal resolution of one hour. The ground-based observations include wind direction and speed, humidity, surface pressure, temperature, sea level pressure and precipitation.

RAIN-F+ [337] is a new version of RAIN-F with new atmospheric variables and TB products, which can also be used to retrieve atmospheric variables from satellite observations or to predict atmospheric state and precipitation, with geographic and temporal coverage identical to that of RAIN-F.

ENS-10 [325] is a post-processing dataset for ensemble weather forecasting, consisting of 10 ensemble members spanning 20 years (1998-2017). These ensemble members are generated by perturbing numerical weather simulations to capture the chaotic behavior of the Earth. To represent the three-dimensional state of the atmosphere, ENS10 provides 11 atmospheric variables at 11 different pressure levels and the most relevant variables at the surface, with a resolution of 0.5 degrees. The dataset includes forecast lead times of T = 0, 24, 48 hours (two data points per week).

SEVIR [86] is a collection of temporally and spatially aligned image sequences depicting weather events captured over the contiguous US (CONUS) by GOES-16 satellite and the mosaic of NEXRAD radars. Five different image data types are included, such as the GOES-16 0.6 µm visible satellite channel (vis), 6.9 µm and 10.7 µm infrared channels (ir069, ir107), a radar mosaic of vertically integrated liquid (vil), and total lightning flashes collected by the GOES-16 geostationary lightning mapper (GLM) (lght). The spatial resolution is 0.5km, 2km, 2km, 1km, and 8km, the temporal resolution is 5 minutes (except for lightning events), and the image coverage is 768×768, 192×192, 192×192, and 384×385, respectively, corresponding to meteorological events 1403, 13552, 13541, 20393, and 15115, which can be used by the applied to weather prediction, image-to-image conversion, extreme weather detection, weather annotation, super resolution and other applications.

SRAD2018 is a precipitation nowcasting dataset composed of a series of radar echo image, is from Tianchi IEEE International Conference on Data Mining (ICDM) 2018 Global Artificial Intelligence Challenge on Meteorology and collected by Shenzhen Meteorological Bureau and Hong Kong Observatory. Each sequence in the dataset contains 501 × 501 km region with 1 × 1 spatial resolution, the temporal resolution is 6 min and complete sequence is 6 h, taken from an altitude of 3 km.

RainBench [338] is a precipitation forecasting dataset consists of European Centre for Medium-Range Weather Forecasts simulated satellite data (SimSat), ERA5 reanalysis product and Integrated Multi-satellite Retrievals (IMAGE) global precipitation estimates. All data is converted from their original resolution to 5.625 resolutions using bilinear interpolation. The time span is 2000 to 2017 and the time resolution is 1 hour.

KnowAir [329] is a weather forecasting dataset based on station observations, which includes 184 meteorological stations in northern China. The dataset covers the time span from 2015 to 2018, with a temporal resolution of three hours. It primarily includes 18 weather features.

Weather2K [87] is a large-scale dataset for weather prediction based on station observation data, which is extracted from 1,866 ground-based meteorological stations throughout China, covering an area of 6 million square kilometers, with 23 features corresponding to each meteorological battle, containing three static variables representing geographic information as well as 20 interacting meteorological variables, and with a temporal coverage of January 1, 2017, to August 31, 2021, with a temporal resolution of one hour.

NASA [24] is a collection of regional weather forecasting datasets, which consists of three subsets, AvePRE, SurTEMP, SurUPS, spanning from Apr 1, 2012 to Feb 28, 2016, Jan 3, 2019 to May 2, 2022, and Jan 2, 2019 to Jul 29, 2022, respectively, all with one-hour temporal resolution, collected from 88, 525, and 238 stations, respectively.

LSDSSIMR [300] is a large-scale dust storm database used for extreme weather and sandstorm prediction. The data is sourced from multi-channel and dust label data of the Fengyun-4A (FY-4A) geostationary orbit satellite, as well as Earth system reanalysis data. The dataset covers the time span from March to May each year from 2020 to 2022, with a time resolution of 15 minutes and a spatial resolution of 4 kilometers. Meteorological reanalysis data is incorporated into LSDSSIMR for spatio-temporal prediction methods. Each data file is stored in HDF5 format, and the final LSDSSIMR consists of nearly 5400 HDF5 files.

RainNet [330] is a large-scale dataset specifically designed for spatial downscaling of precipitation. It contains data from 85 months or 62,424 hours, resulting in a total of 62,424 pairs of high-resolution and low-resolution precipitation maps. The high-resolution precipitation maps have a size of 624x999, while the low-resolution maps have a size of 208x333. These data encompass various meteorological phenomena and precipitation conditions such as hurricanes and squall lines. The precipitation map pairs in RainNet are stored in HDF5 files, occupying a total of 360GB of disk space. The data is collected from satellites, radars, and rain gauge stations, covering the inherent working characteristics of different meteorological measurement systems.

Continental United States Wind Speeds [331] is a climate downscaling (super-resolution) dataset, was obtained from the National Renewable Energy Laboratory’s (NREL’s) Wind Integration National Database (WIND) Toolkit, with a focus on the continental United States. Wind velocity data is comprised of westward (ua) and southward (va) wind components, calculated from wind speeds and directions 100-km from Earth’s surface. The WIND Toolkit has a spatial resolution of 2 km x 1 hr spatiotemporal resolution. The dataset contains data sampled at a 4-hourly temporal resolution for the years 2007 to 2013. The sample test dataset contains data sampled at a 4-hourly temporal resolution for 2014. We transform 2D data arrays of wind speed and direction into corresponding ua and va wind speed components. These are chipped into 100x100 patches. Low resolution imagery is obtained by sampling high resolution data at every fifth data point as instructed by NREL’s guidelines.

Continental United States Solar Irradiance [331] is a climate downscaling (super-resolution) dataset, was obtained from the National Renewable Energy Laboratory’s (NREL’s) National Solar Radiation Database (NSRDB), with a focus on the continental United States. We consider solar irradiance data from the NSRDB in terms of direct normal irradiance (DNI) and diffused horizontal irradiance (DHI) at an approximately 4-km x 1/2-hr spatiotemporal resolution. The solar dataset produced for this work samples data at an hourly temporal resolution from 6 am to 6 pm for the years 2007 to 2013. The test dataset contains datapoints sampled from 2014. A 1D array of data points is provided along with latitude and longitude metadata for each point. We rearrange this 1D array into a 2D image based on the lat/long metadata. These 2D arrays of DNI and DHI are chipped into 100 x 100 patches. Low resolution imagery is obtained by sampling high resolution data at every fifth data point.

#### 8.1.2 Weather and Climate Text Data
This subsection focuses on weather text datasets, which are more thematically oriented towards climate change related policy statements as well as document texts.

CLIMATE-FEVER [339] is a dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change. Each claim is accompanied by five manually annotated evidence sentences retrieved from Wikipedia that support, refute or do not give enough information to validate the claim. The total dataset thus contains 7,675 claim-evidence pairs. Furthermore, the dataset features challenging claims that relate multiple facets and disputed cases of claims where both supporting and refuting evidence are present.

ClimateBERT-NetZero [198] is an expert-annotated dataset from the Net Zero Tracker Project that assesses targets for reduction and net zero emissions or similar aims (e.g., zero carbon, climate neutral, or net negative). The dataset contains 273 claims by cities, 1396 claims by companies, 205 claims by countries, and 159 claims by regions.

ClimaText [205] is a dataset for climate change topic detection, consists of labeled sentences. The label generated heuristically or via a manual process indicates whether a sentence talks about climate change or not. All sentences are collected from Wikipedia, the U.S. Securities and Exchange Commission (SEC) 10K files. For Wikipedia, collect 6,885 documents, 715 relevant to climate change and 6,170 not relevant to climate change.

CLIMA-INS [340] contains survey from annual NAIC Climate Risk Disclosure Survey responses for the years 2012-2021, the purpose of the survey is to enhance transparency about how insurers manage climate-related risks and opportunities to enable better-informed collaboration on climate-related issues, where each survey consists of eight questions.

CLIMA-CDP [340] is composed of three subset part where each part is a set of questionnaires filled out by a city, company, or state respectively. The dataset can performs topic classification and question classification. The number of sample from train, development, and test for task of topic classification is 46.8K, 8.7k, and 8.9K, respectively. In addition, the number of sample from train, development, and test for task for question answering task is 48.2K (8.7K for states, 34.5K for corporations), 8.5K (0.9K for states, 34.5K for corporations), and 9.3K (1.1K for states, 4.9K for corporations), respectively. The number of classes for topic classification task is 12, for question answering is 294, 132, and 43 respectively.

CLIMATESTANCE & CLIMATEENG [341] is a ternary classification dataset about climate-related text, extracted Twitter data consisting of 3777 tweets posted during the 2019 United Nations Framework Convention on Climate Change. Each tweet was labelled for two tasks: stance detection and categorical classification. For stance detection the authors labelled each tweet as In Favour, Against or Ambiguous towards climate change prevention. For categorical classification, the five classes are Disaster, Ocean/Water, Agriculture/Forestry, Politics, and General.

SCIDCC [342] is curated by scraping new articles from the Science Daily website [342]. It contains around 11k news articles with 20 labelled categories relevant to climate change such as Earthquakes, Pollution, and Hurricanes. Each article comprises of a title, a summary, and a body which on average is much longer (500-600 words) than other climate text datasets.

### 8.2 Tools and Models
In this subsection, we collect and compile a rich and usable set of tools and foundation models for modeling weather and climate data.

• OpenCastKit: A new global AI weather forecasting project based on FourCastNet and GraphCast. https://github.com/HFAiLab/OpenCastKit  
• GraphCast: A foundation model for medium-range global weather forecasting. https://github.com/google-deepmind/graphcast  
• FourCastNet: A foundation model for weather and climate data based on AFNO. https://github.com/NVlabs/FourCastNet  
• PanGu-Weather: A foundation model for medium-range global weather forecasting. https://github.com/198808xc/Pangu-Weather  
• FuXi: A forecasting system for 15-day global weather forecast. https://github.com/tpys/FuXi  
• W-MAE: An unsupervised learning global weather forecasting model via Masked Autoencoder. https://github.com/Gufrannn/W-MAE  
• ClimaX: A versatile climate foundation model covering forecasting, projection, and downscaling. https://github.com/microsoft/ClimaX  
• OceanGPT: A large language model for ocean science tasks trained with KnowLM. https://huggingface.co/zjunlp/OceanGPT-7b  
• ClimateBert: An algorithm that enables to analyze climate-risk disclosures along the four main TCFD categories. https://huggingface.co/climatebert  
• Climate X Quantus: An XAI toolbox for ML/DL-based climate models. https://github.com/philine-bommer/Climate-X-Quantus

## 9 CHALLENGES, OUTLOOK, AND OPPORTUNITIES
The potential pitfalls of AI foundation models in weather and climate (WFMs) data understanding are manifested in a large number of pending challenges to which data-driven models are more susceptible than traditional NWP models. In this section, we identify five main challenge areas and suggest some best practices that should be recognised and implemented in future research, as well as pointing out research opportunities and routes that hold great promise for the future.

### 9.1 Post-Processing of Data
For DL models, the quality of the data is paramount. However, numerous challenges associated with data pose threats to the development of expansive foundation models for weather and climate data understanding, including issues related to data quality and quantity, post-processing costs, scarcity of historical data, non-stationarity, and the under-utilization of existing datasets.

• Data Quality and Quantity. Large-scale foundation models require comprehensive and high-quality data for robust results. Despite the exponential increase in global climate data [73], like ERA5 and CMIP [88], general-purpose datasets that are both large-scale and high-quality are seldom available.

• Post-processing Costs. Large models, such as PanGu-Weather [63] and ClimaX [25], often necessitate costly post-processing for scenario-specific analyses. The analysis of extreme events, for example, presents a unique challenge. These rare events, which are increasingly likely in a non-stationary climate, are often characterized by outliers in climate variables. Their development involves physical processes that span time cycles from weeks to years, complicating the creation of fine-grained annotations [302].

• Underutilization of Existing Datasets. Large-scale datasets, despite their size, remain underdeveloped due to the enormous post-processing costs. Benchmark datasets like WeatherBench [88], WeatherBench2 [89], OceanBench [346], and ClimateLearn [90], which contain post-processed data, are still in early stages of development due to limited data scenarios.

The creation of general WFMs hinges upon the availability of rich, large-scale, post-processed datasets. There is substantial scope for deeper analyses and post-processing of these datasets, including understanding anomalous weather events, integrating physical models, and efficient, rational annotations. Overcoming these challenges is key to realizing the full potential of climate foundation models.

### 9.2 Development of Multi-Modal Models
Time series data are often enriched with supplementary information, including textual descriptions. This is particularly beneficial in economics and finance, where forecasting can harness information from textual data sources such as news articles or tweets, in conjunction with digital economic time series data [110]. Analogously, weather and climate analysis can profit from the diverse modalities encompassed in climate data, which include reanalysis data, multimodal observation data (e.g., radar echoes [84], [107], satellite imagery [300], and geographic terrain features [314], etc.). The development of models capable of integrating and learning from this rich array of data modalities has the potential to enhance predictive accuracy. However, while efforts have been made to develop weather prediction and meteorological analysis models based on multimodal meteorological data [86], [314], [337], these models often exhibit limitations. They are typically confined to specific geographic regions and struggle to accommodate the extensive spectrum of meteorological modes. A salient challenge in constructing multimodal climate foundation models lies in enabling these models to learn joint representations that encapsulate the sequential nature of temporal data and the unique traits of other meteorological modes.

This challenge encompasses understanding and accommodating the disparate temporal and spatial resolutions across modes. For instance, meteorological observations may have an hourly temporal resolution, radar echo data might possess a six-minute temporal resolution and 1-4 km spatial resolution, and satellite images could exhibit half-hourly temporal resolution and a 5-12 km spatial resolution. The task of leveraging information with different temporal and spatial resolutions to construct a robust and powerful climate foundation model is complex. Furthermore, it is a challenge to balance and align multimodal information collected at different time points to achieve more precise fixed-point prediction and analysis. As such, the development of models that can effectively integrate and learn from these diverse data sources remains a challenging but important frontier in the field of weather and climate analysis.

### 9.3 Interpretability and Causability
A significant challenge associated with the use of AI models for weather and climate analysis is the often inscrutable nature of the model’s decision-making process. Many DL algorithms are inherently complex and opaque, rendering their decision-making processes unintelligible to users [65], [66]. For applications such as machine translation and text generation, the interpretability may not be a key concern. In these contexts, it is typically sufficient for the model to display competent performance to meet most requirements. However, in weather and climate applications, the interpretability of the model is of paramount importance. Non-transparent, black-box models can precipitate catastrophic errors in predictions, which could have devastating impacts on society and the environment. To mitigate this interpretability challenge, tools rooted in the concept of Explainable AI (XAI) have been proposed, such as XAITools, InterpretML, SHAP, LIME, and AI Explainability 360, etc. These tools aim to bring increased transparency and trustworthiness to black-box models, including those used in various fields such as Earth sciences [347] (Climate X Quantus), and offer new insights for refining models that underperform. However, these interpretability tools are not without their shortcomings and can exhibit significant biases. In some cases, the truthful representation of the model may depend more on the specifics of the application and its settings, which can render the results difficult to interpret. This suggests that the interpretability insights of climate AI are influenced more by the network’s architecture than by the causal inference of weather and climate data.

Unless appropriately designed, Weather/Climate AI may base predictions on non-physical relationships or false correlations. This limitation in drawing causal conclusions from climate models using XAI tools refers to the limited causality these tools can provide. Physics-guided AI, also known as knowledge-guided or physics-informed AI, is one avenue researchers are exploring to impose physical realism and mitigate the effects of false correlations on predictive algorithms [244], [246], [248], [294]. However, research in this area is still nascent. Thus, while strides have been made in enhancing the interpretability of AI models, substantial challenges remain, highlighting the need for continued research and development in this critical area.

### 9.4 Generalizability of Models
The generalization capability of a model refers to its competence in making effective predictions beyond the spatio-temporal confines of its training dataset. Lots of DL techniques operate on the assumption of independent and identically distributed (IID) training and test data [66]. This implies that the weights calculated during model training remain efficacious even on unseen datasets. However, when applied to weather and climate analysis, foundation models may exhibit suboptimal performance when predicting Non-IID data beyond the training dataset. A notable example of this is the use of foundation models for the prediction of extreme events outside their trained distribution. These biased and anomalous data often induce significant performance degradation in the model. This is especially the case as the warming climate alters the Earth’s spatiotemporal distribution. The existing relationships that currently describe the predictive variables and extreme climate events may no longer apply in the future.

Moreover, climate foundation models are typically pre-trained on general data before being fine-tuned on specific task datasets [25]. If the fine-tuning data includes adversarial or noisy examples, the process may introduce vulnerabilities. If the temporal data employed for fine-tuning is not meticulously managed, the model may adopt biases or flaws from this data, leading to compromised robustness in practical applications and unreliable outputs. This underscores the imperative for robust generalization. The advent of physics-informed deep learning represents a promising step towards enhancing the robust generalization of climate models. However, the extension of these models beyond their trained distribution remains an area that is not yet fully explored. This highlights the need for continued research into the generalization capabilities of climate models, particularly in light of the rapidly changing climate and the ever-evolving challenges it presents.

### 9.5 Privacy, Adversarial Attacks, and Communication
Weather and climate data are often of high sensitivity, encapsulating a wealth of climate variables, geographical information, and topographical details dispersed across various regions/countries [24], [154]. In particular, radar and satellite data are highly sensitive. The training of WFMs using such data poses significant challenges from aspects of centralized training, privacy leaks and adversarial attacks.

• Centralized Training Issues. Models typically undergo pre-training with substantial data before being deployed to various downstream tasks [25], [63], [136], [137], [138]. However, the centralized training strategy can be fraught with problems. Aggregating sensitive data from different regions or countries onto a central server is neither reliable nor practical due to the inherent risks of data leakage and contamination [24].

• Privacy Leaks and Adversarial Attacks. During the fine-tuning process, WFMs often memorize specific details from the datasets, which can potentially compromise private data. Contaminated data also pose a risk of deteriorating model performance. Therefore, the adoption of privacy-preserving techniques to prevent privacy leaks and mitigate adversarial attacks is crucial in the training/fine-tuning of WFMs.

Recent studies have introduced the use of differential privacy (DP) techniques or federated learning (FL) to train WFMs [24], [154], effectively lessening the risk of sensitive climate data leakage [348]. However, these methods are still confronted with communication challenges.

• Communication Overheads in Federated Learning. Federated learning allows different clients to collaboratively train a global model, with each client maintaining a locally replicated model with consistent structures. During the global aggregation stage, each participant uploads their local model parameters to a cloud server for aggregation. This process results in a significant increase in communication overhead between clients and the server due to the large-scale nature of climate models, posing a serious challenge to computational and hardware costs.

### 9.6 Continuous Learning and On-device Adaption
The performance of WFMs, despite showing promising results, can be substantially improved through the application of continuous learning and on-device adaption. Continual learning [349], also referred to lifelong or incremental learning, is the process of updating a model over time as new data emerges. Given the ever-evolving nature of climate and weather patterns due to natural variability and anthropogenic climate change, this approach proves particularly beneficial. It enables models to adapt to these changes, enhancing their predictive accuracy and robustness. On-device adaptation [75] involves the customization of a model based on local data at the point of deployment. It has the potential to boost model performance by enabling adjustments to local climate and weather patterns, which may not be comprehensively captured in global training data. Furthermore, on-device adaptation can minimize the requirement for data transmission, thereby enhancing model efficiency and preserving privacy. However, the implementation of continuous learning and on-device adaptation in models poses several challenges. These include ensuring model stability during continual learning and managing the computational and storage constraints of on-device learning:

• Maintaining Model Stability. Models undergoing learning can experience a phenomenon known as "catastrophic forgetting," where a model may forget previously learned patterns after being updated with new data. Balancing the maintenance of model stability while still allowing it to learn from new data poses a significant challenge.

• Managing Computational and Storage Constraints. The computational power and storage capacity of a device inherently limit on-device machine learning. Deploying and updating large climate models, on devices with limited resources may prove difficult. Techniques for model compression, efficient computation, and selective model updating are essential to make on-device adaptation of models feasible.

Despite these obstacles, continual learning and on-device adaptation present a promising avenue for enhancing the performance of climate models.

### 9.7 Reproducibility
Reproducibility stands as a cornerstone principle in the realm of scientific research. The capacity to reproduce results using identical data and methodologies not only reinforces the validity of the findings but also propels further research and innovation. Nevertheless, the pursuit of reproducibility in climate foundation models, poses several formidable challenges:

• Data Availability and Consistency. Climate foundation models frequently utilise extensive datasets, gathered from a plethora of sources over extended periods. The challenge lies in ensuring the availability and consistency of this data for model reproduction. Data may undergo updates or corrections, and access permissions can fluctuate, thereby adding complexity to reproducibility endeavours.

• Model Complexity. Climate foundation models often incorporate sophisticated machine learning architectures, intricate pre-processing steps, and advanced training procedures. Reproducing these models necessitates a comprehensive understanding of all these facets. If any segment of the process is inadequately documented or if specific implementation details are proprietary, model reproduction can become an insurmountable task.

• Computational Resources. Climate foundation models typically demand substantial computational resources for training and inference. Reproduction of these models may be prohibitively costly or technically challenging for researchers lacking comparable resources. This disparity can erect barriers to reproducibility and impede the progress of the broader research community.

• Non-Determinism in Training. Several training processes involve elements of randomness, such as random initialization of weights, shuffling of training data, and stochastic optimization methods. These factors can yield slightly divergent models and results, even when employing the same data and model architecture. Ensuring reproducibility amidst such non-determinism can prove challenging.

• Model Versioning. As climate foundation models evolve, new model versions are developed. It’s crucial to maintain a record of model versions and align them with the specific results they generated for reproducibility. However, this can become complex and arduous to manage, particularly in large collaborative projects.

Addressing these challenges necessitates a united effort from the entire research community. This includes the establishment of standards for data management and model documentation, investment in open-source software and infrastructure, and the cultivation of a research culture underscored by transparency and openness. While these issues are complex, resolving them is paramount to the advancement of climate foundation models research and ensuring its benefits are widely disseminated.

## 10 INSIGHT FOR FOUNDATION MODEL DESIGNING
This section presents an intricate examination of the design principles that serve as the foundation of current state-of-the-art (SOTA) WFMs. Its intent is to offer an exhaustive guide and insights for the development of resilient, multipurpose climate foundation models. Five perspectives are covered in this discourse: functional design, fusion of multi-source data, data representation, design of network architecture, and strategy for pre-training/fine-tuning.

### 10.1 One Fits All
Establishing foundation models necessitates a judicious selection of tasks, which influences the data employed, the training strategies deployed, the fine-tuning methodologies adopted, and other associated factors. Foundation models are often viewed as a panacea, pre-trained models that are subsequently fine-tuned for various application-specific tasks. Premier climate foundation models, such as FengWu [138] and PanGu-Weather [63], prioritize systematic modeling of the Earth system, encompassing the prediction of terrestrial and atmospheric climate variables at distinct spatio-temporal scales. Conventionally, these models are trained using data of spatial resolution derived from the widely accepted ERA5 dataset. In contrast, ClimaX [25] adopts an alternate approach, pre-training the foundation model at a coarser resolution and later achieving finer spatial resolution predictions, mappings, or down-sampling via fine-tuning. Thus, the primary technical strategy for the development of Weather and WFMs involves pre-training the models with extensive high-resolution data and then fine-tuning them with minimal effort to demonstrate exceptional performance across a range of downstream tasks.

### 10.2 Multi-source Data Fusion
Weather and climate data primarily fall into spatio-temporal series. Our discussion primarily revolves around spatio-temporal sequence tasks, as delineated in Sec. 8. Due to the variety of data sources, including but not limited to ground stations, remote sensing devices, and simulation-based climate products, the fusion of information from multiple data sources can explicitly benefit the training process of the foundation model and thus lead to improved performance. However, significant modal differences and heterogeneity among data complicate the realization of multi-source fusion operations. We present here insights into this from two main aspects: Spatio-Temporal Scales, Data Modality.

• Spatio-Temporal Scales. Practitioners can implement weather and climate models on a global scale by considering data at multiple spatio-temporal scales simultaneously, most commonly under reanalysis data (see Sec. 8) by fusing high- and low-resolution data to model both fine- and coarse-global features.

• Data Modality. Weather and climate data’s modal mainly focuses on time series and text. Fusion of multi-source data for foundation model training for weather and climate can be encouraged to capture interrelated knowledge from different scales and data modalities. Examples precipitation nowcasting and the fusion of multiple neutrals at different pressures for robust global forecasting models. Practitioners can explore simultaneous or staged fusion of multimodal weather data to benefit the foundation model.

### 10.3 Data Representation and Model Design
The robust development of WFMs is contingent on effective data interpretation and representation of weather and climate statistics. This process typically involves two stages: initial data representation construction through pre-training, and application of this representational knowledge to downstream tasks via fine-tuning. Unique representation methods are required given that each data point encodes complex contextual information, unlike the features of natural images. The subsequent discourse seeks to address two pivotal questions in this domain: (1) Which network architectures can effectively represent weather and climate data? and (2) What strategies can improve models and facilitate efficient and accurate representations?

#### 10.3.1 Which network architectures can effectively represent weather and climate data?
Reanalysis weather and climate datasets bear significant resemblances to natural images, most notably using grid cells to delineate local semantic information. Consequently, almost all network architectures employed in computer vision can be utilised for processing weather and climate grid data, including but not limited to ResNet, U-Net, Vision Transformer, generative adversarial networks (GANs), and diffusion models.

These models serve as the backbone of WFMs designs such as ClimaX [25], PanGu-Weather [63], FourCastNet [136], Dyffusion [151], GraphCast [137]. These models strive to establish more efficient relationships between different regions, atmospheric pressure levels, and atmospheric/surface meteorological variables, by leveraging diverse Earth system modeling techniques.

Therefore, when considering the architectural design of foundational models, choices can be made from the foundational architectures of CNNs, RNNs, Transformers, Graph models, GANs, and Diffusion models. When necessary, these models can be combined to enhance the representation capabilities. Detailed descriptions of these models can be found in Sec. 6.

#### 10.3.2 What strategies can enhance models and facilitate efficient and accurate representations?
Accurate representation of the latent semantic information in weather and climate data hinges on jointly modeling the temporal, spatial, and variable dimensions of the data. Potential strategies to enhance these models include tokenization strategies, positional encoding, attention mechanisms, and time feature extraction. Here we discuss these four strategies in detail:

• Tokenization Strategy. The term "token" originated in the context of Transformers, where a critical operation is dividing the original input image into small blocks of local semantic information based on a patch size - a process referred to as tokenization. For irregular reanalysis gridded weather and climate data, the absence of specific rules or definitions for segmentation implies that the choice of tokenization significantly impacts model performance. For instance, ClimaX introduces a coherent tokenization operation [25], while PanGu-Weather [63], FuXi [139], and FengWu [138] use different methods for encoding variables. A good tokenization strategy should consider spatio-temporal correlations of different variables while accounting for different physical scales, without introducing excessive complexity.

• Positional Encoding. Positional encoding in a Transformer provides spatial information about data points in a sequence. For weather and climate data, different positional encoding strategies can be employed. Compared to fixed encoding, learnable encodings offer more flexibility, as their positional parameters can be updated to increase model robustness.

• Attention Mechanisms. Attention mechanisms are critical in Transformers for modeling dependencies between different elements in a sequence. For weather and climate data, attention mechanisms can help capture relationships between different time steps, geographical locations, and meteorological variables. The computational complexity of attention mechanisms also needs to be considered, as many models encounter high cost and reduced speeds during training and inference.

• Time Feature Extraction. Weather and climate data contain a temporal dimension, and extracting time features is crucial for model accuracy. Various methods can be employed to extract time features, which can then be used as part of the model input to aid in better understanding and modeling temporal correlations.

### 10.4 Learning Strategies
Pre-training a WFM on large-scale datasets not only hinges on costly data post-processing, but also a substantial investment in computational resources. A prime example of this is PanGu-Weather, whose pre-training necessitates over 60TB of high-resolution data and more than 3000 GPU-days on V100-80G [63], underscoring the immense scale of the model. In this section, we primarily delve into a variety of learning strategies. These strategies are designed to alleviate the computational burden, thereby facilitating the training and fine-tuning of foundational models for weather and climate tasks.

• Self-Supervised Learning. Self-supervised Learning (SSL) is an unsupervised paradigm wherein models are assigned the task of predicting certain components of their own input data. This approach generates labels intrinsically from the data, obviating the need for external annotations. As a result, SSL can exploit copious amounts of unlabeled data for training. Within the sphere of weather and climate modeling, SSL could be utilized to identify climate patterns and trends. For instance, future meteorological conditions could be forecasted using historical weather variables such as temperature, humidity, and wind velocity. This could be accomplished by projecting the subsequent data point within a pre-established temporal window. In so doing, the model can apprehend inherent weather data trends and patterns. The principal advantage of SSL lies in its capacity to harness vast quantities of unlabeled data for training. Furthermore, it can reveal inherent data patterns and structures, which is especially advantageous for weather and climate tasks [64].

• Semi-Supervised Learning. Semi-supervised Learning (SML) represents an intermediate approach between Fully Supervised Learning (FSL) and Self-Supervised Learning (SSL), leveraging both labeled and unlabeled data for model training. This method is particularly advantageous for weather and climate prediction tasks due to the potential scarcity of labeled weather data and abundance of unlabeled data. One prevalent methodology in SML is self-training. Initially, a supervised model is trained using the available labeled data. Subsequently, this model is applied to predict labels for the unlabeled data, which are then employed as pseudo-labels for retraining the model. This iterative process continues until the model’s performance plateaus. The salient advantage of SML is its capacity to concurrently utilize labeled and unlabeled data for training. This facilitates an enhancement in model performance, especially when labeled data is limited, by capitalizing on the extensive quantity of unlabeled data.

• Federated Learning. Federated learning [204] (FL) is a distributed ML paradigm with the central goal of enabling multiple participants to collaboratively train a model, all while safeguarding data privacy and security [350]. In FL, every participant trains their model locally and shares only model updates, rather than the raw data. This endows FL with a distinct advantage when dealing with sensitive data, while also permitting cross-learning from diverse data sources that might be geographically dispersed or unable to be centralized due to privacy or other reasons. In the context of training WFMs, the application of federated learning carries significant benefits. Firstly, meteorological bureaus and research institutions across the globe possess extensive climate data, but owing to data ownership, privacy, and security concerns, this data cannot easily be centralized for processing. Federated learning enables these institutions to collaboratively train a robust weather forecasting model without the direct sharing of data. Secondly, given the typically large scale of weather and climate data, data transfer could potentially become a bottleneck. With FL, data can be processed and trained locally, requiring only the transfer of model updates, thus significantly reducing data transmission demands. Lastly, FL allows the model to benefit from climate data from different geographical locations and types, enhancing the model’s generalization ability and accuracy. Currently, numerous studies have incorporated FL into the process of training WFM [24], [154].

## 11 CONCLUSION
In conclusion, we present a comprehensive and up-to-date survey of data-driven models tailored to analyze weather and climate data. The intention is to offer a fresh viewpoint on this evolving discipline through a systematically organized appraisal of pertinent models. We distill the most salient methodologies within each category, investigate their respective advantages and drawbacks, and propose viable trajectories for forthcoming exploration. This survey is intended to act as an impetus to kindle sustained interest and nurture a persistent enthusiasm for research within the realm of data-driven models for weather and climate data understanding.