Scaling transformer neural networks for skillful and
reliable medium-range weather forecasting
Tung Nguyen1 Rohan Shah1, 2 Hritik Bansal1 Troy Arcomano3 Romit Maulik3, 4
V eerabhadra Kotamarthi3 Ian Foster3 Sandeep Madireddy3 Aditya Grover1
1UCLA 2CMU 3Argonne National Laboratory 4Penn State University
Abstract
Weather forecasting is a fundamental problem for anticipating and mitigating the
impacts of climate change. Recently, data-driven approaches for weather fore-
casting based on deep learning have shown great promise, achieving accuracies
that are competitive with operational systems. However, those methods often
employ complex, customized architectures without sufﬁcient ablation analysis,
making it difﬁcult to understand what truly contributes to their success. Here
we introduce Stormer, a simple transformer model that achieves state-of-the-art
performance on weather forecasting with minimal changes to the standard trans-
former backbone. We identify the key components of Stormer through careful
empirical analyses, including weather-speciﬁc embedding, randomized dynam-
ics forecast, and pressure-weighted loss. At the core of Stormer is a random-
ized forecasting objective that trains the model to forecast the weather dynamics
over varying time intervals. During inference, this allows us to produce multi-
ple forecasts for a target lead time and combine them to obtain better forecast
accuracy. On WeatherBench 2, Stormer performs competitively at short to medium-
range forecasts and outperforms current methods beyond 7 days, while requiring
orders-of-magnitude less training data and compute. Additionally, we demonstrate
Stormer’s favorable scaling properties, showing consistent improvements with
increases in model size and training tokens. Code and checkpoints are available at
https://github.com/tung-nd/stormer.
5-day ForecastInitial Conditions 
26 December 2020 00:00 UTC31 December 2020 00:00 UTC31 December 2020 00:00 UTC
Ground Truth
m/s
Figure 1: Illustration of an example 5-day forecast of near-surface wind speed (color-ﬁll) and mean
sea level pressure (contours). On December 31, 2020, an extratropical cyclone impacted Alaska
setting a new North Paciﬁc low-pressure record. We evaluate the ability of Stormer to predict this
record-breaking event 5 days in advance. Using initial conditions from 0000 UTC, 26 December 2011,
Stormer successfully forecasts the location and strength of this extreme event with great accuracy.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).
1 Introduction
Weather forecasting is a fundamental problem for science and society. With increasing concerns about
climate change, accurate weather forecasting helps prepare and recover from the effects of natural
disasters and extreme weather events, while serving as an important tool for researchers to better
understand the atmosphere. Traditionally, atmospheric scientists have relied on numerical weather
prediction (NWP) models [ 2]. These models utilize systems of differential equations describing ﬂuid
ﬂow and thermodynamics, which can be integrated over time to obtain future forecasts [29, 2]. Despite
their widespread use, NWP models suffer from many challenges, such as parameterization errors
of important small-scale physical processes, including cloud physics and radiation [ 44]. Numerical
methods also incur high computation costs due to the complexity of integrating a large system of
differential equations, especially when modeling at ﬁne spatial and temporal resolutions. Furthermore,
NWP forecast accuracy does not improve with more data, as the models rely on the expertise of
climate scientists to reﬁne equations, parameterizations, and algorithms [30].
To address the above challenges of NWP models, there has been an increasing interest in data-driven
approaches based on deep learning for weather forecasting [ 11, 42, 48]. The key idea involves
training deep neural networks to predict future weather conditions using historical data, such as the
ERA5 reanalysis dataset [ 16, 17, 40, 41]. Once trained, these models can produce forecasts in a few
seconds, as opposed to the hours required by typical NWP models. Because of the similar spatial
structure between weather data and natural images, early works in this space attempted to adopt
standard vision architectures such as ResNet [ 39, 8] and UNet [ 49] for weather forecasting, but their
performances lagged behind those of numerical models. However, signiﬁcant improvements have
been made in recent years due to better model architectures and training recipes, and increasing data
and compute [ 22, 35, 32, 3, 26, 5, 7]. Pangu-Weather [3], a 3D Earth-Speciﬁc Transformer model
trained on 0.25 → data (721 →1440 grids), was the ﬁrst model to outperform operational IFS [ 47].
Shortly after, GraphCast [26] scaled up the graph neural network architecture proposed by Keisler [22]
to 0.25→ data and showed improvements over Pangu-Weather. Despite impressive forecast accuracy,
existing methods often involve highly customized neural network architectures with minimal ablation
studies, making it difﬁcult to identify which components contribute to their success. For example, it is
unclear what the beneﬁts of 3D Earth-Speciﬁc Transformer over a standard Transformer are, and how
critical the multi-mesh message-passing in GraphCast is to its performance. A deeper understanding,
and ideally a simpliﬁcation, of these existing approaches is essential for future progress in the ﬁeld.
Furthermore, establishing a common framework would facilitate the development of foundation
models for weather and climate that extend beyond weather forecasting [32].
In this paper, we show that a simple architecture with a proper training recipe can achieve state-of-the-
art performance. We start with a standard vision transformer (ViT) architecture, and through extensive
ablation studies, identify the three key components to the performance of the model: (1) a weather-
speciﬁc embedding layer that transforms the input data to a sequence of tokens by modeling the
interactions among atmospheric variables; (2) a randomized dynamics forecasting objective that trains
the model to predict the weather dynamics at random intervals; and (3) a pressure-weighted loss that
weights variables at different pressure levels in the loss function to approximate the density at each
pressure level. During inference, our proposed randomized dynamics forecasting objective allows a
single model to produce multiple forecasts for a speciﬁed lead time by using different combinations
of the intervals for which the model was trained. For example, one can obtain a 3-day forecast by
rolling out the 6-hour predictions 12 times or 12-hour predictions 6 times. Combining these forecasts
leads to signiﬁcant accuracy improvements, especially for long lead times. We evaluate our proposed
method, namely Scalable transformers for weath er forecasting (Stormer), on WeatherBench 2 [ 41],
a widely used benchmark for data-driven weather forecasting. Stormer achieves competitive forecast
accuracy of key atmospheric variables for 1–7 days and outperforms the state-of-the-art beyond 7
days. Notably, Stormer achieves this performance by training on more than 5 → lower-resolution data
and orders-of-magnitude fewer GPU hours compared to the baselines. Finally, our scaling analysis
shows that the performance of Stormer improves consistently with increases in model capacity and
data size, demonstrating the potential for further improvements.
2 Background and Preliminaries
Given a dataset D = {Xi}N
i=1 of historical weather data, the task of global weather forecasting is
to forecast future weather conditions XT ↑ RV ↑ H↑ W given initial conditions X0 ↑ RV ↑ H↑ W ,
2
Figure 2: Different approaches to weather forecasting. Direct and continuous methods output
forecasts directly, but continuous forecasting is adaptable to various lead times by conditioning on
T . Iterative forecasting generates forecasts at small intervals ωt, which are rolled out for the ﬁnal
forecast. Our proposed randomized iterative forecasting combines continuous and iterative methods.
in which T is the target lead time, e.g., 7 days; V is the number of input and output atmospheric
variables, such as temperature and humidity; and H → W is the spatial resolution of the data, which
depends on how densely we grid the globe. This formulation is similar to many image-to-image
tasks in computer vision such as segmentation or video frame prediction. However, unlike the RGB
channels in natural images, weather data can contain up to 100s of channels. These channels represent
actual physical variables that can be unbounded in values and follow complex laws governed by
atmospheric physics. Therefore, the ability to model the spatial and temporal correlations between
these variables is crucial to forecasting.
There are three major approaches to data-driven weather forecasting. The ﬁrst and simplest is
direct forecasting, which trains the model to directly output future weather “XT = fω (X0) for each
target lead time T . Most early works in the ﬁeld adopt this approach [ 11, 42, 48, 39, 8, 49]. Since
the weather is a chaotic system, forecasting the future directly for large T is challenging, which
may explain the poor performances of these early models. Moreover, direct forecasting requires
training one neural network for each lead time, which can be computationally expensive when the
number of target lead times increases. To avoid the latter issue, continuous forecasting uses T as
an additional input: “XT = fω (X0,T ), allowing a single model to produce forecasts at any target
lead time after training. MetNet [ 43, 12, 1] employed the continuous approach for nowcasting at
different lead times up to 24 hours, WeatherBench [39] considered continuous forecasting as one
of the baselines, and ClimaX [ 32] used this approach for pretraining. However, since this approach
still attempts to forecast future weather directly, it suffers from the same challenging problem of
forecasting the chaotic weather in one step. Finally, iterative forecasting trains the model to produce
forecasts at a small interval “Xεt = fω (X0), in which ωt is typically from 6 to 24 hours. To produce
longer-horizon forecasts, we roll out the model by iteratively feeding its predictions back in as
input. This is a common paradigm in both traditional NWP systems and the two state-of-the-art
deep learning methods, Pangu-Weather and GraphCast. One drawback of this approach is error
accumulation when the number of rollout steps increases, which can be mitigated by a multi-step loss
function [22, 26, 5, 7]. In iterative forecasting, one can forecast either the weather conditions Xεt or
the weather dynamics !εt = Xεt ↓ X0, and Xεt can be recovered by adding the predicted dynamics
to the initial conditions. In this work, we adopt the latter approach, which we refer to as iterative
dynamics forecasting. We show empirically that our approach achieves superior performance relative
to the former approach in Section 4.2. Figure 2 summarizes these different approaches.
3 Methodology
We introduce Stormer, a skillful method for weather forecasting, and show that a simple architecture
can achieve competitive forecast performances with a well-designed framework. We ﬁrst present the
overall training and inference procedure of Stormer, then describe the model architecture we use in
practice. Section 4.2 empirically demonstrates the importance of each component of Stormer.
3
(a) Time interval comparison. (b) Patch embedding comparison. (c) Time embedding comparison.
Figure 3: Preliminary results on forecasting surface temperature that led to the design choices of
Stormer: (a) Different intervals are better at different lead times, (b) Weather-speciﬁc embedding is
superior to standard ViT embedding, and (c) Adaptive layer norm outperforms additive embedding.
3.1 Training
We adopt the iterative approach for Stormer, and train the model to forecast the weather dynamics
!εt = Xεt ↓ X0, which is the difference between two consecutive weather conditions, X0 and
Xεt, across the time interval ωt. A common practice in previous works [ 22, 26] is to use a small
ﬁxed value of ωt such as 6 hours. However, as we show in Figure 3a, while small intervals tend to
work well for short lead times, larger intervals excel at longer lead times (beyond 7 days) due to less
error accumulation. Therefore, having a model that can produce forecasts at different intervals and
combine them in an effective manner has the potential to improve the performance of single-interval
models. This motivates our randomized dynamics forecasting objective , which trains Stormer to
forecast the dynamics at random intervals ωt by conditioning on ωt:
L(ω)= Eωt→P (ωt),(X0 ,Xωt )→D
î
||fε (X0,ε t) → !ωt ||2
2
ó
, (1)
in which P (ωt) is the distribution of the random interval. In our experiments, unless otherwise
speciﬁed, P (ωt) is a uniform distribution over three values ωt ↔U { 6, 12, 24}. These three time
intervals play an important role in atmospheric dynamics. The 6 and 12-hour values help to encourage
the model to learn and resolve the diurnal cycle (day-night cycle), one of the most important
oscillations in the atmosphere driving short-term dynamics (e.g., temperature over the course of a
day). The 24-hour value ﬁlters the effects of the diurnal cycle and allows the model to learn longer,
synoptic-scale dynamics which are particularly important for medium-range weather forecasting [ 19].
From a practical standpoint, this randomized objective provides two beneﬁts. First, randomizing
ωt enlarges the training data, serving as data augmentation. Second, it allows a single trained
model to generate various forecasts for a speciﬁed lead time T by creating different combinations of
intervals ωt that sum to T . For example, to forecast 7 days ahead, one could use 12-hour forecasts 14
times or 24-hour forecasts 7 times. Our experiments show that combining these forecasts is crucial
for achieving good accuracy, especially for longer lead times. While both our approach and the
continuous approach use the time interval as an additional input, we perform iterative forecasting
instead of direct forecasting. This avoids the challenge of directly modeling chaotic weather and
offers more ﬂexibility for combining different intervals at test time.
3.1.1 Pressure-weighted loss
Due to the large number of variables being predicted, we use a physics-based weighting function to
weigh variables near the surface higher. Since each variable lies on a speciﬁc pressure level, we can
use pressure as a proxy for the density of the atmosphere at each level. This weighting allows the
model to prioritize near-surface variables, which are important for weather forecasting and have the
most societal impact. The ﬁnal objective function that we use for training is:
L(ω)= E
[
1
VH W
V∑
v=1
H∑
i=1
W∑
j=1
w(v)L(i)(“!vij
ωt → !vij
ωt )2
]
. (2)
The expectation is over ωt, X0, and Xεt which we omit for notational simplicity. In this equation,
w(v) is the weight of variable v, and L(i) is the latitude-weighting factor commonly used in previous
4
works to account for the non-uniformity when we grid the spherical globe [ 40, 22, 35, 32, 3, 26]. The
pressure-weighted loss was ﬁrst introduced by GraphCast [ 26], and we show that it also helps with a
different architecture.
3.1.2 Multi-step ﬁnetuning
To produce forecasts at a lead time beyond the training intervals, we roll out the model several times.
Since the model’s forecasts are fed back as input, the forecast error accumulates as we roll out more
steps. To alleviate this issue, we ﬁnetune the model on a multi-step loss function. Speciﬁcally, for
each gradient step, we roll out the model K times, and average the objective (2) over the K steps:
L(ω)= E
[
1
KV HW
K∑
k=1
V∑
v=1
H∑
i=1
W∑
j=1
w(v)L(i)(“!vij
kωt → !vij
kωt )2
]
. (3)
In practice, we implement a three-phase training procedure for Stormer. In the ﬁrst phase, we train
the model to perform single-step forecasting, which is equivalent to optimizing the objective in (2).
In the second and third phases, we ﬁnetune the trained model from the preceding phase with K =
4 and K = 8, respectively. We use the same sampled value of the interval ωt for all K steps. We
tried randomizing ωt at each rollout step, but found that doing so destabilized training as the loss
value at each step is of different magnitudes, hurting the ﬁnal performance of the model. Multi-step
ﬁnetuning was used in FourCastNet [35] and also adopted in more recent works [22, 26].
3.2 Inference
At test time, Stormer can produce forecasts at any time interval ωt used during training. Thus the
model can generate multiple forecasts for a target lead time T by creating different combinations of
ωt that sum to T . We consider two inference strategies for generating forecasts:
Homogeneous In this strategy, we only consider homogeneous combinations of ωt, i.e., combinations
with just one value of ωt. For example, for T = 24 we consider [6, 6, 6, 6], [12, 12], and [24].
Best m in n We generate n different, possibly heterogeneous combinations of ωt, validate each
combination, and pick m combinations with the lowest validation losses for testing.
The two strategies offer a trade-off between efﬁciency and expressivity. The homogeneous strategy
only requires running three combinations for each lead time T , while best m in n provides greater
expressivity. Upon determining these combinations and executing the model rollouts, we obtain the
ﬁnal forecast by averaging the individual predictions. This approach achieves a similar effect to
ensembling in NWP , where multiple forecasts are generated by running NWP models with different
perturbed versions of the initial condition [ 27]. As target lead times extend beyond 5–7 days and
individual forecasts begin to diverge due to the chaotic nature of the atmosphere, averaging these
forecasts is a Monte Carlo integration approach to handle this sensitivity to initial conditions and
the uncertainty in the analyses used as initial conditions [ 31]. We note that our inference strategy is
distinguished from that used in Pangu-Weather: while Pangu-Weather trains a separate model for
each time interval ωt, we train a single model for all ωt values by conditioning on ωt. Additionally,
while Pangu-Weather relies on a single combination of intervals to minimize rollout steps, our method
improves forecast accuracy by averaging multiple forecasts derived from diverse combinations.
3.3 Model architecture
We instantiate the framework in Section 3.1 with a simple Transformer [ 45]-based architecture. Due
to the similarity of weather forecasting to various dense prediction tasks in computer vision, one
might consider applying Vision Transformer (ViT) [10] for this task. However, weather data is distinct
from natural images, primarily due to its signiﬁcantly higher number of input channels, representing
atmospheric variables with intricate physical relationships. For example, the wind ﬁelds are closely
related to the gradient and shape of the geopotential ﬁeld, and redistribute moisture and heat around
the globe. Effectively modeling these interactions is critical to forecast accuracy.
3.4 Weather-speciﬁc embedding
The standard patch embedding module in ViT, which uses a linear layer for embedding all input
channels within a patch into a vector, may not sufﬁciently capture the complex interactions among
5
input atmospheric variables. Therefore, we adopt for our architecture a weather-speciﬁc embedding
module, consisting of two components, variable tokenization and variable aggregation.
Variable tokenization Given an input of shape V → H → W , variable tokenization linearly embeds
each variable independently to a sequence of shape (H/p) → (W/p) → D, in which p is the patch
size and D is the hidden dimension. We then concatenate the output of all variables, resulting in a
sequence of shape (H/p) → (W/p) → V → D.
Variable aggregation We employ a single-layer cross-attention mechanism with a learnable query
vector to aggregate information across variables. This module operates over the variable dimension on
the output of the tokenization stage to produce a sequence of shape (H/p)→ (W/p)→ D. This module
offers two primary advantages. First, it reduces the sequence length by a factor of V , signiﬁcantly
alleviating the computational cost as we use transformer to process the sequence. Second, unlike
standard patch embedding, the cross-attention layer allows the models to learn non-linear relationships
among input variables, enhancing the model’s capacity to capture complex physical interactions. We
present the complete implementation details of the weather-speciﬁc embedding in Section B.
Figure 3b shows the superior performance of weather-speciﬁc embedding to standard patch embedding
at all lead times from 1 to 10 days. A similar weather-speciﬁc embedding module was introduced by
ClimaX [32] to improve the model’s ﬂexibility when handling diverse data sources with heterogeneous
input variables. We show that this specialized embedding module outperforms the standard patch
embedding even when trained on a single dataset, due to its ability to model interactions between
atmospheric variables through cross-attention effectively.
3.4.1 Stormer Transformer block
Following weather-speciﬁc embedding, the tokens are processed by a stack of transformer blocks [ 45].
In addition to the input X0, the block also needs to process the time interval ωt. We do this by replacing
the standard layer normalization module used in transformer blocks with adaptive layer normalization
(adaLN) [37]. In adaLN, instead of learning the scale and shift parameters ε and ϑ as independent
parameters of the network, we regress them with an one-layer MLP from the embedding of ωt.
Compared to ClimaX [ 32] which only adds the lead time embedding to the tokens before the ﬁrst
attention layer, adaLN is applied to every transformer block, thus amplifying the conditioning signal.
Figure 3c shows the consistent improvement of adaLN over the additive lead time embedding used
in ClimaX. Adaptive layer norm was widely used in both GANs [ 21, 4] and Diffusion [ 9, 36] to
condition on additional inputs such as time steps or class labels. Figure 7 illustrates Stormer’s
architecture. We refer to [32] for illustrations of the weather-speciﬁc embedding block.
4 Experiments
We compare Stormer with state-of-the-art weather forecasting methods, and conduct extensive
ablation analyses to understand the importance of each component in Stormer. We also study Stormer
scalability by varying model size and the number of training tokens. We conduct all experiments on
WeatherBench 2 (WB2) [41], a standard benchmark for data-driven weather forecasting.
Data: We train and evaluate Stormer on the ERA5 dataset from WB2, which is the curated version
of the ERA5 reanalysis data provided by ECMWF [ 17]. In its raw form, ERA5 contains hourly
data from 1979 to the current time at 0.25 → (721→1440 grids) resolution, with different atmospheric
variables spanning 137 pressure levels plus the Earth’s surface. WB2 downsamples this data to
6-hourly with 13 pressure levels and provides different spatial resolutions. In this work, we use the
1.40625→ (128→256 grids) data. We use four surface-level variables – 2-meter temperature (T2m),
10-meter U and V components of wind (U10 and V10), and Mean sea-level pressure (MSLP), and
ﬁve atmospheric variables – Geopotential (Z), Temperature (T), U and V components of wind (U and
V), and Speciﬁc humidity (Q), each at 13 pressure levels {50, 100, 150, 200, 250, 300, 400, 500, 600,
700, 850, 925, 1000}. We use 1979 to 2018 for training, 2019 for validation, and 2020 for testing.
Stormer architecture: For the main comparison in Section 4.1, we report the results of our largest
Stormer model with 24 transformer blocks, 1024 hidden dimensions, and a patch size of 2, which is
equivalent to ViT-L except for the smaller patch size. We vary the model size and patch size in the
scaling analysis. For the remaining experiments, we report the performance of the same model as for
the main result, but with a larger patch size of 4 for faster training.
6
Figure 4: Global forecast results of Stormer and the baselines. We show the latitude-weighted RMSE
for select variables. Stormer is on par or outperforms the baselines for the shown variables. During
the later portion of the forecasts, Stormer gains ↔ 1 day of forecast skill with respect to climatology
compared to the next best deep learning model. We note that Stormer was trained on much lower
resolution data (1.40625→) compared to Pangu-Weather (0.25 →) and GraphCast (0.25 →).
Training: For the main result in Section 4.1, we train Stormer in three phases, as described in
Section 3.1.2. We train the model for 100 epochs for the ﬁrst phase, 20 epochs for the second, and 20
epochs for the third. We perform early stopping on the validation loss aggregated across all variables,
and evaluate the best checkpoint of the ﬁnal phase on the test set. For the remaining experiments, we
only train Stormer for the ﬁrst phase due to computational constraints.
Evaluation: We evaluate Stormer and two deep learning baselines on forecasting nine key variables:
T2m, U10, V10, MSLP , Z500, T850, Q700, U850, and V850. These variables are also used to report
the headline scores in WB2. For each variable, we evaluate the forecast accuracy at lead times from 1
to 14 days, using the latitude-weighted root-mean-square error (RMSE) metric. For the main results,
we use best m in n inference for rolling out Stormer as it yields the best result, with m = 32 and
n = 128 chosen randomly from all possible combinations. For the remaining experiments, we use
homogeneous inference for faster evaluations. We provide results on the non-ensemble version of
Stormer, probabilistic metrics with IC perturbations, a comparison between two inference strategies,
and additional ablation studies in Appendix C.
4.1 Comparison with State-of-the-art models
We compare the forecast performance of Stormer with Pangu-Weather [ 3] and GraphCast [ 26], two
leading deep learning methods for weather forecasting. Pangu-Weather employs a 3D Earth-Speciﬁc
Transformer architecture trained on the same variables as Stormer, but with hourly data and a higher
spatial resolution of 0.25 →. GraphCast is a graph neural network that was trained on 6-hourly ERA5
data at 0.25 →, using 37 pressure levels for the atmospheric variables, and two additional variables,
7
(a) Impact of randomized forecasting. (b) Impact of weighted loss. (c) Absolute vs. dynamics forecast.
Figure 5: Ablation studies showing the importance of different components in Stormer: (a) Random-
ized forecasting, (b) Pressure-weighted loss, and (c) Dynamics forecasting.
total precipitation and vertical wind speed. Both Pangu-Weather and GraphCast are iterative methods.
GraphCast operates at 6-hour intervals, while Pangu-Weather uses four distinct models for 1-, 3-, 6-,
and 24-hour intervals, and combines them to produce forecasts for speciﬁc lead times. We include
Climatology as a simple baseline. We also compare Stormer with IFS HRES, the state-of-the-art
numerical forecasting system, and IFS ENS (mean), which is the ensemble version of IFS. Since
WB2 does not provide forecasts of these numerical models beyond 10 days, we defer the comparison
against these models to Appendix C.1.
Results: Figure 4 evaluates different methods on forecasting nine key weather variables at lead times
from 1 to 14 days. For short-range, 1–5 day forecasts, Stormer’s accuracy is on par with or exceeds
that of Pangu-Weather, but lags slightly behind GraphCast. At longer lead times, Stormer excels,
consistently outperforming both Pangu-Weather and GraphCast from day 6 onwards by a large
margin. Moreover, the performance gap increases as we increase the lead time. At 14 day forecasts,
Stormer performs better than GraphCast by 10% ↓ 20% across all 9 key variables. Stormer is also the
only model in this comparison that performs better than Climatology at long lead times, while other
methods approach or even do worse than this simple baseline. The model’s superior performance at
long lead times is attributed to the use of randomized dynamics training, which improves forecast
accuracy by averaging out multiple forecasts, especially when individual forecasts begin to diverge.
Moreover, we also note that Stormer achieves this performance with much less compute and training
data compared to the two deep learning baselines. We train Stormer on 6-hourly data of 1.40625 →
with 13 pressure levels, which is approximately 190 → less data than Pangu-Weather’s hourly data
at 0.25→ and 90→ less than that used for GraphCast, which also uses 6-hourly data but at a 0.25 →
resolution with 37 pressure levels. The training of Stormer was completed in under 24 hours on 128
A100 GPUs. In contrast, Pangu-Weather took 60 days to train four models on 192 V100 GPUs, and
GraphCast required 28 days on 32 TPUv4 devices. This training efﬁciency will facilitate future works
that build upon our proposed framework.
4.2 Ablation studies
We analyze the signiﬁcance of individual elements within Stormer by systematically omitting one
component at a time and observing the difference in performance.
Impact of randomized forecasts: We evaluate the effectiveness of our proposed randomized iterative
forecasting approach. Figure 5a compares the forecast accuracy on surface temperature of Stormer
and three models trained with different values of ωt. Stormer consistently outperforms all single-
interval models at all lead times, and the performance gap widens as the lead time increases. We
attribute this result to the ability of Stormer to produce multiple forecasts and combine them to
improve accuracy. We note that Stormer achieves this improvement with no computational overhead
compared to the single-interval models, as the different models share the same architecture and were
trained for the same duration.
Impact of pressure-weighted loss: Figure 5b shows the superior performance of Stormer when
trained with the pressure-weighted loss. Intuitively, the weighting factor prioritizes variables that
are nearer to the surface, as these variables are more important for weather forecasting and climate
science.
8
Figure 6: Stormer improves consistently with larger models (left) and smaller patch sizes (right).
Dynamics vs. absolute forecasts: We justify our decision to forecast the dynamics !εt by comparing
with a counterpart that forecasts Xεt. Figure 5c shows that forecasting the changes in weather
conditions (dynamics) is consistently more accurate than predicting complete weather states. One
possible explanation for this result is that it is simpler for the model to predict the changes between
two consecutive weather conditions than the entire state of the weather; thus, the model can focus on
learning the most signiﬁcant signal, enhancing forecast accuracy.
4.3 Scaling analysis
We examine Stormer’s scalability in terms of model size and training tokens. We evaluate three
variants – Stormer-S, Stormer-B, and Stormer-L, with parameter counts similar to ViT-S, ViT-B, and
ViT-L, respectively. To understand the impact of training token count, we vary the patch size from 2
to 16, quadrupling the training tokens each time the patch size is halved. Figure 6 shows a signiﬁcant
improvement in forecast accuracy with larger models, and the performance gap widens with increased
lead time. Since we do not perform multi-step ﬁne-tuning for these models, minor performance
differences at short intervals may magnify over time. While multi-step ﬁne-tuning could potentially
reduce this gap, it is unlikely to eliminate it entirely. Reducing the patch size also improves the
performance of the model consistently. From a practical view, smaller patches mean more tokens and
consequently more training data. From a climate perspective, smaller patches capture ﬁner weather
details and processes not evident in larger patches, allowing the model to more effectively capture
physical dynamics that drive weather patterns.
5 Related Work
Deterministic weather forecasting Deep learning offers a promising approach to weather fore-
casting due to its fast inference and high expressivity. Early efforts [ 11, 42, 48] attempted training
simple architectures on small weather datasets. To facilitate progress, WeatherBench [ 40] provided
standard datasets and benchmarks, leading to subsequent works that trained Resnet [ 15] and UNet
architectures [49] for weather forecasting. These works showed the potential of deep learning but
still displayed inferior accuracy to numerical systems. However, signiﬁcant improvements have
been made in the last few years. Keisler [22] proposed a graph neural network (GNN) that per-
forms iterative forecasting with 6-hour intervals, performing comparably with some NWP models.
FourCastNet [35] trained an adaptive Fourier neural operator and was the ﬁrst neural network to
run on 0.25 → data. Pangu-Weather [ 3], with its 3D Earth-Speciﬁc Transformer design, trained on
high-resolution data, surpassed the benchmark IFS model. Following this, GraphCast [ 26] scaled
up Keisler’s GNN architecture to 0.25→, achieving even better results than Pangu-Weather. FuXi [ 6]
was a subsequent work that trained a SwinV2 [ 28] on 0.25→ data and showed improvements over
GraphCast at long lead times. However, FuXi requires ﬁnetuning multiple models specialized for
different time ranges, increasing model complexity and computation. FengWu [ 5] was a concurrent
work with FuXi that also focused on improving long-horizon forecasts, but has not revealed complete
model architecture and training details. ClimODE [ 46] introduced physical inductive biases to provide
better interpretability but was empirically inferior to existing methods.
Probabilistic weather forecasting In addition to high accuracy, a desired ability of a weather
forecasting model is to quantify forecast uncertainty. One common approach to achieve this is to
combine an existing architecture with a probabilistic loss function. Gencast [ 38] was one of the ﬁrst
9
works in this direction, combining the Graphcast architecture with a diffusion objective [ 18, 21],
followed by Graph-EFM [ 33], which combined a hierarchical variant of Graphcast with the V AE
objective [23]. This approach allows the model to generate multiple forecasts and estimate uncertainty
after training. In an orthogonal approach, NeuralGCM [ 25] proposed a hybrid forecasting system
that combined a differentiable dynamical core with ML components for end-to-end training. The
dynamical core allows the method to leverage powerful general circulation models and generate
forecast ensembles via IC perturbations similar to NWP . However, the dynamical core in NeuralGCM
is more computationally expensive than forward-passing a neural network and can limit the method’s
performance with an imperfect circulation model.
6 Conclusion and Future Work
This work proposes Stormer, a simple yet effective deep learning model for weather forecasting.
We demonstrate that a standard vision architecture can achieve competitive results with a carefully
designed training recipe. Our novel approach, randomized iterative forecasting, trains the model to
forecast at different time intervals, enabling it to produce and combine multiple forecasts for each
target lead time for better accuracy. Experiments show Stormer’s competitive accuracy in short-range
forecasts and exceptional performance beyond 7 days, all with signiﬁcantly less data and computing
resources. Future research could explore using multiple forecasts to quantify uncertainty, randomizing
other model components like input variables to increase variability and accuracy, and evaluating
Stormer on higher-resolution data and larger model sizes due to its favorable scaling properties.
7 Acknowledgments
AG acknowledges support from Google, Cisco, and Meta. SM is supported by the U.S. Department of
Energy, Ofﬁce of Science, Advanced Scientiﬁc Computing Research, through the SciDAC-RAPIDS2
institute under Contract DE-AC02-06CH11357. RM and VK are supported under a Laboratory
Directed Research and Development (LDRD) Program at Argonne National Laboratory, through
U.S. Department of Energy (DOE) contract DE-AC02-06CH11357. TA is supported by the Global
Change Fellowship in the Environmental Science Division at Argonne National Laboratory (grant
no. LDRD 2023-0236). RM acknowledges support from DOE-FOA-2493: "Data intensive scientiﬁc
machine learning". An award for computer time was provided by the U.S. Department of Energy’s
(DOE) Innovative and Novel Computational Impact on Theory and Experiment (INCITE) Program
and Argonne Leadership Computing Facility Director’s discretionary award. This research used
resources from the Argonne Leadership Computing Facility, a U.S. DOE Ofﬁce of Science user
facility at Argonne National Laboratory, which is supported by the Ofﬁce of Science of the U.S. DOE
under Contract No. DE-AC02-06CH11357.
10
References
[1] Marcin Andrychowicz, Lasse Espeholt, Di Li, Samier Merchant, Alex Merose, Fred Zyda,
Shreya Agrawal, and Nal Kalchbrenner. Deep learning for day forecasts from sparse observa-
tions. arXiv preprint arXiv:2306.06079, 2023.
[2] Peter Bauer, Alan Thorpe, and Gilbert Brunet. The quiet revolution of numerical weather
prediction. Nature, 525(7567):47–55, 2015.
[3] Kaifeng Bi, Lingxi Xie, Hengheng Zhang, Xin Chen, Xiaotao Gu, and Qi Tian. Accurate
medium-range global weather forecasting with 3D neural networks. Nature, 619(7970):533–
538, 2023.
[4] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high ﬁdelity
natural image synthesis. arXiv preprint arXiv:1809.11096, 2018.
[5] Kang Chen, Tao Han, Junchao Gong, Lei Bai, Fenghua Ling, Jing-Jia Luo, Xi Chen, Leiming
Ma, Tianning Zhang, Rui Su, et al. Fengwu: Pushing the skillful global medium-range weather
forecast beyond 10 days lead. arXiv preprint arXiv:2304.02948, 2023.
[6] Lei Chen, Xiaohui Zhong, Feng Zhang, Y uan Cheng, Yinghui Xu, Y uan Qi, and Hao Li.
Fuxi: a cascade machine learning forecasting system for 15-day global weather forecast. npj
Climate and Atmospheric Science , 6(1):190, 2023. doi: 10.1038/s41612-023-00512-1. URL
https://doi.org/10.1038/s41612-023-00512-1 .
[7] Lei Chen, Xiaohui Zhong, Feng Zhang, Y uan Cheng, Yinghui Xu, Y uan Qi, and Hao Li. FuXi:
A cascade machine learning forecasting system for 15-day global weather forecast. arXiv
preprint arXiv:2306.12873, 2023.
[8] Mariana CA Clare, Omar Jamil, and Cyril J Morcrette. Combining distribution-based neural net-
works to predict weather forecast probabilities. Quarterly Journal of the Royal Meteorological
Society, 147(741):4337–4357, 2021.
[9] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat GANs on image synthesis.
Advances in Neural Information Processing Systems , 34:8780–8794, 2021.
[10] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,
Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly,
Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image
recognition at scale. arXiv preprint arXiv:2010.11929, 2020.
[11] P . D. Dueben and P . Bauer. Challenges and design choices for global weather and climate
models based on machine learning. Geoscientiﬁc Model Development , 11(10):3999–4009,
2018. doi: 10.5194/gmd-11-3999-2018. URL https://gmd.copernicus.org/articles/
11/3999/2018/.
[12] Lasse Espeholt, Shreya Agrawal, Casper Sønderby, Manoj Kumar, Jonathan Heek, Carla
Bromberg, Cenk Gazen, Rob Carver, Marcin Andrychowicz, Jason Hickey, et al. Deep learning
for twelve hour precipitation forecasts. Nature communications, 13(1):1–10, 2022.
[13] William A Falcon. PyTorch lightning. GitHub, 3, 2019.
[14] Charles R. Harris, K. Jarrod Millman, Stéfan J. van der Walt, Ralf Gommers, Pauli Vir-
tanen, David Cournapeau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathaniel J. Smith,
Robert Kern, Matti Picus, Stephan Hoyer, Marten H. van Kerkwijk, Matthew Brett, Allan Hal-
dane, Jaime Fernández del Río, Mark Wiebe, Pearu Peterson, Pierre Gérard-Marchant, Kevin
Sheppard, Tyler Reddy, Warren Weckesser, Hameer Abbasi, Christoph Gohlke, and Travis E.
Oliphant. Array programming with NumPy. Nature, 585(7825):357–362, September 2020. doi:
10.1038/s41586-020-2649-2. URL https://doi.org/10.1038/s41586-020-2649-2 .
[15] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition ,
pages 770–778, 2016.
11
[16] Hans Hersbach, Bill Bell, Paul Berrisford, Gionata Biavati, András Horányi, Joaquín
Muñoz Sabater, Julien Nicolas, Carole Peubey, Raluca Radu, Iryna Rozum, Dinand Schepers,
Adrian Simmons, Cornel Soci, Dick Dee, and Jean-Noël Thépaut. ERA5 hourly data on single
levels from 1979 to present. Copernicus Climate Change Service (C3S) Climate Data Dtore
(CDS), 10(10.24381), 2018.
[17] Hans Hersbach, Bill Bell, Paul Berrisford, Shoji Hirahara, András Horányi, Joaquín Muñoz-
Sabater, Julien Nicolas, Carole Peubey, Raluca Radu, Dinand Schepers, , Adrian Simmons,
Cornel Soci, Saleh Abdalla, Xavier Abellan, Gianpaolo Balsamo, Peter Bechtold, Gionata
Biavati, Jean Bidlot, Massimo Bonavita, Giovanna De Chiara, Per Dahlgren, Dick Dee, Michail
Diamantakis, Rossana Dragani, Johannes Flemming, Richard Forbes, Manuel Fuentes, Alan
Geer, Leo Haimberger, Sean Healy, Robin J. Hogan, Elías Hólm, Marta Janisková, Sarah
Keeley, Patrick Laloyaux, Philippe Lopez, Cristina Lupu, Gabor Radnoti, Patricia de Rosnay,
Iryna Rozum, Freja V amborg, Sebastien Villaume, and Jean-Noël Thépaut. The ERA5 global
reanalysis. Quarterly Journal of the Royal Meteorological Society , 146(730):1999–2049, 2020.
[18] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances
in neural information processing systems , 33:6840–6851, 2020.
[19] James R. Holton. An Introduction to Dynamic Meteorology. International Geophysics Series.
Elsevier Academic Press, Burlington, MA, 4 edition, 2004. ISBN 9780123540157.
[20] Stephan Hoyer and Joe Hamman. xarray: N-D labeled arrays and datasets in Python. Journal
of Open Research Software, 5(1):10, April 2017. doi: 10.5334/jors.148.
[21] Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative
adversarial networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pages 4401–4410, 2019.
[22] Ryan Keisler. Forecasting global weather with graph neural networks. arXiv preprint
arXiv:2202.07575, 2022.
[23] Diederik P Kingma. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.
[24] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
[25] Dmitrii Kochkov, Janni Y uval, Ian Langmore, Peter Norgaard, Jamie Smith, Grifﬁn Mooers,
Milan Klöwer, James Lottes, Stephan Rasp, Peter Düben, et al. Neural general circulation
models for weather and climate. Nature, 632(8027):1060–1066, 2024.
[26] Remi Lam, Alvaro Sanchez-Gonzalez, Matthew Willson, Peter Wirnsberger, Meire Fortunato,
Ferran Alet, Suman Ravuri, Timo Ewalds, Zach Eaton-Rosen, Weihua Hu, Alexander Merose,
Stephan Hoyer, George Holland, Oriol Vinyals, Jacklynn Stott, Alexander Pritzel, Shakir
Mohamed, and Peter Battaglia. Learning skillful medium-range global weather forecasting.
Science, 0(0):eadi2336, 2023. doi: 10.1126/science.adi2336. URL https://www.science.
org/doi/abs/10.1126/science.adi2336.
[27] John M. Lewis. Roots of ensemble forecasting. Monthly Weather Review, 133(7):1865 – 1885,
2005. doi: https://doi.org/10.1175/MWR2949.1. URL https://journals.ametsoc.org/
view/journals/mwre/133/7/mwr2949.1.xml.
[28] Ze Liu, Han Hu, Y utong Lin, Zhuliang Y ao, Zhenda Xie, Yixuan Wei, Jia Ning, Y ue Cao, Zheng
Zhang, Li Dong, et al. Swin transformer v2: Scaling up capacity and resolution. In Proceedings
of the IEEE/CVF conference on computer vision and pattern recognition , pages 12009–12019,
2022.
[29] Peter Lynch. The origins of computer weather prediction and climate modeling. Journal of
Computational Physics, 227(7):3431–3444, 2008.
[30] Linus Magnusson and Erland Källén. Factors inﬂuencing skill improvements in the ecmwf
forecasting system. Monthly Weather Review, 141(9):3142–3153, 2013.
12
[31] N. Metropolis and S. Ulam. The Monte Carlo method. Journal of the American Statistical
Association, 44:335, 1949.
[32] Tung Nguyen, Johannes Brandstetter, Ashish Kapoor, Jayesh K Gupta, and Aditya Grover.
ClimaX: A foundation model for weather and climate. arXiv preprint arXiv:2301.10343, 2023.
[33] Joel Oskarsson, Tomas Landelius, Marc Peter Deisenroth, and Fredrik Lindsten. Probabilistic
weather forecasting with hierarchical graph neural networks. arXiv preprint arXiv:2406.04759,
2024.
[34] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas
Köpf, Edward Y ang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,
Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An imperative style,
high-performance deep learning library. Advances in Neural Information Processing Systems ,
32, 2019.
[35] Jaideep Pathak, Shashank Subramanian, Peter Harrington, Sanjeev Raja, Ashesh Chattopadhyay,
Morteza Mardani, Thorsten Kurth, David Hall, Zongyi Li, Kamyar Azizzadenesheli, Pedram
Hassanzadeh, Karthik Kashinath, and Animashree Anandkumar. FourCastNet: A global data-
driven high-resolution weather model using adaptive Fourier neural operators. arXiv preprint
arXiv:2202.11214, 2022.
[36] William Peebles and Saining Xie. Scalable diffusion models with transformers. In Proceedings
of the IEEE/CVF International Conference on Computer Vision , pages 4195–4205, 2023.
[37] Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron Courville. FiLM:
Visual reasoning with a general conditioning layer. In Proceedings of the AAAI Conference on
Artiﬁcial Intelligence, volume 32, 2018.
[38] Ilan Price, Alvaro Sanchez-Gonzalez, Ferran Alet, Timo Ewalds, Andrew El-Kadi, Jacklynn
Stott, Shakir Mohamed, Peter Battaglia, Remi Lam, and Matthew Willson. Gencast: Diffusion-
based ensemble forecasting for medium-range weather. arXiv preprint arXiv:2312.15796 ,
2023.
[39] Stephan Rasp and Nils Thuerey. Data-driven medium-range weather prediction with a resnet
pretrained on climate simulations: A new model for WeatherBench. Journal of Advances in
Modeling Earth Systems, 13(2):e2020MS002405, 2021.
[40] Stephan Rasp, Peter D Dueben, Sebastian Scher, Jonathan A Weyn, Soukayna Mouatadid, and
Nils Thuerey. WeatherBench: a benchmark data set for data-driven weather forecasting. Journal
of Advances in Modeling Earth Systems , 12(11):e2020MS002203, 2020.
[41] Stephan Rasp, Stephan Hoyer, Alexander Merose, Ian Langmore, Peter Battaglia, Tyler Russel,
Alvaro Sanchez-Gonzalez, Vivian Y ang, Rob Carver, Shreya Agrawal, Matthew Chantry,
Zied Ben Bouallegue, Peter Dueben, Carla Bromberg, Jared Sisk, Luke Barrington, Aaron Bell,
and Fei Sha. WeatherBench 2: A benchmark for the next generation of data-driven global
weather models. arXiv preprint arXiv:2308.15560, 2023.
[42] Sebastian Scher. Toward data-driven weather and climate forecasting: Approximating a simple
general circulation model with deep learning. Geophysical Research Letters, 45(22):12–616,
2018.
[43] Casper Kaae Sønderby, Lasse Espeholt, Jonathan Heek, Mostafa Dehghani, Avital Oliver, Tim
Salimans, Shreya Agrawal, Jason Hickey, and Nal Kalchbrenner. Metnet: A neural weather
model for precipitation forecasting. arXiv preprint arXiv:2003.12140, 2020.
[44] David J Stensrud. Parameterization Schemes: Keys to Understanding Numerical Weather
Prediction Models. Cambridge University Press, 2009.
[45] Ashish V aswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
!ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in Neural Information
Processing Systems, 30, 2017.
13
[46] Y ogesh V erma, Markus Heinonen, and Vikas Garg. Climode: Climate and weather forecasting
with physics-informed neural odes. In The Twelfth International Conference on Learning
Representations.
[47] NP Wedi, P Bauer, W Denoninck, M Diamantakis, M Hamrud, C Kuhnlein, S Malardel,
K Mogensen, G Mozdzynski, and PK Smolarkiewicz. The modelling infrastructure of the
Integrated F orecasting System: Recent advances and future challenges. European Centre for
Medium-Range Weather Forecasts, 2015.
[48] Jonathan A Weyn, Dale R Durran, and Rich Caruana. Can machines learn to predict weather?
Using deep learning to predict gridded 500-hPa geopotential height from historical weather
data. Journal of Advances in Modeling Earth Systems , 11(8):2680–2693, 2019.
[49] Jonathan A Weyn, Dale R Durran, and Rich Caruana. Improving data-driven global weather
prediction using deep convolutional neural networks on a cubed sphere. Journal of Advances in
Modeling Earth Systems, 12(9):e2020MS002109, 2020.
[50] Ross Wightman. PyTorch image models. https://github.com/rwightman/
pytorch-image-models, 2019.
14