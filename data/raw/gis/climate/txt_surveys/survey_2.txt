1
Foundation Models for Weather and Climate
Data Understanding: A Comprehensive Survey
Shengchao Chen, Member, IEEE, Guodong Long, Jing Jiang, Dikai Liu, Senior Member, IEEE, and
Chengqi Zhang, Senior Member, IEEE
Abstract—
As artificial intelligence (AI) continues to rapidly evolve, the realm of Earth and atmospheric sciences is increasingly adopting data-
driven models, powered by progressive developments in deep learning (DL). Specifically, DL techniques are extensively utilized to
decode the chaotic and nonlinear aspects of Earth systems, and to address climate challenges via understanding weather and climate
data. Cutting-edge performance on specific tasks within narrower spatio-temporal scales has been achieved recently through DL. The
rise of large models, specifically large language models (LLMs), has enabled fine-tuning processes that yield remarkable outcomes
across various downstream tasks, thereby propelling the advancement of general AI. However, we are still navigating the initial
stages of crafting general AI for weather and climate. In this survey, we offer an exhaustive, timely overview of state-of-the-art AI
methodologies specifically engineered for weather and climate data, with a special focus on time series and text data. Our primary
coverage encompasses four critical aspects: types of weather and climate data, principal model architectures, model scopes and
applications, and datasets for weather and climate. Furthermore, in relation to the creation and application of foundation models for
weather and climate data understanding, we delve into the field’s prevailing challenges, offer crucial insights, and propose detailed
avenues for future research. This comprehensive approach equips practitioners with the requisite knowledge to make substantial
progress in this domain. Our survey encapsulates the most recent breakthroughs in research on large, data-driven models for weather
and climate data understanding, emphasizing robust foundations, current advancements, practical applications, crucial resources, and
prospective research opportunities.
Index Terms—Foundation Models, Weather & Climate Analysis, Deep Learning, Time Series, Spatio-Temporal data, Earth System.
✦
CONTENTS
1 Introduction 2
2 Related Work and Differences 5
3 Background and Preliminary 5
3.1 Foundation Models . . . . . . . . . . . . 5
3.2 Task-Specific Models . . . . . . . . . . . 6
3.3 Types of Weather and Climate Data . . . 7
3.4 Mainstream Tasks for Weather and Cli-
mate . . . . . . . . . . . . . . . . . . . . 8
4 Basic Structure for Weather & Climate 9
4.1 Recurrent Neural Networks . . . . . . . 9
4.2 Diffusion Models . . . . . . . . . . . . . 10
4.3 Transformers . . . . . . . . . . . . . . . . 10
4.4 Generative Adversarial Networks . . . . 11
4.5 Spatio-Temporal Graph Neural Networks 11
• Shengchao Chen, Guodong Long, Jing Jiang, and Chengqi Zhang are
with the Australian Artificial Intelligence Institute, School of Computer
Science, Faculty of Engineering and Information Technology, Univer-
sity of Technology Sydney, Sydney, NSW, 2007, Australia. (Email:
pavelchen@ieee.org, guodong.long@uts.edu.au, jing.jiang@uts.edu.au,
chengqi.zhang@uts.edu.au)
• Dikai Liu is with the Robotics Institute, University of Technology Sydney,
Sydney, NSW, 2007, Australia. (Email: dikai.liu@uts.edu.au)
• Corresponding Author: guodong.long@uts.edu.au (Guodong Long)
• Github-https://github.com/shengchaochen82/
Awesome-Large-Models-for-Weather-and-Climate.
Survey Version Dec. 4, 2023.
5 Overview and Categorization 11
6 Models for Weather & Climate 13
6.1 Foundation Models for Weather & Cli-
mate . . . . . . . . . . . . . . . . . . . . 13
6.2 Task-specific Models for Weather & Cli-
mate . . . . . . . . . . . . . . . . . . . . 13
7 Applications 15
7.1 Forecasting . . . . . . . . . . . . . . . . . 15
7.2 Precipitation Nowcasting . . . . . . . . . 16
7.3 Downscaling . . . . . . . . . . . . . . . . 17
7.4 Bias Correction . . . . . . . . . . . . . . 18
7.5 Data Assimilation . . . . . . . . . . . . . 18
7.6 Climate Text Analysis . . . . . . . . . . . 18
7.7 Weather Patterns Understanding . . . . 18
7.7.1 Climate Phenomena Under-
standing and Prediction . . . . 19
7.7.2 Extreme Weather Prediction
and Understanding . . . . . . 19
8 Resources 20
8.1 Dataset . . . . . . . . . . . . . . . . . . . 20
8.1.1 Weather and Climate Series
Data . . . . . . . . . . . . . . . 20
8.1.2 Weather and Climate Text Data 24
8.2 Tools and Models . . . . . . . . . . . . . 24
arXiv:2312.03014v1  [cs.LG]  5 Dec 2023
2
9 Challenges, Outlook, and Opportunities 24
9.1 Post-Processing of Data . . . . . . . . . . 25
9.2 Development of Multi-Modal Models . . 25
9.3 Interpretability and Causability . . . . . 25
9.4 Generalizability of Models . . . . . . . . 26
9.5 Privacy, Adversarial Attacks, and Com-
munication . . . . . . . . . . . . . . . . . 26
9.6 Continuous Learning and On-device
Adaption . . . . . . . . . . . . . . . . . . 26
9.7 Reproducibility . . . . . . . . . . . . . . 27
10 Insight for Foundation Model Designing 27
10.1 One Fits All . . . . . . . . . . . . . . . . 27
10.2 Multi-source Data Fusion . . . . . . . . 27
10.3 Data Representation and Model Design 28
10.3.1 Which network architectures
can effectively represent weather
and climate data? . . . . . . . . 28
10.3.2 What strategies can enhance
models and facilitate efficient
and accurate representations? . . 28
10.4 Learning Strategies . . . . . . . . . . . . 28
11 Conclusion 29
References 29
Full Name Abbreviation
Artificial Intelligence AI
Machine Learning ML
Deep Learning DL
General Circulation Models GCMs
Numerical Weather Prediction NWP
Natural Language Processing NLP
Computer Vision CV
Large Language Models LLMs
Vision-Language Models VLMs
Segement Anything Model SAM
Foundation Models FMs
Weather & Climate Foundation Models WFMs
Task-Specific Models TSM
Few-/Zero Shot Learning FSL/ZSL
Convolutional Neural Networks CNNs
Recurrent Neural Networks RNNs
Generative Advarsial Netowrks GANs
Gated Recurrent Unit GRU
Long Short-Term Memory LSTM
Diffusion Models DMs
Graph Neural Networks GNNs
Spatio-Temporal Graph STG
Temporal Knowledge Graph TKG
Vision Transformer ViT
Fully-Connected Feed-Forward Network FFN
Adaptive Fourier Neural Operator AFNO
Adaptive Neuro-Fuzzy Inference System ANFIS
Masked Auto-Encoder MAE
Autoregressive AR
Evolutionary Multi-Objective Optimization EMO
El Nino-Southern Oscillation ENSO
Madden-Julian Oscillation MJO
Explainable AI XAI
Independent and Identically Distribution IID
Differential Privacy DP
Self-Supervised Learning SSL
Semi-Supervised Learning SML
Full-Supervised Learning FLSL
Federated Learning FL
TABLE 1: Full names and abbreviations of key nouns.
1 I NTRODUCTION
Concept 1. Weather and Climate are distinct concepts with
notable differences in spatial and temporal scales, variability,
and predictability. The dissimilarities between the two can be
elucidated as follows:
• T emporal Scale.Weather pertains to the immediate state of
atmospheric conditions, typically within a short-term time-
frame. Conversely, climate represents a statistical summary
of long-term weather patterns.
• Spatial Scale. Weather represents atmospheric conditions
at a specific location, whereas climate encompasses a compre-
hensive summary of typical weather patterns within a region
over an extended period.
• Variability. Weather exhibits rapid and frequent changes,
while climate change occurs at a slower pace and encompasses
long-term shifts in weather patterns.
• Predictability. Weather prediction focuses on forecasting
weather conditions in the next few days or shorter time scales.
In contrast, climate prediction aims to forecast climate trends
over the following months to decades.
Climate change delineates noticeable alterations in
global temperature and weather patterns over protracted
periods. Currently, our planet is experiencing a prolifera-
tion in extreme natural phenomena, such as droughts [1],
[2], floods [1], earthquakes [3], heatwaves [4], and intense
rainfall [5], propelled by escalating climate change. Further
amplifying these challenges are the alarming threats to
ecosystems from mounting global warming and sea-level
reductions [6], [7]. Given the projected augmentation in
surface temperatures this century, we foresee an intensi-
fication in the harshness and frequency of these extreme
phenomena [8].
Leveraging advanced climate modeling and prediction
techniques, which integrate a plethora of atmospheric and
surface variables - encompassing atmospheric conditions,
ocean currents, terrestrial ecosystems, and biosphere in-
teractions - can enhance our comprehension of climate
change [9], [10]. These insights can guide the formulation of
bespoke mitigation strategies [11]. Long-term, accurate pre-
dictions of sea level changes can strengthen urban planning
and disaster preparedness in coastal cities [12], [13], [14].
In the short term, precise forecasts of rainfall, temperature,
and humidity can heighten the safety of human activities,
including agricultural planning and transportation schedul-
ing [15], [16], [17].
Traditionally, general circulation models (GCMs) [18]
and numerical weather prediction models (NWPs) [19],
[20], [21] have been favored tools for studying climate
change trends and predicting future weather and climate
scenarios. These models assimilate major Earth system com-
ponents, including the atmosphere, surface, and oceans,
to emulate the multidimensional dynamics of the Earth
system. They identify potential nonlinear correlations be-
tween these components through complex physical equa-
tions, such as atmospheric dynamics, to generate predic-
tions within a wide spectrum of physical parameters [22].
However, despite their considerable maturation, numeri-
cally constrained weather prediction models still encounter
numerous challenges and limitations. One of these is their
3
Climate Events: A strong upper level 
disturbance interacted with a weak front and 
plenty of low level moisture to produce a 
cyclic supercell thunderstorm during the 
early morning hours. This cyclic supercell 
thunderstorm produced a tornado near 
Christoval and another one in Brady.
Weather & Climate Time Series 
Climate Spatio-Temporal Data
Climate Text Data
Training
Fine-Tuning
Weather Pattern Understanding
Forecasting & Precipitation Nowcasting
Downscaling
......
Weather & Climate 
Foundation Model
Fig. 1: Large-scale Foundation Models for weather and climate data understanding can be both trained and skillfully
redesigned and fine-tuned to handle a range of related downstream domains, such as forecasting, downscaling and weather
pattern understanding, time series for text analysis, spatio-temporal data, and text data.
oversimplified representation of local geographical fea-
tures [23], as they often fail to capture the intricate nuances
of local topography, which exerts a critical influence on
regional weather and climate patterns. Another obstacle is
the effective integration of observational data from disparate
sources, such as weather stations, radars, and satellites [8].
Traditional models often struggle with incorporating these
data, with varying spatial and temporal resolutions, into
their modeling frameworks. Moreover, they require sub-
stantial computational resources to manage the myriad of
physical constraints [24]. The complexity and scale of the
Earth system demand extensive calculations, presenting
challenges to computational capacity and efficiency.
The rapid advancement of AI technology has intro-
duced cost-effective, direct, and simplified solution strate-
gies for weather and cliamte modeling. In particular, Ma-
chine Learning (ML) and Deep Learning (DL) technolo-
gies can discern potential trend representations in weather
and climate data, bypassing the need for intricate phys-
ical relationships. Initially, ML techniques were sparingly
used for short-term, localized forecasts of weather and cli-
mate conditions, given their limited capabilities compared
with large-scale, time-extensive physical models. However,
the past decade has witnessed an exponential surge in
the application of data-driven deep learning methods in
weather and climate research, propelled by the explosive
expansion of global weather and climate data [25], [26].
Capitalizing on abundant data resources and advancements
in computational technology [27], [28], these models are
revolutionizing climate science [29]. Employing voluminous
data, deep learning models unravel the intricate nonlinear
relationships concealed within climate variables, thereby
capturing the dynamism and complexity of the climate
system with enhanced precision [30], [31]. However, these
models are often designed for specific tasks and trained
with data in particular formats, such as regional weather
forecasting or downscaling on a microscale. Differences in
the representations of training data sources have resulted in
an overly compartmentalized functionality of data-driven
deep learning models for understanding weather and cli-
mate data. Consequently, it poses a significant challenge to
develop a versatile climate model that can be fine-tuned for
simulating the global weather and climate system.
The recent emergence and swift advancement of large
models have yielded significant gains across various fields,
including natural language processing (NLP), computer vi-
sion (CV) [32], robotics [33], and a range of interdisciplinary
areas encompassing life sciences [34], [35], [36], [37], [38].
Particularly in the NLP field, large models, or large language
models (LLMs), are evolving rapidly, trained on large-scale
corpora and fine-tuned for various downstream tasks [39],
[40], [41]. In computer vision, large vision models trained
4
on substantial natural images [42], [43], [44] demonstrate
exceptional zero-shot capabilities [45], [46]. The impressive
performance of these models across tasks arises from their
substantial parameter counts and large-scale pre-training
data. For instance, GPT-3 [47], [48] possesses nearly 120
times the parameters of GPT-2 [49], enabling it to learn more
powerfully from fewer samples, while GPT-4 [50] has less
than ten times the parameters of GPT-3, yet excels in text
generation and image understanding. The rapid ascension
of LLMs has redefined the path forward for deep learn-
ing, despite long-standing developments in areas such as
unsupervised/semi-supervised and transfer learning. A no-
table example is the vision-language large model [46], [51],
[52], [53], such as CLIP [46], which is trained on numerous
natural image-text pairs and fine-tuned to achieve promis-
ing results in tasks like image segmentation [54], [55], [56]
and video subtitle generation [57], [58]. Recently, the exten-
sion of large models into domains such as speech [59], [60],
physics [61], and mathematical analysis [62] has catalyzed
advancements in fundamental science and specialized areas.
The groundbreaking success of pre-trained foundation
models has propelled the domains of NLP and CV sig-
nificantly closer to the realization of versatile AI. This
advancement prompts an intriguing question: The success
of pre-trained foundation models has allowed the fields of
NLP and CV to take a meaningful step towards realizing
general-purpose AI, which not only leads one to wonder:
Is it possible to develop a universal foundation model for
weather and climate data understanding that effectively
addresses a myriad of related tasks?
Building upon the theory of pre-trained models, C LI-
MAX [25] introduces an innovative approach towards the
development of a weather and climate base model. It
leverages the Transformer to pre-train large-scale weather
and climate data, yielding a flexible foundation model
proficient in short- to medium-term forecasting,, climate
projection, and downscaling. Both P ANGU-WEATHER [63]
and W-MAE [64] exhibit robust climate prediction capabil-
ities by modeling the global climate system using copious
data. However, the quest for large-scale, universal climate
models faces significant obstacles. A primary challenge
is the scarcity of large, diverse, and high-quality train-
ing datasets. Existing datasets (refer to Table. 4 for more
details) struggle with inconsistent measurements, spatial-
temporal biases, and limited functionality, hampering the
progression of all-encompassing, multipurpose large-scale
foundation models. Additionally, the computational de-
mands of these models add another dimension of complex-
ity, with the required infrastructure potentially unachiev-
able in resource-limited settings. Ideally, a weather/climate
foundation model should seamlessly handle multi-source
observations and incorporate detailed representations of
geographic features to generate more precise simulations of
weather and climate trends. Unfortunately, this remains a
largely uncharted territory for current weather and climate
base models. Moreover, the interpretability of these models,
often perceived as ”black boxes,” is a significant concern. In
tasks related to weather and climate, where erroneous pre-
dictions can wreak havoc on ecosystems and societies, the
need for interpretability is especially accentuated [36], [65],
[66]. Despite the remarkable strides and potential in under-
standing weather and climate data, the distinct challenges
associated with the development of large-scale foundation
models, as outlined above, necessitate concentrated research
(refer to Sec. 9 for more details). This emphasizes the need
for a thorough review of advancements in this nascent field.
In this paper, we conduct a comprehensive review of
data-driven models explicitly designed for weather and
climate data. Our survey encompasses a wide array of large
foundation models/task-specific models spanning various
data types, model architectures, application domains, and
representative tasks. This review amplifies the scope of
insights derived from weather and climate data, encourag-
ing novel strategies and fostering the cross-application of
large models in the weather and climate. By leveraging the
power of DL in large-scale models, we aim to reveal com-
plex climate patterns, augment predictions, and deepen our
comprehension of the climate system, thereby empowering
society to more effectively adapt to the challenges posed
by climate change. Our contributions are summarized as
follows:
• First Comprehensive and Contemporary Survey. To
the best of our knowledge, this paper constitutes the
inaugural comprehensive survey that thoroughly en-
capsulates the state-of-the-art developments of large,
and task-specific models for weather and climate
data understanding, spanning across time series, video
streams, and text sequences. We furnish an in-depth
and current panorama that covers the broad spectrum
of the domain, simultaneously delving into the sub-
tleties of distinct methodologies, thereby providing the
reader with a comprehensive and current apprehension
of this field.
• Systematic and In-depth Categorization. We introduce
and discuss an organized and detailed categorization,
dividing existing related research into two main cat-
egories: large climate foundation models and task-
specific climate models. Furthermore, we further clas-
sify them based on the underlying model architectures,
including RNNs, Transformers, GANs, Diffusion mod-
els, and Graph Neural Networks. Subsequent divisions
are made based on the models’ application domains
and specific tasks, with detailed explanations of these
task definitions. This multidimensional categorization
provides readers with a coherent roadmap.
• Abundant Resource Compilation. e have assembled
a substantial collection of datasets and open-source
implementations pertinent to the field of weather and
climate science. Each dataset is supplemented with an
exhaustive description of its structure, pertinent tasks,
and direct hyperlinks for expedient access. This compi-
lation serves as an invaluable resource for prospective
research and developmental endeavors in the domain.
• Future Outlook and Research Opportunities. We have
delineated several promising trajectories for future ex-
ploration. These viewpoints span across various do-
mains, including data post-processing, model architec-
tures, interpretability, privacy, and training paradigms,
among others. This discourse equips the readers with
an intricate understanding of the current status of the
field and potential avenues for future exploration.
5
• Insights for Designing. We discuss and pinpoint cru-
cial design elements for promising weather and climate
foundation models. These design components incor-
porate the selection of temporal and spatial scales,
dataset choice, data representation and model design,
learning strategies, and evaluation schemes. Adherence
to this systematic design pipeline enables practitioners
to rapidly comprehend the design principles and con-
struct robust weather and climate foundation models,
thereby fostering the expeditious advancement of the
weather and climate domain.
Paper Organization. The remainder of this survey is
structured as follows: Section 2 delineates the distinctions
between our survey and other corresponding studies. Sec-
tion 3 instills the reader with fundamental knowledge on
foundational models, primary depictions of weather and
climate data, and related tasks. Section 4 expounds upon
the core architecture of paramount models for weather
and climate tasks. Section 6, we present a synopsis of the
principal model classifications currently in use for weather
and climate tasks, encompassing climate basic models and
task-specific models. This section furnishes a holistic view of
the field prior to probing into the complexities of individual
methodologies. Section 5 imparts a concise introduction
to climate basic models and task-specific models, further
stratifying task-specific models based on dissimilar model
architectures. Subsequently, Section 7 undertakes an exten-
sive exploration of data-driven deep learning models for
specific weather and climate tasks. Considering the lack
of a unified and comprehensive index for weather and
climate datasets, Section 8 presents an exhaustive collection
of dataset resources and introductions, aiming to impart
convenience and efficiency for readers. Section 9 delineates
the challenges currently impeding the evolution of weather
and climate basic models, as well as prospective future
directions in this field. Section 10 proposes a potential
blueprint for the construction of weather and meteoro-
logical basic models, aiding contemplation and execution
by practitioners, and fostering the development of climate
foundation models. Finally, Sec. 11 provides a summary and
concluding remarks on the content of the survey.
2 R ELATED WORK AND DIFFERENCES
While numerous expansive surveys have been executed to
model weather and climate-related data from various van-
tage points, none of them emphasize the broad-spectrum
scope of weather data. For example, Ren et al. [31] under-
took a survey on deep learning-based weather forecasting,
focusing on neural network architecture design and spatial
and temporal scales, yet it omitted models pertinent to the
era of the weather data explosion. Both Fang et al. [67]
and Jones et al. [71] reviewed deep learning-based weather
forecasting within the confines of specific scenarios, namely
extreme weather conditions and climate impacts on flood
risk. Conversely, Bochenek et al. [68] and Jaseena et al.
[74] exclusively addressed and summarized machine learn-
ing/deep learning-based works concerning ordinary time
series. Chen et al. [70] provided a survey of machine learn-
ing methodologies in weather and climate, but the focus re-
mained restricted to forecasting tasks. Furthermore, Molina
et al. [72] primarily emphasized the application of machine
learning in climate modeling, such as sources of predictabil-
ity in climate variability models, feature detection, extreme
weather and climate prediction, observational model in-
tegration, downscaling, and bias correction. Materia [8]
primarily centered on reviewing literature that employed
machine learning techniques for extreme weather detec-
tion and understanding. These aforementioned surveys lack
thorough investigation into the applications of foundational
models in weather data understanding. Mukkavilli et al. [73]
discussed the application of large models to weather and
climate tasks and the architectural design, which bears sim-
ilarity to our endeavor, but does not include more detailed
task-specific models and a wider range of data modalities.
Globally, these surveys also lack a structured delineation
and an exhaustive discussion of deep learning-based mod-
els for weather data understanding, as well as adequate
resources (datasets, open-source models and tools, etc.) that
are either not provided or are limited in their availability.
Given the recent multiplication of large-scale models in
domains such as vision [45], [75], audio [50], and text [56],
our intention with this survey is to provide an exhaustive
and up-to-date overview of large-scale models for weather
data understanding, as well as a structured delineation,
synthesis, and discussion of pertinent task-specific models,
with the objective of establishing a robust foundation for the
design of weather and climate base models. Our aim sur-
passes merely documenting recent advances; we also focus
on available resources, practical applications, and potential
research directions. Table. 2 encapsulates the discrepancies
between our survey and other analogous reviews.
3 B ACKGROUND AND PRELIMINARY
This study aims to review the recent progress in imple-
menting data-driven models, with a primary emphasis on
DL techniques, to address weather and climate tasks. The
objective is to illuminate potential pathways for develop-
ing foundation models dedicated to weather and climate
data understanding. We direct our attention towards two
principal categories of models in the weather and climate
domains: large-scale foundational models and task-specific
models. In this section, we commence by discussing these
two model types and elucidate their distinctions and con-
nections. Subsequently, we delineate weather and climate-
related data types and representative tasks across diverse
domains. We conclude with an introduction to four preva-
lent base model architectures employed in weather and
climate tasks.
3.1 Foundation Models
Foundation Models (FMs) originated as pre-trained LLMs
with a broad capability to undertake a myriad of down-
stream tasks through fine-tuning strategies. These models
constitute a versatile class, separate from task-specific mod-
els, due to their capacity to accommodate a range of down-
stream tasks and integrate heterogeneous representations.
The prowess of FMs can be classified into two categories:
(1) Cross-Modal Representation and (2) Reasoning and In-
teraction.
6
TABLE 2: Comparison between this and other related surveys, focusing on domains (i.e. specific vs. general), relevant data
modalities (e.g., time series, graphs, video streams, and text), primary areas of focus (i.e., Weather and Climate Foundation
Models (WFM) and Task-Specific Models (TSM)), and available resources (i.e., dataset, and tools & models).
Survey Year
Domain Modality of Weather Data Focus Resource
Specific General Time Series Graphs Video Streams Text WFM TSM Dataset Tools & Models
Ren et al. [31] 2021 ! % ! % % % % ! % %
Fang et al. [67] 2021 ! % ! % ! % ! % % %
Bochenek et al. [68] 2022 ! % ! % % % % ! % %
Jaseena et al. [69] 2022 ! % ! % % % % ! ! %
Chen et al. [70] 2023 ! % ! ! % % ! % % %
Jones et al. [71] 2023 ! % ! % % % % ! % %
Molina et al. [72] 2023 ! % ! % % % % ! % %
Materia et al. [8] 2023 ! % ! % % % % % % %
Mukkavilli et al. [73] 2023 % ! ! ! % % ! % % %
Our Survey 2023 ! ! ! ! ! ! ! ! ! !
Cross-Modal Representation. his category involves
multi-modal models, including vision-language models
(VLMs) [46], [51], [76], [77]. These models merge and align
linguistic and visual modalities, demonstrating a significant
potential for modal unification. A prime example is CLIP
(Contrastive Language-Image Pre-training) [46], which con-
currently trains on text and image data using the contrastive
learning method. It displays substantial Zero-Shot Learning
(ZSL) and Few-Shot Learning (FSL) abilities on downstream
tasks. Another innovative model, SAM (Segment Anything
Model) [45], integrates the concept of prompting into visual
tasks, yielding remarkable zero-shot segmentation perfor-
mance. Models like InstructBLIP [78], CoCa [79], BEIT-3 [80],
InstructGPT [81], and LLaMa [82], [83] further expand the
reach of cross-modal foundation models, accommodating a
broader spectrum of tasks and modal representations. In
weather prediction and climate change applications, data
typically exhibit large-scale and multimodal characteristics,
such as radar observations [84], [85], satellite images [86],
ground-based observatories [24], [87], and organized grid-
ded data [88], [89], [90]. These characteristics provide impe-
tus for the development of data-driven FMs for weather and
climate tasks.
Reasoning and Interaction. FMs demonstrate excep-
tional reasoning and planning ablities, exemplified by mod-
els like CoT [91], ToT [92], and GoT [93], in addition to
task planning agents. This category also involves interaction
abilities, encompassing operations and communication. This
study emphasizes the application of data-driven FMs for
weather and climate tasks. Nonetheless, this area remains
uncharted, offering abundant opportunities for innovation.
3.2 Task-Specific Models
Contrary to previously mentioned FMs, the majority of
DL models for weather and climate are mainly domain-
specific (e.g., global/regional precipitation forecasting, ex-
treme weather comprehension, climate model downscaling).
This survey classifies these task-specific models into two
categories based on the nature of task for time series: (1)
Time Series-based Weather and Climate Analysis; (2) Spatio-
Temporal Series-based Weather and Climate Analysis. We
also delineate an area for climate text data: Climate Text
Analysis Tasks.
Time Series-based Weather and Climate Analysis. This
category primarily comprises DL models for weather and
climate analysis that leverage time series data. These models
typically utilize weather time series data obtained from a
single weather station to determine sequential relationships
between one or multiple variables from past observations,
thereby facilitating future trend predictions for specific
weather variables.
A classic example of a data-driven model for weather
forecasting is the Auto Regressive Integrated Moving Av-
erage (ARIMA) [94], which enables non-stationary data to
become stationary through a differencing operation, and
subsequently employs a combination of auto-regression
and moving averages to model the time series. Given
the significant seasonality often present in weather data,
such as fluctuations in temperature and rainfall, Seasonal
ARIMA (SARIMA) [95] and Seasonal ARIMA with eX-
ogenous variables (SARIMAX) [96] have been developed
to model weather series, building upon seasonal auto-
regression/moving average principles. Vector Autoregres-
sion (VAR) serves as an alternate method capable of mod-
elling and predicting multiple correlated variables concur-
rently. Deep Learning-based models, such as families of
Recurrent Neural Networks (RNNs) [97], [98], [99], con-
volutional neural network (CNN)-based architectures, and
models based on the Transformer (e.g., Informer [100],
Autoformer [101], Crossformer [102], ETSFormer [103], Re-
former [104], FEDformer [105]), have exhibited superior
performance when dealing with non-stationary time series.
These models are particularly useful due to their lack of
reliance on additional statistical knowledge and their effi-
ciency in long-term forecasting.
Spatio-Temporal Series-based Weather and Climate
Analysis. Another focal area is DL models for weather and
climate analysis that employ spatio-temporal series. Un-
like time-series data, spatio-temporal data covers weather
variable observations across multiple locations over time,
allowing for the extraction of intricate spatio-temporal pat-
terns. In this context, continuous radar echoes or satellite
images that represent independent weather times are also
considered as spatio-temporal sequences.
Data-driven models designed for analysing spatio-
temporal series for weather and climate analysis are often
required to capture both temporal and spatial correlations.
7
For instance, the convolutional LSTM [97], a variant of the
LSTM, incorporates convolutional operations to the LSTM
to capture additional spatial correlations. 3D Convolutional
Neural Networks (3D-CNNs) are frequently employed to
consider spatio-temporal correlations of sequences simul-
taneously. Spatio-Temporal Graph Neural Networks [106],
and other graph-based structures, effectively encode dif-
ferent spatial information into graphs that capture spatial
correlations as well as temporal trends of weather variables.
Transformer models utilize self-attention mechanisms to
assess the importance of different locations and time points
when making predictions [107]. Recent advancements in
the field have also seen the exploration of generative AI,
such as generative adversarial networks [108] and diffusion
models [109], for weather prediction and climate change
based on spatio-temporal sequences, owing to their excel-
lent generative quality.
3.3 Types of Weather and Climate Data
Investigations into weather and climate typically necessitate
the exploration of both temporal and textual data. The
primary objectives of these tasks involve discerning the
relationships between historical weather patterns — often
characterized by numerous meteorological variables — and
future changes. This process also includes the extraction of
specific features from textual sequences to aid detailed sub-
sequent analysis. In these scenarios, our discussion mainly
revolves around three primary data types: time series,
spatio-temporal, and textual data. n the context of weather
and climate analysis, time series can be broadly divided into
two types: univariate and multivariate. A univariate time
series might be represented by the daily mean temperature
at a single observation point, while a multivariate time
series may include daily precipitation and humidity data
collected from the same observation point. Here, we first
discuss the definition of univariate/multivariate time series.
Formally, we follow the definitions of time series data in
Ref. [110], which we summarize below.
Definition 3.1 (Time Series Data). For a single point ob-
servation, a univariate time series sole weather variables
(such as temperature) x = {x1, x2, x3, ..., xT } ∈ RT is
a sequence of T time step indexed in time order, where
xt ∈ R is the variable value of the time series at time
t. A multivariate time series including different climate
variables (i.e., temperature, humidity, precipitation, etc.)
X = {x1, x2, x3, ..., xT } ∈ RT ×D is a sequence of T time
steps indexed in time order but with D dimensions (vari-
ables), in which x ∈ RD denotes the values of the time series
at time t along D channels.
Global climate data are often represented as spatio-
temporal series, i.e., chaotic correlations with both tem-
poral (change trend) and spatial dimensions (geographic
location). We define two distinct Spatio-Temporal Series:
univerate spatio-temporal series and multivariate spatio-
temporal series. They are both sequence of data points
organized by both temporal and spatial dimensions.
Definition 3.2 (Spatio-Temporal Series). For univerate
spatio-temporal series, follow Definition 2.1, there exist
N points on the Earth system, at each point there ex-
its a time series x = {x1, x2, x3, ..., xT } ∈ RT , where
xt ∈ R, the spatio-temporal series is formulated as Xu =
{x1, x2, x3, ..., xN } ∈ RT ×N . Similarly, for multivariate
spatio-temporal sequences, the series can be formulated
as Xmu = {X1, X2, X3, ..., XN } ∈ RT ×D×N , where XN
denote the multivariate time series at the N space point.
Notably that graph-based structure usually utilized to
construct a spatio-temporal series, such as spatio-temporal
graphs (STGs), temporal knowledge graphs (TKGs), video
streams, and others. In this survey, we mainly focus above-
mentioned classes, which are higly representative and
align closely with the current spatio-temporal series-based
weather forecasting and climate analysis tasks. And we
follow the Ref. to define STGs and TKGs firstly, as follows.
Definition 3.3 (Spatio-Temporal Graphs). A spatio-
temporal graph G = {G1, G2, G3, ..., GT } denotes a sequence
of T static graph snapshots (also named time steps) indexed
in time order, in which Gt = ( Vt, ϵt) presents a snapshot at
t-th time step; Vt and ϵt are sets of nodes and edges at time
t. The adjacent matrix represents the correlation between
nodes in the graph and node feature matrices are defined
as At ∈ RN ×N and Xt ∈ RN ×D, where At = {at
i,j} and
at
i,j ̸= 0 if there is an edge between nodei and j. In addition,
N = |Vt| is the number of nodes and D is the dimension of
node features.
Definition 3.4 (Temporal Knowledge Graphs). Follow the
definition of STGs, a temporal knowledge graph G =
{G1, G2, G3, ..., GT } is a sequence of T knowledge graph
snapshots indexed in time order, where Gt = ( ϵtmRt)
is a snapshot consisting of the entity and relation sets at
time t. Specifically, ϵt encapsulates both subject and object
entities, and Rt presents the set of relations between them.
In a temporal knowledge graph, entities and relations may
posses different features, denoted by X ∈ R|ϵt|×De and
Xr
t ∈ R|R|×Dr, where De and Dr are feature dimensions.
Spatio-temporal video streams belong to a species of
spatio-temporal series, which are represented as regular
spatial shapes and sequences organized in time order. In
weather forecasting and climate analysis tasks, regional
contiguous weather radar echoes and satellite images that
symbolize specific climate events belong to this type, and
we define spatio-temporal video streams based on the defi-
nition of spatio-temporal sequences as follows.
Definition 3.5(Spatio-Temporal Video Streams). Assume a
spatio-temporal video streams V = {F1, F2, F3, ..., FT } is
a set of continue frames that cover T time steps indexed
in time order, where Ft denotes the t-th frame (or time
step). Each frame is viewed as a matrix of pixels 1 can be
formulated as Ft ∈ RC×H×W , where C, H, W denote the
channels, height, and width of the frame, respectively.
Definition 3.6 (Text Sequence). Let S be a text sequence,
where each element in the sequence represents a word or
character. The text sequence can be represented as S =
{x1, x2, . . . , xn}, where xi represents the i-th element in
the sequence. The length of the text sequence, denoted as
1. we only consider the image mode withou any knowledge there.
8
(N), can be defined as N = |S|, where | · | represents the
cardinality or number of elements in the sequence. Further-
more, each element in the text sequence can be represented
as a one-hot encoded vector, denoted as X. The one-hot
encoded vector Xi for the i-th element in the sequence is
a binary vector of length M, where M represents the total
number of unique words or characters in the text corpus.
The one-hot encoded vector Xi has a value of 1 at the
position corresponding to the index of the word or character
in the vocabulary, and 0 elsewhere.
3.4 Mainstream Tasks for Weather and Climate
Based on the above definitions, we will present representa-
tive weather and climate analysis tasks associated with the
above data types and structures.
• Weather/Climate Time Series Tasks. Time series anal-
ysis forms the bedrock of weather and climate studies.
Researchers frequently harness this methodology to
extract meteorological trends from sequential data, pro-
jecting these tendencies onto multiple variable values
across a specified temporal span for granular analy-
sis. This overarching task encompasses three subtasks:
Forecasting, Classification, and Imputation. In the fore-
casting task, the primary goal in to precisely predict
a specific variable for a designated future temporal
window grounded on historical observation. This task
can be bifurcated, based on the magnitude of the pre-
diction window, into short-term forecasting (typically
spanning several hours to a few days) and long-term
forecasting (generally a week or beyond). Short-term
weather forecasting is often employed in immediate
weather prediction and urban planning, whereas long-
term forecasting predominantly serves climate studies,
agriculture, and energy sectors. Subsequently, the clas-
sification task is aimed at mapping distinct meteoro-
logical phenomena, such as drought intensities, based
on a historical chronology of atmospheric observations.
Finally, the imputation task is structured to fill missing
values in the series. This task exploits potential infor-
mation embedded in the series, accounting for data
gaps that might emanate from sensor malfunctions or
severe climate events, among other factors.
• Graph Structure-based Tasks. The mainstream task of
graph structure-based for climate change is forecasting.
We explore graph structure-based tasks in terms of
both STGs and TKGs, as previously mentioned. STGs
and TKGs is extensions for representing and reasoning
about spatio-temporal information, fusing the relation-
ships between time, space, and entities into a unified
graph structure. Forecasting tasks aim to infer weather
conditions at future spatio-temporal points based on
historical observations and model predictions. Such
tasks involve multiple variables, such as temperature,
humidity, and barometric pressure, as well as temporal
and spatial dimensions. The key challenges of spatio-
temporal map prediction tasks are how to effectively
capture and model spatio-temporal dependencies and
how to cope with data uncertainty and missingness.
• Spatio-Temporal Video Streams Tasks. Video data
stands as a crucial asset in the examination of climate
change and weather forecasting. In meteorological con-
texts, spatio-temporal video streams typically manifest
as sequences of frames that depict weather fluctua-
tions over a fixed period. These sequences may include
regularly shaped radar images, satellite images, and
other types of weather-related visual data. Therefore,
the primary interest in spatio-temporal video stream
data lies in prediction tasks—namely, the forecasting
of future images based on a series of past consecutive
frames. The quintessential task in this context involves
the prediction of imminent rainfall based on radar
echoes or the extrapolation of satellite imagery.
• Climate Text Tasks. The analysis of climate textual
data, or climate text analysis, aspires to distill signif-
icant patterns and insights. This process encapsulates
several subtasks including Sentiment Analysis , Topic
Modeling, Information Extraction, and Trend Analysis. Sen-
timent analysis endeavors to preceive the sentiment
or perspectives encapsulated in cliamte text data (e.g.,
public perceptions of climate change). Topic modeling,
conversely, strives to identify and classify the cardi-
nal themes or subjects broached within climate texts,
thereby fostering a comprehensive understanding of
pivotal focus areas.Information extraction constitutes
the extraction of specific details from climate texts, such
as instances of extreme weather events or particulars of
climate policy. Finally, trend analysis concentrates on
pinpointing and examining trends within climate texts,
aiding in the monitoring of shifts in public dialogue,
scientific research, or policy discussions over time. Col-
lectively, these tasks converge to a deeper discernment
of climate issues. The insights harvested can enlighten
decision-making mechanisms, policy development, and
initiatives to amplify public cognizance.
Considering the aforementioned types of weather and cli-
mate data, we will now expound on a variety of tasks
pertinent to weather and climate analysis. Note that we
have omitted the explicit outline and definition of the Cli-
mate Text Analysis task due to its closely related subtasks,
and instead adopted the aforementioned Climate Task as a
proxy for the Climate Text Analysis definition. A succinct
description of each task is as follows:
• Forecasting Tasks. These tasks span from a few hours
(nowcasting) to days and weeks (short- and medium-
range forecasting). They may include regional fore-
casting for continental states, counties, or cities. Sub-
seasonal to seasonal prediction involves forecasting
weather between 2 weeks and 2 months in advance,
bridging the gap between weather forecasts and sea-
sonal climate predictions, which is imperative for dis-
aster mitigation.
• Precipitation nowcasting tasks. Precipitation Nowcast-
ing is a weather forecasting technique designed to
predict precipitation over the next few hours. Unlike
traditional weather forecasting, it focuses on short-
term changes in precipitation, usually predicted on time
scales of minutes to hours. This task employs data from
radar systems, satellites, weather observation facilities,
and numerical models, combined with image process-
ing techniques, to predict the distribution, intensity, and
9
movement of precipitation over a brief future period
via real-time monitoring and analysis of atmospheric
clouds and precipitation systems. Therefore, we have
isolated it from the general forecasting task.
• Downscaling tasks. Given the coarse spatial resolution
of global climate models, they can only offer general
estimates of climate conditions at local or regional
scales. Simulations often exhibit systematic biases that
diverge from trends in observed data. Downscaling
climate models aims to generate locally precise climate
information from global climate projections by correlat-
ing this climate information to observed local climate
conditions. This process enhances the data’s spatial and
temporal resolution, rendering it more suitable for local
and regional analysis.
• Bias correction tasks. Bias correction is vital in weather
and climate applications. It aims to minimize or elim-
inate systematic biases in model outputs and obser-
vational data, which emerge due to uncertainties in
weather models and measurement errors. In weather
forecasting, bias correction enhances the accuracy of
model predictions by adjusting variables such as tem-
perature and precipitation to match actual observa-
tions. In climate research, bias correction is crucial
for aligning climate model outputs with observational
data, facilitating accurate analysis of climate change
trends, evaluation of model performance, and reliable
predictions of future climate changes. Various methods,
including statistical, machine learning, and deep learn-
ing techniques, can be employed for bias correction,
tailoring the approach based on the specific application
and data characteristics. By minimizing or eliminating
systematic biases, bias correction improves the quality
and reliability of weather and climate data.
• Weather pattern understanding tasks. This task strives
to analyze weather data to comprehend the variations
and trends in weather patterns and the climate system.
It involves modeling and analyzing various elements
of the weather system, such as pressure, temperature,
humidity, wind speed, and wind direction, to disclose
their relationships and interactions. The objective is to
identify and interpret different weather patterns, such
as cyclones, fronts, and high-pressure systems, and
deduce their impacts on weather changes and extreme
weather events. By gaining a deeper understanding
of weather patterns, we can enhance our knowledge
of weather forecasting and climate change, providing
decision-makers and researchers with more accurate
and comprehensive information about the weather sys-
tem.
4 B ASIC STRUCTURE FOR WEATHER & CLIMATE
Considering the different types of data present in weather
and climate tasks, we mainly consider the use of Convo-
lutional Neural Networks (CNNs), Recurrent Neural Net-
works (RNNs), Graph Neural Networks (GNNs), Trans-
formers, Generative Adversarial Networks (GANs), and
Diffusion Models to mine complex correlations from these
data. In this survey, we mainly focus on Recurrent Neural
Networks, Transformers, Generative Adversarial Networks,
Graph Neural Networks, and Diffusion Models. Consider-
ing the particular representations of weather and climate
data, we focus on spatio-temporal graphical neural net-
works in our discussion of GNNs.
4.1 Recurrent Neural Networks
Recurrent Neural Networks [111] (RNNs) are a neural net-
work architecture specialized in processing sequential data.
In RNNs, information is passed on all the time, enabling
the RNN to utilize previous information to influence sub-
sequent outputs. RNNs are fundamental modules in deep
learning and are widely used in language modeling [112],
[113], [114], time series analysis [98], [115], [116], and many
other sequence-related tasks. RNNs have also pioneered the
use of deep learning techniques to deal with weather and
climate modeling [97]. The update rule for a general RNN
can be expressed as:
ht = σ(Whxt + Uhht−1 + bh), (1)
where ht is the hidden state at t-th time step, xt is the input
at t-th time step, Wh and Uh are the weight matrices, bh is
the bias, and σ is a nonlinear activation function such as
tanh or ReLU.
However, ordinary RNNs often encounter the problems
of gradient vanishing and gradient explosion in practice,
making it difficult to handle long sequences. To solve this
problem, some improved RNN structures have been pro-
posed, such as Long Short-Term Memory [99] (LSTM) and
Gated Recurrent Unit [117] (GRU). ConvLSTM [97] and
ConvGRU [97] are variants that introduce convolutional
operations into LSTM and GRU, allowing them to process
spatially structured data such as images or videos, they
usually have utilized to process weather spatio-temporal
series data such as radar echo or satellite image sequences.
In these models, fully connected operations are replaced by
convolutional operations. For example, the update rule of
ConvLSTM can be expressed as:
ft = σ(Wxf ∗ xt + Whf ∗ ht−1 + bf )
it = σ(Wxi ∗ xt + Whi ∗ ht−1 + bi)
ot = σ(Wxo ∗ xt + Who ∗ ht−1 + bo)
˜Ct = tanh(Wxc ∗ xt + Whc ∗ ht−1 + bc)
Ct = ft ◦ Ct−1 + it ◦ ˜Ct
ht = ot ◦ tanh(Ct)
(2)
where ft, it, ot, and ˜Ct are forgetting gates, input gates,
output gates, and candidate memory cells, respectively,
∗ denotes the convolution operation, and ◦ denotes the
Hadamard product. The ConvGRU update rules can be
represented as follows:
rt = σ(Wxr ∗ xt + Whr ∗ ht−1 + br)
zt = σ(Wxz ∗ xt + Whz ∗ ht−1 + bz)
˜ht = tanh(Wxh ∗ xt + rt ◦ (Whh ∗ ht−1) + bh)
ht = (1 − zt) ◦ ht−1 + zt ◦ ˜ht
(3)
where rt and zt are the reset and update gates, respectively.
These gating mechanisms allow ConvGRU to handle long
time dependencies more efficiently. These formulas show
that ConvGRU first computes the reset and update gates at
10
each time step, then computes the candidate hidden state˜ht,
and finally computes the new hidden state ht. The update
gate zt plays a role in determining how many new candidate
hidden states to use when computing new hidden states.
4.2 Diffusion Models
Diffusion Models (DMs) [118], [119] have achieved promis-
ing achievements in extensive applications across a range
of fields including computer vision [109], [120], [121], [122],
natural language processing [123], [124], [125], due to their
efficacy in emulating intricate, high-dimensional data dis-
tributions. DMs comprise a category of probabilistic gen-
erative models and the core of these lie the principles of
diffusion process, which are stochastic procedures delin-
eating the continuous stochastic motion of particles over
time. At the core of these models lie the principles of
diffusion processes, which are stochastic procedures delin-
eating the continuous stochastic motion of particles over
time. These processes model spatial or temporal diffusion
wherein particles incline towards transitioning from zones
of high concentration to those with lower densities, fa-
cilitating a gradual assimilation or blending of quantities.
The principal concept involves conducting a sequence of
diffusion steps, with each step updating the data’s prob-
ability distribution. This is accomplished by incorporating
Gaussian noise into the current data samples and iteratively
refining them. The noise addition in each diffusion step
perturbs the data points, and the iterative refinement guides
these perturbed points to gradually converge to the target
distribution. This iterative process is akin to a random walk
in the data space, where the random perturbations, guided
by the model, eventually lead to the generation of new data
points following the target distribution.
Mathematically, a diffusion model describes a Markov
chain that begins with the data and ends with noise. Let’s
denote the data as x and the noise as z. The Markov chain
has the following form:
xt =
q
(1 − dt) ∗ x(t − 1) +
q
(dt) ∗ zt (4)
where zt is sampled from a standard Gaussian distribution,
dt is a small time step and t is the current step. The goal
of the diffusion model is to learn the reverse transition of
this Markov chain, i.e., to generate data from noise. This
is done by estimating the conditional distribution p(x(t −
1)|xt) and sampling from it. With enough steps, the chain
will transform the noise z into the data x.
4.3 Transformers
Transformer is a DL model and has become a key infras-
tructure for existing state-of-the-art (SOTA) large models
applied to NLP and other sequence-to-sequence tasks (i.e.,
weather forecasting) [126]. The key to this is its ability to
handle dependencies between any part of the input se-
quence and any part of the output sequence without having
to rely on the order of the sequences as in RNNs [127].
Vanilla Transformer utilizes an encoder-decoder archi-
tecture, where both the encoder and decoder are comprised
of a series of stacked blocks. Each Transformer layer is com-
posed of a self-attention layer and a fully-connected feed-
forward network (FFN). Additionally, the decoder block
incorporates an additional cross-attention layer on top of the
self-attention layer to capture information from the encoder.
To facilitate information flow and alleviate the vanishing
gradient problem, residual connections [128] and layer nor-
malization modules are implemented between each layer.
Multi-Head Self-Attention. At the heart of the Trans-
former achitecture lies in the self-attention mechanism. This
mechanism plays a pivotal role in capturing relationships
within an input sequence. It accomplishes this by calculating
attention scores for each element in the sequence in relation
to the other elements. These scores are then utilized to assign
weights to the input sequence, resulting in the generation of
a new weighted sequence. The formula for the self-attention
mechanism is as follows:
H = Attention(Q, K, V) = softmax
 QKT
√dk

V, (5)
where the dk denotes the dimension of the key, Q ∈ Rn×dk,
K ∈ Rm×dk, V ∈ Rm×dv are the query matrix, key matrix
and value matrix respectively, which are linear transforma-
tions of the same input sequence X ∈ Rn×d (or feature
matrix from the previous layer) based on three weight
matrices Wq ∈ Rd×dk, Wk ∈ Rd×dk, Wv ∈ Rd×dv, as
Q = XWq, K = XWk, V = XWv, (6)
The attention score is obtained by computing the dot prod-
uct of the query martix and key matrix, then dividing by√dk for scaling, and finally normalizing by softmax.
Transformer uses multi-head self-attention with multiple
sets of Q(i), K(i), V(i), each set corresponding to a distinct
set of linear transformation matrix W(i)
q ∈ Rd×dk, W(i)
k ∈
Rd×dk, W(i)
v ∈ Rd×dh, where dh is set to dv
h , h is the number
of heads. The final output of the multi-head self-attention is
obtained by projecting the concatenation of a series of Hi
into a new feature space with a new weight matrix Wproj ∈
Rdv×dproj , as follows:
H = Multi-Head Self-Attention(Q, K, V)
= Concat(H1, H2, ..., Hh)Wproj ,
Hi = Attention(Q(i), K(i), V(i).
(7)
For decoder, there is an additional mask mechanism that
prevents query vectors from attending to the future posi-
tions yet to be decoded. In addition, an extra cross-attention
following the self-attention, where the Q is derived from
the output of the previous layer in the decoder, and the K
and V are transformed from the output of the last layer
of the encoder. It is designed to avoid foreseeing the true
label while considering information from the encoder when
encoding.
Fully-connected Feed-Forward Layer. Fully-connected
feed-forward Layers following the attention layer is consists
of linear transformation and a non-linear activation func-
tion. Denote the input matrix X ∈ Rn×di, the output of the
feed-forward layer is
F = FFN(X) = σ(W1X + b1) + b2, (8)
where σ(·) presents the activation function, and W1 ∈
Rdi×dm, b1 ∈ Rdm, W2 ∈ Rdm×do, b2 ∈ Rdo are all learnable
parameters.
11
Residual Connection and Normalization. Following
each attention layer and each feed-forward layer, residual
connection and layer normalization are applied. They con-
duct to retaining information when the model is consid-
erably deep and thus guarantees the model performance.
Formally, given a neural layer f (·), the residual connection
and normalization layer is defined as
Add & Norm(X, f) = LayerNorm(X + f (X)). (9)
Transformer Layer.The design of the Transformer model
enables parallel processing of the entire sequence, eliminat-
ing the need for sequential processing of elements as in
RNNs. This parallel processing enhances its efficiency in
handling long sequences. By utilizing a multi-layer self-
attention mechanism, the Transformer model effectively
captures long-distance dependencies in sequences, which is
crucial for tasks involving translation, summarization, and
other sequence-to-sequence operations.
4.4 Generative Adversarial Networks
Generative Adversarial Networks (GANs) [108] aim to
train a generative model via adversarial processes, it have
widely used to image generation [29], [129], [130], super-
resolution [131], [132], style transferring [133], [134], and
image-based weather forecasting [135]. The fundamental
concept of GANs involves training two NNs adversarially:
a Generator G and a Discriminator D. The objective of the
Generator G is to learn the underlying data distribution and
generate novel samples accordingly. The discriminator (D)’s
objective is to differentiate between the samples generated
by the generator and the real samples.During training, the
generator aims to produce samples that can effectively fool
the discriminator, while the discriminator strives to enhance
its ability to differentiate between real and generated sam-
ples. This process can be regarded as a two-player zero-
sum game, ultimately leading to an equilibrium where the
discriminator cannot distinguish between the generator-
generated samples and the real samples.
The objective function of GANs can be expressed as the
following optimization problem:
min
G
max
D
V (D, G) =Ex∼pdata(x)[log D(x)]
+ Ez∼pz(z)[log(1 − D(G(z)))],
(10)
where x is a sample from the true data distributionpdata, z is
a sample from some a prior noisy distributionpz, G(z) is the
sample generated by the generator using the noisy sample
z, and Dx is the discriminator’s estimate of whether the
sample x (either the true sample or the generated sample)
is the true sample. Training of GANs typically involves
alternately optimizing two of this objective function. First,
the generator is fixed and the discriminator is optimized.
Then, fix the discriminator and optimize the generator. This
process is repeated until some equilibrium is reached, at
which point the samples generated by the generator should
be indistinguishable from the true samples by the discrimi-
nator.
4.5 Spatio-Temporal Graph Neural Networks
Spatio-Temporal Graph Neural Networks (STGNNs) [106]
is a concept in machine learning that combines spatial
and temporal information using graph structures. It is par-
ticularly useful for analyzing data with both spatial and
temporal dependencies. In STGNN, the basic concept in-
volves representing the data as a graph, where each node
represents a spatial location and the edges capture the
spatial connectivity. Additionally, each node also contains
temporal information, representing the state of the variable
at different time steps.
Spatial Graph Structure. Let G = ( V, E) be the graph
representing the spatial connections, where V is the set
of nodes representing spatial locations, and E is the set
of edges representing the spatial relationships. Each node
vi represents the feature vector xi of the corresponding
location i.
Temporal Information. Let X = xt
i be the set of feature
vectors for all locations at time t. Each feature vector xt
i
represents the state of the variable at location i and time
t.
Spatio-temporal Graph Convolution. STGNN incorpo-
rates both spatial and temporal information through graph
convolution operations, which capture the relationships be-
tween variables at different locations and time steps. The
spatio-temporal graph convolution can be represented as:
ht+1
i = f (
X
j∈N (i)
wij · ht
j + bt
i). (11)
Here, ht+1
i represents the updated feature vector of node
i at time t + 1, N (i) denotes the set of neighbors of node
i, capturing the spatial connections between locations, wij
represents the weight between node i and its neighbor j,
indicating the strength of their relationship, ht
j represents
the feature vector of the neighboring node j at time t. bt
i is a
bias term for node i at time t. f (·) represents an activation
function, such as ReLU or Sigmoid, applied element-wise
to the sum of weighted inputs. The spatio-temporal graph
convolution operation combines the spatial connectivity and
temporal dependencies to effectively capture the evolving
patterns and relationships in the data.
5 O VERVIEW AND CATEGORIZATION
In this section, we provide an overview and categorization
of DL models for weather and climate. Our survey is
structured along three main dimensions: data types, model
architectures, and application domains. A detailed synopsis
of the related works can be found in the Table. 3. Based on
the scope of application, we primarily divide the existing
literature into two main categories: Large Foundation Models
and Task-Specific Weather and Climate Models. Considering the
task generality of weather/climate foundation models, we
discuss them at a high level without further subdivisions.
For task-specific weather/climate models, we categorize
them based on specific underlying architectures to facilitate
readers in indexing and referencing specific works accord-
ing to model architectures, including Recurrent Neural Net-
works, Generative Adversarial Networks, Transformers, Diffusion
Models, and Graph Neural Networks . Subsequently, at the
application level, we divide the existing literature into two
12
TABLE 3: List of representative models under mainstream applications for weather and climate data. Each column
represents, in turn, data type, model category, method, scope, specific task/domain, base model, institution, and year
of publication, respectively, noting that the base model is dominated by the primary starter module. More details available
in Section. 7.
Data Category Method Scope Task/Domain Base Institute Year
Time Series
Large Foundation Models
FourCastNet [136] Task-Specific Forecasting RNN Nvidia 2022
GraphCast [137] Task-Specific Forecasting GNN Google 2022
PanGu-Weather [63] Task-Specific Forecasting Transformer HUAWEI 2023
FengWu [138] Task-Specific Forecasting Transformer SHAI 2023
FuXi [139] Task-Specific Forecasting Transformer FuDan 2023
W-MAE [64] Task-Specific Forecasting Transformer UESTC 2023
ClimaX [25] General Forecasting/Downscaling Transformer UCLA 2023
Task-Specific Models
PGnet Task-Specific Forecasting GAN CAAC 2021
Graphino [140] Task-Specific Forecasting GNN TUD 2021
TemperatureGAN [141] Task-Specific Forecasting GAN FuDan 2021
Keisler GNN [142] Task-Specific Forecasting GNN NONE 2022
GE-STDGN [143] Task-Specific Forecasting RNN, GNN SEU 2022
HiSTGNN [144] Task-Specific Forecasting GNN SWJTU 2022
DWFH [145] Task-Specific Forecasting RNN UHK 2023
SWINRDW [146] Task-Specific Forecasting RNN, Diffusion Models Alibaba 2023
SWINVRNN [147] Task-Specific Forecasting RNN Alibaba 2023
PoET [148] Task-Specific Forecasting Transformer ECMWF 2023
OceanFourCastNet [149] Task-Specific Forecasting Transformer MIT 2023
SEEDS [150] Task-Specific Forecasting Diffusion Model Google 2023
Dyfussion [151] Task-Specific Forecasting Diffusion Model UCSD 2023
DITTO [152] Task-Specific Forecasting Diffusion Model TelAviv 2023
TeleViT [153] Task-Specific Forecasting Transformer NOA 2023
MetePFL [24] Task-Specific Forecasting Transformer UTS 2023
FedWing [154] Task-Specific Forecasting Transformer UTS 2023
FuXi-Extreme [155] Task-Specific Forecasting Transformer FuDan 2023
Meshfreeflownet [156] Task-Specific Downscaling CNN UCB 2020
Cdanet [157] Task-Specific Downscaling CNN KAUST 2022
GPCHC [158] Task-Specific Downscaling GAN Mila 2022
Bayesian AIG-Transformer [159] Task-Specific Downscaling Transformer UH 2022
Deepesd [160] Task-Specific Downscaling CNN IFCA 2022
Multi-Varibales HP [161] Task-Specific Downscaling CNN IFCA 2023
PhysicsDL [162] Task-Specific Downscaling RNN Mila 2023
Torchclim [163] Task-Specific Downscaling CNN UNSW 2023
ResDiff [164] Task-Specific Downscaling Diffusion Model SDU 2023
MetNet [165] Task-Specific Precipitation Nowcasting CNN Google 2020
Nowformer [166] Task-Specific Precipitation Nowcasting Transformer KAIST 2021
MPL-GAN [167] Task-Specific Precipitation Nowcasting GAN JCU 2021
CMGAT [168] Task-Specific Precipitation Nowcasting GNN NUDT 2021
GDE [169] Task-Specific Precipitation Nowcasting Diffusion Model UNIBO 2021
DMSF-GAN [84] Task-Specific Precipitation Nowcasting GAN GBAMWF 2022
PCT-CYCLEGAN [170] Task-Specific Precipitation Nowcasting GAN KMA 2022
Rainformer [171] Task-Specific Precipitation Nowcasting Transformer ZUT 2022
EarthFormer [172] Task-Specific Precipitation Nowcasting Transformer HKUTS 2022
PTCT [173] Task-Specific Precipitation Nowcasting Transformer SYSU 2022
MM-RNN [174] Task-Specific Precipitation Nowcasting RNN HIT 2023
STIN [175] Task-Specific Precipitation Nowcasting RNN UCAS 2023
TempEE [107] Task-Specific Precipitation Nowcasting Transformer GBAMWF 2023
Preformer [176] Task-Specific Precipitation Nowcasting Transformer UCAS 2023
PreDiff [177] Task-Specific Precipitation Nowcasting Diffusion Model HKUTS 2023
MetNet-3 Task-Specific Precipitation Nowcasting CNN Google 2023
ENSOTR [178] Task-Specific Weather Pattern Understanding Transformer FJNU 2021
All-seanson CNN [179] Task-Specific Weather Pattern Understanding CNN CNU 2021
CNN-GRU [180] Task-Specific Weather Pattern Understanding RNN USQ 2021
ENSO-GTC [181] Task-Specific Weather Pattern Understanding GNN TJU 2022
DLHF [74] Task-Specific Weather Pattern Understanding CNN UCB 2022
ARIMA-LSTM [182] Task-Specific Weather Pattern Understanding RNN NCUWE 2022
ENSO-ConvGRU [183] Task-Specific Weather Pattern Understanding RNN UIUC 2023
DK-STN [184] Task-Specific Weather Pattern Understanding GNN JLU 2023
STIEF [66] Task-Specific Weather Pattern Understanding RNN UCAS 2023
XDL-CN [65] Task-Specific Weather Pattern Understanding CNN NEU 2023
CUNet [185] Task-Specific Bias Correction CNN OUC 2021
SVMBC [186] Task-Specific Bias Correction CNN UTokyo 2022
Birectional GRU [187] Task-Specific Bias Correction RNN WHU 2022
Bi-LSTM [188] Task-Specific Bias Correction RNN FuDan 2022
LSTM-TCN [189] Task-Specific Bias Correction RNN Verisk 2022
BLSTM-AM-GS [190] Task-Specific Bias Correction RNN CUST 2022
SRDRN [191] Task-Specific Bias Correction CNN AU 2022
DIcorrector-remapper [192] Task-Specific Bias Correction CNN WUSTL 2022
UNIT+QM [193] Task-Specific Bias Correction GAN UOE 2023
Weathergnn [194] Task-Specific Bias Correction GNN Alibaba 2023
Text Data
Large Foundation Models
ClimateBert [195] General Climate Text Analysis Transformer FAU 2021
CliMedBert [196] General Climate Text Analysis Transformer UNMC 2022
OceanGPT [197] General Climate Text Analysis Transformer ZJU 2023
ClimateBert-NetZero [198] General Climate Text Analysis Transformer UZH 2023
FClimateBert [199] General Climate Text Analysis Transformer UPC 2023
13
main categories based on specific data categories:Time Series
for Weather and Climate2 and Text for Weather and Climate.
In the first category, we further dissect the existing
literature into six primary classes predicated on the do-
mains of application: Forecasting, Precipitation Nowcasting ,
Downscaling, Data Assimilation, Bias Correction, and Weather
Pattern Understanding. For the second category, we explore
it as a general subject ( Climate Text Analysis ), refraining
from subdividing it into different subtasks. This is because
these often originate from pre-trained LLMs, and the spe-
cific task characteristics are typically delineated based on
downstream datasets rather than the model itself.
6 M ODELS FOR WEATHER & CLIMATE
In this section, we will delve into the advancements of
Foundation Models and Task-Specific Models for weather
and climate data understanding. A categorization of repre-
sentative methods and detailed information can be found in
Table. 3.
6.1 Foundation Models for Weather & Climate
The burgeoning development of foundation models in
NLP [47], [82], [200] and CV [45], [46] has piqued research
interest in foundation models for weather and climate data
understanding. Large Foundation Models, created through
pre-training strategies, can substantially enhance the gen-
eralization capability of AI-based climate models and can
be fine-tuned for specific downstream tasks. Pre-training
of such models necessitates large-scale sequence data, not
typically sourced from ordinary time-series data.
Mindful of computational efficiency and the demand for
timely climate predictions, Pathak et al. proposed F OUR -
CAST NET [136], a climate pre-trained foundation model
based on Vision Transformer and Adaptive Fourier Neural
Network Operator (AFNO) [201], for high-resolution pre-
dictions and rapid inference. Its training process consists of
self-supervised pre-training and autoregressive fine-tuning
based on the pre-trained model. P ANGU -WEATHER [63], a
data-driven model leveraging the 3D Earth-specific Trans-
former, is notable for its swift, precise global predictions and
superior performance. It predicts atmospheric states over
time based on the current state, described by five upper-air
variables and four surface variables on a 0.25° horizontal
grid with 13 vertical layers for the upper-air variables. On
the other hand, C LIMA X [25] introduces the concept of fun-
damental modeling to weather prediction with its fully su-
pervised pre-training based on the Transformer. It proposes
variable disambiguation and variable aggregation strategies
for merging and revealing potential relationships between
different weather variations at various altitudes, offering
promising flexibility for adapting to diverse downstream
tasks, including global/regional/seasonal forecasting, cli-
mate mapping, and downscaling tasks. F ENG WU [138]
tackles the medium-term forecasting problem from a mul-
timodal, multitask perspective with a uniquely designed
deep learning architecture. It features a model-specific de-
coder and a cross-modal fusion Transformer that balances
2. The scope of time series data includes spatio-temporal series data
and spatio-temporal video stream data.
the optimization of different predictors in a regionally
adaptive manner under the supervision of uncertainty
loss. Given that the aforementioned large-scale models
are trained via a fully supervised approach, W-MAE [64]
implements unsupervised training of weather prediction
models using a Masked Auto-Encoder (MAE)-based [202],
[203] approach, which can be fine-tuned for downstream
tasks through various data sources. MetePFL [24] and Fed-
Wing [154] also propose a Prompt-based federated learn-
ing [204] for training large foundation models, considerably
reducing the cost of collaborative model training across
regions while safeguarding data privacy. The rapid ad-
vancement of LLMs has led to the processing of weather
and climate tasks that are no longer restricted to visual
or time-series models. O CEAN GPT [197], based on LLMs,
proposes a methodology for processing a wide range of
ocean-related tasks. Beyond the foundation models used for
forecasting and simulation, C LIMATE BERT [195] is an NLP-
based foundation model for processing climate-related texts.
It is trained on over 2 million climate-related paragraphs
from diverse sources such as news articles, research papers,
and company climate reports [205].
6.2 Task-specific Models for Weather & Climate
In the realm of weather and climate analysis, task-specific
models have been utilized for a myriad of specific tasks. This
section will delve into the progress made in task-specific
models for weather and climate, focusing on these principal
architectures: RNNs, Transformers, GANs, Diffusion Mod-
els, and Graph Neural Networks (GNNs).
• Recurrent Neural Networks (RNNs). RNNs serve as
the backbone of numerous weather forecasting mod-
els [85], [97], [145], [175], [206], [207], [208], [209],
[210], [211], [212], [213]. In addition to weather and
climate prediction models built on RNNs architectures,
hybrid models fusing RNN with other mechanisms
have also gained traction [146], [147], [214], [215], [216],
[217]. For instance, the amalgamation of Swin Trans-
former [218] with RNN has given birth to models like
SwinVRNN [147], which capitalize on the advantages
of both architectures. Moreover, the fusion of SwinRNN
with generative models has led to models for the diffu-
sion model SwinRDM [146] and for GAN [216], [217].
Added to this, physical-informed based approaches
have been introduced [219]. Concurrently, with the
evolution of Transformer-based spatio-temporal extrac-
tion, the integration of RNN architecture and Trans-
former models to address this problem has been on the
rise [214], [215].
• Diffusion Models. Standard diffusion models, com-
prising forward noisy processes and backward denois-
ing processes, are widely employed for learning data
distribution and generating data representations in me-
teorological and climatic contexts [146], [147], [150],
[152], [177], [220], [221], [222], [223] [164], [224]. For
instance, SwinRDM [146] amalgamates SwinRNN [147]
and diffusion models to attain high-resolution weather
forecasting. However, it is important to note that the
application of diffusion models in weather and climate
studies is still in its nascent stage.
14
In March 2018 Congress authorized an additional $10billion to be used for reimbursements 
related to repacking and directed that a portion of the additional funds be usedto reimburse low 
power television stations, television translator stations and FM stations that are required to 
modify their facilities on a temporary or permanent basis to accommodate changes made 
bytelevision stations being repacked as well as for consumer education efforts.
Fig. 2: An overview of large foundation models for weather and climate, Left: Foundation Models specialized in weather
and climate time series (including time series, spatio-temporal series, video streams, etc.), Right: Foundation Models
specialized in climate-related text data.
• Generative Adversarial Networks (GANs). GANs
have widely used in image generation tasks, ranging
from generating handwritten digits [225] to generat-
ing large-scale image datasets [226], [227]. They are
commonly employed in weather and climate tasks for
spatiotemporal video stream prediction [228], [229],
aiming to generate realistic and temporally coherent se-
quences and match high-dimensional data distributions
between them. Therefore, GAN-based architecture is
common in weather and climate prediction tasks aims
to generate predicted future frames like ground-truth
as same as possible [84], [230], [231], [232] [167] [170],
[216], [217], [233], [234], [235], [236], [237] [238], [239].
Additional physical constraints are often introduced to
improve the accuracy of weather and climate modeling
in these hybrid models [229], [240], [241], [242], [243],
[244], [245], [246], [247], [248].
• Transformers. Transformer-based models are widely
used for tasks related to time series analysis due
to its powerful long series modeling capabilities,
which also include responding to weather and climate
change [149]. It focuses on short-term/long-term fore-
casting tasks in weather and climate applications and
can be categorized into two types, the former focus-
ing on one-/two-dimensional forecasts of weather and
climate, such as predicting trends in relevant weather
variables globally or regionally on single atmosphere
level, and the latter focusing on multidimensional fore-
casts, such as extrapolations based on radar-echo im-
agery [249], satellite cloud images [250] and multi-
layer atmosphere status, thus contributing to the un-
derstanding of weather patterns in the region. For the
first category, the Transformer is used to perform short-
and long-term forecasts, modeling dependencies on
variables at different points in time through positional
coding as well as self-attention mechanisms [178], [251],
[252], [253], [254], [255]. As for the second category,
Transformers are expected to establish complex multi-
layered spatio-temporal relationships of meteorological
variables at different atmospheric pressures, and the
results of this type of Transformer are usually chal-
lenged based on the characteristics of the data itself
(atmospheric pressures, spatio-temporal correlations,
variable correlations), and so on [25], [63], [64], [138],
[148]. Inspired by the fields of NLP and CV , the Trans-
former structure has also been redesigned for the devel-
opment of large-scale weather and climate foundation
models [25], [63], [138]. In addition, in the filed of NLP-
based climate text analysis, Transformers is a general
architecture [196], [196], [198], [199], [256], [257], [258],
[259].
• Graph Neural Networks. In the field of weather and
climate, numerous studies have explored the appli-
cation of graph neural networks, particularly spatial-
temporal graph neural networks, due to their ability to
establish potential spatial-temporal relationships of the
15
Earth system. [181]. Two common applications include
spatial-temporal sequence prediction [137], [142], [143],
[144], [183], [184], [221], [260], [261], [262], [263], [264],
[265] and spatial-temporal video stream prediction in
weather forecasting [168]. In spatial-temporal sequence
prediction, graph neural networks are used to model
the spatio-temporal dependencies and correlations in
weather data. This involves predicting future weather
conditions based on historical observations at different
locations [24], [154]. The graph structure is used to
capture the spatial relationships between nodes, and
the temporal dependencies are modeled using recur-
rent [264], [265] or convolutional layers [144], [183]. In
spatial-temporal video stream prediction, graph neural
networks are employed to predict future weather con-
ditions in the form of video-like sequences [168]. This
involves predicting the evolution of weather patterns
over time, taking into account both spatial and tempo-
ral dependencies.
7 A PPLICATIONS
This section presents an overview of prevalent DL models,
categorized by their applications in weather and climate
analysis. These applications include forecasting, precipita-
tion nowcasting, downscaling, bias correction, data assim-
ilation, climate text analysis, and weather pattern under-
standing.
7.1 Forecasting
Accurate weather and climate forecasting is critical for en-
vironmental and societal planning. Significant strides have
been made in developing robust DL methods that model
the nonlinear associations between historical and future
weather patterns. This section mainly focuses on discuss the
advancement in the task of weather and climate forecasting
based on time series and spatio-temporal series. The most
common in such tasks are RNNs-based architecture, which
are widely used due to their autoregressive (AR) architec-
ture [145], [146], [147], [212], [213]. For instance, DWFH in-
troduces conductive long and short-term memory models to
enhance data-driven deep weather prediction models [145].
Ref. [212] merges the LSTM and an adaptive neuro-fuzzy
inference system (ANFIS) for atmospheric pressure forecast-
ing. SwinRDM introduces the SwinRNN as a fundamental
component for high-resolution weather forecasting [146],
and diffusion models to achieve high-resolution weather
forecasting at 0.25 degrees using a two-step training strat-
egy: first, cyclic prediction of future atmospheric fields is
performed at low resolution, followed by high-resolution
and fine-grained atmospheric detail reconstruction based
on the diffusion-based super-resolution model. Moreover,
SWINVRNN employs a Recurrent Neural Network-based ar-
chitecture with variations loss to improve long-lead weather
forecasts [147]. In addition, Transformer, especially Vision
Transformer, is also widely used in weather and climate
prediction based on spatio-temporal series due to its bright
performance in modeling potential representational asso-
ciations between image regions using Patch mechanism
and self-attention mechanism. F OUR CAST NET [136] deliv-
ers impressive performance in various weather forecasting
tasks using 0.25° resolution. This achievement is based on
the Vision Transformer (ViT) [266] and Adaptive Fourier
Neural Network Operators (AFNO). P OET [148] introduces
hierarchical ensemble transformers to enhance medium-
range ensemble weather forecasts on a global scale. T ELE -
VIT [153] integrates fine-grained local-scale and global-scale
inputs, treating the Earth as one interconnected system
for seasonal wildfire forecasting. Large models came out
of nowhere when considering the ultra-large-scale, high-
resolution global medium-term forecasting task. P ANGU -
WEATHER [63], a data-driven model based on 3D Earth-
specific transformers, is lauded for its rapid and accurate
global forecasts. This model predicts the atmospheric state
at a given time based on the current state, described by
five upper-air variables on a 0.25° horizontal grid and four
surface variables, with 13 vertical levels for the upper-air
variables. FENG WU [138] addresses the medium-range fore-
casting problem from a multi-modal, multi-task perspective,
with its elaborate deep learning architecture with model-
specific decoders and cross-modal fusion transformers that
learn under the supervision of uncertainty loss to balance
the optimization of different predictors in a regionally
adaptive manner. FuXi [139] cascades cubic embeddings
and U-transformers and is trained using 39 years of high-
resolution in-analysis data. It delivers forecast performance
comparable to that of the ECMWF EM with a temporal
resolution of 6 hr and a spatial resolution of 0.25° in a
15-day forecast. The FuXi-Extreme model [155] employs
a denoising diffusion probabilistic model (DDPM) [118]
to refine the surface forecast data generated by the FuXi
model [139] in 5-day forecasts, thereby enhancing extreme
rainfall/wind forecasting. As an all-purpose foundation
model, C LIMA X [25] introduces the concept of founda-
tion modeling to the field of weather prediction, with its
fully supervised pre-training based on the Transformer, and
proposes variable tokenization and variable aggregation
strategies for fusing and mining the potential relationships
of different weather variations at different heights, which
gives it very promising flexibility to adapt to different
downstream tasks, including global/regional/seasonal pre-
diction, as well as the tasks of climate mapping, and down-
scaling. While the aforementioned models are trained in a
fully supervised-based pre-training, W-MAE [64] leverages
a Masked Auto-Encoder (MAE)-based approach [202], [203]
for self-supervised training in weather forecasting models,
potentially allowing fine-tuning by different data sources to
adapt to downstream tasks.
Generative AI are carving a niche in the field of climate
and weather forecasting, with several promising approaches
recently reported. SEEDS [150], for instance, employs an
array of finely-tuned ensemble simulators to generate prob-
abilistic weather forecasts. These forecasts are akin to the
“seeds“ of weather states provided during the inference
process, with two different ensemble simulators gener-
ating two distinct event predictions. However, the self-
regression mechanism underpinning this approach, similar
to the RNN architecture used in diffusion model training,
is susceptible to instability and feature dissipation over
time, particularly in long-range forecasting tasks. Contrast-
ingly, Dyfussion [151] uses pristine initial conditions, while
the PDE-Refiner [222] enhances the diffusion process-based
16
predictions by iteratively observing them to capture low-
amplitude information that may not be immediately evident
in the data. DITTO [152] adopts a unique approach, generat-
ing a continuous interpolation between the initial and final
time steps, and using time fireworks instead of incremental
noise in the forward process. TemperatureGAN [242], a
conditional GAN, considers factors such as the month, loca-
tion, and time period to generate atmospheric temperature
predictions at an hourly resolution above ground level.
Furthermore, GANs that integrate physical information
constraints are being deployed to emulate ocean systems,
thereby enhancing climate prediction capabilities [244],
[245], [246], [247], [248].For instance, Refs. [244], [245] de-
scribe GAN-based models that learn underlying physical
relationships between surface and subsurface temperatures
in numerical models. Subsequent calibration of model pa-
rameters using observational data leads to enhanced pre-
dictions. PGnet [248] is a generative neural network model
that uses a mask matrix to identify regions of low-quality
prediction generated during the initial physical stage. The
generative neural network then uses this mask as a prior for
the second stage of fine prediction. WGC-LSTM [260] har-
nesses graph convolutions to capture spatial relationships
and amalgamates these with LSTM to concurrently consider
both spatial and temporal relationships.
Reflecting upon the intricate interconnections between
atmospheric elements, surface variables, and precise ter-
restrial coordinates within the Earth system, a substan-
tial amount of research has utilized graph-based method-
ologies for weather and climate prediction tasks. For in-
stance, K EISLER GRAPH NEURAL NETWORK [142] lever-
ages a graph neural network architecture [267] to achieve
weather forecasting. It uses an encoder that maps the orig-
inal 1° latitude/longitude mesh to an icosahedral mesh,
performs message passing computations on this mesh, and
then decodes back into latitude/longitude space. G RAPH -
CAST [137], on the other hand, also utilizes a GNN-based
framework for weather prediction, albeit with a much
higher resolution and flexibility. It stands as the inaugu-
ral large-scale foundation model for weather and climate
predictions based on graph methodology. G RAPHINO [140],
a globally spatial GNN, is specifically designed for sea-
sonal forecasting tasks, including prediction of the El
Nino-Southern Oscillation (ENSO) phenomenon [268]. The
model begins by constructing an initial graph with grid
cells as nodes and learns the edges based on the con-
nectivity between geographical locations. In addition, GE-
STDGN [143] employs a graph structure learning and opti-
mization method underpinned by the evolutionary multi-
objective optimization (EMO) algorithm known as graph
evolution [269]. This augments the model’s ability to ana-
lyze intricate node correlations for spatio-temporal weather
sequence prediction. HiSTGNN [144] features an adaptive
graph learning module that builds a self-learning hierar-
chical graph [270]. This graph is comprised of a global
graph that represents region-specific information and a lo-
cal graph that encapsulates meteorological variables within
each region. The model effectively identifies hidden spatial
dependencies and diverse long-term weather patterns using
graph convolution and gated temporal convolution with a
dilated initial as its core structure. Lastly, WeKG-MF [261]
presents an innovative approach by constructing a knowl-
edge graph from open weather observations published by
M´et´eo-France. This model is built upon a semantic schema
that encapsulates the knowledge of meteorological observa-
tions for an array of downstream scenarios.
7.2 Precipitation Nowcasting
The domain of precipitation nowcasting has garnered sub-
stantial advancements through the application of DL tech-
niques, including CNNs [84], [271], [272], [273], [274], [275],
RNNs [85], [97], [238], [274], [276], [277], and Transform-
ers [107], [166], [171], [173], [176], [278]. These methodolo-
gies have demonstrated remarkable proficiency in manag-
ing spatio-temporal data, a prevalent format in Earth system
observation.
CONV LSTM [97] was pioneering in its integration of
deep learning for processing precipitation proximity fore-
casts, effectively amalgamating CNN and LSTM to man-
age spatio-temporal radar data. Successive models, such as
PRED RNN [209] and E3D-LSTM [210], similarly incorpo-
rate spatio-temporal data within LSTM and CNN architec-
tures to extract long-term higher-order correlations. P HYD-
NET [279] introduces partial differential equation (PDE)
[280] constraints into its theoretical space. M ETNET [165]
and its subsequent iterations, M ETNET-2 and M ETNET-
3 [281], proposed an architecture based on ConvLSTM and
advanced CNNs, thereby enabling proficient precipitation
forecasting up to 12 hours ahead.
The ascension of Transformers in the visual realm has
benefited the spatio-temporal video streaming data-based
approach to rainfall prediction. For instance, PTCT [173]
divides original frames into multiple patches to eliminate
inductive bias constraints. It also applies 3D temporal con-
volutions to effectively capture short-term dependencies.
The Preformer [176] model proposes an encoder-translator-
decoder architecture where the encoder integrates spa-
tial features from multiple elements, the translator mod-
els spatio-temporal dynamics, and the decoder combines
temporal and spatial information for future precipitation
prediction. Rainformer [171] introduces global feature ex-
traction units and gate fusion units (GFUs) to balance
the fusion of local and global features, thereby enabling
efficient rainfall prediction. T EMP EE [107] proposes a par-
allel use of spatio-temporal encoders and decoders based
on the Transformer architecture, achieving promising re-
sults in the egoless regression strategy for handling non-
stationary spatio-temporal sequences. This significantly im-
proves the accuracy of precipitation nowcasting. E ARTH -
FORMER model [172], based on Cuboid Attention, is utilized
for Earth system forecasting, including precipitation now-
casting and ENSO [282].
Taking into account the instructive role of knowledge
from other modes, multimodal spatial-temporal tasks have
been introduced [174], [175], [276]. The MM-RNN [174] in-
troduces elemental knowledge to guide precipitation now-
casting, enforcing a constraint that requires the movement of
precipitation to follow basic atmospheric laws of motion for
accurate forecasting. STIN [175] utilizes spatio-temporally
specific filters to generate precipitation forecasts from multi-
modal meteorological data. Recently, precipitation nowcast-
ing, viewed as an uncertainty assessment problem, has
17
also benefited from the successful application of diffuison
modeling.
Recently, precipitation nowcasting, viewed as an uncer-
tainty assessment problem, has also benefited from the suc-
cessful application of generative modeling. DGMR employs
an adversarial training methodology to generate sharp and
accurate proximity forecasts, which solves the problem of
fuzzy prediction. DMSF-GAN [84], on the other hand,
completely eschews autoregressive strategies and is based
on adversarial training and pure CNN architectures to
address the problem of feature dispersion over time.PCT-
CYCLE GAN [170] generates temporal causality using two
generator networks with forward and backward temporal
dynamics. Each generator network learns a multitude of
one-to-one mappings on precipitation data based on time-
dependent radar to approximate a mapping function rep-
resenting the temporal dynamics in each direction. The
MPL-GAN [167] utilizes a multi-path learning strategy to
improve the diversity of generated sequences while pro-
viding accurate predictions. In addition, to simultaneously
handle uncertainty and enhance domain-specific standards,
PreDiff [177] adopts a two-stage probabilistic spatiotem-
poral prediction pipeline, incorporating explicit knowledge
control mechanisms to enforce predictions conforming to
specific domain’s physical constraints. This is achieved by
estimating the bias of the constraints imposed in each de-
noising step and correspondingly challenging the overfit-
ting distribution. GED [169], known as Generative Ensemble
Diffusion, utilizes a diffusion model to generate a set of pos-
sible weather scenarios which are then amalgamated into
a probable prediction via the use of a post-processing net-
work. Ref. [231] utilizes radar-based deep learning models
for skillful short-term precipitation forecasting, achieving
display-consistent predictions over a 1536x1280 km region.
The introduction of physical constraints and graph rela-
tions can improve the efficiency and accuracy of the model.
Ref. [240] introduces a generative adversarial network with
physical information constraints to improve both local dis-
tribution and spatial structure for daily precipitation field
improvement. CNGAT [168] fuses spatial and temporal
information for improved Radar quantitvative precipitation
estimate (RQPE) [283]. The precipitation estimation area was
partitioned into subares that were treated as nodes to from
an input graph. All nodes were then categorized according
to the temporal mean radar reflectivity for precipitation
estimation with an attention mechanism.
7.3 Downscaling
Achieving precise, fine-grained weather predictions neces-
sitates high spatial resolution data. However, most global
weather forecasting models are restricted by the availability
and scale of data, resulting in an over-reliance on data
with approximately a 5.625° spatial resolution, equivalent
to a grid point spacing of about 625 kilometers. Despite
these limitations, the data volume is significant. For in-
stance, the data scale of the ERA5 system at a 0.25° spa-
tial resolution is several tens of times larger—around 15
terabytes—compared to the 5.625° spatial resolution data.
High spatial resolution data offer a more granular represen-
tation of complex atmospheric processes and the interplay
between different weather systems. One strategy to tackle
this issue is the enhancement of weather data’s spatial res-
olution, a process referred to as super-resolution (SR) [284],
[285]. SR can bolster the resolution of gridded data, surpass-
ing conventional interpolation methods in effectiveness.
A popular DL-based SR model, U-Net, leverages a
synergistic encoder-decoder structure to produce high-
resolution outputs from low-resolution inputs [286], [287],
[288]. Within the realm of semi-supervised learning, gen-
erative adversarial networks (GANs) have demonstrated
potential in enhancing the representation of more intricate
structures and details [164], [217], [236], [237], [289], [290],
[291], [292]. The typical procedure involves training the
generator to learn the potential mapping between low- and
high-resolution grid data or images. For example, Stengel
et al. presented an adversarial DL approach that super-
resolves the predictions of wind speed and solar irradiance
in global climate models to a sufficient scale for renewable
energy resource assessment, thereby improving the resolu-
tion of wind and solar energy data nearly fiftyfold [292].
Recent research has deployed diverse strategies such
as normalizing flows and neural operators. Self-supervised
learning-based methods have also been investigated for
downscaling low-resolution grid weather data. For instance,
the pre-trained foundation model, CLIMA X [25], allows fine-
tuning for resolution downscaling. Gonz ´alez et al. intro-
duced a downscaling strategy based on multi-variable phys-
ical hard constraints, ensuring the physical relationships
between variable sets [161].
Physics-constrained DL-based methods have also been
proposed to improve the model’s performance via exter-
nal adjustment [156], [157], [158], [162], [163], [293], [294].
For example, MeshfreeFlowNet [156] employs a physics-
informed model which incorporates Partial Differential
Equations (PDEs) as regularization terms into the loss
function, achieving spatio-temporal downscaling. Harder
et al. [158] were the first to apply hard-constraining to
achieve fine-grained downscaling outputs in climate change
datasets. Furthermore, strategies such as contrastive learn-
ing [285] and Betrays DL models [159] were adpoted.
In response to the lack of interpretability of DL-based
downscaling methods, Gong et al. explored the inter-
pretability of fundamental CNNs in climate model down-
scaling strategies, thus paving the way for trustworthy
artificial intelligence in downscaling models [273]. Bano et
al. analyzed the downscaling issue from a multimodel per-
spective, developing a CNN-based downscaling prediction
ensemble (DeepESD) for temperature and precipitation in
the European EUR-44i (0.5°) domain based on eight global
circulation models [160]. This represents the first application
of CNNs in generating a downscaled multimodel ensemble
based on perfect prognosis methods, allowing for the quan-
tification of model uncertainty in climate change signals.
The introduction of uncertainty modeling also allows
downscaling gains in DL-based models, significantly im-
proving efficiency as well as reconstruction resolution. Res-
Diff [164] employs a two-step diffusion model-based ap-
proach. In the first step, U-Net regression predicts the mean
values, while in the second step, the diffusion model pre-
dicts the residuals, thereby achieving kilometer-scale atmo-
spheric downscaling. However, it should be noted that the
18
use of diffusion models in the field of weather and climate is
still in the exploratory stage. Ref. [223] also employs similar
operations, utilizing diffusion models for cloud cover and
super-resolution diffusion models for high-resolution solar
energy forecasting.
7.4 Bias Correction
Bias correction in weather predictions has traditionally re-
lied on statistical methods [186]. Over time, these techniques
have evolved, embracing machine learning strategies such
as Deep Belief Networks and Support Vector Machines. The
advent and proliferation of data availability have further
catalyzed the shift towards deep learning methodologies,
including Long Short-Term Memory (LSTM) [187], [188],
[189] and Convolutional Neural Networks (CNN) [185],
[190], [191]. These methodologies have been instrumental
in mitigating common weather-related biases.
A notable approach is the DL-Corrector-Remapper tech-
nique [192], which stands apart in its ability to correct,
remap, and fine-tune gridded uniform forecasts from the
FourCastNet system. This process enables a direct compar-
ison with non-uniform, sparse observational ground truth
data via the AFNO method. The Super Resolution Deep
Residual Network (SRDRN) [191] has been employed for
climate downscaling and bias correction. This network uti-
lizes stacked general circulation models and extracts spatial
features, effectively diminishing biases and correcting spa-
tial dependencies relative to observational data.
In an intriguing application, the Unsupervised Image-
to-Image Translation (UNIT) network [193] capitalizes on
unpaired image translation for bias correction. This method
offers a novel perspective on bias mitigation. Hess et
al. [240] have proposed a post-processing technique that
employs a physics-constrained Generative Adversarial Net-
work (cGAN) to concurrently correct biases in local fre-
quency distribution and spatial patterns of state-of-the-art
CMIP6-level Earth System Models.
Recently, the WeatherGNN model [194] has been devel-
oped, which leverages a Graph Neural Network within a
comprehensive framework. This model learns the intricate
relationships between weather and geography, capturing
meteorological interactions and spatial dependencies be-
tween grids. This approach provides a robust and sophisti-
cated tool for bias correction. These advancements illustrate
the potential of deep learning methodologies in refining
weather prediction systems.
7.5 Data Assimilation
Data assimilation (DA) is a key component of high-level
NWP systems. These systems not only forecast future states,
but also integrate observational data to establish the initial
state, guiding the model’s trajectory to future states. This
complex process is computationally demanding, making it
an active area of research. Existing approaches often rely
on simplifying assumptions, such as linearity, which adds
to the challenges in the field. However, the integration of
deep learning into DA is gaining recognition, with encour-
aging research outcomes. For instance, O CEANFOURCAST
[149] employs neural operators alongside a Transformer-
based architecture, inspired by F OUR CAST NET [136], to
support adjoint-based data assimilation in ocean modeling.
Furthermore, Bocquet et al. [295] innovatively combine DA,
machine learning, and expectation maximization to perform
Bayesian inference of chaotic dynamics, enabling the assim-
ilative reconstruction of observational data for geophysical
flows. For an in-depth review of DA, we refer readers to
Geer’s work [296].
7.6 Climate Text Analysis
The rapid development of LLMs has provided new in-
sights for climate text analysis. Hershcovich et al. intro-
duced a climate performance model card, designed with
the intent of practical application requiring minimal in-
formation on the experimental setup and associated com-
puter hardware [297]. A language model, known as C LI-
MATE BERT [195], was developed with a foundation in D IS-
TILL ROBERTA, specifically designed for analyzing climate-
orientated text. This versatile model can be employed in
a variety of tasks, such as detecting climate-related con-
tent, discerning sentiment in climate-related paragraphs,
identifying commitment and action-related content, distin-
guishing specific from non-specific climate-related text, and
assigning climate-related content to one of four categories
as per the recommendations of the Task Force on Climate-
related Financial Disclosures (TCFD Further refinement of
CLIMATE BERT is seen in the work of Garrido-Merch ´an et
al. [199], who utilized ClimaText [205] to fine-tune the
model for the specific task of analyzing disclosures relat-
ing to financial risks connected with climate change. An
extension, C LIMATE BERT-N ETZERO [198], was designed
to classify whether a given text contains a net zero or
reduction target. Krishnan et al. employed C LIMATE BERT
in their C LIMATE NLP project, analyzing public sentiment
towards climate change using data gathered from Twitter
and Facebook [257]. Auzepy et al. proposed the use of
pretrained LLMs’ zero-shot capabilities to evaluate TCFD
reporting [258] . However, this approach is not without its
challenges. Pre-trained LLMs often lack up-to-date infor-
mation and tend to use imprecise language, a significant
disadvantage in the field of climate change where accuracy
is paramount. To mitigate this, Kraus et al. incorporated
emission data from ClimateWatch and utilized a general
Google search to enhance the language model [259]. Vaghefi
et al. integrated information from the Intergovernmental
Panel on Climate Change’s Sixth Assessment Report (IPCC
AR6) into GPT-4 [298], laying the groundwork for the im-
plementation of conversational AI in the realm of climate
science [256] . In the intersection of climate and health,
CLIMEDBERT [196] was developed for diverse applications,
including understanding climate and health-related con-
cepts, fact-checking, relationship extraction, and generating
evidence on the impact of health on policy text generation.
Additionally, Bi et al. have proposed OceanGPT [197], based
on LLM (e.g., Llama [82] and GPT3.5 [48]), to handle specific
tasks related to the ocean, such as ocean text analysis and
intelligent underwater agent instructions.
7.7 Weather Patterns Understanding
Weather pattern understanding, as opposed to forecasting,
tends to lean towards a qualitative analysis of climate
19
change. By integrating predictions derived from reanalysis
datasets, we can more effectively quantify the potential im-
pact of future weather events. Traditional numerical meth-
ods, though costly, rely on manually crafted features such as
fronts, tropical cyclones [299], extratropical cyclones, and at-
mospheric rivers, using heuristic detection algorithms based
on empirical knowledge. However, weather patterns with
more distinct features, like tornadoes and typhoons, may be
more amenable to pattern detection and prediction due to
their characteristic features. For instance, a typhoon’s eye
and surrounding rainbands present distinct patterns. This
pattern detection and prediction could potentially prove
more advantageous than predicting the general atmospheric
state in standard training. One approach might be to employ
spatio-temporal video stream data, such as radar reflectivity
data [107] and weather satellite cloud imagery [300]. This
transition from spatio-temporal weather video stream data
to predictions offers a more dynamic and visually intuitive
method for weather pattern understanding.
Weather pattern understanding based on DL techniques
often requires large-scale, well-annotated samples. In one
study, Kashinath et al. [301] created a dataset suitable for
tropical cyclone (TC) detection in the 25km CAM5.1 model.
They achieved fine-grained and rapid segmentation of TCs
and atmospheric rivers (ARs) using DL-based segmenta-
tion algorithms. Racah et al. [302] extended this dataset
to detect and precisely locate TCs, extra-tropical cyclones
(ERCs), ARs, and tropical low-pressure systems using a 3D-
CNN. Furthermore, Sobash et al. [303] combined CNNs and
logistic regression (LR) to detect tornadoes in six-hourly
dynamical forecasts and turbulence conditions in regional
or high-resolution weather forecasts. In addition to detect-
ing different weather patterns from large-scale reanalysis
datasets, advanced AI models are frequently used to study
the evolutionary processes of meteorological phenomena.
These include the genesis and dissipation of typhoons in
a regional context, as well as the movement trajectories of
TCs. Next, we will proceed to conduct a literature review
and discussion on the field of weather pattern understand-
ing, focusing on climate phenomena and extreme weather
events.
7.7.1 Climate Phenomena Understanding and Prediction
We mainly focus on discussing three primary climate phe-
nomena/representation in the global scale, including El
Ni˜no-Southern Oscillation, Climate Tipping Points, and
Madden-Julian Oscillation.
• El Ni ˜ no-Southern Oscillation. The El Ni ˜no phe-
nomenon, arising from intense ocean-atmosphere in-
teractions, is marked by heightened sea surface tem-
peratures (SST), a levelled equatorial Pacific thermo-
cline, and a diminished tropical Pacific Walker circu-
lation [304]. Together with its inverse phase, La Ni ˜na,
it constitutes the El Ni ˜no-Southern Oscillation (ENSO)
cycle. This cycle, with a duration of 2 to 7 years,
is the principal driver of global climate interannual
variability, frequently correlating with significant global
climatic and socio-economic repercussions [305]. Con-
sequently, accurate ENSO forecasting is of paramount
scientific and practical significance. Several methods
have been proposed to enhance ENSO forecasting.
Ref. [178] incorporates a Transformer-based architec-
ture, considering long-term correlations among meteo-
rological variables. A spatial-temporal Transformer for
multi-year ENSO prediction is suggested by Ref. [306].
ENSO-GTC [181] applies the Global Teleconnections
Coupler (GTC) for potential teleconnections between
global SST. Ref. [65], [66] develop an interpretable deep
learning model for ENSO forecasting. Ref. [179] intro-
duces a holistic deep learning model for ENSO that
integrates seasonality in climate data to enhance fore-
cast fluctuation. Comprehensive reviews and surveys
on deep learning-based ENSO forecasting can be found
in Refs. [268], [307].
• Climate Tipping Points. Climate tipping points denote
crucial thresholds within the climate system where
the system undergoes significant and irreversible alter-
ations in response to certain changes or external forc-
ings [281], [308], [309]. These transitions can instigate
major climate system shifts, including modifications in
oceanic circulation patterns, accelerated glacier melting,
and climate zone migration. The transgression of these
tipping points can destabilize the long-term equilib-
rium of the climate system, inciting more severe cli-
mate transformations. TIP-GAN [243] is a Generative
Adversarial Network (GAN)-based model designed to
identify potential climate tipping points in Earth system
models, with a particular emphasis on precipitating
the collapse of the Atlantic Meridional Overturning
Circulation (AMOC). Additionally, a neural-symbolic
question answering program translator, NS-QAPT, is
presented as a neural-symbolic approach to enhance
the interpretability and explainability of deep learning
climate simulations applied to climate tipping point
detection [281]. Further relevant works can be explored
in Refs. [310], [311].
• Madden-Julian Oscillation. The Madden-Julian Oscil-
lation (MJO) [312], [313] is a substantial atmospheric
circulation phenomenon predominantly observed near
the equator. It is characterized by regular oscillations
in convection activity and precipitation in equatorial
regions, with a typical duration spanning 20 to 90
days. The MJO exerts substantial influence on global
weather and climate systems, impacting precipitation
patterns, wind fields, and the origination and evolution
of tropical cyclones. Consequently, comprehension and
prediction of the MJO are vital for accurate precipitation
forecasting and disaster prevention, thereby effectively
managing and mitigating potential risks. DK-STN [184],
leveraging spatio-temporal knowledge embedding, has
notably enhanced the prediction accuracy of the ANN
method, while preserving high levels of efficiency and
stability. For further related works, refer to Ref. [8].
7.7.2 Extreme Weather Prediction and Understanding
This discussion primarily centers around the application
of DL models for the prediction and understanding of
four pivotal extreme weather events: Extreme Temperatures,
Drought, Cyclones, and Extreme Precipitation.
• Extreme temperatures. Extreme Temperatures. These
often present as intense, prolonged, and frequent heat-
waves [74], imposing substantial challenges to human
20
activities and the ecological environment. Extreme tem-
perature events are typically defined as a series of days
with temperature variables surpassing a specific thresh-
old or evaluated using accumulation indices composed
of amplitude, duration, and frequency. Data-driven cli-
mate models rooted in machine learning/deep learning
have demonstrated effectiveness in extreme tempera-
ture prediction tasks. Techniques such as random forest
and XGBoost have offered promising results. Further-
more, convolutional neural networks, recurrent neural
networks, and Transformers have seen extensive use in
extreme temperature prediction due to their capacity to
capture spatiotemporal representations.
• Drought. Droughts occur at various spatiotemporal
scales and involve multiple triggering mechanisms,
which complicates a clear and comprehensive defini-
tion [314]. They represent an extremely complex natural
disaster. Recent research has gravitated towards using
AI algorithms [315] based on geospatial weather data
for long-term drought prediction, such as in [180],
[182], [316]. For example, Ref. [180] proposed a one-
dimensional CNN combined with a GRU for evapo-
transpiration prediction, enabling the model to better
capture dependencies in time series data. Meanwhile,
Ref. [316] combined CNN and LSTM for drought pre-
diction one month in advance. A more comprehensive
review of AI applications in drought prediction can
be found in Refs. [180], [317]. However, most existing
studies are geographically focused, causing the model
performances to heavily depend on specific research
conditions such as the study area, drought index, or
considered input variables. This dependency makes it
difficult to generalize major findings from one study to
another.
• Cyclones & Extreme Precipitation. In tropical and mid-
latitude regions, weather-scale cyclones represent some
of the most extreme events causing significant economic
damage due to heavy rainfall, strong winds, and storm
surges [318]. Evidence suggests that climate change
may amplify the severity of these extreme events, even
if not their frequency [299]. However, predicting their
variability on sub-seasonal to decadal timescales re-
mains a challenge [319]. Heavy precipitation events
are not always linked with large-scale weather systems
such as cyclones or fronts; many impactful events are
tied to brief, small-scale severe convective events. These
extremes pose a greater challenge for operational cli-
mate prediction systems as their spatial resolution is
too coarse to capture the explicit representation of con-
vection. In most regions where extreme precipitation is
analyzed, the skill of numerical climate prediction sys-
tems for extreme precipitation decreases significantly
after a few days. AI techniques have been applied to
improve the prediction of cyclones and heavy precipi-
tation events from various perspectives. The objective
is to enhance the skill of numerical prediction sys-
tems (e.g., seasonal forecasting) in representing extreme
weather events by identifying the relationship between
large-scale driving factors and the occurrence of ex-
treme events. This approach has been applied to large-
scale extreme events, such as tropical or extratropical
cyclones, or directly to precipitation fields [320], [321].
De Burgh-Day & Leibnberg [322] proposed a systematic
model ablation study as a potential approach to address
the interpretability issue of DL models while main-
taining their good skill. Additionally, some DL-based
strategies aim to handle cyclones and extreme precipita-
tion forecasting via meteorological image extrapolation
(refer to Section. Precipitation Nowcasting), and others
focus on improving model outputs by achieving high-
resolution observations to enhance the representation
of precipitation or wind patterns associated with cy-
clones rather than directly performing the prediction
task [323], [324] (refer to Sec. 7).
8 R ESOURCES
In this section, we catalog the prevalent datasets and tools
pertinent to weather and climate change analysis, aspiring
to streamline their accessibility for practitioners.
8.1 Dataset
This segment classifies datasets employed in data-driven
weather and climate studies. These datasets facilitate
weather time-series analysis, weather spatio-temporal series
analysis, weather spatio-temporal video stream analysis,
and climate text analysis. We bifurcate them into two cat-
egories: weather and climate series data and climate text
data. It’s noteworthy that the datasets are unordered.
8.1.1 Weather and Climate Series Data
This subsection concentrates on datasets related to weather
and climate sequences, encompassing time series, spatio-
temporal sequences, spatio-temporal video streams, and
multimodal sequence data.
CMIP6 [88], [89], [90] is a compendium of simulated data
from Phase 6 of the Coupled Model Comparison Project
(CMCP). It encompasses a wide array of different climate
variables within the Earth system, such as precipitation,
temperature, evapotranspiration, and others. The data, de-
rived from over 150 climate models, spans more than 150
years (1850-2015). It can be utilized to predict the ENSO
phenomenon and common climate variables.
ERA5 [88], [89], [90] is widely used for training and
benchmarking data-driven weather and climate forecast-
ing, down-scaling, and projection models. Managed by the
European Center for Medium-Range Weather Forecasting
(ECMWF) [343], it is regularly updated. ERA5 contains
hourly data on a 0.25° grid from 1979 till present, at 37
different pressure levels, as well as various surface climate
variables, resulting in nearly 400,000 data points at a resolu-
tion of 721 × 1440.
HCOSD3 is provided by the Institute for Climate and
Applied Frontier Research (ICAR), is a refined subset of the
CMIP dataset. Standing for Historical Climate Observation
and Stimulation Dataset, it includes historical simulated
data from the CMIP5/6 model and assimilated data from
nearly a century of historical observations, reconstructed
from the US SODA model [344]. Each sample encapsulates
meteorological and spatial variables, such as sea surface
3. https://tianchi.aliyun.com/dataset/98942
21
TABLE 4: Summary of weather and climate-related dataset resources in different applications. ( FO: Forecasting; PR:
Projection; DO: Downscaling; BC: Bias Correlation; DA: Data Assimilation; WPU: Weather Pattern Understanding; PN:
Precipitation Nowcasting; CTA: Climate Text Analysis. All datasets have accessible hyperlinks on their names.
Data Types Dataset Statistics Timeframe ApplicationsFO PR DO BC DA WPU PN CTA
Time Series
Reanalysis/Simulation
CMIP6 [88], [89], [90] Reanalysis Grid Data 1850-2100 ! ! ! ! ! % % %
ERA5 [88], [89], [90] Reanalysis Grid Data 1779 to the present ! ! ! ! ! % % %
HCOSD Reanalysis Grid Data 1850-2100 ! ! % % % ! % %
Extreme-ERA5 [90] Reanalysis Grid Data 1979-2018 ! ! ! ! ! ! % %
ExtremeWeather [302] Reanalysis Grid Data 1979-2005 ! ! % % % % ! %
ClimateNet [301] Reanalysis Grid Data 1996-2010 ! ! % % % ! % %
ENS-10 [325] Reanalysis Grid Data 1998-2017 ! % ! ! ! % % %
ClimART [221] Reanalysis Grad Data 1979-2014 ! ! % ! ! ! % %
Observation
China-Precipitation,Temperature [326] Observation Data 1901-2017 ! % % % % % % %
Digital Typhoon [327] Observation Data 1978-2022 ! % % % % ! ! %
DroughtED [314] Observation Data June 2017 - December 2017 ! % % % % ! % %
IowaRain [328] Observation Data 2016-2019 ! ! % % % ! % %
SRAD2018 Observation Data 2018 % % % % % ! ! %
KnowAir [329] Observation Data 2015-2018 ! % % % % % % %
NASA [24] Observation Data 2012-2022 ! % % % % % % %
PRISM [90] Observation Data 1895 to the present ! ! ! ! ! ! % %
RainNet [330] Observation Data None % % ! % % ! ! %
Continental United States Wind Speeds [331] Observation Data 2007-2013 % % ! % % % % %
Continental United States Solar Irradiance [331] Observation Data 2007-2013 % % ! % % % % %
Multimodal
EarthNet2021 [332] Multimodal Observation Data 2018 ! ! % % % ! % %
KoMet [333] Multimodal Observation Data 2011-2018 ! % % % % % % %
Germany [334] Multimodal Observation Data 2011-2018 ! % % % % ! ! %
China [335] Multimodal Observation Data 2020-2021 ! % % % % ! ! %
MeteoNet [336] Multimodal Observation Data 2016 to 2018 ! % % % % ! ! %
RAIN-F [337] Multimodal Observation Data 2017-2019 ! % % % % ! ! %
RAIN-F+ [337] Multimodal Observation Data 2017-2019 ! % % % % ! ! %
SEVIR [86] Multimodal Observation Data None ! ! % % ! ! ! !
RainBench [338] Multimodal Observation & Reanalysis Data 2000-2017 ! ! ! % % ! ! %
Weather2K [87] Multimodal Observation Data 2017-2021 ! % % % % % % %
LSDSSIMR [300] Multimodal Observation & Reanalysis Data 2020-2022 ! ! % % % ! % %
Text
CLIMATE-FEVER [339] Climate-related Text None % % % % % % % !
ClimateBERT-NetZero [198] Climate-related Text None % % % % % % % !
ClimaText [205] Climate-related Text None % % % % % % % !
CLIMA-INS [340] Climate-related Text 2012-2021 % % % % % % % !
CLIMA-CDP [340] Climate-related Text 2012-2021 % % % % % % % !
CLIMATESTANCE & CLIMATEENG [341] Climate-related Text None % % % % % % % !
SCIDCC [342] Climate-related Text None % % % % % % % !
temperature anomalies, heat content anomalies (T300), lati-
tudinal wind anomalies, and longitudinal wind anomalies,
with data dimensions (year,month,lat,lon). The training data
offers Nino3.4 index-labeled data for the corresponding
month. The testing data comprises 12 randomly selected
time series from multiple international oceanographic data
assimilation results.
Extreme-ERA5 [90] is a subset constructed by Climate-
Learn from ERA5 to evaluate the prediction capability of
data-driven models under extreme weather conditions. It
comprises various extreme weather events, defined by cli-
mate variables exceeding localized thresholds (e.g., heat-
waves and cold breaks due to sea level temperature anoma-
lies). The dataset covers the period 1979-2018, with 1979-
2015 considered the training dataset.
PRISM [90] is a dataset contains myriad observed atmo-
spheric variables, including but not limited to temperature
and precipitation for the conterminous U.S. region. Main-
tained by the PRISM Climate Organization at Oregon State
University, the dataset spans from 1895 to the present. At its
highest resolution, it provides daily data based on 4 km x 4
km grid cells, forming a matrix of shape 621 x 1405.
DroughtED [314] is a drought forecast data that com-
bines 180 daily weather observations for the continental
United States and geospatial location metadata for all 3,108
counties. It includes meteorological real-time and historical
data from NASA’s Global Energy Resources (Electricity)
Prediction Program, and variables include measurements of
precipitation, surface pressure, relative humidity dew/frost
point, wind speed, and daily resolution temperature. Past
drought observations were also included and given a par-
allel categorization of USDM drought levels, including no
drought (none), abnormally dry (D0), moderate (D1), severe
(D2), extreme (D3), and abnormal (D4). Additionally consid-
ering that drought is a seasonal phenomenon, seasonal char-
acteristics were also included within the dataset. In addition,
a location metric was included, including topographic slope,
gradient, and elevation for each site, as well as land use
(e.g., rain-fed cropland or forested land) for each site, and
soil quality, such as toxicity or nutrient utilization.
Digital Typhoon [327] is a image-based dataset utilized
to long-term spatio-temporal modeling for tropical cyclones.
It is created from the comprehensive satellite image archive
of the Japanese geostationary satellites eries, Himawari,
from Himawari-1 to Himawari-9. The dataset consists of
1,099 typhoons and 189,364 images. Geographically, it cov-
ers the complete record of typhoons occurring in the North-
western Pacific region, with a time span from 1978 to 2022.
The dataset has a temporal resolution of one hour and a
spatial resolution of 5km.
EarthNet2021 [332] is large dataset for Earth surface
prediction, extreme summer prediction and seasonal cycle
prediction. It contains more than 32,000 samples of Sentinel
2 (high temporal and spatial resolution Earth satellite) Class
2A imagery, as well as daily climate data derived from the E-
OBS observational dataset containing interpolated ground-
truth observations of weather from multiple stations across
Europe for the full year 2018.
ClimateNet [301] is an open and expert-labeled dataset
designed for high-precision analyses of extreme weather
events. It focuses on capturing tropical cyclones and at-
mospheric rivers in high-resolution climate model outputs,
22
simulating the recent historical period from 1996 to 2010.
This dataset is valuable for various applications in machine
learning and climate research, such as transfer learning, cur-
riculum learning, active learning, spatiotemporal segmenta-
tion, probabilistic segmentation, and hypothesis testing.
IowaRain [328] is primarily derived from the Quan-
titative Precipitation Estimation System (QPES) based on
the National Weather Service’s Weather Detection Radar
Network lowa Flood Center. It covers the region of Iowa and
spans the period from 2016 through the end of 2019. Each
event in the dataset includes a collection of 2D rainfall rate
maps, along with information about the size of the event
(i.e., the number of rainfall rate maps in the set) and the
start date of the event. This dataset is specifically designed
for predicting regional rainfall events.
ExtremeWeather [302] is a comprehensive dataset that
aims to facilitate the detection, localization, and under-
standing of extreme weather events. It is based on post-
processed simulations of CAM5, a widely used atmospheric
3D model for global climate simulations. The dataset focuses
on extreme weather events and provides a spatial resolution
of 25-km. Each snapshot of the global atmospheric state is
represented as a 768 × 1152 grid, with 16 simulated climate
variables including surface temperature, surface pressure,
precipitation, latitudinal winds, meridional winds, humid-
ity, cloud fraction, and water vapor. The dataset covers a
time span from 1979 to 2005, with a temporal resolution of
3 hours. It consists of a total of 78,840 samples, capturing
four types of extreme weather events: Tropical Depression
(TD), Tropical Cyclone (TC), Extratropical Cyclone (ETC),
and Atmospheric Rivers (AR). The center of each storm is
considered as the reference point for marking the bounding
box coordinates. Notably, the dataset includes 39,420 labeled
images, providing valuable annotations for training and
analysis purposes.
KoMet [333] is a collection of data specifically gathered
in Korea. It utilizes input data from GDAPS-KIM, a global
numerical weather prediction model that offers hourly fore-
casts for various atmospheric variables. The dataset focuses
on precipitation prediction and has a spatial resolution of
12 × 12 kilometers, resulting in a spatial size of 65 × 50.
The dataset includes two types of variables: pressure level
variables and surface variables. These variables provide
valuable information for predicting and understanding pre-
cipitation patterns in Korea. In terms of the distribution of
samples, approximately 87.24% of the samples in the dataset
are classified as ”no rain,” indicating instances where pre-
cipitation is not observed. Around 11.57% of the samples
correspond to rainy conditions, while 1.19% represent ex-
treme rainfall events.
Germany [334] is a precipitation forecasting dataset col-
lected in West Germany. It spans the period from 2011 to
2018 and focuses on precipitation forecasting. The input
data for this dataset are derived from the COSMO-DE-EPS
forecast, which provides 143 variables representing different
atmospheric states. The dataset has a spatial resolution of
36 × 36 for the input data, indicating the grid size used
to represent the atmospheric conditions. The output data,
representing the precipitation forecasts, have a higher res-
olution of 72 × 72. In terms of the distribution of samples,
approximately 85.10% of the samples in the dataset are clas-
sified as “no rain“ indicating instances where precipitation
is not observed. Around 13.80% of the samples correspond
to rainy conditions, while 1.10% represent extreme rainfall
events.
China [335] is a precipitation forecasting dataset col-
lected in China, provided hourly, 1 km × 1 km resolution,
3-hourly grid-point precipitation data for the rainy sea-
son. This dataset lasts from April through October for the
2020 and 2021 seasons. In addition, it includes 3-hour lead
time projections from the regional NWP model, including
28 surface and pressure level variables such as 2-meter
temperature, 2-meter dew point temperature, 10-meter u
and v wind components, and CAPE (Convective Available
Potential Energy) values. Each time frame in this dataset
covers a sizable spatial region with a grid size of 430 × 815.
China-Precipitation/Temperature [326] is a high-spatial-
resolution monthly precipitation and temperature dataset
for China, covering the period from 1901 to 2017. The
dataset includes monthly minimum, maximum, and mean
temperatures, as well as precipitation data, at a spatial
resolution of 0.5 arcminutes (approximately 1 kilometer) for
the main land area of China. The dataset was downscaled
using the Delta spatial downscaling method from the 30
arcminute Climatic Research Unit (CRU) time series dataset
and the WorldClim climatology dataset. It was evaluated us-
ing observations collected from 496 weather stations across
China during the period from 1951 to 2016.
ClimART [221] is a dataset for emulating atmospheric
radiative transfer in weather and climate models, with more
than 10 million samples from present, pre-industrial. and
future climate conditions, based on the Canadian Earth Sys-
tem Model. This dataset of global snapshots of the current
atmospheric state from CanESM5 was simulated every 205
hours from 1979 to 2014. CanESM5 has a horizontal grid
discretizing longitude to 128 columns of the same size and
latitude to 64 columns using a Gaussian grid (8192 = 128 x
64 columns). This resulted in 43 global snapshots per year
for the period 1979-2014, totaling over 12 million columns
and a raw dataset size of 1.5 TB.
MeteoNet [336] is a multimodal dataset for regional pre-
cipitation nowcasting covering a geographical area of 550
× 550 km in the northwestern quarter of France, spanning
the years 2016 to 2018. The modalities of the dataset include
radar echo observations, earth-observing satellite imagery,
ground station observations, weather forecast model data
and topographic maps. The ground observation data has a
temporal resolution of six minutes and includes meteorolog-
ical variables such as temperature, humidity, atmospheric
pressure, and wind speed measured by 500 ground stations.
The radar echoes, on the other hand, are precipitation radar
records with a five-minute time resolution, i.e., 12 frames
recorded in one hour, including radar reflectivity and rain-
fall estimates. The satellite data are recorded every 15 min
for Cloud Type (CT) and every 1 hour for Channels (visible,
infrared). Weather models are also included forecasts from 2
weather models with 2D parameters, generated once a day.
RAIN-F [345] is a pre-processed spatio-temporally
aligned multimodal dataset for short-advance rainfall fore-
casting, which includes radar, ground-based observations,
and a variety of summed satellite data, for the time period
from 2017 to 2019, with a coverage of the Korean Penin-
23
sula. Specifically, nine different atmospheric state variables
(one radar, seven ground observations, and one satellite)
associated with precipitation variables are included with a
temporal resolution of one hour. The ground-based obser-
vations include wind direction and speed, humidity, surface
pressure, temperature, sea level pressure and precipitation.
RAIF-F+ [337] is a new version of RAIN-F with new
atmospheric variables and TB products, which can also be
used to retrieve atmospheric variables from satellite obser-
vations or to predict atmospheric state and precipitation,
with geographic and temporal coverage identical to that of
RAIN-F.
ENS-10 [325] is a post-processing dataset for ensemble
weather forecasting, consisting of 10 ensemble members
spanning 20 years (1998-2017). These ensemble members are
generated by perturbing numerical weather simulations to
capture the chaotic behavior of the Earth. To represent the
three-dimensional state of the atmosphere, ENS10 provides
11 atmospheric variables at 11 different pressure levels and
the most relevant variables at the surface, with a resolution
of 0.5 degrees. The dataset includes forecast lead times of
T = 0, 24, 48 hours (two data points per week).
SEVIR [86] is a collection of temporally and spatially
aligned image sequences depicting weather events captured
over the contiguous US (CONUS) by GOES-16 satellite and
the mosaic of NEXRAD radars. Five different image data
types are included, such as the GOES-16 0.6 µm visible
satellite channel (vis), 6.9 µm and 10.7 µm infrared channels
(ir069, ir107), a radar mosaic of vertically integrated liquid
(vil), and total lightning flashes collected by the GOES-16
geostationary lightning mapper (GLM) (lght). The spatial
resolution is 0.5km, 2km, 2km, 1km, and 8km, the temporal
resolution is 5 minutes (except for lightning events), and the
image coverage is 768×768, 192×192, 192×192, and 384×385,
respectively, corresponding to meteorological events 1403,
13552, 13541, 20393, and 15115, which can be used by the
applied to weather prediction, image-to-image conversion,
extreme weather detection, weather annotation, super reso-
lution and other applications.
SRAD2018 is a precipitation nowcasting dataset com-
posed of a series of radar echo image, is from Tianchi IEEE
International Conference on Data Mining (ICDM) 2018 Global
Artificial Intelligence Challenge on Meteorology and collected
by Shenzhen Meteorological Bureau and Hong Kong Obser-
vatory. Each sequence in the dataset contains 501 × 501 km
region with 1 × 1 spatial resolution, the temporal resolution
is 6 min and complete sequence is 6 h, taken from an altitude
of 3 km.
RainBench [338] is a precipitation forecasting dataset
consists of European Centre for Medium-Range Weather
Forecasts simulated satellite data (SimSat), ERA5 reanalysis
product and Integrated Multi-satelliteE Rettrievals (IMAGE)
global precipitation estimates. All data is converted from
their original resolution to 5.625 resolutions using bilinear
interpolation. The time span is 2000 to 2017 and the time
resolution is 1 hour.
KnowAir [329] is a weather forecasting dataset based
on station observations, which includes 184 meteorological
stations in northern China. The dataset covers the time span
from 2015 to 2018, with a temporal resolution of three hours.
It primarily includes 18 weather features.
Weather2K [87] is a large-scale dataset for weather pre-
diction based on station observation data, which is extracted
from 1,866 ground-based meteorological stations through-
out China, covering an area of 6 million square kilometers,
with 23 features corresponding to each meteorological bat-
tle, containing three static variables representing geographic
information as well as 20 interacting meteorological vari-
ables, and with a temporal coverage of January 1, 2017, to
August 31, 2021, with a temporal resolution of one hour.
NASA [24] is a collection of regional weather forecasting
datasets, which consists of three subsets, AvePRE, SurTEMP ,
SurUPS, spanning from Apr 1, 2012 to Feb 28, 2016, Jan 3,
2019 to May 2, 2022, and Jan 2, 2019 to Jul 29, 2022, respec-
tively, all with one-hour temporal resolution, collected from
88, 525, and 238 stations, respectively.
LSDSSIMR [300] is a large-scale dust storm database
used for extreme weather and sandstorm prediction. The
data is sourced from multi-channel and dust label data
of the Fengyun-4A (FY-4A) geostationary orbit satellite, as
well as Earth system reanalysis data. The dataset covers
the time span from March to May each year from 2020 to
2022, with a time resolution of 15 minutes and a spatial
resolution of 4 kilometers. Meteorological reanalysis data is
incorporated into LSDSSIMR for spatio-temporal prediction
methods. Each data file is stored in HDF5 format, and the
final LSDSSIMR consists of nearly 5400 HDF5 files.
RainNet [330] is a large-scale dataset specifically de-
signed for spatial downscaling of precipitation. It contains
data from 85 months or 62,424 hours, resulting in a total of
62,424 pairs of high-resolution and low-resolution precipi-
tation maps. The high-resolution precipitation maps have a
size of 624x999, while the low-resolution maps have a size
of 208x333. These data encompass various meteorological
phenomena and precipitation conditions such as hurricanes
and squall lines. The precipitation map pairs in RainNet are
stored in HDF5 files, occupying a total of 360GB of disk
space. The data is collected from satellites, radars, and rain
gauge stations, covering the inherent working characteris-
tics of different meteorological measurement systems.
Continental United States Wind Speeds [331] is a cli-
mate downscaling (super-resolution) dataset, was obtained
from the National Renewable Energy Laboratory’s (NREL’s)
Wind Integration National Database (WIND) Toolkit, with a
focus on the continental United States. Wind velocity data is
comprised of westward (ua) and southward (va) wind com-
ponents, calculated from wind speeds and directions 100-
km from Earth’s surface. The WIND Toolkit has a spatial res-
olution of 2 km x 1 hr spatiotemporal resolution. The dataset
contains data sampled at a 4-hourly temporal resolution for
the years 2007 to 2013. The sample test dataset contains
data sampled at a 4-hourly temporal resolution for 2014. We
transform 2D data arrays of wind speed and direction into
corresponding ua and va wind speed components. These
are chipped into 100x100 patches. Low resolution imagery
is obtained by sampling high resolution data at every fifth
data point as instructed by NREL’s guidelines.
Continental United States Solar Irradiance [331] is
a climate downscaling (super-resolution) dataset, was ob-
tained from the National Renewable Energy Laboratory’s
(NREL’s) National Solar Radiation Database (NSRDB), with
a focus on the continental United States. we consider solar
24
irradiance data from the NSRDB in terms of direct normal
irradiance (DNI) and diffused horizontal irradiance (DHI) at
an approximately 4-km x 1/2-hr spatiotemporal resolution.
The solar dataset produced for this work samples data at an
hourly temporal resolution from 6 am to 6 pm for the years
2007 to 2013. The test dataset contains datapoints sampled
from 2014. A 1D array of data points is provided along
with latitude and longitude metadata for each point. We re-
arrange this 1D array into a 2D image based on the lat/long
metadata. These 2D arrays of DNI and DHI are chipped
into 100 x 100 patches. Low resolution imagery is obtained
by sampling high resolution data at every fifth data point.
8.1.2 Weather and Climate Text Data
This subsection focuses on weather text datasets, which are
more thematically oriented towards climate change related
policy statements as well as document texts.
CLIMATE-FEVER. [339] is a dataset adopting the
FEVER methodology that consists of 1,535 real-world claims
regarding climate-change. Each claim is accompanied by
five manually annotated evidence sentences retrieved from
Wikipedia that support, refute or do not give enough in-
formation to validate the claim. The total dataset thus con-
tains 7,675 claim-evidence pairs. Furthermore, the dataset
features challenging claims that relate multiple facets and
disputed cases of claims where both supporting and refut-
ing evidence are present.
ClimateBERT-NetZero. [198] is an expert-annotated
dataset from the Net Zero Tracker Project that assesses
targets for reduction and net zero emissions or similar aims
(e.g., zero carbon, climate neutral, or net negative). The
dataset contains 273 claims by cities, 1396 claims by com-
panies, 205 claims by countries, and 159 claims by regions.
ClimaText. [205] is a dataset for climate change topic
detection, consists of labeled sentences. The label generated
heuristically or via a mannual process. indicates whether a
sentence talks about climate change or not. All sentences are
collected from Wikipedia, the U.S. Securities and Exchange
COMMISSION (SEC) 10K files. For Wikipedia, collect 6,885
documents, 715 relevant to climate change and 6,170 not
relevant to climate change.
CLIMA-INS [340] contains survey from annual NAIC
Climate Risk Disclosure Survey responses for the years
2012-2021, the purpose of the survey is to enhance trans-
parency about how insurers manage climate-related risks
and opportunities to enable better-informed collaboration
on climate-related issues, where each survey consists of
eight questions.
CLIMA-CDP [340] is composed of three subset part
where each part is a set of questionnaires filled out by a city,
company, or state respectively. The dataset can performs
topic classification and question classification. The number
of sample from train, development, and test for task of
topic classification is 46.8K, 8.7k, and 8.9K, respectively. In
addition, the number of sample from train, development,
and test for task for question answering task is 48.2K (8.7K
for states, 34.5K for corporations), 8.5K (0.9K for states,
34.5K for corporations), and 9.3K (1.1K for states, 4.9K for
corporations), respectively. The number of classes for topic
classification task is 12, for question answering is 294, 132,
and 43 respectively.
CLIMATESTANCE & CLIMATEENG [341] is a ternary
classification dataset about climate-related text, extracted
Twitter data consisting of 3777 tweets posted during the
2019 United Nations Framework Convention on Climate
Change. Each tweet was labelled for two tasks: stance de-
tection and categorical classification. For stance detection
the authors labelled each tweet as In Favour, Against or
Ambiguous towards climate change prevention. For categor-
ical classification, the five classes are Disaster, Ocean/Water,
Agriculture/Forestry, Politics, and General.
SCIDCC [342] is curated by scraping new articles from
the Science Daily website [342]. It contains around 11k
news articles with 20 labelled categories relevant to climate
change such as Earthquakes, Pollution, and Hurricanes. Each
article comprises of a title, a summary, and a body which on
average is much longer (500-600 words) than other climate
text datasets.
8.2 Tools and Models
In this subsection, we collect and compile a rich and usable
set of tools and foundation models for modeling weather
and climate data.
• OpenCastKit: A new global AI weather forecasting
project based on FourCastNet and GraphCast. https:
//github.com/HFAiLab/OpenCastKit
• GraphCast: A foundation model for medium-
range global weather forecasting. https://github.com/
google-deepmind/graphcast
• FourCastNet: A foundation model for weather and
climate data based on AFNO. https://github.com/
NVlabs/FourCastNet
• PanGu-Weather: A foundation model for medium-
range glocal weather forecasting. https://github.com/
198808xc/Pangu-Weather
• FuXi: A forecasting system for 15-day global weather
forecast. https://github.com/tpys/FuXi
• W-MAE: A unsupervised learning global weather
forecasting model via Masked Autoencoder. https://
github.com/Gufrannn/W-MAE
• ClimaX: A versatile climatefoundation model cover-
ing forecasting, projection, and downscaling. https://
github.com/microsoft/ClimaX
• OceanGPT: A large language model for ocean science
tasks trained with KnowLM. https://huggingface.co/
zjunlp/OceanGPT-7b
• ClimateBert: An algorithm that enables to analyze
climate-risk disclosures along the four main TCFD cat-
egories. https://huggingface.co/climatebert
• Climate X Quantus: An XAI toolbox for ML/DL-based
climate models. https://github.com/philine-bommer/
Climate X Quantus
9 C HALLENGES , OUTLOOK , AND OPPORTUNITIES
The potential pitfalls of AI foundation models in weather
and climate (WFMs) data understanding are manifested in
a large number of pending challenges to which data-driven
models are more susceptible than traditional NWP models.
In this section, we identify five main challenge areas and
suggest some best practices that should be recognised and
25
implemented in future research, as well as pointing out
research opportunities and routes that hold great promise
for the future.
9.1 Post-Processing of Data
For DL models, the quality of the data is paramount. How-
ever, numerous challenges associated with data pose threats
to the development of expansive foundation models for
weather and climate data understanding, including issues
related to data quality and quantity, post-processing costs,
scarcity of historical data, non-stationarity, and the under-
utilization of existing datasets.
• Data Quality and Quantity. Large-scale foundation
models require comprehensive and high-quality data
for robust results. Despite the exponential increase in
global climate data [73], like ERA5 and CMIP [88],
general-purpose datasets that are both large-scale and
high-quality are seldom available.
• Post-processing Costs. Large models, such as P ANGU -
WEATHER [63] and C LIMA X [25], often necessitate
costly post-processing for scenario-specific analyses.
The analysis of extreme events, for example, presents
a unique challenge. These rare events, which are in-
creasingly likely in a non-stationary climate, are often
characterized by outliers in climate variables. Their de-
velopment involves physical processes that span time
cycles from weeks to years, complicating the creation
of fine-grained annotations [302].
• Underutilization of Existing Datasets. Large-scale
datasets, despite their size, remain underdeveloped
due to the enormous post-processing costs. Benchmark
datasets like WeatherBench [88], WeatherBench2 [89],
OceanBench [346], and ClimateLearn [90], which con-
tain post-processed data, are still in early stages of
development due to limited data scenarios.
The creation of general WFMs hinges upon the avail-
ability of rich, large-scale, post-processed datasets. There is
substantial scope for deeper analyses and post-processing of
these datasets, including understanding anomalous weather
events, integrating physical models, and efficient, rational
annotations. Overcoming these challenges is key to realizing
the full potential of climate foundation models.
9.2 Development of Multi-Modal Models
Time series data are often enriched with supplementary
information, including textual descriptions. This is particu-
larly beneficial in economics and finance, where forecasting
can harness information from textual data sources such as
news articles or tweets, in conjunction with digital economic
time series data [110]. Analogously, weather and climate
analysis can profit from the diverse modalities encompassed
in climate data, which include reanalysis data, multimodal
observation data (e.g, radar echoes [84], [107], satellite im-
agery [300], and geographic terrain features [314], etc.). The
development of models capable of integrating and learning
from this rich array of data modalities has the potential to
enhance predictive accuracy. However, while efforts have
been made to develop weather prediction and meteorolog-
ical analysis models based on multimodal meteorological
data [86], [314], [337], these models often exhibit limitations.
They are typically confined to specific geographic regions
and struggle to accommodate the extensive spectrum of
meteorological modes. A salient challenge in constructing
multimodal climate foundation models lies in enabling
these models to learn joint representations that encapsulate
the sequential nature of temporal data and the unique traits
of other meteorological modes.
This challenge encompasses understanding and accom-
modating the disparate temporal and spatial resolutions
across modes. For instance, meteorological observations
may have an hourly temporal resolution, radar echo data
might possess a six-minute temporal resolution and 1-4 km
spatial resolution, and satellite images could exhibit half-
hourly temporal resolution and a 5-12 km spatial resolution.
The task of leveraging information with different temporal
and spatial resolutions to construct a robust and powerful
climate foundation model is complex. Furthermore, it is a
challenge to balance and align multimodal information col-
lected at different time points to achieve more precise fixed-
point prediction and analysis. As such, the development of
models that can effectively integrate and learn from these
diverse data sources remains a challenging but important
frontier in the field of weather and climate analysis.
9.3 Interpretability and Causability
A significant challenge associated with the use of AI models
for weather and climate analysis is the often inscrutable
nature of the model’s decision-making process. Many DL
algorithms are inherently complex and opaque, rendering
their decision-making processes unintelligible to users [65],
[66]. For applications such as machine translation and text
generation, the interpretability may not be a key concern.
In these contexts, it is typically sufficient for the model to
display competent performance to meet most requirements.
However, in weather and cliamte applications, the inter-
pretability of the model is of paramount importance.
Non-transparent, black-box models can precipitate catas-
trophic errors in predictions, which could have devastating
impacts on society and the environment. To mitigate this
interpretability challenge, tools rooted in the concept of Ex-
plainable AI (XAI) have been proposed, such as XAITools 4,
InterpretML5, SHAP 6, LIME 7, and AI Explainability 360 8,
etc. These tools aim to bring increased transparency and
trustworthiness to black-box models, including those used
in various fields such as Earth sciences [347] (Climate X
Quantus9), and offer new insights for refining models that
underperform. However, these interpretability tools are not
without their shortcomings and can exhibit significant bi-
ases. In some cases, the truthful representation of the model
may depend more on the specifics of the application and its
settings, which can render the results difficult to interpret.
This suggests that the interpretability insights of climate AI
are influenced more by the network’s architecture than by
the causal inference of weather and climate data.
4. https://github.com/IntelAI/intel-xai-tools
5. https://github.com/interpretml/interpret
6. https://github.com/shap/shap
7. https://github.com/marcotcr/lime
8. https://github.com/Trusted-AI/AIX360
9. https://github.com/philine-bommer/Climate X Quantus
26
Unless appropriately designed, Weather/Climate AI
may base predictions on non-physical relationships or false
correlations. This limitation in drawing causal conclusions
from climate models using XAI tools refers to the limited
causality these tools can provide. Physics-guided AI, also
known as knowledge-guided or physics-informed AI, is one
avenue researchers are exploring to impose physical realism
and mitigate the effects of false correlations on predictive
algorithms [244], [246], [248], [294]. However, research in
this area is still nascent. Thus, while strides have been made
in enhancing the interpretability of AI models, substantial
challenges remain, highlighting the need for continued re-
search and development in this critical area.
9.4 Generalizability of Models
The generalization capability of a model refers to its compe-
tence in making effective predictions beyond the spatiotem-
poral confines of its training dataset. Lots of DL techniques
operate on the assumption of independent and identically
distributed (IID) training and test data [66]. This implies
that the weights calculated during model training remain
efficacious even on unseen datasets. However, when applied
to weather and climate analysis, foundation models may
exhibit suboptimal performance when predicting Non-IID
data beyond the training dataset. A notable example of this
is the use of foundation models for the prediction of ex-
treme events outside their trained distribution. These biased
and anomalous data often induce significant performance
degradation in the model. This is especially the case as
the warming climate alters the Earth’s spatiotemporal dis-
tribution. The existing relationships that currently describe
the predictive variables and extreme climate events may no
longer apply in the future.
Moreover, climate foundation models are typically pre-
trained on general data before being fine-tuned on specific
task datasets [25]. If the fine-tuning data includes adversar-
ial or noisy examples, the process may introduce vulner-
abilities. If the temporal data employed for fine-tuning is
not meticulously managed, the model may adopt biases or
flaws from this data, leading to compromised robustness in
practical applications and unreliable outputs. This under-
scores the imperative for robust generalization. The advent
of physics-informed deep learning represents a promising
step towards enhancing the robust generalization of climate
models. However, the extension of these models beyond
their trained distribution remains an area that is not yet
fully explored. This highlights the need for continued re-
search into the generalization capabilities of climate models,
particularly in light of the rapidly changing climate and the
ever-evolving challenges it presents.
9.5 Privacy, Adversarial Attacks, and Communication
Weather and climate data are often of high sensitivity,
encapsulating a wealth of climate variables, geographical
information, and topographical details dispersed across var-
ious regions/ countries [24], [154]. In particular, radar and
satellite data are highly sensitive. The training of WFMs
using such data poses significant challenges from aspects of
centralized training, privacy leaks and adversarial attacks.
• Centralized Training Issues. Models typically undergo
pre-training with substantial data before being de-
ployed to various downstream tasks [25], [63], [136],
[137], [138]. However, the centralized training strategy
can be fraught with problems. Aggregating sensitive
data from different regions or countries onto a central
server is neither reliable nor practical due to the inher-
ent risks of data leakage and contamination [24].
• Privacy Leaks and Adversarial Attacks. During the
fine-tuning process, WFMs often memorize specific
details from the datasets, which can potentially com-
promise private data. Contaminated data also pose a
risk of deteriorating model performance. Therefore, the
adoption of privacy-preserving techniques to prevent
privacy leaks and mitigate adversarial attacks is crucial
in the training/fine-tuning of WFMs.
Recent studies have introduced the use of differential
privacy (DP) techniques or federated learning (FL) to train
WFMs [24], [154], effectively lessening the risk of sensitive
climate data leakage [348]. However, these methods are still
confronted with communication challenges.
• Communication Overheads in Federated Learning
Federated learning allows different clients to collabora-
tively train a global model, with each client maintaining
a locally replicated model with consistent structures.
During the global aggregation stage, each participant
uploads their local model parameters to a cloud server
for aggregation. This process results in a significant
increase in communication overhead between clients
and the server due to the large-scale nature of climate
models, posing a serious challenge to computational
and hardware costs.
9.6 Continuous Learning and On-device Adaption
The performance of WFMs, despite showing promising re-
sults, can be substantially improved through the application
of continuous learning and on-device adaption. Continual
learning [349], also referred to lifelong or incremental learning,
is the process of updating a model over time as new data
emerges. Given the ever-evolving nature of climate and
weather patterns due to natural variability and anthro-
pogenic climate change, this approach proves particularly
beneficial. It enables models to adapt to these changes, en-
hancing their predictive accuracy and robustness. On-device
adaptation [75] involves the customization of a model based
on local data at the point of deployment. It has the potential
to boost model performance by enabling adjustments to
local climate and weather patterns, which may not be com-
prehensively captured in global training data. Furthermore,
on-device adaptation can minimize the requirement for
data transmission, thereby enhancing model efficiency and
preserving privacy. However, the implementation of con-
tinuous learning and on-device adaptation in models poses
several challenges. These include ensuring model stability
during Continual learning and managing the computational
and storage constraints of on-device learning:
• Maintaining Model Stability. Models undergoing
learning can experience a phenomenon known as
”catastrophic forgetting,” where a model may forget
previously learned patterns after being updated with
27
new data. Balancing the maintenance of model stability
while still allowing it to learn from new data poses a
significant challenge.
• Managing Computational and Storage Constraints.
The computational power and storage capacity of a
device inherently limit on-device machine learning. De-
ploying and updating large climate models, on devices
with limited resources may prove difficult. Techniques
for model compression, efficient computation, and se-
lective model updating are essential to make on-device
adaptation of models feasible.
Despite these obstacles, Continual learning and on-device
adaptation present a promising avenue for enhancing the
performance of climate models.
9.7 Reproducibility
Reproducibility stands as a cornerstone principle in the
realm of scientific research. The capacity to reproduce re-
sults using identical data and methodologies not only re-
inforces the validity of the findings but also propels fur-
ther research and innovation. Nevertheless, the pursuit of
reproducibility in climate foundation models, poses several
formidable challenges:
• Data Availability and Consistency. climate foundation
models frequently utilise extensive datasets, gathered
from a plethora of sources over extended periods. The
challenge lies in ensuring the availability and consis-
tency of this data for model reproduction. Data may
undergo updates or corrections, and access permis-
sions can fluctuate, thereby adding complexity to re-
producibility endeavours.
• Model Complexity. climate foundation models of-
ten incorporate sophisticated machine learning archi-
tectures, intricate pre-processing steps, and advanced
training procedures. Reproducing these models neces-
sitates a comprehensive understanding of all these
facets. If any segment of the process is inadequately
documented or if specific implementation details are
proprietary, model reproduction can become an insur-
mountable task.
• Computational Resources. Climate foundation models
typically demand substantial computational resources
for training and inference. Reproduction of these mod-
els may be prohibitively costly or technically challeng-
ing for researchers lacking comparable resources. This
disparity can erect barriers to reproducibility and im-
pede the progress of the broader research community.
• Non-Determinism in Training. Several training pro-
cesses involve elements of randomness, such as ran-
dom initialization of weights, shuffling of training data,
and stochastic optimization methods. These factors can
yield slightly divergent models and results, even when
employing the same data and model architecture. En-
suring reproducibility amidst such non-determinism
can prove challenging.
• Model Versioning. As climate foundation models
evolve, new model versions are developed. It’s crucial
to maintain a record of model versions and align them
with the specific results they generated for reproducibil-
ity. However, this can become complex and arduous to
manage, particularly in large collaborative projects.
Addressing these challenges necessitates a united effort
from the entire research community. This includes the es-
tablishment of standards for data management and model
documentation, investment in open-source software and
infrastructure, and the cultivation of a research culture
underscored by transparency and openness. While these
issues are complex, resolving them is paramount to the
advancement of climate foundation models research and
ensuring its benefits are widely disseminated.
10 I NSIGHT FOR FOUNDATION MODEL DESIGNING
This section presents an intricate examination of the design
principles that serve as the foundation of current state-
of-the-art (SOTA) WFMs. Its intent is to offer an exhaus-
tive guide and insights for the development of resilient,
multipurpose climate foundation models. Five perspectives
are covered in this discourse: functional design, fusion of
multi-source data, data representation, design of network
architecture, and strategy for pre-training/fine-tuning.
10.1 One Fits All
Establishing foundation models necessitates a judicious se-
lection of tasks, which influences the data employed, the
training strategies deployed, the fine-tuning methodologies
adopted, and other associated factors. Foundation mod-
els are often viewed as a panacea, pre-trained models
that are subsequently fine-tuned for various application-
specific tasks. Premier climate foundation models, such as
FengWu [138] and Pangu-Weather [63], prioritize systematic
modeling of the Earth system, encompassing the prediction
of terrestrial and atmospheric climate variables at distinct
spatio-temporal scales. Conventionally, these models are
trained using data of spatial resolution derived from the
widely accepted ERA5 dataset. In contrast, ClimaX [25]
adopts an alternate approach, pre-training the foundation
model at a coarser resolution and later achieving finer
spatial resolution predictions, mappings, or down-sampling
via fine-tuning. Thus, the primary technical strategy for the
development of Weather and WFMs involves pre-training
the models with extensive high-resolution data and then
fine-tuning them with minimal effort to demonstrate excep-
tional performance across a range of downstream tasks.
10.2 Multi-source Data Fusion
Weather and climate data primarily fall into spatio-temporal
series. Our discussion primarily revolves around spatio-
temporal sequence tasks, as delineated in Sec. 8. Due to the
variety of data sources, including but not limited to ground
stations, remote sensing devices, and simulation-based cli-
mate products, the fusion of information from multiple data
sources can explicitly benefit the training process of the
foundation model and thus lead to improved performance.
However, significant modal differences and heterogeneity
among data complicate the realization of multi-source fu-
sion operations. We present here insights into this from two
main aspects: Spatio-Temporal Scales, Data Modality.
28
• Spatio-T emporal Scales. Practitioners can implement
weather and climate models on a global scale by consid-
ering data at multiple spatio-temporal scales simultane-
ously, most commonly under reanalysis data (see Sec. 8)
by fusing high- and low-resolution data to model both
fine- and coarse-global features.
• Data Modality. Weather and climate data’s modal
mainly focuses on time series 10 and text. Fusion of
multi-source data for foundation model training for
weather and climate can be encouraged to capture
interrelated knowledge from different scales and data
modalities. Examples precipitation nowcasting and the
fusion of multiple neutrals at different pressures for
robust global forecasting models. Practitioners can ex-
plore simultaneous or staged fusion of multimodal
weather data to benefit the foundation model.
10.3 Data Representation and Model Design
The robust development of WFMs is contingent on ef-
fective data interpretation and representation of weather
and climate statistics. This process typically involves two
stages: initial data representation construction through pre-
training, and application of this representational knowledge
to downstream tasks via fine-tuning. Unique representation
methods are required given that each data point encodes
complex contextual information, unlike the features of nat-
ural images. The subsequent discourse seeks to address
two pivotal questions in this domain: (1) Which network
architectures can effectively represent weather and climate data?
and (2) What strategies can improve models and facilitate efficient
and accurate representations?
10.3.1 Which network architectures can effectively repre-
sent weather and climate data?
Reanalysis weather and climate datasets bear significant
resemblances to natural images, most notably using grid
cells to delineate local semantic information. Consequently,
almost all network architectures employed in computer
vision can be utilised for processing weather and climate
grid data, including but not limited to ResNet, U-Net, Vision
Transformer, generative adversarial networks (GANs), and
diffusion models.
These models serve as the backbone of WFMs de-
signs such as ClimaX [25], PanGu-Weather [63], FourCast-
Net [136], DYffusion [151], GraphCast [137]. These mod-
els strive to establish more efficient relationships between
different regions, atmospheric pressure levels, and atmo-
spheric/surface meteorological variables, by leveraging di-
verse Earth system modeling techniques.
Therefore, when considering the architectural design of
foundational models, choices can be made from the founda-
tional architectures of CNNs, RNNs, Transformers, Graph
models, GANs, and Diffusion models. When necessary,
these models can be combined to enhance the representation
capabilities. Detailed descriptions of these models can be
found in Sec. 6.
10. The definition of time series in this survey covering
univerate/multivariate/spatio-temporal time series, and video
streams.
10.3.2 What strategies can enhance models and facilitate
efficient and accurate representations?
Accurate representation of the latent semantic information
in weather and climate data hinges on jointly modeling the
temporal, spatial, and variable dimensions of the data. Po-
tential strategies to enhance these models include tokeniza-
tion strategies, positional encoding, attention mechanisms,
and time feature extraction. Here we discuss these four
strategies in detail:
• Tokenization Strategy. The term ”token” originated in
the context of Transformers, where a critical operation
is dividing the original input image into small blocks
of local semantic information based on a patch size
- a process referred to as tokenization. For irregular
reanalysis gridded weather and climate data, the ab-
sence of specific rules or definitions for segmentation
implies that the choice of tokenization significantly
impacts model performance. For instance, ClimaX in-
troduces a coherent tokenization operation [25], while
PanGu-Weather [63], FuXi [139], and FengWu [138]
use different methods for encoding variables. A good
tokenization strategy should consider sptaio-temporal
correlations of different variables while accounting for
different physical scales, without introducing excessive
complexity.
• Positional Encoding. Positional encoding in a Trans-
former provides spatial information about data points
in a sequence. For weather and climate data, different
positional encoding strategies can be employed. Com-
pared to fixed encoding, learnable encodings offer more
flexibility, as their positional parameters can be updated
to increase model robustness.
• Attention Mechanisms. Attention mechanisms are crit-
ical in Transformers for modeling dependencies be-
tween different elements in a sequence. For weather
and climate data, attention mechanisms can help cap-
ture relationships between different time steps, geo-
graphical locations, and meteorological variables. The
computational complexity of attention mechanisms also
needs to be considered, as many models encounter high
cost and reduced speeds during training and inference.
• Time Feature Extraction. Weather and climate data
contain a temporal dimension, and extracting time fea-
tures is crucial for model accuracy. Various methods
can be employed to extract time features, which can
then be used as part of the model input to aid in better
understanding and modeling temporal correlations.
10.4 Learning Strategies
Pre-training a WFM on large-scale datasets not only hinges
on costly data post-processing, but also a substantial in-
vestment in computational resources. A prime example of
this is PanGu-Weather, whose pre-training necessitates over
60TB of high-resolution data and more than 3000 GPU-days
on V100-80G [63], underscoring the immense scale of the
model. In this section, we primarily delve into a variety of
learning strategies. These strategies are designed to alleviate
the computational burden, thereby facilitating the training
and fine-tuning of foundational models for weather and
climate tasks.
29
• Self-Supervised Learning. Self-supervised Learning
(SSL) is an unsupervised paradigm wherein models are
assigned the task of predicting certain components of
their own input data. This approach generates labels
intrinsically from the data, obviating the need for exter-
nal annotations. As a result, SSL can exploit copious
amounts of unlabeled data for training. Within the
sphere of weather and climate modeling, SSL could
be utilized to identify climate patterns and trends.
For instance, future meteorological conditions could be
forecasted using historical weather variables such as
temperature, humidity, and wind velocity. This could
be accomplished by projecting the subsequent data
point within a pre-established temporal window. In so
doing, the model can apprehend inherent weather data
trends and patterns. The principal advantage of SSL lies
in its capacity to harness vast quantities of unlabeled
data for training. Furthermore, it can reveal inherent
data patterns and structures, which is especially advan-
tageous for weather and climate tasks [64].
• Semi-Supervised Learning. Semi-supervised Learning
(SML) represents an intermediate approach between
Fully Supervised Learning (FLSL) and Self-Supervised
Learning (SSL), leveraging both labeled and unlabeled
data for model training. This method is particularly
advantageous for weather and climate prediction tasks
due to the potential scarcity of labeled weather data and
abundance of unlabeled data. One prevalent method-
ology in SML is self-training. Initially, a supervised
model is trained using the available labeled data. Sub-
sequently, this model is applied to predict labels for the
unlabeled data, which are then employed as pseudo-
labels for retraining the model. This iterative process
continues until the model’s performance plateaus. The
salient advantage of SML is its capacity to concurrently
utilize labeled and unlabeled data for training. This
facilitates an enhancement in model performance, es-
pecially when labeled data is limited, by capitalizing
on the extensive quantity of unlabeled data.
• Federated Learning. Federated learning [204] (FL) is
a distributed ML paradigm with the central goal of
enabling multiple participants to collaboratively train
a model, all while safeguarding data privacy and se-
curity [350]. In FL, every participant trains their model
locally and shares only model updates, rather than the
raw data. This endows FL with a distinct advantage
when dealing with sensitive data, while also permitting
cross-learning from diverse data sources that might be
geographically dispersed or unable to be centralized
due to privacy or other reasons. In the context of train-
ing WFMs, the application of federated learning carries
significant benefits. Firstly, meteorological bureaus and
research institutions across the globe possess extensive
climate data, but owing to data ownership, privacy, and
security concerns, this data cannot easily be central-
ized for processing. Federated learning enables these
institutions to collaboratively train a robust weather
forecasting model without the direct sharing of data.
Secondly, given the typically large scale of weather and
climate data, data transfer could potentially become a
bottleneck. With FL, data can be processed and trained
locally, requiring only the transfer of model updates,
thus significantly reducing data transmission demands.
Lastly, FL allows the model to benefit from climate
data from different geographical locations and types,
enhancing the model’s generalization ability and accu-
racy. Currently, numerous studies have incorporated FL
into the process of training WFM [24], [154].
11 C ONCLUSION
In conclusion, we present a comprehensive and up-to-date
survey of data-driven models tailored to analyze weather
and climate data. The intention is to offer a fresh view-
point on this evolving discipline through a systematically
organized appraisal of pertinent models. We distill the most
salient methodologies within each category, investigate their
respective advantages and drawbacks, and propose viable
trajectories for forthcoming exploration. This survey is in-
tended to act as an impetus to kindle sustained interest
and nurture a persistent enthusiasm for research within the
realm of data-driven models for weather and climate data
understanding.
REFERENCES
[1] P . S. Fabian, H.-H. Kwon, M. Vithanage, and J.-H. Lee, “Mod-
eling, challenges, and strategies for understanding impacts of
climate extremes (droughts and floods) on water quality in asia:
A review,” Environmental Research, p. 115617, 2023.
[2] Y. Deng, X. Wang, T. Lu, H. Du, P . Ciais, and X. Lin, “Divergent
seasonal responses of carbon fluxes to extreme droughts over
china,” Agricultural and Forest Meteorology , vol. 328, p. 109253,
2023.
[3] Z. Zhou, Y. Chen, M. C. Yam, K. Ke, and X. He, “Experimental
investigation of a high strength steel frame with curved knee
braces subjected to extreme earthquakes,” Thin-Walled Structures,
vol. 185, p. 110596, 2023.
[4] D. Barriopedro, R. Garc ´ıa-Herrera, C. Ord´o˜nez, D. Miralles, and
S. Salcedo-Sanz, “Heat waves: Physical understanding and scien-
tific challenges,” Reviews of Geophysics, p. e2022RG000780, 2023.
[5] J. Zeng, G. Han, S. Zhang, X. Xiao, Y. Li, X. Gao, D. Wang,
and R. Qu, “Response of dissolved organic carbon in rainwater
during extreme rainfall period in megacity: Status, potential
source, and deposition flux,” Sustainable Cities and Society, vol. 88,
p. 104299, 2023.
[6] M. P . Couldrey, J. M. Gregory, X. Dong, O. Garuba, H. Haak,
A. Hu, W. J. Hurlin, J. Jin, J. Jungclaus, A. K ¨ohl et al. ,
“Greenhouse-gas forced changes in the atlantic meridional over-
turning circulation and related worldwide sea-level change,”
Climate Dynamics, vol. 60, no. 7-8, pp. 2003–2039, 2023.
[7] A. Raihan, “A review of the global climate change impacts, adap-
tation strategies, and mitigation options in the socio-economic
and environmental sectors,” Journal of Environmental Science and
Economics, vol. 2, no. 3, pp. 36–58, 2023.
[8] S. Materia, L. P . Garc ´ıa, C. van Straaten, A. Mamalakis, L. Cavic-
chia, D. Coumou, P . De Luca, M. Kretschmer, M. G. Donat et al.,
“Artificial intelligence for prediction of climate extremes: State
of the art, challenges and future perspectives,” arXiv preprint
arXiv:2310.01944, 2023.
[9] J. R. Beddington, M. Asaduzzaman, A. Fernandez, M. E. Clark,
M. Guillou, M. M. Jahn, L. Erda, T. Mamo, B. N. Van, C. A. Nobre
et al. , “Achieving food security in the face of climate change:
Summary for policy makers from the commission on sustainable
agriculture and climate change,” 2011.
[10] R. Connor, The United Nations world water development report 2015:
water for a sustainable world. UNESCO publishing, 2015, vol. 1.
[11] J. F. Kok, T. Storelvmo, V . A. Karydis, A. A. Adebiyi, N. M.
Mahowald, A. T. Evan, C. He, and D. M. Leung, “Mineral dust
aerosol impacts on global climate and climate change,” Nature
Reviews Earth & Environment, vol. 4, no. 2, pp. 71–86, 2023.
30
[12] P . Loh, Y. Twumasi, Z. Ning, M. Anokye, J. Oppong, R. Armah,
C. Apraku, and J. Namwamba, “Analyzing the impact of sea
level rise on coastal flooding and shoreline changes along the
coast of louisiana using remote sensory imagery,” The Interna-
tional Archives of the Photogrammetry, Remote Sensing and Spatial
Information Sciences, vol. 48, pp. 139–145, 2023.
[13] L. Yu, W. Sun, H. Zhang, N. Cong, Y. Chen, J. Hu, and X. Jing,
“Grazing exclusion jeopardizes plant biodiversity effect but en-
hances dryness effect on multifunctionality in arid grasslands,”
Available at SSRN 4575743.
[14] I. M. Voskamp and F. H. Van de Ven, “Planning support sys-
tem for climate adaptation: Composing effective sets of blue-
green measures to reduce urban vulnerability to extreme weather
events,” Building and Environment, vol. 83, pp. 159–167, 2015.
[15] H. R. Maier and G. C. Dandy, “Neural networks for the pre-
diction and forecasting of water resources variables: a review
of modelling issues and applications,” Environmental modelling &
software, vol. 15, no. 1, pp. 101–124, 2000.
[16] S. A. Markolf, C. Hoehne, A. Fraser, M. V . Chester, and B. S.
Underwood, “Transportation resilience to climate change and
extreme weather events–beyond risk and robustness,” Transport
policy, vol. 74, pp. 174–186, 2019.
[17] M. J. Koetse and P . Rietveld, “The impact of climate change
and weather on transport: An overview of empirical findings,”
Transportation Research Part D: Transport and Environment, vol. 14,
no. 3, pp. 205–221, 2009.
[18] K. Ravindra, P . Rattan, S. Mor, and A. N. Aggarwal, “General-
ized additive models: Building evidence of air pollution, climate
change and human health,” Environment international, vol. 132, p.
104987, 2019.
[19] P . Bauer, A. Thorpe, and G. Brunet, “The quiet revolution of
numerical weather prediction,” Nature, vol. 525, no. 7567, pp. 47–
55, 2015.
[20] J. Coiffier, Fundamentals of numerical weather prediction . Cam-
bridge University Press, 2011.
[21] R. Kimura, “Numerical weather prediction,” Journal of Wind
Engineering and Industrial Aerodynamics , vol. 90, no. 12-15, pp.
1403–1414, 2002.
[22] T. N. Krishnamurti and L. Bounoua, An introduction to numerical
weather prediction techniques. CRC press, 2018.
[23] D. Maraun, F. Wetterhall, A. Ireson, R. Chandler, E. Kendon,
M. Widmann, S. Brienen, H. Rust, T. Sauter, M. Themeßl et al. ,
“Precipitation downscaling under climate change: Recent devel-
opments to bridge the gap between dynamical models and the
end user,” Reviews of geophysics, vol. 48, no. 3, 2010.
[24] S. Chen, G. Long, T. Shen, and J. Jiang, “Prompt federated
learning for weather forecasting: Toward foundation models on
meteorological data,” arXiv preprint arXiv:2301.09152, 2023.
[25] T. Nguyen, J. Brandstetter, A. Kapoor, J. K. Gupta, and A. Grover,
“Climax: A foundation model for weather and climate,” arXiv
preprint arXiv:2301.10343, 2023.
[26] M. G. Schultz, C. Betancourt, B. Gong, F. Kleinert, M. Langguth,
L. H. Leufen, A. Mozaffari, and S. Stadtler, “Can deep learning
beat numerical weather prediction?” Philosophical Transactions of
the Royal Society A, vol. 379, no. 2194, p. 20200097, 2021.
[27] J. Wei, J. Jiang, H. Liu, F. Zhang, P . Lin, P . Wang, Y. Yu, X. Chi,
L. Zhao, M. Ding et al., “Licom3-cuda: A gpu version of lasg/iap
climate system ocean model version 3 based on cuda,”The Journal
of Supercomputing, pp. 1–31, 2023.
[28] A. F. Prein, N. Ban, T. Ou, J. Tang, K. Sakaguchi, E. Collier,
S. Jayanarayanan, L. Li, S. Sobolowski, X. Chen et al. , “To-
wards ensemble-based kilometer-scale climate simulations over
the third pole region,” Climate Dynamics , vol. 60, no. 11-12, pp.
4055–4081, 2023.
[29] V . L. T. de Souza, B. A. D. Marques, H. C. Batagelo, and J. P .
Gois, “A review on generative adversarial networks for image
generation,” Computers & Graphics, 2023.
[30] J. Willard, X. Jia, S. Xu, M. Steinbach, and V . Kumar, “Integrating
physics-based modeling with machine learning: A survey,” arXiv
preprint arXiv:2003.04919, vol. 1, no. 1, pp. 1–34, 2020.
[31] X. Ren, X. Li, K. Ren, J. Song, Z. Xu, K. Deng, and X. Wang, “Deep
learning-based weather prediction: a survey,” Big Data Research ,
vol. 23, p. 100178, 2021.
[32] L. Yuan, D. Chen, Y.-L. Chen, N. Codella, X. Dai, J. Gao, H. Hu,
X. Huang, B. Li, C. Li et al., “Florence: A new foundation model
for computer vision,” arXiv preprint arXiv:2111.11432, 2021.
[33] I. Singh, V . Blukis, A. Mousavian, A. Goyal, D. Xu, J. Tremblay,
D. Fox, J. Thomason, and A. Garg, “Progprompt: Generating
situated robot task plans using large language models,” in 2023
IEEE International Conference on Robotics and Automation (ICRA) .
IEEE, 2023, pp. 11 523–11 530.
[34] S. Gilbert, H. Harvey, T. Melvin, E. Vollebregt, and P . Wicks,
“Large language model ai chatbots require approval as medical
devices,” Nature Medicine, pp. 1–3, 2023.
[35] A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutier-
rez, T. F. Tan, and D. S. W. Ting, “Large language models in
medicine,” Nature medicine, vol. 29, no. 8, pp. 1930–1940, 2023.
[36] S. Chen, S. Ren, G. Wang, M. Huang, and C. Xue, “Interpretable
cnn-multilevel attention transformer for rapid recognition of
pneumonia from chest x-ray images,” IEEE Journal of Biomedical
and Health Informatics, 2023.
[37] K. Zhang and D. Liu, “Customized segment anything model
for medical image segmentation,”arXiv preprint arXiv:2304.13785,
2023.
[38] J. Ma and B. Wang, “Segment anything in medical images,” arXiv
preprint arXiv:2304.12306, 2023.
[39] H. Abburi, M. Suesserman, N. Pudota, B. Veeramani, E. Bowen,
and S. Bhattacharya, “Generative ai text classification using en-
semble llm approaches,” arXiv preprint arXiv:2309.07755, 2023.
[40] Y. Shi, H. Ma, W. Zhong, G. Mai, X. Li, T. Liu, and J. Huang,
“Chatgraph: Interpretable text classification by converting chat-
gpt knowledge to graphs,” arXiv preprint arXiv:2305.03513, 2023.
[41] X. Sun, X. Li, J. Li, F. Wu, S. Guo, T. Zhang, and G. Wang,
“Text classification via large language models,” arXiv preprint
arXiv:2305.08377, 2023.
[42] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P . Perona, D. Ramanan,
P . Doll´ar, and C. L. Zitnick, “Microsoft coco: Common objects in
context,” in Computer Vision–ECCV 2014: 13th European Confer-
ence, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V
13. Springer, 2014, pp. 740–755.
[43] A. Veit, T. Matera, L. Neumann, J. Matas, and S. Belongie, “Coco-
text: Dataset and benchmark for text detection and recognition in
natural images,” arXiv preprint arXiv:1601.07140, 2016.
[44] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei,
“Imagenet: A large-scale hierarchical image database,” in 2009
IEEE conference on computer vision and pattern recognition . Ieee,
2009, pp. 248–255.
[45] A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson,
T. Xiao, S. Whitehead, A. C. Berg, W.-Y. Lo et al. , “Segment
anything,” arXiv preprint arXiv:2304.02643, 2023.
[46] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agar-
wal, G. Sastry, A. Askell, P . Mishkin, J. Clark et al. , “Learning
transferable visual models from natural language supervision,”
in International conference on machine learning . PMLR, 2021, pp.
8748–8763.
[47] L. Floridi and M. Chiriatti, “Gpt-3: Its nature, scope, limits, and
consequences,” Minds and Machines, vol. 30, pp. 681–694, 2020.
[48] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P . Dhari-
wal, A. Neelakantan, P . Shyam, G. Sastry, A. Askell et al. ,
“Language models are few-shot learners,” Advances in neural
information processing systems, vol. 33, pp. 1877–1901, 2020.
[49] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever
et al. , “Language models are unsupervised multitask learners,”
OpenAI blog, vol. 1, no. 8, p. 9, 2019.
[50] S. Bubeck, V . Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz,
E. Kamar, P . Lee, Y. T. Lee, Y. Li, S. Lundberg et al. , “Sparks
of artificial general intelligence: Early experiments with gpt-4,”
arXiv preprint arXiv:2303.12712, 2023.
[51] D. Zhu, J. Chen, X. Shen, X. Li, and M. Elhoseiny, “Minigpt-4:
Enhancing vision-language understanding with advanced large
language models,” arXiv preprint arXiv:2304.10592, 2023.
[52] Y. Gao, J. Liu, Z. Xu, J. Zhang, K. Li, R. Ji, and C. Shen, “Pyramid-
clip: Hierarchical feature alignment for vision-language model
pretraining,” Advances in neural information processing systems ,
vol. 35, pp. 35 959–35 970, 2022.
[53] P . Zhang, X. Li, X. Hu, J. Yang, L. Zhang, L. Wang, Y. Choi,
and J. Gao, “Vinvl: Revisiting visual representations in vision-
language models,” in Proceedings of the IEEE/CVF conference on
computer vision and pattern recognition, 2021, pp. 5579–5588.
[54] Z. Wang, Y. Lu, Q. Li, X. Tao, Y. Guo, M. Gong, and T. Liu, “Cris:
Clip-driven referring image segmentation,” in Proceedings of the
IEEE/CVF conference on computer vision and pattern recognition ,
2022, pp. 11 686–11 695.
31
[55] K. Park, S. Woo, S. W. Oh, I. S. Kweon, and J.-Y. Lee, “Per-
clip video object segmentation,” in Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition , 2022, pp.
1352–1361.
[56] F. Liang, B. Wu, X. Dai, K. Li, Y. Zhao, H. Zhang, P . Zhang, P . Va-
jda, and D. Marculescu, “Open-vocabulary semantic segmenta-
tion with mask-adapted clip,” in Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition , 2023, pp.
7061–7070.
[57] M. Tang, Z. Wang, Z. Liu, F. Rao, D. Li, and X. Li, “Clip4caption:
Clip for video caption,” in Proceedings of the 29th ACM Interna-
tional Conference on Multimedia, 2021, pp. 4858–4862.
[58] Z. Zhang, Y. Chen, Z. Ma, Z. Qi, C. Yuan, B. Li, Y. Shan, and
W. Hu, “Create: A benchmark for chinese short video retrieval
and title generation,” arXiv preprint arXiv:2203.16763, 2022.
[59] S. Ling, Y. Hu, S. Qian, G. Ye, Y. Qian, Y. Gong, E. Lin, and
M. Zeng, “Adapting large language model with speech for
fully formatted end-to-end speech recognition,” arXiv preprint
arXiv:2307.08234, 2023.
[60] Y. Zhang, W. Han, J. Qin, Y. Wang, A. Bapna, Z. Chen, N. Chen,
B. Li, V . Axelrod, G. Wang et al. , “Google usm: Scaling auto-
matic speech recognition beyond 100 languages,” arXiv preprint
arXiv:2303.01037, 2023.
[61] J. Holmes, Z. Liu, L. Zhang, Y. Ding, T. T. Sio, L. A. McGee,
J. B. Ashman, X. Li, T. Liu, J. Shen et al., “Evaluating large lan-
guage models on a highly-specialized topic, radiation oncology
physics,” arXiv preprint arXiv:2304.01938, 2023.
[62] N. Matzakos, S. Doukakis, and M. Moundridou, “Learning math-
ematics with large language models: A comparative study with
computer algebra systems and other tools.” International Journal
of Emerging Technologies in Learning, vol. 18, no. 20, 2023.
[63] K. Bi, L. Xie, H. Zhang, X. Chen, X. Gu, and Q. Tian, “Accurate
medium-range global weather forecasting with 3d neural net-
works,” Nature, vol. 619, no. 7970, pp. 533–538, 2023.
[64] X. Man, C. Zhang, C. Li, and J. Shao, “W-mae: Pre-trained
weather model with masked autoencoder for multi-variable
weather forecasting,” arXiv preprint arXiv:2304.08754, 2023.
[65] Y. Liu, K. Duffy, J. G. Dy, and A. R. Ganguly, “Explainable
deep learning for insights in el ni ˜no and river flows,” Nature
Communications, vol. 14, no. 1, p. 339, 2023.
[66] H. Wang, S. Hu, and X. Li, “An interpretable deep learning enso
forecasting model,” Ocean-Land-Atmosphere Research , vol. 2, p.
0012, 2023.
[67] W. Fang, Q. Xue, L. Shen, and V . S. Sheng, “Survey on the
application of deep learning in extreme weather prediction,”
Atmosphere, vol. 12, no. 6, p. 661, 2021.
[68] B. Bochenek and Z. Ustrnul, “Machine learning in weather
prediction and climate analyses—applications and perspectives,”
Atmosphere, vol. 13, no. 2, p. 180, 2022.
[69] K. Jaseena and B. C. Kovoor, “Deterministic weather forecasting
models based on intelligent predictors: A survey,” Journal of King
Saud University-Computer and Information Sciences , vol. 34, no. 6,
pp. 3393–3412, 2022.
[70] L. Chen, B. Han, X. Wang, J. Zhao, W. Yang, and Z. Yang,
“Machine learning methods in weather and climate applications:
A survey,” Applied Sciences, vol. 13, no. 21, p. 12019, 2023.
[71] A. Jones, J. Kuehnert, P . Fraccaro, O. Meuriot, T. Ishikawa, B. Ed-
wards, N. Stoyanov, S. L. Remy, K. Weldemariam, and S. Assefa,
“Ai for climate impacts: applications in flood risk,” npj Climate
and Atmospheric Science, vol. 6, no. 1, p. 63, 2023.
[72] M. J. Molina, T. A. O’Brien, G. Anderson, M. Ashfaq, K. E.
Bennett, W. D. Collins, K. Dagon, J. M. Restrepo, and P . A.
Ullrich, “A review of recent and emerging machine learning
applications for climate variability and weather phenomena,”
Artificial Intelligence for the Earth Systems, pp. 1–46, 2023.
[73] S. K. Mukkavilli, D. S. Civitarese, J. Schmude, J. Jakubik, A. Jones,
N. Nguyen, C. Phillips, S. Roy, S. Singh, C. Watsonet al., “Ai foun-
dation models for weather and climate: Applications, design, and
implementation,” arXiv preprint arXiv:2309.10808, 2023.
[74] V . Jacques-Dumas, F. Ragone, P . Borgnat, P . Abry, and F. Bouchet,
“Deep learning-based extreme heatwave forecast,” Frontiers in
Climate, vol. 4, 2022.
[75] S. Lee and S. Nirjon, “Learning in the wild: When, how, and
what to learn for on-device dataset adaptation,” in Proceedings of
the 2nd International Workshop on Challenges in Artificial Intelligence
and Machine Learning for Internet of Things , 2020, pp. 34–40.
[76] K. Zhou, J. Yang, C. C. Loy, and Z. Liu, “Conditional prompt
learning for vision-language models,” in Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition ,
2022, pp. 16 816–16 825.
[77] M. Maaz, H. Rasheed, S. Khan, and F. S. Khan, “Video-chatgpt:
Towards detailed video understanding via large vision and lan-
guage models,” arXiv preprint arXiv:2306.05424, 2023.
[78] W. Dai, J. Li, D. Li, A. M. H. Tiong, J. Zhao, W. Wang, B. Li,
P . Fung, and S. Hoi, “Instructblip: Towards general-purpose
vision-language models with instruction tuning,” 2023.
[79] J. Yu, Z. Wang, V . Vasudevan, L. Yeung, M. Seyedhosseini, and
Y. Wu, “Coca: Contrastive captioners are image-text foundation
models,” arXiv preprint arXiv:2205.01917, 2022.
[80] W. Wang, H. Bao, L. Dong, J. Bjorck, Z. Peng, Q. Liu, K. Aggarwal,
O. K. Mohammed, S. Singhal, S. Som, and F. Wei, “Image as
a foreign language: Beit pretraining for all vision and vision-
language tasks,” 2022.
[81] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright,
P . Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, J. Schulman,
J. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P . Welinder,
P . Christiano, J. Leike, and R. Lowe, “Training language models
to follow instructions with human feedback,” 2022.
[82] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,
T. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro, F. Azhar et al. ,
“Llama: Open and efficient foundation language models,” arXiv
preprint arXiv:2302.13971, 2023.
[83] H. Touvron, L. Martin, K. Stone, P . Albert, A. Almahairi,
Y. Babaei, N. Bashlykov, S. Batra, P . Bhargava, S. Bhosale, D. Bikel,
L. Blecher, C. C. Ferrer, M. Chen, G. Cucurull, D. Esiobu, J. Fer-
nandes, J. Fu, W. Fu, B. Fuller, C. Gao, V . Goswami, N. Goyal,
A. Hartshorn, S. Hosseini, R. Hou, H. Inan, M. Kardas, V . Kerkez,
M. Khabsa, I. Kloumann, A. Korenev, P . S. Koura, M.-A. Lachaux,
T. Lavril, J. Lee, D. Liskovich, Y. Lu, Y. Mao, X. Martinet, T. Mi-
haylov, P . Mishra, I. Molybog, Y. Nie, A. Poulton, J. Reizenstein,
R. Rungta, K. Saladi, A. Schelten, R. Silva, E. M. Smith, R. Sub-
ramanian, X. E. Tan, B. Tang, R. Taylor, A. Williams, J. X. Kuan,
P . Xu, Z. Yan, I. Zarov, Y. Zhang, A. Fan, M. Kambadur, S. Narang,
A. Rodriguez, R. Stojnic, S. Edunov, and T. Scialom, “Llama 2:
Open foundation and fine-tuned chat models,” 2023.
[84] S. Chen, T. Shu, H. Zhao, Q. Wan, J. Huang, and C. Li, “Dynamic
multiscale fusion generative adversarial network for radar image
extrapolation,” IEEE Transactions on Geoscience and Remote Sens-
ing, vol. 60, pp. 1–11, 2022.
[85] H. Wu, Z. Yao, J. Wang, and M. Long, “Motionrnn: A flexible
model for video prediction with spacetime-varying motions,”
in Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition, 2021, pp. 15 435–15 444.
[86] M. Veillette, S. Samsi, and C. Mattioli, “Sevir: A storm event
imagery dataset for deep learning applications in radar and
satellite meteorology,” Advances in Neural Information Processing
Systems, vol. 33, pp. 22 009–22 019, 2020.
[87] X. Zhu, Y. Xiong, M. Wu, G. Nie, B. Zhang, and Z. Yang,
“Weather2k: A multivariate spatio-temporal benchmark dataset
for meteorological forecasting based on real-time observa-
tion data from ground weather stations,” arXiv preprint
arXiv:2302.10493, 2023.
[88] S. Rasp, P . D. Dueben, S. Scher, J. A. Weyn, S. Mouatadid, and
N. Thuerey, “Weatherbench: a benchmark data set for data-
driven weather forecasting,” Journal of Advances in Modeling Earth
Systems, vol. 12, no. 11, p. e2020MS002203, 2020.
[89] S. Rasp, S. Hoyer, A. Merose, I. Langmore, P . Battaglia, T. Russel,
A. Sanchez-Gonzalez, V . Yang, R. Carver, S. Agrawal et al. ,
“Weatherbench 2: A benchmark for the next generation of data-
driven global weather models,” arXiv preprint arXiv:2308.15560 ,
2023.
[90] T. Nguyen, J. Jewik, H. Bansal, P . Sharma, and A. Grover,
“Climatelearn: Benchmarking machine learning for weather and
climate modeling,” arXiv preprint arXiv:2307.01909, 2023.
[91] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia,
E. Chi, Q. Le, and D. Zhou, “Chain-of-thought prompting elicits
reasoning in large language models,” 2023.
[92] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, and
K. Narasimhan, “Tree of thoughts: Deliberate problem solving
with large language models,” 2023.
[93] M. Besta, N. Blach, A. Kubicek, R. Gerstenberger, L. Gianinazzi,
J. Gajda, T. Lehmann, M. Podstawski, H. Niewiadomski, P . Ny-
32
czyk, and T. Hoefler, “Graph of thoughts: Solving elaborate
problems with large language models,” 2023.
[94] G. P . Zhang, “Time series forecasting using a hybrid arima and
neural network model,” Neurocomputing, vol. 50, pp. 159–175,
2003.
[95] P . Chen, A. Niu, D. Liu, W. Jiang, and B. Ma, “Time series fore-
casting of temperatures using sarima: An example from nanjing,”
in IOP Conference Series: Materials Science and Engineering, vol. 394.
IOP Publishing, 2018, p. 052024.
[96] Y. Chen and S. Tjandra, “Daily collision prediction with sarimax
and generalized linear models on the basis of temporal and
weather variables,” Transportation Research Record, vol. 2432, no. 1,
pp. 26–36, 2014.
[97] X. Shi, Z. Chen, H. Wang, D.-Y. Yeung, W.-K. Wong, and W.-
c. Woo, “Convolutional lstm network: A machine learning ap-
proach for precipitation nowcasting,” Advances in neural informa-
tion processing systems, vol. 28, 2015.
[98] M. H ¨usken and P . Stagge, “Recurrent neural networks for time
series classification,” Neurocomputing, vol. 50, pp. 223–235, 2003.
[99] S. Hochreiter and J. Schmidhuber, “Long short-term memory,”
Neural computation, vol. 9, no. 8, pp. 1735–1780, 1997.
[100] H. Zhou, S. Zhang, J. Peng, S. Zhang, J. Li, H. Xiong, and
W. Zhang, “Informer: Beyond efficient transformer for long se-
quence time-series forecasting,” in Proceedings of the AAAI confer-
ence on artificial intelligence, vol. 35, no. 12, 2021, pp. 11 106–11 115.
[101] M. Chen, H. Peng, J. Fu, and H. Ling, “Autoformer: Search-
ing transformers for visual recognition,” in Proceedings of the
IEEE/CVF international conference on computer vision , 2021, pp.
12 270–12 280.
[102] Y. Zhang and J. Yan, “Crossformer: Transformer utilizing cross-
dimension dependency for multivariate time series forecasting,”
in The Eleventh International Conference on Learning Representations,
2022.
[103] G. Woo, C. Liu, D. Sahoo, A. Kumar, and S. Hoi, “Etsformer:
Exponential smoothing transformers for time-series forecasting,”
arXiv preprint arXiv:2202.01381, 2022.
[104] N. Kitaev, Ł. Kaiser, and A. Levskaya, “Reformer: The efficient
transformer,” arXiv preprint arXiv:2001.04451, 2020.
[105] T. Zhou, Z. Ma, Q. Wen, X. Wang, L. Sun, and R. Jin, “Fedformer:
Frequency enhanced decomposed transformer for long-term se-
ries forecasting,” in International Conference on Machine Learning .
PMLR, 2022, pp. 27 268–27 286.
[106] B. Yu, H. Yin, and Z. Zhu, “Spatio-temporal graph convolutional
networks: A deep learning framework for traffic forecasting,”
arXiv preprint arXiv:1709.04875, 2017.
[107] S. Chen, T. Shu, H. Zhao, G. Zhong, and X. Chen,
“Tempee: Temporal–spatial parallel transformer for radar echo
extrapolation beyond autoregression,” IEEE Transactions on
Geoscience and Remote Sensing , vol. 61, pp. 1–14, 2023. [Online].
Available: https://doi.org/10.1109%2Ftgrs.2023.3311510
[108] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-
Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adver-
sarial networks,” Communications of the ACM , vol. 63, no. 11, pp.
139–144, 2020.
[109] P . Dhariwal and A. Nichol, “Diffusion models beat gans on im-
age synthesis,” Advances in neural information processing systems ,
vol. 34, pp. 8780–8794, 2021.
[110] M. Jin, Q. Wen, Y. Liang, C. Zhang, S. Xue, X. Wang, J. Zhang,
Y. Wang, H. Chen, X. Li et al. , “Large models for time series
and spatio-temporal data: A survey and outlook,” arXiv preprint
arXiv:2310.10196, 2023.
[111] L. R. Medsker and L. Jain, “Recurrent neural networks,” Design
and Applications, vol. 5, no. 64-67, p. 2, 2001.
[112] W. De Mulder, S. Bethard, and M.-F. Moens, “A survey on the
application of recurrent neural networks to statistical language
modeling,” Computer Speech & Language, vol. 30, no. 1, pp. 61–98,
2015.
[113] T. Mikolov, S. Kombrink, L. Burget, J. ˇCernock`y, and S. Khudan-
pur, “Extensions of recurrent neural network language model,”
in 2011 IEEE international conference on acoustics, speech and signal
processing (ICASSP). IEEE, 2011, pp. 5528–5531.
[114] T. Mikolov and G. Zweig, “Context dependent recurrent neural
network language model,” in 2012 IEEE Spoken Language Technol-
ogy Workshop (SLT). IEEE, 2012, pp. 234–239.
[115] H. Hewamalage, C. Bergmeir, and K. Bandara, “Recurrent neural
networks for time series forecasting: Current status and future
directions,” International Journal of Forecasting , vol. 37, no. 1, pp.
388–427, 2021.
[116] A. Lazcano, P . J. Herrera, and M. Monge, “A combined model
based on recurrent neural networks and graph convolutional net-
works for financial time series forecasting,” Mathematics, vol. 11,
no. 1, p. 224, 2023.
[117] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, “Empirical evalua-
tion of gated recurrent neural networks on sequence modeling,”
arXiv preprint arXiv:1412.3555, 2014.
[118] J. Ho, A. Jain, and P . Abbeel, “Denoising diffusion probabilistic
models,” Advances in neural information processing systems, vol. 33,
pp. 6840–6851, 2020.
[119] J. Song, C. Meng, and S. Ermon, “Denoising diffusion implicit
models,” arXiv preprint arXiv:2010.02502, 2020.
[120] C. Saharia, W. Chan, H. Chang, C. Lee, J. Ho, T. Salimans, D. Fleet,
and M. Norouzi, “Palette: Image-to-image diffusion models,” in
ACM SIGGRAPH 2022 Conference Proceedings, 2022, pp. 1–10.
[121] R. Rombach, A. Blattmann, D. Lorenz, P . Esser, and B. Ommer,
“High-resolution image synthesis with latent diffusion models,”
in Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition, 2022, pp. 10 684–10 695.
[122] F.-A. Croitoru, V . Hondru, R. T. Ionescu, and M. Shah, “Diffusion
models in vision: A survey,” IEEE Transactions on Pattern Analysis
and Machine Intelligence, 2023.
[123] A. Hertz, R. Mokady, J. Tenenbaum, K. Aberman, Y. Pritch,
and D. Cohen-Or, “Prompt-to-prompt image editing with cross
attention control,” arXiv preprint arXiv:2208.01626, 2022.
[124] A. Blattmann, R. Rombach, K. Oktay, J. M ¨uller, and B. Ommer,
“Retrieval-augmented diffusion models,” Advances in Neural In-
formation Processing Systems, vol. 35, pp. 15 309–15 324, 2022.
[125] Y. Li, K. Zhou, W. X. Zhao, and J.-R. Wen, “Diffusion models
for non-autoregressive text generation: A survey,” arXiv preprint
arXiv:2303.06574, 2023.
[126] Q. Wen, T. Zhou, C. Zhang, W. Chen, Z. Ma, J. Yan, and
L. Sun, “Transformers in time series: A survey,” arXiv preprint
arXiv:2202.07125, 2022.
[127] K. S. Kalyan, A. Rajasekharan, and S. Sangeetha, “Ammus: A sur-
vey of transformer-based pretrained models in natural language
processing,” arXiv preprint arXiv:2108.05542, 2021.
[128] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning
for image recognition,” in Proceedings of the IEEE conference on
computer vision and pattern recognition, 2016, pp. 770–778.
[129] T. Xu, P . Zhang, Q. Huang, H. Zhang, Z. Gan, X. Huang, and
X. He, “Attngan: Fine-grained text to image generation with
attentional generative adversarial networks,” in Proceedings of the
IEEE conference on computer vision and pattern recognition, 2018, pp.
1316–1324.
[130] Y. Zhang, Y. Wang, Z. Jiang, F. Liao, L. Zheng, D. Tan, J. Chen, and
J. Lu, “Diversifying tire-defect image generation based on gener-
ative adversarial network,” IEEE Transactions on Instrumentation
and Measurement, vol. 71, pp. 1–12, 2022.
[131] J. He, W. Shi, K. Chen, L. Fu, and C. Dong, “Gcfsr: a generative
and controllable face super resolution method without facial and
gan priors,” in Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, 2022, pp. 1889–1898.
[132] J. Park, S. Son, and K. M. Lee, “Content-aware local gan for
photo-realistic super-resolution,” in Proceedings of the IEEE/CVF
International Conference on Computer Vision , 2023, pp. 10 585–
10 594.
[133] Z. Zheng, J. Liu, and N. Zheng, “ p2-gan: Efficient stroke style
transfer using single style image,” IEEE Transactions on Multime-
dia, 2022.
[134] S. M. Bafti, C. S. Ang, G. Marcelli, M. M. Hossain, S. Maxamhud,
and A. D. Tsaousis, “Biogan: An unpaired gan-based image
to image translation model for microbiological images,” arXiv
preprint arXiv:2306.06217, 2023.
[135] X. Cheng, J. Zhou, J. Song, and X. Zhao, “A highway traffic image
enhancement algorithm based on improved gan in complex
weather conditions,” IEEE Transactions on Intelligent Transporta-
tion Systems, 2023.
[136] J. Pathak, S. Subramanian, P . Harrington, S. Raja, A. Chattopad-
hyay, M. Mardani, T. Kurth, D. Hall, Z. Li, K. Azizzadenesheli
et al., “Fourcastnet: A global data-driven high-resolution weather
model using adaptive fourier neural operators,” arXiv preprint
arXiv:2202.11214, 2022.
[137] R. Lam, A. Sanchez-Gonzalez, M. Willson, P . Wirnsberger, M. For-
tunato, A. Pritzel, S. Ravuri, T. Ewalds, F. Alet, Z. Eaton-Rosen
33
et al., “Graphcast: Learning skillful medium-range global weather
forecasting,” arXiv preprint arXiv:2212.12794, 2022.
[138] K. Chen, T. Han, J. Gong, L. Bai, F. Ling, J.-J. Luo, X. Chen,
L. Ma, T. Zhang, R. Su, Y. Ci, B. Li, X. Yang, and W. Ouyang,
“Fengwu: Pushing the skillful global medium-range weather
forecast beyond 10 days lead,” 2023.
[139] L. Chen, X. Zhong, F. Zhang, Y. Cheng, Y. Xu, Y. Qi, and H. Li,
“Fuxi: A cascade machine learning forecasting system for 15-day
global weather forecast,” arXiv preprint arXiv:2306.12873, 2023.
[140] S. R. Cachay, E. Erickson, A. F. C. Bucker, E. Pokropek, W. Po-
tosnak, S. Bire, S. Osei, and B. L ¨utjens, “The world as a graph:
Improving el ni ˜no forecasts with graph neural networks,” 2021.
[141] Q. You, Z. Cai, F. Wu, Z. Jiang, N. Pepin, and S. S. Shen,
“Temperature dataset of cmip6 models over china: evaluation,
trend and uncertainty,”Climate Dynamics, vol. 57, pp. 17–35, 2021.
[142] R. Keisler, “Forecasting global weather with graph neural net-
works,” 2022.
[143] Q. Ni, Y. Wang, and Y. Fang, “Ge-stdgn: a novel spatio-temporal
weather prediction model based on graph evolution,” Applied
Intelligence, pp. 1–15, 2022.
[144] M. Ma, P . Xie, F. Teng, B. Wang, S. Ji, J. Zhang, and T. Li, “Histgnn:
Hierarchical spatio-temporal graph neural network for weather
forecasting,” Information Sciences, vol. 648, p. 119580, 2023.
[145] K. Venkatachalam, P . Trojovsk `y, D. Pamucar, N. Bacanin, and
V . Simic, “Dwfh: An improved data-driven deep weather fore-
casting hybrid model using transductive long short term memory
(t-lstm),” Expert Systems with Applications , vol. 213, p. 119270,
2023.
[146] L. Chen, F. Du, Y. Hu, Z. Wang, and F. Wang, “Swinrdm: integrate
swinrnn with diffusion model towards high-resolution and high-
quality weather forecasting,” in Proceedings of the AAAI Conference
on Artificial Intelligence, vol. 37, no. 1, 2023, pp. 322–330.
[147] Y. Hu, L. Chen, Z. Wang, and H. Li, “Swinvrnn: A data-driven en-
semble forecasting model via learned distribution perturbation,”
Journal of Advances in Modeling Earth Systems , vol. 15, no. 2, p.
e2022MS003211, 2023.
[148] Z. Ben-Bouallegue, J. A. Weyn, M. C. Clare, J. Dramsch,
P . Dueben, and M. Chantry, “Improving medium-range ensem-
ble weather forecasts with hierarchical ensemble transformers,”
arXiv preprint arXiv:2303.17195, 2023.
[149] S. Bire, B. L ¨utjens, D. Newman, and C. Hill, “Oceanfourcast:
Emulating ocean models with transformers for adjoint-based
data assimilation,” Copernicus Meetings, Tech. Rep., 2023.
[150] L. Li, R. Carver, I. Lopez-Gomez, F. Sha, and J. Anderson, “Seeds:
Emulation of weather forecast ensembles with diffusion models,”
arXiv preprint arXiv:2306.14066, 2023.
[151] S. R. Cachay, B. Zhao, H. James, and R. Yu, “Dyffusion: A
dynamics-informed diffusion model for spatiotemporal forecast-
ing,” arXiv preprint arXiv:2306.01984, 2023.
[152] O. Ovadia, E. Turkel, A. Kahana, and G. E. Karniadakis, “Ditto:
Diffusion-inspired temporal transformer operator,”arXiv preprint
arXiv:2307.09072, 2023.
[153] I. Prapas, N.-I. Bountos, S. Kondylatos, D. Michail, G. Camps-
Valls, and I. Papoutsis, “Televit: Teleconnection-driven trans-
formers improve subseasonal to seasonal wildfire forecasting,”
in Proceedings of the IEEE/CVF International Conference on Computer
Vision, 2023, pp. 3754–3759.
[154] S. Chen, G. Long, T. Shen, T. Zhou, and J. Jiang, “Spatial-
temporal prompt learning for federated weather forecasting,”
arXiv preprint arXiv:2305.14244, 2023.
[155] X. Zhong, L. Chen, J. Liu, C. Lin, Y. Qi, and H. Li, “Fuxi-extreme:
Improving extreme rainfall and wind forecasts with diffusion
model,” 2023.
[156] S. Esmaeilzadeh, K. Azizzadenesheli, K. Kashinath, M. Mustafa,
H. A. Tchelepi, P . Marcus, M. Prabhat, A. Anandkumar
et al., “Meshfreeflownet: A physics-constrained deep continuous
space-time super-resolution framework,” in SC20: International
Conference for High Performance Computing, Networking, Storage and
Analysis. IEEE, 2020, pp. 1–15.
[157] M. A. E. R. Hammoud, E. S. Titi, I. Hoteit, and O. Knio, “Cdanet:
A physics-informed deep neural network for downscaling fluid
flows,” Journal of Advances in Modeling Earth Systems , vol. 14,
no. 12, p. e2022MS003051, 2022.
[158] P . Harder, Q. Yang, V . Ramesh, P . Sattigeri, A. Hernandez-
Garcia, C. Watson, D. Szwarcman, and D. Rolnick, “Generating
physically-consistent high-resolution climate data with hard-
constrained neural networks,” arXiv preprint arXiv:2208.05424 ,
2022.
[159] F. Gerges, M. C. Boufadel, E. Bou-Zeid, H. Nassif, and J. T. Wang,
“A novel bayesian deep learning approach to the downscaling
of wind speed with uncertainty quantification,” in Pacific-Asia
Conference on Knowledge Discovery and Data Mining . Springer,
2022, pp. 55–66.
[160] J. Ba ˜no-Medina, R. Manzanas, E. Cimadevilla, J. Fern ´andez,
J. Gonz ´alez-Abad, A. S. Cofi ˜no, and J. M. Guti ´errez, “Downscal-
ing multi-model climate projection ensembles with deep learning
(deepesd): contribution to cordex eur-44,” Geoscientific Model
Development, vol. 15, no. 17, pp. 6747–6758, 2022.
[161] J. Gonz ´alez-Abad, ´Alex Hern´andez-Garc´ıa, P . Harder, D. Rolnick,
and J. M. Guti´errez, “Multi-variable hard physical constraints for
climate model downscaling,” 2023.
[162] P . Harder, V . Ramesh, A. Hernandez-Garcia, Q. Yang, P . Sattigeri,
D. Szwarcman, C. Watson, and D. Rolnick, “Physics-constrained
deep learning for downscaling,” Copernicus Meetings, Tech.
Rep., 2023.
[163] D. Fuchs, S. C. Sherwood, A. Prasad, K. Trapeznikov, and J. Gim-
lett, “Torchclim v1. 0: A deep-learning framework for climate
model physics,” EGUsphere, vol. 2023, pp. 1–25, 2023.
[164] M. Mardani, N. Brenowitz, Y. Cohen, J. Pathak, C.-Y. Chen, C.-C.
Liu, A. Vahdat, K. Kashinath, J. Kautz, and M. Pritchard, “Gen-
erative residual diffusion modeling for km-scale atmospheric
downscaling,” 2023.
[165] C. K. Sønderby, L. Espeholt, J. Heek, M. Dehghani, A. Oliver,
T. Salimans, S. Agrawal, J. Hickey, and N. Kalchbrenner, “Metnet:
A neural weather model for precipitation forecasting,” arXiv
preprint arXiv:2003.12140, 2020.
[166] J. Park, I. Lee, M. Son, S. Cho, and C. Kim, “Nowformer: A locally
enhanced temporal learner for precipitation nowcasting.”
[167] H.-B. Liu and I. Lee, “Mpl-gan: Toward realistic meteorological
predictive learning using conditional gan,” IEEE Access , vol. 8,
pp. 93 179–93 186, 2020.
[168] X. Peng, Q. Li, and J. Jing, “Cngat: A graph neural network model
for radar quantitative precipitation estimation,”IEEE Transactions
on Geoscience and Remote Sensing, vol. 60, pp. 1–14, 2021.
[169] A. Asperti, F. Merizzi, A. Paparella, G. Pedrazzi, M. Angelinelli,
and S. Colamonaco, “Precipitation nowcasting with generative
diffusion models,” 2023.
[170] J. Choi, Y. Kim, K.-H. Kim, S.-H. Jung, and I. Cho, “Pct-cyclegan:
Paired complementary temporal cycle-consistent adversarial net-
works for radar-based precipitation nowcasting,” in Proceedings
of the 32nd ACM International Conference on Information and Knowl-
edge Management, 2023, pp. 348–358.
[171] C. Bai, F. Sun, J. Zhang, Y. Song, and S. Chen, “Rainformer: Fea-
tures extraction balanced network for radar-based precipitation
nowcasting,” IEEE Geoscience and Remote Sensing Letters , vol. 19,
pp. 1–5, 2022.
[172] Z. Gao, X. Shi, H. Wang, Y. Zhu, Y. B. Wang, M. Li, and D.-
Y. Yeung, “Earthformer: Exploring space-time transformers for
earth system forecasting,” Advances in Neural Information Process-
ing Systems, vol. 35, pp. 25 390–25 403, 2022.
[173] Z. Yang, X. Yang, and Q. Lin, “Ptct: Patches with 3d-temporal
convolutional transformer network for precipitation nowcast-
ing,” arXiv preprint arXiv:2112.01085, 2021.
[174] Z. Ma, H. Zhang, and J. Liu, “Mm-rnn: A multimodal rnn for
precipitation nowcasting,” IEEE Transactions on Geoscience and
Remote Sensing, 2023.
[175] Q. Jin, X. Zhang, X. Xiao, G. Meng, S. Xiang, C. Pan et al. ,
“Spatiotemporal inference network for precipitation nowcasting
with multi-modal fusion,” IEEE Journal of Selected Topics in Applied
Earth Observations and Remote Sensing, 2023.
[176] Q. Jin, X. Zhang, X. Xiao, Y. Wang, S. Xiang, and C. Pan, “Pre-
former: Simple and efficient design for precipitation nowcasting
with transformers,” IEEE Geoscience and Remote Sensing Letters ,
2023.
[177] Z. Gao, X. Shi, B. Han, H. Wang, X. Jin, D. Maddix, Y. Zhu,
M. Li, and Y. Wang, “Prediff: Precipitation nowcasting with latent
diffusion models,” arXiv preprint arXiv:2307.10422, 2023.
[178] F. Ye, J. Hu, T.-Q. Huang, L.-J. You, B. Weng, and J.-Y. Gao,
“Transformer for ei ni ˜no-southern oscillation prediction,” IEEE
Geoscience and Remote Sensing Letters, vol. 19, pp. 1–5, 2021.
[179] Y.-G. Ham, J.-H. Kim, E.-S. Kim, and K.-W. On, “Unified deep
learning model for el ni ˜no/southern oscillation forecasts by in-
34
corporating seasonality in climate data,” Science Bulletin, vol. 66,
no. 13, pp. 1358–1366, 2021.
[180] A. M. Ahmed, R. C. Deo, Q. Feng, A. Ghahramani, N. Raj, Z. Yin,
and L. Yang, “Hybrid deep learning method for a week-ahead
evapotranspiration forecasting,” Stochastic Environmental Research
and Risk Assessment, pp. 1–19, 2021.
[181] B. Mu, B. Qin, and S. Yuan, “Enso-gtc: Enso deep learning forecast
model with a global spatial-temporal teleconnection coupler,”
Journal of Advances in Modeling Earth Systems , vol. 14, no. 12, p.
e2022MS003132, 2022.
[182] D. Xu, Q. Zhang, Y. Ding, and D. Zhang, “Application of a hybrid
arima-lstm model based on the spei for drought forecasting,”
Environmental Science and Pollution Research , vol. 29, no. 3, pp.
4128–4144, 2022.
[183] L. Wang, S. Ammons, V . M. Hur, R. L. Sriver, and Z. Zhao,
“Convolutional gru network for seasonal prediction of the el ni\˜
no-southern oscillation,” arXiv preprint arXiv:2306.10443, 2023.
[184] H. Li, N. Zhang, Z. Xu, X. Li, C. Liu, C. Zhao, and J. Wu, “Dk-stn:
A domain knowledge embedded spatio-temporal network model
for mjo forecast,” Expert Systems With Applications, Forthcoming ,
2023.
[185] L. Han, M. Chen, K. Chen, H. Chen, Y. Zhang, B. Lu, L. Song, and
R. Qin, “A deep learning method for bias correction of ecmwf 24–
240 h forecasts,” Advances in Atmospheric Sciences , vol. 38, no. 9,
pp. 1444–1459, 2021.
[186] T. Yoshikane and K. Yoshimura, “A bias correction method for
precipitation through recognizing mesoscale precipitation sys-
tems corresponding to weather conditions,” PLoS Water, vol. 1,
no. 5, p. e0000016, 2022.
[187] Y. Li, F. Tang, X. Gao, T. Zhang, J. Qi, J. Xie, X. Li, and Y. Guo,
“Numerical weather prediction correction strategy for short-term
wind power forecasting based on bidirectional gated recurrent
unit and xgboost,” Frontiers in Energy Research , vol. 9, p. 836144,
2022.
[188] X. Yang, S. Yang, M. L. Tan, H. Pan, H. Zhang, G. Wang, R. He,
and Z. Wang, “Correcting the bias of daily satellite precipitation
estimates in tropical regions using deep neural network,” Journal
of Hydrology, vol. 608, p. 127656, 2022.
[189] A. Blanchard, N. Parashar, B. Dodov, C. Lessig, and T. Sapsis,
“A multi-scale deep learning framework for projecting weather
extremes,” 2022.
[190] Y. Han, L. Mi, L. Shen, C. Cai, Y. Liu, K. Li, and G. Xu, “A short-
term wind speed prediction method utilizing novel hybrid deep
learning algorithms to correct numerical weather forecasting,”
Applied Energy, vol. 312, p. 118777, 2022.
[191] F. Wang and D. Tian, “On deep learning-based bias correction
and downscaling of multiple climate models simulations,” Cli-
mate dynamics, vol. 59, no. 11-12, pp. 3451–3468, 2022.
[192] T. Ge, J. Pathak, A. Subramaniam, and K. Kashinath, “Dl-
corrector-remapper: A grid-free bias-correction deep learning
methodology for data-driven high-resolution global weather
forecasting,” arXiv preprint arXiv:2210.12293, 2022.
[193] D. J. Fulton, B. J. Clarke, and G. C. Hegerl, “Bias correcting
climate model simulations using unpaired image-to-image trans-
lation networks,” Artificial Intelligence for the Earth Systems, vol. 2,
no. 2, p. e220031, 2023.
[194] B. Wu, W. Chen, W. Wang, B. Peng, L. Sun, and L. Chen,
“Weathergnn: Exploiting complicated relationships in numerical
weather prediction bias correction,” 2023.
[195] N. Webersinke, M. Kraus, J. A. Bingler, and M. Leippold, “Cli-
matebert: A pretrained language model for climate-related text,”
2022.
[196] B. J. Fard, S. A. Hasan, and J. E. Bell, “Climedbert: A pre-trained
language model for climate and health-related text,” 2022.
[197] Z. Bi, N. Zhang, Y. Xue, Y. Ou, D. Ji, G. Zheng, and H. Chen,
“Oceangpt: A large language model for ocean science tasks,”
2023.
[198] T. Schimanski, J. Bingler, C. Hyslop, M. Kraus, and M. Leippold,
“Climatebert-netzero: Detecting and assessing net zero and re-
duction targets,” 2023.
[199] E. C. Garrido-Merch ´an, C. Gonz ´alez-Barthe, and M. C. Vaca,
“Fine-tuning climatebert transformer with climatext for the dis-
closure analysis of climate-related financial risks,” 2023.
[200] K. Chen, Y. Meng, X. Sun, S. Guo, T. Zhang, J. Li, and C. Fan,
“Badpre: Task-agnostic backdoor attacks to pre-trained nlp foun-
dation models,” arXiv preprint arXiv:2110.02467, 2021.
[201] J. Guibas, M. Mardani, Z. Li, A. Tao, A. Anandkumar, and
B. Catanzaro, “Adaptive fourier neural operators: Efficient token
mixers for transformers,” arXiv preprint arXiv:2111.13587, 2021.
[202] K. He, X. Chen, S. Xie, Y. Li, P . Doll ´ar, and R. Girshick, “Masked
autoencoders are scalable vision learners,” in Proceedings of the
IEEE/CVF conference on computer vision and pattern recognition ,
2022, pp. 16 000–16 009.
[203] C. Feichtenhofer, Y. Li, K. He et al. , “Masked autoencoders as
spatiotemporal learners,” Advances in neural information processing
systems, vol. 35, pp. 35 946–35 958, 2022.
[204] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A.
y Arcas, “Communication-efficient learning of deep networks
from decentralized data,” in Artificial intelligence and statistics .
PMLR, 2017, pp. 1273–1282.
[205] F. S. Varini, J. Boyd-Graber, M. Ciaramita, and M. Leippold,
“Climatext: A dataset for climate change topic detection,” 2021.
[206] C.-A. Diaconu, S. Saha, S. G ¨unnemann, and X. X. Zhu, “Under-
standing the role of weather data for earth surface forecasting
using a convlstm-based model,” in Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition , 2022, pp.
1362–1371.
[207] S. F. Tekin, O. Karaahmetoglu, F. Ilhan, I. Balaban, and S. S. Kozat,
“Spatio-temporal weather forecasting and attention mechanism
on convolutional lstms,” arXiv preprint arXiv:2102.00696, 2021.
[208] J. Su, W. Byeon, J. Kossaifi, F. Huang, J. Kautz, and A. Anandku-
mar, “Convolutional tensor-train lstm for spatio-temporal learn-
ing,” Advances in Neural Information Processing Systems , vol. 33,
pp. 13 714–13 726, 2020.
[209] Y. Wang, H. Wu, J. Zhang, Z. Gao, J. Wang, S. Y. Philip, and
M. Long, “Predrnn: A recurrent neural network for spatiotempo-
ral predictive learning,” IEEE Transactions on Pattern Analysis and
Machine Intelligence, vol. 45, no. 2, pp. 2208–2225, 2022.
[210] Y. Wang, L. Jiang, M.-H. Yang, L.-J. Li, M. Long, and L. Fei-Fei,
“Eidetic 3d lstm: A model for video prediction and beyond,” in
International conference on learning representations, 2018.
[211] C. Luo, X. Zhao, Y. Sun, X. Li, and Y. Ye, “Predrann: the spa-
tiotemporal attention convolution recurrent neural network for
precipitation nowcasting,” Knowledge-Based Systems , vol. 239, p.
107900, 2022.
[212] M. Bilgili, A. Ilhan, and S ¸.¨Unal, “Time-series prediction of hourly
atmospheric pressure using anfis and lstm approaches,” Neural
Computing and Applications, vol. 34, no. 18, pp. 15 633–15 648, 2022.
[213] B. Usharani, “Ilf-lstm: Enhanced loss function in lstm to predict
the sea surface temperature,” Soft Computing, vol. 27, no. 18, pp.
13 129–13 141, 2023.
[214] S. Tang, C. Li, P . Zhang, and R. Tang, “Swinlstm: Improving
spatiotemporal prediction accuracy using swin transformer and
lstm,” in Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV), October 2023, pp. 13 470–13 479.
[215] L. Zhifeng, D. Feng, L. Jianyong, Z. Yue, and C. Hetao, “Com-
parison of blstm-attention and blstm-transformer models for
wind speed prediction,” in Proceedings of the Bulgarian Academy
of Sciences, vol. 75, no. 1, 2022, pp. 80–89.
[216] L. Tian, X. Li, Y. Ye, P . Xie, and Y. Li, “A generative adversarial
gated recurrent unit model for precipitation nowcasting,” IEEE
Geoscience and Remote Sensing Letters , vol. 17, no. 4, pp. 601–605,
2019.
[217] J. Leinonen, D. Nerini, and A. Berne, “Stochastic super-resolution
for downscaling time-evolving atmospheric fields with a gener-
ative adversarial network,” IEEE Transactions on Geoscience and
Remote Sensing, vol. 59, no. 9, pp. 7211–7223, 2020.
[218] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo,
“Swin transformer: Hierarchical vision transformer using shifted
windows,” in Proceedings of the IEEE/CVF international conference
on computer vision, 2021, pp. 10 012–10 022.
[219] V . Zantedeschi, D. De Martini, C. Tong, C. S. de Witt,
A. Kalaitzis, M. Chantry, and D. Watson-Parris, “Towards data-
driven physics-informed global precipitation forecasting from
satellite imagery,” in Proceedings of the AI for Earth Sciences Work-
shop at NeurIPS, 2020.
[220] J. Leinonen, U. Hamann, D. Nerini, U. Germann, and G. Franch,
“Latent diffusion models for generative precipitation nowcast-
ing with accurate uncertainty quantification,” arXiv preprint
arXiv:2304.12891, 2023.
[221] S. R. Cachay, V . Ramesh, J. N. Cole, H. Barker, and D. Rolnick,
“Climart: A benchmark dataset for emulating atmospheric ra-
35
diative transfer in weather and climate models,” arXiv preprint
arXiv:2111.14671, 2021.
[222] P . Lippe, B. S. Veeling, P . Perdikaris, R. E. Turner, and J. Brand-
stetter, “Pde-refiner: Achieving accurate long rollouts with neural
pde solvers,” arXiv preprint arXiv:2308.05732, 2023.
[223] Y. Hatanaka, Y. Glaser, G. Galgon, G. Torri, and P . Sadowski, “Dif-
fusion models for high-resolution solar forecasts,” arXiv preprint
arXiv:2302.00170, 2023.
[224] G. P . Høivang, “Diffmet: Diffusion models and deep learning for
precipitation nowcasting,” Master’s thesis, 2023.
[225] A. Radford, L. Metz, and S. Chintala, “Unsupervised represen-
tation learning with deep convolutional generative adversarial
networks,” arXiv preprint arXiv:1511.06434, 2015.
[226] A. Brock, J. Donahue, and K. Simonyan, “Large scale gan training
for high fidelity natural image synthesis,” in International Confer-
ence on Learning Representations, 2018.
[227] T. Karras, T. Aila, S. Laine, and J. Lehtinen, “Progressive growing
of gans for improved quality, stability, and variation,” in Interna-
tional Conference on Learning Representations, 2018.
[228] A. Bihlo, “A generative adversarial network approach to (en-
semble) weather prediction,” Neural Networks, vol. 139, pp. 1–16,
2021.
[229] R. Gupta, M. Mustafa, and K. Kashinath, “Climate-style gan:
Modeling turbulent climate dynamics using style-gan,” in AI for
Earth Science Workshop, 2020.
[230] K. Klemmer, S. Saha, M. Kahl, T. Xu, and X. X. Zhu, “Genera-
tive modeling of spatio-temporal weather patterns with extreme
event conditioning,” arXiv preprint arXiv:2104.12469, 2021.
[231] S. Ravuri, K. Lenc, M. Willson, D. Kangin, R. Lam, P . Mirowski,
M. Fitzsimons, M. Athanassiadou, S. Kashem, S. Madge et al. ,
“Skilful precipitation nowcasting using deep generative models
of radar,” Nature, vol. 597, no. 7878, pp. 672–677, 2021.
[232] K. Klemmer, T. Xu, B. Acciaio, and D. B. Neill, “Spate-gan:
Improved generative modeling of dynamic spatio-temporal pat-
terns with an autoregressive embedding loss,” in Proceedings of
the AAAI Conference on Artificial Intelligence , vol. 36, no. 4, 2022,
pp. 4523–4531.
[233] Y. Ji, B. Gong, M. Langguth, A. Mozaffari, and X. Zhi, “Clgan:
a generative adversarial network (gan)-based video prediction
model for precipitation nowcasting,” Geoscientific Model Develop-
ment, vol. 16, no. 10, pp. 2737–2752, 2023.
[234] C. Luo, X. Li, Y. Ye, S. Feng, and M. K. Ng, “Experimental study
on generative adversarial network for precipitation nowcasting,”
IEEE Transactions on Geoscience and Remote Sensing , vol. 60, pp.
1–20, 2022.
[235] R. Wang, L. Su, W. K. Wong, A. K. Lau, and J. C. Fung, “Skill-
ful radar-based heavy rainfall nowcasting using task-segmented
generative adversarial network,” IEEE Transactions on Geoscience
and Remote Sensing, 2023.
[236] L. Harris, A. T. McRae, M. Chantry, P . D. Dueben, and T. N.
Palmer, “A generative deep learning approach to stochastic
downscaling of precipitation forecasts,” Journal of Advances in
Modeling Earth Systems, vol. 14, no. 10, p. e2022MS003120, 2022.
[237] N. J. Annau, A. J. Cannon, and A. H. Monahan, “Algorith-
mic hallucinations of near-surface winds: Statistical downscaling
with generative adversarial networks to convection-permitting
scales,” Artificial Intelligence for the Earth Systems, 2023.
[238] K. Dai, X. Li, Y. Ye, S. Feng, D. Qin, and R. Ye, “Mstcgan:
Multiscale time conditional generative adversarial network for
long-term satellite image sequence prediction,” IEEE Transactions
on Geoscience and Remote Sensing, vol. 60, pp. 1–16, 2022.
[239] Y. Kim and S. Hong, “Very short-term rainfall prediction using
ground radar observations and conditional generative adversar-
ial networks,” IEEE Transactions on Geoscience and Remote Sensing,
vol. 60, pp. 1–8, 2021.
[240] P . Hess, M. Dr ¨uke, S. Petri, F. M. Strnad, and N. Boers, “Physi-
cally constrained generative adversarial networks for improving
precipitation fields from earth system models,” Nature Machine
Intelligence, vol. 4, no. 10, pp. 828–839, 2022.
[241] C. Besombes, O. Pannekoucke, C. Lapeyre, B. Sanderson, and
O. Thual, “Producing realistic climate data with generative ad-
versarial networks,” Nonlinear Processes in Geophysics , vol. 28,
no. 3, pp. 347–370, 2021.
[242] E. Balogun, R. Buechler, R. Rajagopal, and A. Majumdar, “Tem-
peraturegan: Generative modeling of regional atmospheric tem-
peratures,” 2023.
[243] J. Sleeman, D. Chung, A. Gnanadesikan, J. Brett, Y. Kevrekidis,
M. Hughes, T. Haine, M.-A. Pradal, R. Gelderloos, C. Ashcraft,
C. Tang, A. Saksena, and L. White, “A generative adversarial
network for climate tipping point discovery (tip-gan),” 2023.
[244] Y. Meng, E. Rigall, X. Chen, F. Gao, J. Dong, and S. Chen,
“Physics-guided generative adversarial networks for sea subsur-
face temperature prediction,” IEEE transactions on neural networks
and learning systems, 2021.
[245] Y. Meng, F. Gao, E. Rigall, R. Dong, J. Dong, and Q. Du, “Physical
knowledge-enhanced deep neural network for sea surface tem-
perature prediction,” IEEE Transactions on Geoscience and Remote
Sensing, vol. 61, pp. 1–13, 2023.
[246] B. L ¨utjens, B. Leshchinskiy, C. Requena-Mesa, F. Chishtie,
N. D ´ıaz-Rodr´ıguez, O. Boulais, A. Sankaranarayanan, A. Pina,
Y. Gal, C. Ra ¨ıssi et al. , “Physically-consistent generative adver-
sarial networks for coastal flood visualization,” arXiv preprint
arXiv:2104.04785, 2021.
[247] T. Yuan, J. Zhu, W. Wang, J. Lu, X. Wang, X. Li, and K. Ren,
“A space-time partial differential equation based physics-guided
neural network for sea surface temperature prediction,” Remote
Sensing, vol. 15, no. 14, p. 3498, 2023.
[248] Z. Chen, J. Gao, W. Wang, and Z. Yan, “Physics-informed gen-
erative neural network: an application to troposphere tempera-
ture prediction,” Environmental Research Letters , vol. 16, no. 6, p.
065003, 2021.
[249] F. Lin, X. Yuan, Y. Zhang, P . Sigdel, L. Chen, L. Peng, and N.-
F. Tzeng, “Comprehensive transformer-based model architecture
for real-world storm prediction,” in Joint European Conference on
Machine Learning and Knowledge Discovery in Databases. Springer,
2023, pp. 54–71.
[250] C ¸ . K¨uc ¸¨uk, A. Giannakos, S. Schneider, and A. Jann, “Transformer-
based nowcasting of radar composites from satellite images for
severe weather,” arXiv preprint arXiv:2310.19515, 2023.
[251] A. Bojesomo, H. Al-Marzouqi, P . Liatsis, G. Cong, and M. Ra-
manath, “Spatiotemporal swin-transformer network for short
time weather forecasting.” in CIKM Workshops, 2021.
[252] A. Chattopadhyay, M. Mustafa, P . Hassanzadeh, E. Bach,
and K. Kashinath, “Towards physically consistent data-
driven weather forecasting: Integrating data assimilation with
equivariance-preserving deep spatial transformers,” 2021.
[253] O. Bilgin, P . Maka, T. Vergutz, and S. Mehrkanoon, “Tent: Ten-
sorized encoder transformer for temperature forecasting,” arXiv
preprint arXiv:2106.14742, 2021.
[254] A. Bojesomo, H. AlMarzouqi, and P . Liatsis, “A novel transformer
network with shifted window cross-attention for spatiotemporal
weather forecasting,” IEEE Journal of Selected Topics in Applied
Earth Observations and Remote Sensing, 2023.
[255] Y. Gao, S. Miyata, Y. Matsunami, and Y. Akashi, “Spatio-temporal
interpretable neural network for solar irradiation prediction us-
ing transformer,” Energy and Buildings, vol. 297, p. 113461, 2023.
[256] S. A. Vaghefi, Q. Wang, V . Muccione, J. Ni, M. Kraus, J. Bingler,
T. Schimanski, C. Colesanti-Senni, N. Webersinke, C. Huggel,
and M. Leippold, “chatclimate: Grounding conversational ai in
climate science,” 2023.
[257] A. Krishnan and V . S. Anoop, “Climatenlp: Analyzing public
sentiment towards climate change using natural language pro-
cessing,” 2023.
[258] A. Auzepy, E. T ¨onjes, D. Lenz, and C. Funk, “Evaluating tcfd
reporting: A new application of zero-shot analysis to climate-
related financial disclosures,” 2023.
[259] M. Kraus, J. A. Bingler, M. Leippold, T. Schimanski, C. C. Senni,
D. Stammbach, S. A. Vaghefi, and N. Webersinke, “Enhancing
large language models with climate resources,” 2023.
[260] T. Wilson, P .-N. Tan, and L. Luo, “A low rank weighted graph
convolutional approach to weather prediction,” in 2018 IEEE
International Conference on Data Mining (ICDM) . IEEE, 2018, pp.
627–636.
[261] N. Y. Ayadi, C. Faron, F. Michel, F. Gandon, and O. Corby,
“Wekg-mf: A knowledge graph of observational weather data,”
in European Semantic Web Conference. Springer, 2022, pp. 101–106.
[262] P . Li, Y. Yu, D. Huang, Z.-H. Wang, and A. Sharma, “Regional
heatwave prediction using graph neural network and weather
station data,” Geophysical Research Letters , vol. 50, no. 7, p.
e2023GL103405, 2023.
[263] J. Oskarsson, T. Landelius, and F. Lindsten, “Graph-based neural
weather prediction for limited area modeling,” arXiv preprint
arXiv:2309.17370, 2023.
36
[264] J. Han, H. Liu, H. Zhu, H. Xiong, and D. Dou, “Joint air quality
and weather prediction based on multi-adversarial spatiotempo-
ral networks,” in Proceedings of the AAAI Conference on Artificial
Intelligence, vol. 35, no. 5, 2021, pp. 4081–4089.
[265] J. Han, H. Liu, H. Xiong, and J. Yang, “Semi-supervised air
quality forecasting via self-supervised hierarchical graph neural
network,” IEEE Transactions on Knowledge and Data Engineering ,
vol. 35, no. 5, pp. 5230–5243, 2022.
[266] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai,
T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly
et al., “An image is worth 16x16 words: Transformers for image
recognition at scale,” arXiv preprint arXiv:2010.11929, 2020.
[267] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Mon-
fardini, “The graph neural network model,” IEEE transactions on
neural networks, vol. 20, no. 1, pp. 61–80, 2008.
[268] G.-G. Wang, H. Cheng, Y. Zhang, and H. Yu, “Enso analysis and
prediction using deep learning: A review,” Neurocomputing, 2022.
[269] J. Leskovec, J. Kleinberg, and C. Faloutsos, “Graph evolution:
Densification and shrinking diameters,” ACM transactions on
Knowledge Discovery from Data (TKDD) , vol. 1, no. 1, pp. 2–es,
2007.
[270] Z. Ying, J. You, C. Morris, X. Ren, W. Hamilton, and J. Leskovec,
“Hierarchical graph representation learning with differentiable
pooling,” Advances in neural information processing systems, vol. 31,
2018.
[271] J.-H. Lee, S. S. Lee, H. G. Kim, S.-K. Song, S. Kim, and Y. M. Ro,
“Mcsip net: Multichannel satellite image prediction via deep neu-
ral network,” IEEE Transactions on Geoscience and Remote Sensing ,
vol. 58, no. 3, pp. 2212–2224, 2019.
[272] J. Cuomo and V . Chandrasekar, “Developing deep learning mod-
els for storm nowcasting,” IEEE Transactions on Geoscience and
Remote Sensing, vol. 60, pp. 1–13, 2021.
[273] A. Gong, R. Li, B. Pan, H. Chen, G. Ni, and M. Chen, “Enhancing
spatial variability representation of radar nowcasting with gen-
erative adversarial networks,” Remote Sensing, vol. 15, no. 13, p.
3306, 2023.
[274] M. R. Ehsani, A. Zarei, H. V . Gupta, K. Barnard, E. Lyons,
and A. Behrangi, “Nowcasting-nets: Representation learning to
mitigate latency gap of satellite precipitation products using
convolutional and recurrent neural networks,” IEEE Transactions
on Geoscience and Remote Sensing, vol. 60, pp. 1–21, 2022.
[275] J. G. Fern ´andez and S. Mehrkanoon, “Broad-unet: Multi-scale
feature learning for nowcasting tasks,” Neural Networks, vol. 144,
pp. 419–427, 2021.
[276] C. Huang, C. Bai, S. Chan, and J. Zhang, “Mmstn: A multi-
modal spatial-temporal network for tropical cyclone short-
term prediction,” Geophysical Research Letters , vol. 49, no. 4, p.
e2021GL096898, 2022.
[277] C. Luo, X. Li, and Y. Ye, “Pfst-lstm: A spatiotemporal lstm model
with pseudoflow prediction for precipitation nowcasting,” IEEE
Journal of Selected Topics in Applied Earth Observations and Remote
Sensing, vol. 14, pp. 843–857, 2020.
[278] X. Dong, Z. Zhao, Y. Wang, J. Wang, and C. Hu, “Motion-guided
global–local aggregation transformer network for precipitation
nowcasting,” IEEE Transactions on Geoscience and Remote Sensing ,
vol. 60, pp. 1–16, 2022.
[279] V . L. Guen and N. Thome, “Disentangling physical dynamics
from unknown factors for unsupervised video prediction,” in
Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, 2020, pp. 11 474–11 484.
[280] L. C. Evans, Partial differential equations. American Mathematical
Society, 2022, vol. 19.
[281] M. Andrychowicz, L. Espeholt, D. Li, S. Merchant, A. Merose,
F. Zyda, S. Agrawal, and N. Kalchbrenner, “Deep learning for
day forecasts from sparse observations,” 2023.
[282] W. Cai, A. Santoso, G. Wang, S.-W. Yeh, S.-I. An, K. M. Cobb,
M. Collins, E. Guilyardi, F.-F. Jin, J.-S. Kug et al. , “Enso and
greenhouse warming,” Nature Climate Change , vol. 5, no. 9, pp.
849–859, 2015.
[283] J. Zhang, K. Howard, C. Langston, B. Kaney, Y. Qi, L. Tang,
H. Grams, Y. Wang, S. Cocks, S. Martinaitis et al. , “Multi-radar
multi-sensor (mrms) quantitative precipitation estimation: Initial
operating capabilities,” Bulletin of the American Meteorological
Society, vol. 97, no. 4, pp. 621–638, 2016.
[284] S. C. M. Sharma and A. Mitra, “Resdeepd: A residual super-
resolution network for deep downscaling of daily precipitation
over india,” Environmental Data Science, vol. 1, p. e19, 2022.
[285] T. Ballard and G. Erinjippurath, “Contrastive learning for cli-
mate model bias correction and super-resolution,” arXiv preprint
arXiv:2211.07555, 2022.
[286] X. Hu, M. A. Naiel, A. Wong, M. Lamm, and P . Fieguth, “Runet:
A robust unet architecture for image super-resolution,” in Pro-
ceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition Workshops, 2019, pp. 0–0.
[287] F. Min, L. Wang, S. Pan, and G. Song, “D 2 unet: Dual decoder
u-net for seismic image super-resolution reconstruction,” IEEE
Transactions on Geoscience and Remote Sensing , vol. 61, pp. 1–13,
2023.
[288] Q. Yu, M. Zhu, Q. Zeng, H. Wang, Q. Chen, X. Fu, and Z. Qing,
“Weather radar super-resolution reconstruction based on residual
attention back-projection network,” Remote Sensing, vol. 15, no. 8,
p. 1999, 2023.
[289] X. Wang, K. Yu, S. Wu, J. Gu, Y. Liu, C. Dong, Y. Qiao, and
C. Change Loy, “Esrgan: Enhanced super-resolution generative
adversarial networks,” in Proceedings of the European conference on
computer vision (ECCV) workshops, 2018, pp. 0–0.
[290] C. D. Watson, C. Wang, T. Lynar, and K. Weldemariam, “Investi-
gating two super-resolution methods for downscaling precipita-
tion: Esrgan and car,” arXiv preprint arXiv:2012.01233, 2020.
[291] J. Wang, Z. Liu, I. Foster, W. Chang, R. Kettimuthu, and V . R. Ko-
tamarthi, “Fast and accurate learned multiresolution dynamical
downscaling for precipitation,” Geoscientific Model Development ,
vol. 14, no. 10, pp. 6355–6372, 2021.
[292] K. Stengel, A. Glaws, D. Hettinger, and R. N. King, “Adversarial
super-resolution of climatological wind and solar data,” Proceed-
ings of the National Academy of Sciences, vol. 117, no. 29, pp. 16 805–
16 815, 2020.
[293] N. P . Juan, J. O. Rodr ´ıguez, V . N. Valdecantos, and G. Iglesias,
“Data-driven and physics-based approach for wave downscal-
ing: A comparative study,” Ocean Engineering, vol. 285, p. 115380,
2023.
[294] D. Feng, Z. Tan, and Q. He, “Physics-informed neural net-
works of the saint-venant equations for downscaling a large-
scale river model,” Water Resources Research , vol. 59, no. 2, p.
e2022WR033168, 2023.
[295] M. Bocquet, , J. Brajard, A. Carrassi, L. Bertino, , and and,
“Bayesian inference of chaotic dynamics by merging data
assimilation, machine learning and expectation-maximization,”
Foundations of Data Science, vol. 2, no. 1, pp. 55–80, 2020. [Online].
Available: https://doi.org/10.3934%2Ffods.2020004
[296] A. J. Geer, “Learning earth system models from observations:
machine learning or data assimilation?” Philosophical Transactions
of the Royal Society A, vol. 379, no. 2194, p. 20200089, 2021.
[297] D. Hershcovich, N. Webersinke, M. Kraus, J. A. Bingler, and
M. Leippold, “Towards climate awareness in nlp research,” arXiv
preprint arXiv:2205.05071, 2022.
[298] OpenAI, “Gpt-4 technical report,” 2023.
[299] T. Knutson, S. J. Camargo, J. C. Chan, K. Emanuel, C.-H. Ho,
J. Kossin, M. Mohapatra, M. Satoh, M. Sugi, K. Walshet al., “Trop-
ical cyclones and climate change assessment: Part ii: Projected
response to anthropogenic warming,” Bulletin of the American
Meteorological Society, vol. 101, no. 3, pp. E303–E322, 2020.
[300] C. Bai, Z. Cai, X. Yin, and J. Zhang, “Lsdssimr: Large-scale dust
storm database based on satellite images and meteorological
reanalysis data,” IEEE Journal of Selected Topics in Applied Earth
Observations and Remote Sensing, 2023.
[301] K. Kashinath, M. Mudigonda, S. Kim, L. Kapp-Schwoerer,
A. Graubner, E. Karaismailoglu, L. Von Kleist, T. Kurth,
A. Greiner, A. Mahesh et al. , “Climatenet: An expert-labeled
open dataset and deep learning architecture for enabling high-
precision analyses of extreme weather,” Geoscientific Model Devel-
opment, vol. 14, no. 1, pp. 107–124, 2021.
[302] E. Racah, C. Beckham, T. Maharaj, S. Ebrahimi Kahou, M. Prab-
hat, and C. Pal, “Extremeweather: A large-scale climate dataset
for semi-supervised detection, localization, and understanding of
extreme weather events,” Advances in neural information processing
systems, vol. 30, 2017.
[303] R. A. Sobash, D. J. Gagne, C. L. Becker, D. Ahijevych, G. N.
Gantos, and C. S. Schwartz, “Diagnosing storm mode with
deep learning in convection-allowing models,” Monthly Weather
Review, 2023.
[304] E. M. Rasmusson and T. H. Carpenter, “Variations in tropical sea
surface temperature and surface wind fields associated with the
37
southern oscillation/el ni ˜no,” Monthly Weather Review , vol. 110,
no. 5, pp. 354–384, 1982.
[305] M. Latif, D. Anderson, T. Barnett, M. Cane, R. Kleeman, A. Leet-
maa, J. O’Brien, A. Rosati, and E. Schneider, “A review of the
predictability and prediction of enso,” Journal of Geophysical Re-
search: Oceans, vol. 103, no. C7, pp. 14 375–14 393, 1998.
[306] D. Song, X. Su, W. Li, Z. Sun, T. Ren, W. Liu, and A.-A. Liu,
“Spatial-temporal transformer network for multi-year enso pre-
diction,” Frontiers in Marine Science, vol. 10, p. 1143499, 2023.
[307] W. Fang, Y. Sha, and V . S. Sheng, “Survey on the application of
artificial intelligence in enso forecasting,” Mathematics, vol. 10,
no. 20, p. 3793, 2022.
[308] M. Liu-Schiaffini, C. E. Singer, N. Kovachki, T. Schneider, K. Az-
izzadenesheli, and A. Anandkumar, “Tipping point forecasting
in non-stationary dynamics on function spaces,” 2023.
[309] A. Gnanadesikan, J. Brett, J. Sleeman, and D. Chung, “Using ai
to detect climate tipping points-or why it’s hard to understand
rapid changes in the earth system,” 2023.
[310] M. Rietkerk, R. Bastiaansen, S. Banerjee, J. van de Koppel, M. Bau-
dena, and A. Doelman, “Evasion of tipping in complex systems
through spatial pattern formation,” Science, vol. 374, no. 6564, p.
eabj0359, 2021.
[311] T. M. Bury, R. Sujith, I. Pavithran, M. Scheffer, T. M. Lenton,
M. Anand, and C. T. Bauch, “Deep learning for early warning
signals of tipping points,” Proceedings of the National Academy of
Sciences, vol. 118, no. 39, p. e2106140118, 2021.
[312] C. Zhang, “Madden-julian oscillation,” Reviews of Geophysics ,
vol. 43, no. 2, 2005.
[313] ——, “Madden–julian oscillation: Bridging weather and climate,”
Bulletin of the American Meteorological Society , vol. 94, no. 12, pp.
1849–1870, 2013.
[314] C. Minixhofer, M. Swan, C. McMeekin, and P . Andreadis,
“Droughted: A dataset and methodology for drought forecasting
spanning multiple climate zones,” in ICML 2021 Workshop on
Tackling Climate Change with Machine Learning, 2021.
[315] V . Grabar, A. Marusov, A. Zaytsev, Y. Maximov, N. Sotiriadi,
and A. Bulkin, “Long-term drought prediction using deep neu-
ral networks based on geospatial weather data,” arXiv preprint
arXiv:2309.06212, 2023.
[316] A. Danandeh Mehr, A. Rikhtehgar Ghiasi, Z. M. Yaseen, A. U.
Sorman, and L. Abualigah, “A novel intelligent deep learning
predictive model for meteorological drought forecasting,”Journal
of Ambient Intelligence and Humanized Computing, vol. 14, no. 8, pp.
10 441–10 455, 2023.
[317] F. A. Prodhan, J. Zhang, S. S. Hasan, T. P . P . Sharma, and H. P .
Mohana, “A review of machine learning methods for drought
hazard monitoring and forecasting: Current research trends, chal-
lenges, and future research directions,” Environmental Modelling
& Software, vol. 149, p. 105327, 2022.
[318] R. Mendelsohn, K. Emanuel, S. Chonabayashi, and L. Bakkensen,
“The impact of climate change on global tropical cyclone dam-
age,” Nature climate change, vol. 2, no. 3, pp. 205–209, 2012.
[319] D. J. Befort, K. I. Hodges, and A. Weisheimer, “Seasonal predic-
tion of tropical cyclones over the north atlantic and western north
pacific,” Journal of Climate, vol. 35, no. 5, pp. 1385–1397, 2022.
[320] M. Scheuerer, M. B. Switanek, R. P . Worsnop, and T. M. Hamill,
“Using artificial neural networks for generating probabilistic sub-
seasonal precipitation forecasts over california,” Monthly Weather
Review, vol. 148, no. 8, pp. 3489–3506, 2020.
[321] D. Specq and L. Batt ´e, “Improving subseasonal precipitation
forecasts through a statistical–dynamical approach: application
to the southwest tropical pacific,” Climate Dynamics, vol. 55, no.
7-8, pp. 1913–1927, 2020.
[322] C. O. de Burgh-Day and T. Leeuwenburg, “Machine learning for
numerical weather and climate modelling: a review,” EGUsphere,
vol. 2023, pp. 1–48, 2023.
[323] Q. Yang, C.-Y. Lee, M. K. Tippett, D. R. Chavas, and T. R. Knut-
son, “Machine learning–based hurricane wind reconstruction,”
Weather and Forecasting, vol. 37, no. 4, pp. 477–493, 2022.
[324] E. Vosper, P . Watson, L. Harris, A. McRae, R. Santos-Rodriguez,
L. Aitchison, and D. Mitchell, “Deep learning for downscaling
tropical cyclone rainfall to hazard-relevant spatial scales,” Journal
of Geophysical Research: Atmospheres, p. e2022JD038163, 2023.
[325] S. Ashkboos, L. Huang, N. Dryden, T. Ben-Nun, P . Dueben,
L. Gianinazzi, L. Kummer, and T. Hoefler, “Ens-10: A dataset for
post-processing ensemble weather forecasts,” Advances in Neural
Information Processing Systems, vol. 35, pp. 21 974–21 987, 2022.
[326] S. Peng, Y. Ding, W. Liu, and Z. Li, “1 km monthly temperature
and precipitation dataset for china from 1901 to 2017,” Earth
System Science Data, vol. 11, no. 4, pp. 1931–1946, 2019.
[327] A. Kitamoto, J. Hwang, B. Vuillod, L. Gautier, Y. Tian, and
T. Clanuwat, “Digital typhoon: Long-term satellite image dataset
for the spatio-temporal modeling of tropical cyclones,” arXiv
preprint arXiv:2311.02665, 2023.
[328] M. Sit, B.-C. Seo, and I. Demir, “Iowarain: A statewide rain event
dataset based on weather radars and quantitative precipitation
estimation,” arXiv preprint arXiv:2107.03432, 2021.
[329] S. Wang, Y. Li, J. Zhang, Q. Meng, L. Meng, and F. Gao, “Pm2.
5-gnn: A domain knowledge enhanced graph neural network
for pm2. 5 forecasting,” in Proceedings of the 28th international
conference on advances in geographic information systems , 2020, pp.
163–166.
[330] X. Chen, K. Feng, N. Liu, Y. Lu, Z. Tong, B. Ni, Z. Liu, and
N. Lin, “Rainnet: a large-scale dataset for spatial precipitation
downscaling,” arXiv preprint arXiv:2012.09700, 2020.
[331] R. Kurinchi-Vendhan, “Continental united states solar irradi-
ance,” 9 2021.
[332] C. Requena-Mesa, V . Benson, M. Reichstein, J. Runge, and J. Den-
zler, “Earthnet2021: A large-scale dataset and challenge for earth
surface forecasting as a guided video prediction task.” in Pro-
ceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 2021, pp. 1132–1142.
[333] T. Kim, N. Ho, D. Kim, and S.-Y. Yun, “Benchmark dataset
for precipitation forecasting by post-processing the numerical
weather prediction,” arXiv preprint arXiv:2206.15241, 2022.
[334] M. Paulat, C. Frei, M. Hagen, and H. Wernli, “A gridded dataset
of hourly precipitation in germany: Its construction, climatology
and application,” Meteorologische Zeitschrift, vol. 17, pp. 719–732,
2008.
[335] Y. Tang, J. Zhou, X. Pan, Z. Gong, and J. Liang, “Postrainbench:
A comprehensive benchmark and a new model for precipitation
forecasting,” 2023.
[336] G. Larvor, L. Berthomier, V . Chabot, B. Le Pape, B. Pradel, and
L. Perez, “Meteonet, an open reference weather dataset by meteo-
france,” 2020.
[337] Y. Choi, K. Cha, M. Back, H. Choi, and T. Jeon, “Rain-f+: The data-
driven precipitation prediction model for integrated weather
observations,” Remote Sensing, vol. 13, no. 18, p. 3627, 2021.
[338] C. S. de Witt, C. Tong, V . Zantedeschi, D. De Martini, A. Kalaitzis,
M. Chantry, D. Watson-Parris, and P . Bilinski, “Rainbench: To-
wards data-driven global precipitation forecasting from satellite
imagery,” in Proceedings of the AAAI Conference on Artificial Intelli-
gence, vol. 35, no. 17, 2021, pp. 14 902–14 910.
[339] T. Diggelmann, J. Boyd-Graber, J. Bulian, M. Ciaramita, and
M. Leippold, “Climate-fever: A dataset for verification of real-
world climate claims,” 2021.
[340] T. Laud, D. Spokoyny, T. Corringham, and T. Berg-Kirkpatrick,
“Climabench: A benchmark dataset for climate change text un-
derstanding in english,” arXiv preprint arXiv:2301.04253, 2023.
[341] R. Vaid, K. Pant, and M. Shrivastava, “Towards fine-grained
classification of climate change related social media text,” in
Proceedings of the 60th Annual Meeting of the Association for Compu-
tational Linguistics: Student Research Workshop, 2022, pp. 434–443.
[342] P . Mishra and R. Mittal, “Neuralnere: Neural named entity
relationship extraction for end-to-end climate change knowledge
graph construction,” in ICML 2021 Workshop on Tackling
Climate Change with Machine Learning , 2021. [Online]. Available:
https://www.climatechange.ai/papers/icml2021/76
[343] K. E. Trenberth and J. G. Olson, “An evaluation and intercompar-
ison of global analyses from the national meteorological center
and the european centre for medium range weather forecasts,”
Bulletin of the American Meteorological Society , vol. 69, no. 9, pp.
1047–1057, 1988.
[344] J. A. Carton and B. S. Giese, “Soda: A reanalysis of ocean climate,”
J. Geophys. Res., submitted, 2005.
[345] Y. Choi, K. Cha, M. Back, H. Choi, and T. Jeon, “Rain-f: A
fusion dataset for rainfall prediction using convolutional neural
network,” in 2021 IEEE International Geoscience and Remote Sensing
Symposium IGARSS. IEEE, 2021, pp. 7145–7148.
[346] J. E. Johnson, Q. Febvre, A. Gorbunova, S. Metref, M. Ballarotta,
J. L. Sommer, and R. Fablet, “Oceanbench: The sea surface height
edition,” 2023.
[347] P . Bommer, M. Kretschmer, A. Hedstr ¨om, D. Bareeva, and
M. M. C. H ¨ohne, “Finding the right xai method – a guide for
38
the evaluation and ranking of explainable ai methods in climate
science,” 2023.
[348] L. Li, Y. Fan, M. Tse, and K.-Y. Lin, “A review of applications in
federated learning,” Computers & Industrial Engineering , vol. 149,
p. 106854, 2020.
[349] L. Wang, X. Zhang, H. Su, and J. Zhu, “A comprehensive survey
of continual learning: Theory, method and application,” arXiv
preprint arXiv:2302.00487, 2023.
[350] S. Chen, X. Wang, S. Ren, J. Yang, Y. Zhang, and G. Wang,
“Collaborative photonic crystal fiber property optimization: A
new paradigm for reverse design,” IEEE Photonics Technology
Letters, 2023.