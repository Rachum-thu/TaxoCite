title: 'PRUC : P-Regions with User-Defined Constraint'
blocks:
- block_id: 0
  content: 'This paper introduces a generalized spatial regionalization problem, namely, PRUC (ğ‘ƒ-Regions with User-defined
    Constraint) that partitions spatial areas into homogeneous regions. PRUC accounts for user-defined constraints imposed
    over aggregate region properties. We show that PRUC is an NP-Hard problem. To solve PRUC, we introduce GSLO (Global Search
    with Local Optimization), a parallel stochastic regionalization algorithm. GSLO is composed of two phases: (1) Global
    Search that initially partitions areas into regions that satisfy a user-defined constraint, and (2) Local Optimization
    that further improves the quality of the partitioning with respect to intra-region similarity. We conduct an extensive
    experimental study using real datasets to evaluate the performance of GSLO. Experimental results show that GSLO is up
    to 100Ã— faster than the state-of-the-art algorithms. GSLO provides partitioning that is up to 6Ã— better with respect to
    intra-region similarity. Furthermore, GSLO is able to handle 4Ã— larger datasets than the state-of-the-art algorithms.'
  citations: []
- block_id: 1
  content: "Spatial regionalization is an important problem that aims at partitioning spatial areas into regions based on\
    \ specific criteria. Spatial areas assigned to a region need to be spatially contiguous. Spatial regionalization has been\
    \ adopted in numerous applications and domains, such as economics, e.g., imbalance in economic development [44], urban\
    \ planning [24, 56], e.g., resource allocation in urban construction [24], environmental science [54, 55], e.g., understanding\
    \ of environmental patterns in different geographical locations [55].\n\nSpatial regionalization has multiple variations\
    \ that are studied in the literature [3, 4, 6, 8, 9, 34, 35]. The \U0001D45D-regions problem [15, 17] is a popular spatial\
    \ regionalization problem that partitions areas into \U0001D45D regions while maximizing the intra-region similarity with\
    \ respect to a numerical attribute. For example, in urban planning, each area could be a municipality, and a region is\
    \ a group of spatial contiguous municipalities. Maximization of the similarity of household income among municipalities\
    \ within regions is an example of the numerical attribute. One important requirement of spatial regionalization is to\
    \ account for user-defined constraints over regions. A typical use case in urban planning is to partition areas into a\
    \ predefined number of regions where the total population of every region exceeds a specific threshold. Existing variations\
    \ of the \U0001D45D-regions problem do not support user-defined constraints, which limit its applicability to various\
    \ domains and a plethora of use cases.\n\nIn this paper, we formalize a generalized spatial regionalization problem, namely,\
    \ PRUC (\U0001D443-Regions with User-defined Constraint). PRUC aims to partition a set of areas into a predefined number\
    \ of regions p while maximizing the similarity over a specific attribute, e.g., the household income. In PRUC, each region\
    \ needs to satisfy a user-defined constraint on some aggregate attribute, e.g., the total population of each region needs\
    \ to exceed a specific threshold.\n\nPRUC is a generalization of the \U0001D45D-regions problem. The reason is that PRUC\
    \ has the same optimization goal as the \U0001D45D-regions problem, but it enforces an additional user-defined threshold\
    \ constraint on each region. The new input user-defined constraint in PRUC has introduced several challenges on building\
    \ initial regions. First, existing techniques have a high probability, up to 80%, of producing regions that do not satisfy\
    \ the input constraint. Second, producing valid solutions requires significant shuffling of spatial areas among initial\
    \ regions so that invalid regions become valid but not the opposite. This adds a restrictive requirement on the spatial\
    \ connectivity as regions that are vulnerable to spatial disconnection with shuffling retain the high probability of producing\
    \ invalid solutions. Third, the additional overhead of producing valid solutions inflates the scalability problem and\
    \ makes it harder to handle large datasets.\n\nTo address these challenges, we propose an efficient parallel algorithm\
    \ called GSLO (Global Search with Local Optimization) to solve PRUC at scale. GSLO is stochastic and its results may vary\
    \ on different runs. GSLO is composed of two phases: (1) Global Search and (2) Local Optimization. The Global Search phase\
    \ proposes novel techniques to find a partitioning that satisfies the user-defined constraint with high probability of\
    \ success. The regions grown in GSLO are robust against spatial disconnection and have a high probability of surviving\
    \ the shuffling phase. The shuffling phase consists of two complementary steps that boost the probability of success.\
    \ The Local Optimization phase employs parallel stages that incrementally improve the quality of the partitioning with\
    \ respect to the similarity properties within each region.\n\nThere are two main approaches to build partitions, top-down\
    \ edge-cut and bottom-up seeding. Top-down edge cut approaches [3, 4] are time-consuming and less flexible. They are time-consuming\
    \ because they evaluate the effect of each edge cut on the entire graph and less flexible because once the edges are cut,\
    \ there is no following reassignment of areas to regions to further optimize the objective of the regionalization. GSLO\
    \ is a bottom-up seeding-based algorithm that can efficiently grow regions around seed areas locally, which breaks down\
    \ the big problem into several smaller ones. The novel contributions of this paper are summarized as follows:\n\n- We\
    \ introduce a generalized spatial regionalization problem, namely, \U0001D443-regions with User-defined Constraint (PRUC).\n\
    - We show that PRUC is an NP-Hard problem.\n- We develop GSLO, an efficient parallel algorithm that solves PRUC with several\
    \ novel techniques as follows.\n  - A general seeding strategy that does not require any domain knowledge.\n  - A region\
    \ growth algorithm that maximizes the flexibility of the assignment of areas to regions.\n  - Two novel complementary\
    \ inter-region shuffling strategies that increase the ability of finding a feasible solution.\n  - Heuristic search strategies\
    \ to speed up optimizing the final solution and provide region-level parallelization.\n- We conduct an extensive experimental\
    \ evaluation using real datasets.\n\nOur extensive experimental study shows that GSLO runs up to 100Ã— faster, achieves\
    \ up to 6Ã— better solution quality, and scales up to 4Ã— larger datasets than the state-of-the-art algorithms. The rest\
    \ of this paper is organized as follows: Section 2 presents the related work on spatial regionalization. Section 3 defines\
    \ the problem, and Section 4 proves it is an NP-hard problem. Section 5 details our proposed algorithm GSLO. Section 6\
    \ analyzes the complexity of GSLO. Section 7 presents an extensive experimental evaluation and Section 8 concludes the\
    \ paper."
  citations:
  - marker: '[44]'
    intent_label: Prospective Application
    topic_label: regionalization
  - marker: '[24, 56]'
    intent_label: Prospective Application
    topic_label: regionalization
  - marker: '[24]'
    intent_label: Prospective Application
    topic_label: regionalization
  - marker: '[54, 55]'
    intent_label: Prospective Application
    topic_label: regionalization
  - marker: '[55]'
    intent_label: Prospective Application
    topic_label: regionalization
  - marker: '[3, 4, 6, 8, 9, 34, 35]'
    intent_label: Prior Methods
    topic_label: regionalization
  - marker: '[15, 17]'
    intent_label: Problem Formulation
    topic_label: p-regions formulations
  - marker: '[3, 4]'
    intent_label: Prior Methods
    topic_label: Top-down divisive edge-removal methods
- block_id: 2
  content: 'Spatial regionalization [3, 4, 8, 9, 14, 16, 27, 34] refers to the problem of grouping spatial areas into multiple
    regions that are spatially contiguous. There are several variations of the spatial regionalization problem. The ğ‘-regions
    problem [15] finds ğ‘ regions that maximize the similarity between areas within a region. The ğ‘-compact regions problem
    [35] finds ğ‘ regions that maximize the spatial compactness. The max-ğ‘ regions problem [14] computes a maximal-sized partitioning
    that maximizes the similarity between areas within a region. PRUC is a generalization of the ğ‘-regions problem that enforces
    user-defined constraints.


    Traditional clustering algorithms, e.g., k-means [37], are not directly applicable in spatial regionalization problems,
    as they are mainly designed for points rather than polygons and they do not enforce spatial contiguity that is required
    in spatial regionalization. Some techniques have tried to adapt them for regionalization in different contexts [18, 40,
    51]. However, the lack of enforcing spatial contiguity constraints early in the algorithm makes it harder to scale for
    large datasets. To this end, the following approaches have been proposed to address spatial regionalization: (1) linear
    programming, (2) graph partitioning, and (3) seeding.


    Duque et al. [15] transforms a spatial regionalization problem into a mixed integer programming (MIP) problem that can
    be solved using software package such as CPLEX [12]. However, this approach works only for tiny datasets. Hence, this
    approach is not suited to address PRUC over large inputs.


    Graph-partitioning is used in SKATER [3] and SKATER-CON [4] as the state-of-the-art techniques to address the ğ‘-regions
    problem. In this approach, graph nodes represent spatial areas and edges connect spatially contiguous areas. In SKATER,
    a minimum spanning tree (MST) is computed from the graph. The MST is then split into ğ‘ subtrees, each corresponding to
    one of the ğ‘ regions. However, the greedy approach adopted in MST generation results in suboptimal regions with low quality.
    Also, SKATER is computationally expensive and cannot handle large inputs. SKATERCON [4] enhances SKATER by generating
    multiple random spanning trees (RST). SKATER is then applied to all RSTs to generate multiple regionalization results.
    The different results are combined into a single solution using a consensus-based method [26]. SKATERCON is slower than
    SKATER, and cannot handle large inputs. Neither SKATER nor SKATERCON can be directly applied to solve PRUC as they do
    not support user-defined constraints.


    Seeding is an important category of spatial regionalization algorithms. In seeding, multiple spatial areas are chosen
    as seeds for spatial regions. Then, regions grow around seeds by incrementally adding neighboring areas. REGAL [9] and
    SPATIAL [8] are two seeding algorithms that have been tailored to solve the school redistricting problem, so they cannot
    be used to solve PRUC. The reason is that they do not support general user-defined constraints. MERGE [35] is a seeding
    framework for solving the ğ‘-compact regions problem. However, MERGE cannot be used to solve PRUC as it is tailored to
    the ğ‘-compact regions problem and does not support user-defined constraints as well.


    Recently, parallelization has been adopted to speedup spatial regionalization algorithms. Laura et al. [33] introduced
    a parallel algorithm to solve the ğ‘-compact-regions problem. Also, Sindhu et al. [48] used a parallel algorithm to address
    the max-ğ‘ regions problem. Similarly, GSLO is a parallel algorithm to make the best use of multi-core environments.'
  citations:
  - marker: '[3, 4, 8, 9, 14, 16, 27, 34]'
    intent_label: Domain Overview
    topic_label: regionalization
  - marker: '[15]'
    intent_label: Research Gap
    topic_label: p-regions formulations
  - marker: '[35]'
    intent_label: Research Gap
    topic_label: Bottom-up seeded agglomeration
  - marker: '[14]'
    intent_label: Domain Overview
    topic_label: max-p regions formulations
  - marker: '[37]'
    intent_label: Research Gap
    topic_label: Conventional clustering with post hoc contiguity checks
  - marker: '[18, 40, 51]'
    intent_label: Research Gap
    topic_label: Conventional clustering with post hoc contiguity checks
  - marker: '[12]'
    intent_label: Prior Methods
    topic_label: Exact optimization models
  - marker: '[3]'
    intent_label: Research Gap
    topic_label: Top-down divisive edge-removal methods
  - marker: '[4]'
    intent_label: Research Gap
    topic_label: Top-down divisive edge-removal methods
  - marker: '[26]'
    intent_label: Prior Methods
    topic_label: Heuristic concentration and model reduction
  - marker: '[9]'
    intent_label: Research Gap
    topic_label: Bottom-up seeded agglomeration
  - marker: '[8]'
    intent_label: Research Gap
    topic_label: Bottom-up seeded agglomeration
  - marker: '[33]'
    intent_label: Prior Methods
    topic_label: regionalization
  - marker: '[48]'
    intent_label: Prior Methods
    topic_label: max-p regions formulations
- block_id: 3
  content: 'In this section, we give a formal definition of PRUC. Table 2 summarizes the notations used throughout this paper.
    Spatial regionalization is the problem of partitioning spatial areas into non-overlapping regions while satisfying specific
    constrains. An area, say ğ‘, is a spatial polygon that is represented by a set of geographical coordinates, i.e., longitude
    and latitude. Two areas are neighbors if they share a common border. The list of neighbor areas of an area, say ğ‘ğ‘–, is
    represented as ğ‘ğ‘–.ğ‘ğµğ‘…ğ´.


    A region, say ğ‘Ÿ, is a set of spatially contiguous areas {ğ‘ğ‘–, ğ‘ğ‘—, ...}. Each ğ‘Ÿ has a unique identifier ğ‘Ÿ.ğ‘–ğ‘‘. Figure 1,
    shows spatial areas that are partitioned into regions, where areas having the same color constitute a region. Each spatial
    area is associated with numerical attributes, e.g., population and household income as shown in Table 1. We denote the
    attribute used to quantify the similarity among areas as the similarity attribute, i.e., ğ‘ğ‘–.ğ‘ ğ‘–ğ‘š. For example, in Figure
    1, the average household income of an area is the similarity attribute. This attribute is used to group areas into regions
    having similar household income. We call the attribute used in region constraints the extensive attribute. The extensive
    attribute of an area, say ğ‘ğ‘–, is represented as ğ‘ğ‘–.ğ‘’ğ‘¥ğ‘¡. In Figure 1, ğ‘ğ‘–.ğ‘’ğ‘¥ğ‘¡ is the population. For example, ğ‘1.ğ‘’ğ‘¥ğ‘¡ = 210.
    The region to which an area, say ğ‘, belongs to is termed ğ‘.ğ‘Ÿ. The aggregate extensive attribute of region ğ‘Ÿ is represented
    as ğ‘Ÿ.ğ‘’ğ‘¥ğ‘¡, that is defined as the sum of the extensive attribute over all the areas in the region. In Figure 1, the extensive
    attribute of the green region refers to the total population of this region, which is computed as ğ‘Ÿğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘›.ğ‘’ğ‘¥ğ‘¡ = ğ‘5.ğ‘’ğ‘¥ğ‘¡
    + ğ‘6.ğ‘’ğ‘¥ğ‘¡ + ğ‘7.ğ‘’ğ‘¥ğ‘¡ + ğ‘8.ğ‘’ğ‘¥ğ‘¡ = 610.


    The set of neighbor areas of a region ğ‘Ÿ, i.e., ğ‘Ÿ.ğ‘ğµğ‘…ğ´, is defined as the set of areas that do not belong to ğ‘Ÿ and are
    neighbor to at least one area in ğ‘Ÿ. In Figure 1, ğ‘Ÿğ‘Ÿğ‘’ğ‘‘.ğ‘ğµğ‘…ğ´ = {ğ‘5, ğ‘6, ğ‘7, ğ‘8}. Formally, ğ‘Ÿ.ğ‘ğµğ‘…ğ´ = {ğ‘ | âˆƒğ‘ğ‘– (ğ‘ğ‘–.ğ‘Ÿ = ğ‘Ÿ.ğ‘–ğ‘‘
    âˆ§ ğ‘.ğ‘Ÿ â‰  ğ‘ğ‘–.ğ‘Ÿ âˆ§ ğ‘ğ‘– âˆˆ ğ‘.ğ‘ğµğ‘…ğ´)}.


    The set of neighbor regions of an area, i.e., ğ‘.ğ‘ğµğ‘…ğ‘…, is defined as the set of regions that have at least one area ğ‘ğ‘–
    within the region that is a neighbor area of ğ‘. In Figure 1, the neighbor regions of ğ‘6 = {ğ‘Ÿğ‘Ÿğ‘’ğ‘‘, ğ‘Ÿğ‘ğ‘™ğ‘¢ğ‘’}. Formally, ğ‘.ğ‘ğµğ‘…ğ‘…
    = {ğ‘Ÿ | âˆƒğ‘ğ‘– (ğ‘ğ‘–.ğ‘Ÿ = ğ‘Ÿ.ğ‘–ğ‘‘ âˆ§ ğ‘.ğ‘Ÿ â‰  ğ‘Ÿ.ğ‘–ğ‘‘ âˆ§ ğ‘ğ‘– âˆˆ ğ‘.ğ‘ğµğ‘…ğ´)}.


    The set of margin areas of a region, say ğ‘Ÿ, is defined as the set of areas that have at least one neighbor area that belongs
    to a neighbor region or is unassigned. In Figure 1, all of the areas in ğ‘Ÿğ‘Ÿğ‘’ğ‘‘ are margin areas because they have at least
    one neighbor area that belongs to a neighbor region. Formally, ğ‘Ÿ.ğ‘šğ‘ğ‘Ÿğ‘”ğ‘–ğ‘› = {ğ‘ | ğ‘.ğ‘Ÿ = ğ‘Ÿ.ğ‘–ğ‘‘ âˆ§ âˆƒğ‘ğ‘– (ğ‘ğ‘– âˆˆ ğ‘.ğ‘ğµğ‘…ğ´ âˆ§ ğ‘ğ‘–.ğ‘Ÿ â‰ 
    ğ‘.ğ‘Ÿ)}.


    An area is considered an articulation area if removing this area disconnects its region, i.e., areas of the region are
    not contiguous. The set of articulation areas in ğ‘Ÿ is represented as ğ‘Ÿ.ğ‘ğ‘Ÿğ‘¡. In Figure 1, ğ‘Ÿğ‘Ÿğ‘’ğ‘‘.ğ‘ğ‘Ÿğ‘¡ = {ğ‘2, ğ‘3}, since removing
    any of them breaks the regionâ€™s contiguity.


    A user-defined constraint is a numerical constraint that all regions must satisfy. In Figure 1, the user-defined constraint
    is that the aggregate population of each region must be at least 500. A region is incomplete if it does not satisfy the
    user-defined constraint and complete if it does.


    A partition, say ğ‘ƒ, of a set of areas is the set of regions {ğ‘Ÿ1, ğ‘Ÿ2, ..., ğ‘Ÿğ‘} that includes all areas. Each area belongs
    to only one region. ğ‘ƒ is feasible if all its regions are complete, i.e., satisfy the user-defined constraint.


    Heterogeneity is inversely proportional to the similarity among areas. The heterogeneity of ğ‘ğ‘– and ğ‘ğ‘— reflects the degree
    of dissimilarity between ğ‘ğ‘– and ğ‘ğ‘— and it is defined as the absolute difference between the similarity attribute of the
    two areas:

    â„(ğ‘ğ‘–, ğ‘ğ‘—) = |ğ‘ğ‘–.ğ‘ ğ‘–ğ‘š âˆ’ ğ‘ğ‘—.ğ‘ ğ‘–ğ‘š|

    The heterogeneity of a region, say ğ‘Ÿ, is defined as the heterogeneity sum of all pairs of areas in ğ‘Ÿ:

    â„(ğ‘Ÿ) = âˆ‘ï¸ âˆ€ğ‘–<ğ‘—,ğ‘ğ‘–.ğ‘Ÿ=ğ‘ğ‘—.ğ‘Ÿ=ğ‘Ÿ.ğ‘–ğ‘‘ â„(ğ‘ğ‘–, ğ‘ğ‘—)

    The heterogeneity of a partition â„(ğ‘ƒ) is defined as the sum of the heterogeneity of all the regions: â„(ğ‘ƒ) = âˆ‘ï¸ âˆ€ğ‘Ÿ âˆˆ ğ‘ƒ
    â„(ğ‘Ÿ).


    A good partition has low heterogeneity and high intra-region similarity.


    PRUC Problem. P-Regions with User-Defined Constraint (PRUC) problem is formally defined as follows: Given: (1) A set of
    ğ‘› areas: ğ´ = {ğ‘1, ğ‘2, ..., ğ‘ğ‘›}. (2) An integer ğ‘. (3) A threshold ğ‘‡. PRUC finds a partition of regions ğ‘ƒ = {ğ‘Ÿ1, ğ‘Ÿ2, ...,
    ğ‘Ÿğ‘} of size ğ‘, where each region ğ‘Ÿğ‘– is a non-empty set of spatially continuous areas, |ğ‘Ÿğ‘–| â‰¥ 1, so that: (i) ğ‘Ÿğ‘– âˆ© ğ‘Ÿğ‘— =
    Î¦, âˆ€ğ‘Ÿğ‘–, ğ‘Ÿğ‘— âˆˆ ğ‘ƒ âˆ§ ğ‘– â‰  ğ‘—, i.e., all regions are disjoint. (ii) â‹ƒğ‘ğ‘–=1 ğ‘Ÿğ‘– = ğ´. (iii) ğ‘Ÿğ‘–.ğ‘’ğ‘¥ğ‘¡ > ğ‘‡. (iv) The heterogeneity of
    ğ‘ƒ, â„(ğ‘ƒ), is minimum.'
  citations: []
- block_id: 4
  content: 'In this section, we provide a proof for the NP-hardness of PRUC problem using a reduction from the Node-attributed
    Spatial Graph Partitioning (NSGP) problem [6]. NSGP is an NP-Hard problem that aims to partition a node-attributed spatial
    graph into ğ‘˜ subgraphs. The number of nodes in each subgraph must exceed a specific threshold. The nodes of this graph
    represent spatial locations and each node has an associated set of attributes. The objective of the NSGP is to minimize
    the heterogeneity of the generated subgraphs and the number of edges with endpoints belonging to different subgraphs.


    Let ğ‘‹ be an instance of NSGP problem and ğ‘‹ = (ğ´, ğ¸, ğ‘, ğ‘˜, ğ‘ , ğ‘”) where ğ´ is the set of spatial areas, ğ¸ is the set of neighborhood
    relations, ğ‘ is the set of node attributes, ğ‘˜ is the number of subgraphs, ğ‘  is the minimum number of nodes in a subgraph,
    and ğ‘” is the optimization goal of NSGP. Let ğ‘Œ be an instance of PRUC problem and ğ‘Œ = (ğ´, ğ‘, ğ‘‡, ğ‘“) where ğ´ is the set of
    spatial areas, ğ‘ is the predefined number of regions, and ğ‘‡ is the user-defined threshold. ğ‘“ is the optimization goal
    of PRUC. We make ğ‘“ to be the same as ğ‘” (Note that changing the optimization goal in PRUC would not affect the way it works).
    We set the extensive attribute of each area in ğ´ to 1, and set ğ‘ equal to ğ‘˜ in the NSGP problem. Thus ğ‘‹ is a special case
    of ğ‘Œ, and we construct ğ‘Œ from ğ‘‹ in polynomial time, hence the proof.'
  citations:
  - marker: '[6]'
    intent_label: Problem Formulation
    topic_label: p-regions formulations
- block_id: 5
  content: We introduce Global Search with Local Optimization (GSLO), a two-phase algorithm to efficiently address PRUC. The
    Global Search phase aims to find a feasible partition. Local optimization aims to further improve the heterogeneity over
    the partition without violating the user-defined constraint.
  citations: []
- block_id: 6
  content: 'The Global Search phase aims to find a feasible partition with high probability of success. This phase is divided
    into the following steps: Seed Identification, Region Growth, Enclaves Assignment, Inter-region Update, and Indirect Flow
    Push. Each step is optimized to increase the probability of successfully finding a feasible partition. The rest of this
    section details each step.


    #### 5.1.1 Seed Identification

    A seed, say ğ‘ , is a set of ğ‘ areas, i.e., ğ‘  = [ğ‘1, ...ğ‘ğ‘]. Regions incrementally grow by attaching unassigned neighbor
    areas to the seed areas. The seeding-based regionalization literature [8, 9, 14, 33â€“35, 53] either selects seed areas
    randomly [14, 33â€“35, 53] or selects the seed areas manually according to problem-specific guidelines [8, 9]. In this section,
    we propose a general seeding method that does not require any domain knowledge. Having seed areas close to each other
    can restrict the growth of regions and increase the probability of failure. Hence, the objective is to select a seed whose
    areas are scattered. The distance between ğ‘ğ‘– and ğ‘ğ‘— refers to the euclidean distance between the centroids of ğ‘ğ‘– and ğ‘ğ‘—
    and is represented as ğ‘‘ğ‘–ğ‘ ğ‘¡(ğ‘ğ‘–, ğ‘ğ‘—). The quality ğ‘(ğ‘ ) of a seed ğ‘  is defined as the minimum euclidean distance between
    the centroids of all pairs of areas in ğ‘ .


    ğ‘(ğ‘ ) = min ğ‘ğ‘– âˆˆğ‘  âˆ§ ğ‘ğ‘— âˆˆğ‘  âˆ§ ğ‘–â‰ ğ‘— ğ‘‘ğ‘–ğ‘ ğ‘¡(ğ‘ğ‘–, ğ‘ğ‘—)


    The objective is to maximize ğ‘(ğ‘ ). First, ğ‘ areas are selected randomly as the seed. The pair of seed areas having the
    least pairwise distance, say (ğ‘ğ‘–, ğ‘ğ‘—), is identified. Then, an area that does not belong to the seed is chosen at random
    to replace one of the areas (ğ‘ğ‘–, ğ‘ğ‘—). The replacement takes place only when there is improvement in ğ‘(ğ‘ ). The last step
    is repeated ğ‘š times, where ğ‘š is a user-defined parameter.


    The above Seed Identification algorithm assumes no islands present in the dataset, i.e., there is only one connected component.
    To support datasets with islands, first, we run a graph traversal algorithm on the spatial neighborhood graph to detect
    different connected components. We then compute the total extensive attribute on each connected component. If the total
    extensive attribute of any island is less than the user-defined constraint value, then the current user-defined constraint
    cannot be solved. Otherwise, the connected components are sorted in ascending order according to their total extensive
    attribute, i.e., âˆ€0 < ğ‘– < ğ‘— â‰¤ ğ¶, ğ‘ğ‘ğ‘–.ğ‘’ğ‘¥ğ‘¡ â‰¤ ğ‘ğ‘ğ‘—.ğ‘’ğ‘¥ğ‘¡, where ğ¶ is the number of connected components, ğ‘ğ‘ğ‘– is the ğ‘–th component,
    and ğ‘ğ‘ğ‘–.ğ‘’ğ‘¥ğ‘¡ is ğ‘ğ‘ğ‘–â€™s extensive attribute. Starting from ğ‘ğ‘1, for each component ğ‘ğ‘ğ‘–, we put a number of seed areas proportional
    to the ratio of ğ‘ğ‘ğ‘–.ğ‘’ğ‘¥ğ‘¡ divided by the total extensive attribute of the whole input, where at least one seed area is placed
    in each component ğ‘ğ‘ğ‘–. In each connected component, we perform a number of iterations that are proportional to its number
    of seed areas to scatter seed areas in space as described above.


    The Seed Identification phase aims to find spatially scattered seed areas. There are several metrics that can be used
    to quantify seed quality, i.e., scatteredness of the seed, e.g., sum of pairwise distance or minimum pairwise distance
    between seed areas. We choose minimum pairwise distance between seed areas as it guarantees that no pair of seed areas
    are close to each other. Other metrics may result in nearby seed areas that restrict region growth. Figure 4 shows that
    as the seed quality monotonically increases, the heterogeneity of the partition improves and converges to an optimal value.


    Complexity analysis. Seed identification performs ğ‘š iterations to improve the seed quality. The number of seed areas is
    ğ‘, each iteration takes ğ‘‚(ğ‘2) time, which gives a total time of ğ‘‚(ğ‘šğ‘2).


    Remark 5.1. Time complexity of Seed Identification is ğ‘‚(ğ‘šğ‘2).


    #### 5.1.2 Region Growth

    After the Seed Identification step, the seed areas become the initial ğ‘ regions that will subsequently grow. A growing
    step of a region, say ğ‘Ÿ, adds one of the unassigned areas from neighbor areas, i.e., ğ‘Ÿ.ğ‘ğµğ‘…ğ´ to ğ‘Ÿ. A region ğ‘Ÿ stops growing
    when: (1) ğ‘Ÿ satisfies the user-defined constraint, i.e., becomes a complete region, or (2) all the neighbor areas of ğ‘Ÿ
    are assigned to other regions. If the user-defined constraint is not met for a region, the region is marked incomplete.
    The region with the least extensive attribute is chosen for each growing step in order to achieve a balanced distribution
    on the extensive attribute over each region.


    Having many articulation areas in regions restricts the movement of areas across regions. This hinders the ability to
    find a feasible partition or the refinement of the partition in Local Optimization. So, a main objective of this step
    is minimizing the number of articulation areas in the partition. We define the robustness of a region, say ğ‘Ÿ, to be the
    number of areas in its margin, i.e., ğ‘Ÿ.ğ‘šğ‘ğ‘Ÿğ‘”ğ‘–ğ‘› divided by the number of articulation areas in ğ‘Ÿ.ğ‘šğ‘ğ‘Ÿğ‘”ğ‘–ğ‘›. The greater the
    robustness of a region, the less likely ğ‘Ÿ becomes disconnected while attempting to move an area to the neighbor region.


    Region Growth algorithm grows regions while attempting to increase their robustness. A basic approach would be to iterate
    over all the unassigned areas of ğ‘Ÿ.ğ‘ğµğ‘…ğ´ and choose the area that gives the greatest increase in the robustness of ğ‘Ÿ. However,
    identifying the articulation areas for every growing step is rather expensive. To this end, we adopt an approximate approach
    to find areas to be added to regions that improves the robustness of regions. We define the connectivity between a region
    ğ‘Ÿ and an area ğ‘ as the number of neighbor areas of ğ‘ that belong to ğ‘Ÿ.


    ğ‘ğ‘œğ‘›ğ‘›(ğ‘, ğ‘Ÿ) = |{ğ‘ğ‘– | ğ‘ğ‘–.ğ‘Ÿ = ğ‘Ÿ.ğ‘–ğ‘‘ âˆ§ ğ‘ğ‘– âˆˆ ğ‘.ğ‘ğµğ‘…ğ´}|


    Region Growth algorithm grows a region, say ğ‘Ÿ, by choosing the neighbor area, say ğ‘, that has the greatest connectivity,
    i.e., ğ‘ğ‘œğ‘›ğ‘›(ğ‘, ğ‘Ÿ). We call this area ğ‘ğ‘Ÿğ‘ğ‘’ğ‘ ğ‘¡. Ties are broken arbitrarily.


    Region Growth phase aims at building robust regions that provide reassignment flexibility rather than focusing only on
    heterogeneity. Region robustness is achieved by reducing the number of articulation areas. So, the region sustains its
    spatial connectivity even after moving areas to another region. This allows flexibility in area reassignments across regions
    in subsequent phases of GSLO, and leads to improved effectiveness and heterogeneity.


    Complexity analysis. The Region Growth phase incrementally grows the regions from the seed areas. Assume ğ‘(ğ‘Ÿ) denotes
    the number of areas in region ğ‘Ÿ, and ğ‘Ÿğ‘– denotes the region that is selected to grow in the ğ‘–th iteration. In each iteration,
    retrieving the region with the minimum ğ‘Ÿ.ğ‘’ğ‘¥ğ‘¡ takes ğ‘‚(ğ‘). For a growing region ğ‘Ÿ, we need to evaluate all its unassigned
    neighbor areas. Spatial neighborhood relations of areas are represented with a planar graph where nodes are areas and
    an edge exists between any pair of neighbor areas. Since the average degree of the vertices in a planar graph is strictly
    less than six [50], this implies: (i) the size of ğ‘Ÿ.ğ‘ğµğ‘…ğ´ is ğ‘‚(6ğ‘(ğ‘Ÿ)) = ğ‘‚(ğ‘(ğ‘Ÿ)), and (ii) computing ğ‘ğ‘œğ‘›ğ‘›(ğ‘, ğ‘Ÿ), for ğ‘ âˆˆ
    ğ‘Ÿ.ğ‘ğµğ‘…ğ´, is ğ‘‚(1). Meanwhile, computing the heterogeneity increase of ğ‘ to ğ‘Ÿ requires time ğ‘‚(ğ‘(ğ‘Ÿ)) because we need to compute
    the heterogeneity between ğ‘ and all areas in ğ‘Ÿ. Consequently, in each iteration, growing a region ğ‘Ÿ takes time ğ‘‚(ğ‘(ğ‘Ÿ))
    + ğ‘‚(ğ‘). Region Growth phase performs in total ğ‘‚(ğ‘›) iterations, each adds an area to a region. Then, the total runtime
    of Region Growth phase is (âˆ‘ğ‘›ğ‘–=1 ğ‘‚(ğ‘(ğ‘Ÿğ‘–)) + ğ‘‚(ğ‘)), where 1 < ğ‘(ğ‘Ÿğ‘–) < ğ‘›, which is ğ‘‚(ğ‘›2) + ğ‘‚(ğ‘›ğ‘) = ğ‘‚(ğ‘›2).


    Remark 5.2. Time complexity of Region Growth phase is ğ‘‚(ğ‘›2).


    #### 5.1.3 Enclaves Assignment

    After the Region Growth step, some areas may remain unassigned. The reason is that Region Growth of a region terminates
    when it satisfies the user-defined constraint. This can prevent some areas from being assigned to regions. We name the
    remaining unassigned areas enclaves. In Enclaves Assignment, all enclaves are identified and processed one by one. The
    intuition of Enclaves Assignment is rather straightforward. An enclave area is assigned to a region that minimizes heterogeneity
    increase to keep the overall heterogeneity score at its minimum level before the Local Optimization phase. If an enclave,
    say ğ‘, is surrounded by only enclaves, it can not be assigned to any neighbor region at this moment. The assignment of
    ğ‘ is delayed until some or all surrounding enclaves have been assigned to regions. If ğ‘ is surrounded by one or more complete
    regions, we assign this enclave to the region with the minimum heterogeneity increase [14].


    Complexity analysis. In Enclaves Assignment, there are ğ‘£ enclaves, ğ‘£ < ğ‘›. Retrieving the next enclave to process takes
    ğ‘‚(ğ‘£). Processing each enclave is ğ‘‚(ğ‘›), in the worst case, to compute heterogeneity increase to all neighboring regions.
    This gives time complexity ğ‘‚(ğ‘£ + ğ‘›) for processing a single enclave, which is ğ‘‚(ğ‘£ * (ğ‘£ + ğ‘›)) = ğ‘‚(ğ‘£2 + ğ‘£ğ‘›) for ğ‘£ enclaves.
    As ğ‘£ < ğ‘›, i.e., ğ‘£ = ğ‘‚(ğ‘›), the phase complexity is bounded by ğ‘‚(ğ‘›2) in its worst case.


    Remark 5.3. Time complexity of Enclaves Assignment is ğ‘‚(ğ‘›2).


    #### 5.1.4 Inter-region Update

    After the Enclaves Assignment step, all areas are assigned to regions. However, incomplete regions, i.e., regions that
    fail to satisfy the user-defined constraint, might still exist. This step attempts to render all regions complete by moving
    some areas from complete regions to neighbor incomplete regions. First, incomplete regions are identified and added to
    a queue. Then, for every incomplete region ğ‘Ÿğ‘–, all its complete neighbor regions are identified. The Inter-region Update
    algorithm attempts to make ğ‘Ÿğ‘– complete by moving an area ğ‘ from one of ğ‘Ÿâ€²ğ‘–â€™s complete neighbor region to ğ‘Ÿğ‘–. The region
    that donates an area is called ğ‘Ÿğ‘‘ğ‘œğ‘›ğ‘œğ‘Ÿ and the region that receives that area is called ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ. A move is defined as
    a triple (ğ‘, ğ‘Ÿğ‘‘ğ‘œğ‘›ğ‘œğ‘Ÿ, ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ).


    For a given ğ‘Ÿğ‘‘ğ‘œğ‘›ğ‘œğ‘Ÿ and a given ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ, Area ğ‘ from ğ‘Ÿğ‘‘ğ‘œğ‘›ğ‘œğ‘Ÿ is movable if it satisfies all the following properties:

    - ğ‘ is not an articulation area for ğ‘Ÿğ‘‘ğ‘œğ‘›ğ‘œğ‘Ÿ, i.e., ğ‘ âˆ‰ ğ‘Ÿğ‘‘ğ‘œğ‘›ğ‘œğ‘Ÿ.ğ‘ğ‘Ÿğ‘¡.

    - ğ‘ is a neighbor area of ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ, i.e., ğ‘ âˆˆ ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ.ğ‘ğµğ‘…ğ´.


    The articulation areas of a region are identified using Tarjan algorithm [45] to speedup excluding invalid moves that
    cause spatial disconnection. The above conditions do not prevent moves that switch complete regions to incomplete regions,
    which is an incorrect switch. However, this gives more flexibility and higher scalability to this step to fill incomplete
    regions. In case this incorrect switch happens for some regions, they are switched back to complete regions in the following
    step that indirectly flow extra areas from complete regions to all other incomplete regions.


    Algorithm 1 describes the Inter-region Update step. In each iteration, we dequeue an incomplete region and consider it
    as ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ. If ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ does not have a complete neighbor region, then we add the ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ back to the queue to be
    processed later. Otherwise, the ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿâ€™s complete neighbor regions are sorted based on the extensive attribute in descending
    order. Suppose the sorted complete neighbor regions are {ğ‘Ÿğ‘, ğ‘Ÿğ‘, ğ‘Ÿğ‘, ...}, we attempt to consider neighbor region with
    largest extensive attribute ğ‘Ÿğ‘ as the ğ‘Ÿğ‘‘ğ‘œğ‘›ğ‘œğ‘Ÿ and try to find the movable area from ğ‘Ÿğ‘‘ğ‘œğ‘›ğ‘œğ‘Ÿ to ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ that has the largest
    extensive attribute. If the list of movable areas is empty, then we turn to the region with the second-largest extensive
    attribute ğ‘Ÿğ‘, and so on. If no movable area is found among all the complete neighbor regions, then we put the current
    ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ back to the queue to be processed later and start the next iteration. If ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ is still incomplete after
    the move, then we add ğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘Ÿ back to the queue. If ğ‘Ÿğ‘‘ğ‘œğ‘›ğ‘œğ‘Ÿ becomes incomplete after the move, then we add ğ‘Ÿğ‘‘ğ‘œğ‘›ğ‘œğ‘Ÿ to
    the queue as well. This procedure is repeated until a feasible partition is found or the maximum of ğ‘› iterations allowed
    has been exhausted without finding a feasible partition.


    Complexity analysis. In each iteration, for an incomplete region ğ‘Ÿ, retrieving neighbor regions is ğ‘‚(ğ‘(ğ‘Ÿ)) = ğ‘‚(ğ‘›) and
    sorting them is ğ‘‚(ğ‘ log ğ‘). Applying Tarjan algorithm takes ğ‘‚(ğ‘(ğ‘Ÿ) + ğ‘’(ğ‘Ÿ)), where ğ‘’(ğ‘Ÿ) denotes the number of edges within
    a spatial neighborhood graph ğº for region ğ‘Ÿâ€™s areas. As region ğ‘Ÿ is also a planar graph, it has ğ‘’(ğ‘Ÿ) â‰¤ 3ğ‘(ğ‘Ÿ) âˆ’ 6 [50],
    so ğ‘’(ğ‘Ÿ) = ğ‘‚(ğ‘(ğ‘Ÿ)), and applying Tarjan algorithm is ğ‘‚(ğ‘(ğ‘Ÿ))) = ğ‘‚(ğ‘›). Moving an area ğ‘ from a donor region ğ‘Ÿâ€² to a receiver
    region ğ‘Ÿ takes ğ‘‚(ğ‘(ğ‘Ÿ) + ğ‘(ğ‘Ÿâ€²)) = ğ‘‚(ğ‘›) time to locate ğ‘ and compute heterogeneity changes of ğ‘Ÿ and ğ‘Ÿâ€². The same applies
    if multiple donor regions are explored. Then, the runtime of a single iteration is ğ‘‚(ğ‘ log ğ‘ + ğ‘›). For ğ‘› iterations, the
    overall complexity is ğ‘‚(ğ‘›2 + ğ‘›ğ‘ log ğ‘).


    Remark 5.4. Time complexity of Inter-region Update is ğ‘‚(ğ‘›2 + ğ‘›ğ‘ log ğ‘).


    #### 5.1.5 Indirect Flow Push

    If there are remaining incomplete regions after Inter-region Update, then Indirect Flow Push is adopted to attempt transforming
    these regions into complete. In Inter-region Update, after an incomplete region ğ‘Ÿğ‘– is converted to a complete region,
    it might serve as a donor region for some other incomplete neighbor region since it has now become complete. However,
    moving an area from ğ‘Ÿğ‘– to its neighbor incomplete regions would likely make ğ‘Ÿğ‘– incomplete again because the extensive
    attribute of ğ‘Ÿğ‘– is just above the threshold. In this case ğ‘Ÿğ‘– is converted back to incomplete again. Those incomplete regions
    could frequently change status between complete and incomplete. This makes it hard for all the incomplete regions to become
    complete regions. We call this phenomena the chained-flipping problem.


    We propose Indirect Flow Push to solve the chained-flipping problem. This phase is entered only if Inter-region Update
    does not find a feasible partition. The chained-flipping problem is caused by starting from incomplete regions and borrowing
    areas from neighbor complete regions. In Indirect Flow Push, instead of starting from incomplete regions and borrowing
    areas from the neighbor complete regions, we start with the complete regions with the largest extensive attribute and
    push its margin areas to neighbor regions that need them.


    The partition of regions is considered as a flow network where regions are considered as nodes and extensive attribute
    is considered as flow. We push the flow through the network to ensure that there is a balanced distribution of extensive
    attribute over the regions. Each region in the flow network is assigned a state from the following:

    - Unprocessed (UP): This is the initial state of a region. This region has at least two neighbor regions that it could
    donate areas to or receive areas from.

    - Exhausted-incomplete (EI): This is an incomplete region having only one neighbor region that it can donate areas to
    or receive areas from.

    - Exhausted-complete (EC): This is a complete region having only one neighbor region that it can donate areas to or receive
    areas from.

    - Processed (P): This is the final state of a region. This region cannot donate or receive other areas.


    Initially, all the regions are labeled as UP. Notice that regions with only one neighbor region are labeled as EC or EI
    according to their satisfaction of the user-defined constraint. The Indirect Flow Push step keeps track of all incomplete
    regions. At any stage, if the partition no longer contains incomplete region, this step terminates.


    We define the movable boundary between ğ‘Ÿ1 and ğ‘Ÿ2 MBDRY(ğ‘Ÿ1, ğ‘Ÿ2) to be the set of areas ğ´ where each area ğ‘ in ğ´ needs to
    satisfy the following properties:

    - ğ‘ belongs to ğ‘Ÿ1, i.e., ğ‘.ğ‘Ÿ = ğ‘Ÿ1.ğ‘–ğ‘‘, and neighbor to ğ‘Ÿ2, i.e., ğ‘ âˆˆ ğ‘Ÿ2.ğ‘ğµğ‘…ğ´.

    - Removing ğ‘ from ğ‘Ÿ1 would not make ğ‘Ÿ1 incomplete, i.e., ğ‘Ÿ1.ğ‘’ğ‘¥ğ‘¡ âˆ’ ğ‘.ğ‘’ğ‘¥ğ‘¡ > threshold.

    - ğ‘ is not an articulation area for ğ‘Ÿ1, i.e., ğ‘ âˆ‰ ğ‘Ÿ1.ğ‘ğ‘Ÿğ‘¡.


    In this phase, for a given ğ‘€ğµğ·ğ‘…ğ‘Œ(ğ‘Ÿ1, ğ‘Ÿ2), the best area in ğ‘€ğµğ·ğ‘…ğ‘Œ(ğ‘Ÿ1, ğ‘Ÿ2) to move from ğ‘Ÿ1 to ğ‘Ÿ2 is defined as the area
    ğ‘ğ‘ğ‘’ğ‘ ğ‘¡ that maximizes ğ‘ğ‘œğ‘›ğ‘›(ğ‘ğ‘ğ‘’ğ‘ ğ‘¡, ğ‘Ÿ2) âˆ’ ğ‘ğ‘œğ‘›ğ‘›(ğ‘ğ‘ğ‘’ğ‘ ğ‘¡, ğ‘Ÿ1). Ties are broken arbitrarily. The area chosen to be moved from
    ğ‘Ÿ1 to ğ‘Ÿ2 has the most connections to areas in ğ‘Ÿ2 compared to ğ‘Ÿ1. Notice that this move may not result in the best heterogeneity
    improvement because the objective here is to ensure high robustness of regions. This allows areas to move without disconnecting
    regions.


    Then, in each iteration, if there are UP regions, we select the UP region with the largest extensive attribute to be processed
    and name it as ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡. If there are no UP regions but EC regions, then we choose the EC region with the largest extensive
    attribute. If there are no UP or EC regions while having incomplete regions, then GSLO fails to identify a feasible partition
    of the input areas.


    Algorithm 2 describes Indirect Flow Push and proceeds as follows: In each iteration, if ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ has EC neighbor regions,
    we select the EC neighbor region with the largest extensive attribute, say ğ‘Ÿğ‘” and we compute ğ‘€ğµğ·ğ‘…ğ‘Œ(ğ‘Ÿğ‘”, ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡). If ğ‘€ğµğ·ğ‘…ğ‘Œ(ğ‘Ÿğ‘”,
    ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡) is empty, then ğ‘Ÿğ‘” is transformed to P. The reason is that ğ‘Ÿğ‘” is complete and cannot afford to donate any other
    area. Otherwise, we move ğ‘ğ‘ğ‘’ğ‘ ğ‘¡ from ğ‘Ÿğ‘” to ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡. If ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ has EI neighbor regions, we take the EI neighbor region
    with the least extensive attribute, say ğ‘Ÿğ‘  and we compute ğ‘€ğµğ·ğ‘…ğ‘Œ(ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡, ğ‘Ÿğ‘ ). If ğ‘€ğµğ·ğ‘…ğ‘Œ(ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡, ğ‘Ÿğ‘ ) is empty, and ğ‘Ÿğ‘  is
    still incomplete, then the last chance of making ğ‘Ÿğ‘  complete has been exhausted. In this case, Indirect Flow Push step
    fails. Otherwise, we move ğ‘ğ‘ğ‘’ğ‘ ğ‘¡ from ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ to ğ‘Ÿğ‘ . If ğ‘Ÿğ‘  becomes complete after this move, then ğ‘Ÿğ‘  is transformed into
    P. Notice that when the EI neighbor region receives an area from ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡, one or more new NON-P neighbor regions of this
    EI region might be introduced. If this is the case, this EI region converts to UP as it now has two or more NON-P neighbor
    regions. If ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ does not have any EC or EI neighbor regions, then we choose the UP neighbor region with the least
    extensive attribute, say ğ‘Ÿâ€²ğ‘ , where ğ‘€ğµğ·ğ‘…ğ‘Œ(ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡, ğ‘Ÿâ€²ğ‘ ) is not empty. If no movable area is found after all the neighbor
    UP regions are exhausted, ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ converts to P. If ğ‘€ğµğ·ğ‘…ğ‘Œ(ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡, ğ‘Ÿâ€²ğ‘ ) is not empty, we move ğ‘ğ‘ğ‘’ğ‘ ğ‘¡ from ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ to ğ‘Ÿâ€²ğ‘ .


    For a given ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡, we give priority to EC and EI neighbor regions. This is the only opportunity for these regions to
    exchange an area with ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡. For a neighbor EC region, we move the EC regionâ€™s margin areas to ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ until any further
    move would disconnect the EC region or make the EC region incomplete. This is because we want the total extensive attribute
    of this region to be just above the threshold. After the processing of ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡, all the redundant extensive attribute
    in this EC neighbor region would become stagnant, as this EC neighbor region will convert to P. For an EI neighbor region,
    ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ is the last opportunity to make it complete. Once ğ‘Ÿğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ finishes processing, the EI neighbor region will not
    have a chance to exchange an area with its neighbor regions. EI region is converted to P once it becomes complete. We
    can think of areas within regions as flow that is being pushed from regions that have high extensive attribute to regions
    that have low extensive attribute. The state diagram of the Indirect Flow Push step is shown in Figure 3.


    Complexity analysis. It takes ğ‘‚(ğ‘) to find the neighbor region ğ‘Ÿ that has either the minimum or the maximum extensive
    attribute. Then, computing ğ‘€ğµğ·ğ‘…ğ‘Œ(ğ‘Ÿ, ğ‘Ÿâ€²), using Tarjan algorithm, takes ğ‘‚(ğ‘(ğ‘Ÿ)). Filtering out all the areas in ğ‘Ÿ that
    make ğ‘Ÿ incomplete when removed or not in ğ‘Ÿ.ğ‘ğµğ‘…ğ´ also takes ğ‘‚(ğ‘(ğ‘Ÿ)). Last of all, evaluating ğ‘ğ‘œğ‘›ğ‘›(ğ‘, ğ‘Ÿ) and ğ‘ğ‘œğ‘›ğ‘›(ğ‘, ğ‘Ÿâ€²)
    for the remaining areas that takes ğ‘‚(ğ‘(ğ‘Ÿ)), since there are (ğ‘(ğ‘Ÿ)) areas in the boundary and computing ğ‘ğ‘œğ‘›ğ‘›(.) is ğ‘‚(1)
    due to the average constant degree of a node in a spatial neighborhood graph, which is a planar graph. Also, computing
    the heterogeneity variation on ğ‘Ÿ and ğ‘Ÿâ€² takes time ğ‘‚(ğ‘(ğ‘Ÿ) + ğ‘(ğ‘Ÿâ€²)). Therefore, each move takes ğ‘‚(ğ‘(ğ‘Ÿ) + ğ‘(ğ‘Ÿâ€²)) + ğ‘‚(ğ‘)
    = ğ‘‚(ğ‘›). Each area could be moved at most ğ‘‚(ğ‘) times because an area never has a chance to be moved back to the same region
    where it comes from and there are in total ğ‘› areas. Consequently, the overall time complexity of Indirect Flow Push is
    ğ‘‚(ğ‘›)ğ‘‚(ğ‘›ğ‘) = ğ‘‚(ğ‘›2ğ‘).


    Remark 5.5. Time complexity of Indirect Flow Push is ğ‘‚(ğ‘›2ğ‘).'
  citations:
  - marker: '[14]'
    intent_label: Algorithm/Principle Adoption
    topic_label: Heterogeneity objective functions
  - marker: '[8, 9, 14, 33â€“35, 53]'
    intent_label: Prior Methods
    topic_label: Bottom-up seeded agglomeration
  - marker: '[14, 33â€“35, 53]'
    intent_label: Prior Methods
    topic_label: Bottom-up seeded agglomeration
  - marker: '[8, 9]'
    intent_label: Prior Methods
    topic_label: Bottom-up seeded agglomeration
  - marker: '[50]'
    intent_label: Domain Overview
    topic_label: Bottom-up seeded agglomeration
  - marker: '[45]'
    intent_label: Algorithm/Principle Adoption
    topic_label: Heuristic models with explicit contiguity
- block_id: 7
  content: 'If a feasible partition is found in the Global Search phase, Local Optimization is applied to further improve
    the heterogeneity over the partition. Most regionalization algorithms [8, 9, 14, 34, 35, 53] include an optimization phase
    that improves the objective function by changing the membership of the border areas of the regions using heuristic searching
    strategies. Some regionalization algorithms [8, 9, 14] perform an extremely expensive exhaustive search of all possible
    reassignments of border areas just to pick only one reassignment step. This makes it hard to use on large datasets.


    The Local Search in [53] has superior performance for the following reasons: (1) Local Search identifies movable areas
    instead of all the possible moves, (2) Local Search does not recalculate a new set of movable areas until the previous
    list has been exhausted. This makes Local Search efficient in improving the overall heterogeneity of the partition without
    performing extremely expensive computations that do not scale up for large data. An area ğ‘ within region ğ‘Ÿ is movable
    if: (i) ğ‘ is on the margin of ğ‘Ÿ, (ii) ğ‘ is not an articulation area of ğ‘Ÿ, (iii) ğ‘Ÿ remains complete after the area ğ‘ is
    removed. In each iteration, all the movable areas are put into a list. A random area is chosen to be moved to the neighbor
    region with the minimum heterogeneity. If the move decreases the heterogeneity over the current partition, then the move
    is accepted. Otherwise, the acceptance of the move is determined by the Boltzmann probability [31]. After a move is performed,
    all the areas belonging to the donor region and the receiver region are removed from the list. The heuristic does not
    identify the movable areas again unless the list of movable areas has been exhausted.


    We further extend this heuristic to speed up the searching process and improve the optimization goal. First, for each
    selected movable unit, we reassign it to the neighboring region that results in the minimum heterogeneity increase instead
    of the neighboring region that has the minimum heterogeneity. Second, we parallelize Local Search by searching for movable
    areas of regions concurrently. Third, we adopt Tarjan algorithm [45] to find all the articulation areas that are not allowed
    to move. These improvements lead to 100x faster search in Local Optimization.


    Complexity analysis. In Local Optimization, parallelly locating all the movable areas using Tarjan algorithm from each
    region takes âˆ‘ğ‘ğ‘–=1 ğ‘‚(ğ‘(ğ‘Ÿğ‘–)/T) = ğ‘‚(ğ‘›/T) where T is the number of threads available in the parallel environment. After each
    move, areas from donor and receiver regions are removed from the list. So, on average, ğ‘2/2 moves are performed. For each
    move, computing the heterogeneity change and selecting receiver region for reassigning area ğ‘ in ğ‘.ğ‘ğµğ‘…ğ‘… takes time âˆ‘|ğ‘.ğ‘ğµğ‘…ğ‘Ÿ|ğ‘–=1
    ğ‘(ğ‘Ÿğ‘–) = ğ‘‚(ğ‘›). Consequently, each move attempt takes time ğ‘‚(ğ‘›) + ğ‘‚(ğ‘›/T)/ğ‘2 = ğ‘‚(ğ‘›). So, the overall runtime of Local Optimization
    is ğ›¼ğ‘‚(ğ‘›), where ğ›¼ is the number of total move attempts and ğ‘‚(ğ‘›) is the cost for each move attempt.


    Remark 5.6. Time complexity of Local Optimization is ğ‘‚(ğ›¼ğ‘›).'
  citations:
  - marker: '[45]'
    intent_label: Algorithm/Principle Adoption
    topic_label: Local search with area swaps and metaheuristics
  - marker: '[8, 9, 14, 34, 35, 53]'
    intent_label: Prior Methods
    topic_label: Local search with area swaps and metaheuristics
  - marker: '[8, 9, 14]'
    intent_label: Research Gap
    topic_label: Local search with area swaps and metaheuristics
  - marker: '[53]'
    intent_label: Algorithm/Principle Adoption
    topic_label: Local search with area swaps and metaheuristics
  - marker: '[31]'
    intent_label: Algorithm/Principle Adoption
    topic_label: Local search with area swaps and metaheuristics
- block_id: 8
  content: 'This section gives time and space complexity of GSLO. According to Remark 5.1, Remark 5.2, Remark 5.3, Remark
    5.4, Remark 5.5, and Remark 5.6, the overall time complexity of GSLO is ğ‘‚(ğ‘›2ğ‘ + ğ‘šğ‘2 + ğ›¼ğ‘›), where ğ›¼ is the actual number
    of move attempts in the Local Optimization and ğ‘š is the maximum number of iterations during Seed Identification. The value
    of ğ›¼ is mainly affected by the number of iterations in Local Optimization (ğ¼ğ¿ğ‘‚), i.e., the maximum number of non-improving
    moves allowed. Empirically, the value of ğ›¼ is 1-2 orders of magnitude of ğ¼ğ¿ğ‘‚ parameter value (Table 3).


    The space complexity of GSLO is ğ‘‚(ğ‘›). The input stores each area and its corresponding attributes, i.e., extensive attributes,
    similarity attributes, marginal coordinates and etc, which takes ğ‘‚(ğ‘›) storage. GSLO stores the neighbor areas of each
    input area. Since the spatial neighborhood is a planar graph, the number of neighbors is strictly less than six [50].
    Consequently, storing the neighbors takes 6 * ğ‘‚(ğ‘›) = ğ‘‚(ğ‘›) space. On the region level, for each region ğ‘Ÿ, we need to store
    ğ‘Ÿ.ğ‘šğ‘ğ‘Ÿğ‘”ğ‘–ğ‘› and ğ‘Ÿ.ğ‘ğµğ‘…ğ´. Note that âˆ‘ğ‘ğ‘–=1 ğ‘Ÿğ‘–.ğ‘šğ‘ğ‘Ÿğ‘”ğ‘–ğ‘› = ğ‘‚(ğ‘›) and âˆ‘ğ‘ğ‘–=1 ğ‘Ÿğ‘–.ğ‘ğµğ‘…ğ´ = ğ‘‚(ğ‘›). Consequently, the overall space complexity
    of GSLO is ğ‘‚(ğ‘›).'
  citations:
  - marker: '[50]'
    intent_label: Domain Overview
    topic_label: Heuristic models with explicit contiguity
- block_id: 9
  content: 'In this section, we present extensive experimental evaluation to demonstrate the efficiency of GSLO. We use the
    following datasets: (1) TIGER shapefile dataset [10], and (2) Health, Income and Diversity dataset [19]. The TIGER dataset
    is a real dataset of the census tracts of individual states within the United States [10]. Each item in the TIGER dataset
    is a spatial polygon of census tract with multiple numerical attributes. The size of the dataset used in the experiments
    ranges from 2k to 40k spatial polygons, which is an order of magnitude larger than any dataset used in evaluating regionalization
    to the best of our knowledge. In our experiments, we consider the ALAND, which represents the current land area of a census
    tract, as the extensive attribute. Also, we consider AWATER, which represents the current water area of a census tract,
    as the similarity attribute.


    The Health, Income and Diversity dataset [19] has 3k elements. Each item in this dataset is a county within the United
    States that is associated with multiple numerical attributes. We consider cz_pop2000 as the extensive attribute and it
    represents the population of U.S. counties. We consider ratio as the similarity attribute and it represents each countyâ€™s
    median income divided by the stateâ€™s median income. For both datasets, all the island areas are removed. All experiments
    are based on Java 14 implementation using an Intel Xeon(R) server with CPU E5-2637 v4 (3.50 GHz) and 128GB RAM running
    Ubuntu 16.04. Table 3 summarizes the parameters used throughout the experimental evaluation. The bold values indicate
    the default setting for each parameter.


    Our evaluation metrics are: (1) heterogeneity, (2) runtime, and (3) effectiveness, i.e., the probability of finding a
    feasible partition. The heterogeneity is calculated as the mean value from feasible partitions. If no feasible partition
    is generated among all the runs, then the heterogeneity is represented as ğ‘–ğ‘›ğ‘“. The number of runs in all experiments is
    100 except for that the number of runs in the scalability test is 10 to avoid extremely long experimentation time.


    We compare GSLO against four alternatives: (1) SKATER [3], (2) SKATERCON [4], (3) GS, and (4) Greedy. SKATER and SKATERCON
    are the state-of-the-art algorithms for the ğ‘-regions problem. GS is GSLO without Local Optimization. Greedy is a greedy
    baseline algorithm that proceeds as follows: (i) randomly select ğ‘ seed areas, (ii) select the region with the least extensive
    attribute to grow by adding a neighboring area that results in the minimum heterogeneity increase, (iii) regions stop
    growing once the user-defined constraint has been satisfied or there are no neighboring areas, (iv) enclaves are assigned
    similar to GSLO.


    Notice that SKATER and SKATERCON cannot directly solve PRUC because they do not consider user-defined constrains as described
    in Section 2. We modify SKATER and SKATERCON into SKATER* and SKATERCON*, respectively, to allow them to solve PRUC. SKATER*
    changes the tree-partitioning phase in SKATER as follows: The edge selection in SKATER* adopts the edge selection from
    SKATER. However, SKATER* enforces that the edge chosen to be split must be feasible, i.e., the subtrees produced by the
    split must exceed the threshold of the extensive attribute. SKATER* splits the tree in each iteration by choosing the
    edge cut that brings the greatest heterogeneity reduction among all feasible edge cuts. SKATERCON is modified to SKATERCON*
    by using SKATER* instead of SKATER and parallelizing the generation of spanning trees. The execution of SKATER* is also
    parallelized. Additionally, the subgraph with the largest extensive attribute is given the highest priority for partitioning
    in the last step of SKATERCON*. The runtime complexity for SKATER* is ğ‘‚(ğ‘›3ğ‘) and the runtime complexity for SKATERCON*
    is ğ‘‚(ğ›½ğ‘›3ğ‘) where ğ‘› is the total number of spatial areas in the input, ğ‘ is the predefined number of regions, and ğ›½ is
    the number of random spanning trees in SKATERCON*.'
  citations:
  - marker: '[3]'
    intent_label: Result Comparison
    topic_label: Top-down divisive edge-removal methods
  - marker: '[4]'
    intent_label: Result Comparison
    topic_label: Top-down divisive edge-removal methods
  - marker: '[10]'
    intent_label: Benchmark Utilization
    topic_label: regionalization
  - marker: '[19]'
    intent_label: Benchmark Utilization
    topic_label: regionalization
- block_id: 10
  content: 'In this section, we experimentally identify the optimal values for the parameters of GSLO.


    Number of Iterations in Seed Identification Figure 4 shows the heterogeneity and the runtime of GSLO under different number
    of iterations in Seed Identification (ISI) on the TIGER dataset. This figure shows that increasing the number of iterations
    results in improvement in the seed quality and the overall heterogeneity. Note that the seed quality is defined as the
    minimum area-area pair distance, which is discussed in Section 5.1.1 and only applicable for Seed Identification in GSLO.
    However, increasing the number of iterations increases the runtime of GSLO. We set the number of iterations to 1DS as
    it results in a balance between heterogeneity and overall runtime. Also, we compare our seeding strategy with random seeding
    and k-means++ [2] seeding, denoted as GSLO-random and GSLO-kmeans++, respectively. k-means++ seeding is reported as the
    lowest error seeding for k-means clustering [43]. Figure 4(c) shows that around 1DS, GSLO seeding, random seeding, and
    k-means++ seeding achieve nearly the same runtime. Regarding heterogeneity, GSLO seeding slightly outperforms random seeding
    and k-means++ seeding. Figure 4(b) shows that the best heterogeneity GSLO obtained around 1DS, i.e., the optimal setting
    as discussed above, achieves 11.1% better heterogeneity compared to random seeding and 4% better heterogeneity compared
    to k-means++ seeding, which demonstrates the superiority of our Seed Identification.


    Iterations in Local Optimization Iterations in Local Optimization (ILO) refer to the maximum number of non-improving moves
    allowed in Local Optimization that is describe in 5.2. Figure 5 shows the heterogeneity and runtime under different ILO
    using the TIGER dataset. We see that the heterogeneity improves as the number of iterations in Local Optimization increases.
    However, the overall runtime also increases as ILO increases. We set the number of iterations in Local Optimization to
    1DS, i.e., the size of the dataset, as it achieves a good balance between runtime and heterogeneity in Local Optimization.'
  citations:
  - marker: '[2]'
    intent_label: Result Comparison
    topic_label: Compactness-driven locationâ€“allocation approaches
  - marker: '[43]'
    intent_label: Prior Methods
    topic_label: Compactness-driven locationâ€“allocation approaches
- block_id: 11
  content: 'This section analyzes the performance of GSLO under different parameter settings.


    #### 7.2.1 Time Breakdown Analysis

    Figure 6 provides time breakdown analysis of GSLO under the TIGER dataset that shows the average runtime of each phase
    under different ğ‘. The figure shows that the runtime of Local Optimization dominates the runtime of GSLO and it decreases
    as ğ‘ increases since larger ğ‘ means less flexibility to reassign the border areas without violating the user-defined constraint.
    Seed Identification runtime increases slightly as ğ‘ increases because more seed areas are involved. Region Growth runtime
    increases as ğ‘ increases because there are more regions to grow. Enclaves Assignment runtime decreases as ğ‘ increases
    because there are fewer enclaves to assign. Also, the runtime of Inter-region Update and Indirect Flow increases as ğ‘
    increases because a larger ğ‘ results in a higher probability of generating incomplete regions and thus a higher probability
    of invoking both steps. Note that in this experiment the average runtime is computed from solved cases only. When ğ‘ =
    50, no feasible partition is found.


    #### 7.2.2 Exploring Island Dataset

    In this section, we experimentally explore the efficiency of GSLO over a dataset containing islands. We use a dataset
    that consists of two connected components of size 3k, and 0.2k, respectively. SKATER* and SKATERCON* do not support islands
    because the input for both must be a connected spatial neighborhood graph. Thus, we compare GSLO with Greedy. Figure 7
    shows that GSLO consistently achieves better heterogeneity and effectiveness than Greedy in all cases. Notice that when
    ğ‘ > 10, Greedy does not find a feasible partition at all, whereas GSLO finds the feasible partition with high probability
    in all solvable cases. GSLOâ€™s high effectiveness results from all phases of GSLO that take the extensive attribute into
    consideration.


    #### 7.2.3 The effect of the number of regions p

    Figure 8a, Figure 8b, and Figure 8c show the performance of all alternatives under different ğ‘ using the TIGER dataset.
    Note that the effectiveness of SKATER* is either 0 or 1 because SKATER* is deterministic. The result shows that GSLO consistently
    achieves the best heterogeneity and effectiveness. For the TIGER dataset, GSLO achieves up to 5.22Ã— improvement in heterogeneity
    compared to GS, which demonstrates the efficiency of Local Optimization to further optimize the heterogeneity. GSLO achieves
    up to 9Ã— improvement in heterogeneity compared to Greedy. Although the runtime in Greedy is the smallest among all, the
    worst effectiveness and heterogeneity make it impractical to use. Greedy has bad effectiveness because it does not balance
    the extensive attribute across different regions, and has bad heterogeneity because it makes local greedy decisions when
    growing regions, which leads to suboptimal solutions. GSLO achieves up to 4.3Ã— improvement in heterogeneity compared to
    SKATER* and up to 8.8Ã— improvement compared to SKATERCON*. Moreover, GSLO is up to 90.6Ã— faster than SKATER* and up to
    229.7Ã— faster than SKATERCON*. Figure 8d, Figure 8e, and Figure 8f show that using the HID dataset, GSLO achieves up to
    2.24Ã— better heterogeneity compared to GS, and up to 31.6% improvement in heterogeneity compared to Greedy. GSLO achieves
    up to 21.5% improvement in heterogeneity compared to SKATER* and up to 52.3% improvement compared to SKATERCON*. With
    respect to runtime, GSLO is up to 97.1Ã— faster than SKATER* and up to 244.7Ã— faster than SKATERCON*. The percentage of
    heterogeneity reduction in the TIGER dataset of GSLO compared to the other baseline algorithms is much greater than in
    the HID dataset. This is because the similarity attribute in the TIGER dataset has a greater range and variance, thus
    different partitions constructed from the TIGER dataset have greater difference regarding heterogeneity compared to the
    HID dataset where the similarity attribute has closer values. Due to the fact that Greedy is inefficient and GS is part
    of GSLO, in the following experiments we will only compare GSLO with SKATER* and SKATERCON*.


    Notice that the runtime of SKATER* and SKATERCON* increases as ğ‘ increases. Furthermore, SKATERCON* has a higher runtime
    than SKATER* as SKATER* is a phase of SKATERCON*. However, GSLO requires less runtime as ğ‘ increases. The reason is that,
    as ğ‘ increases, the number of areas that can move between regions in Local Optimization is smaller. Hence, the number
    of possible moves is also smaller. This results in less runtime. Notice that GSLO is able to early detect that there is
    no feasible solution to the input problem up to 302.6Ã— faster than SKATER* and SKATERCON*. The reason is that GSLO is
    able to make an early decision about the feasibility of the input problem in the Global Search phase.


    With respect to runtime, GSLO outperforms SKATER* and SKATERCON*, because GSLO is a seeding-based algorithm that incrementally
    grows regions around seed areas. However, SKATER* and SKATERCON* require finding successive expensive edge cuts on the
    input graph. From a theoretical perspective, the time complexity of SKATER* and SKATERCON* is cubic in ğ‘› while the time
    complexity of GSLO is quadratic in ğ‘›. This gives GSLO a consistent edge over SKATER* and SKATERCON*. GSLO achieves superior
    heterogeneity due to the Local Optimization step that reassigns areas to regions to improve the overall heterogeneity,
    whereas in SKATER* and SKATERCON*, once a partition is generated, no adjustment is made to further optimize the heterogeneity.
    GSLO has higher effectiveness due to Inter-region Update and Indirect Flow Push phases that produce complete regions.
    SKATER* and SKATERCON* do not have these abilities.


    #### 7.2.4 The effect of varying the threshold

    Figure 9 shows the heterogeneity, runtime, and effectiveness of GSLO, SKATER*, and SKATERCON* under different threshold
    values in the TIGER and HID datasets. Figure 9a, Figure 9b, and Figure 9c show that, under the TIGER dataset, GSLO achieves
    up to 6.1Ã— better heterogeneity than SKATER* and up to 8.6Ã— better heterogeneity than SKATERCON*. Additionally, GSLO is
    up to 26Ã— faster than SKATER* and up to 74.5Ã— faster than SKATERCON*. Figure 9d, Figure 9e, and Figure 9f show that, under
    the HID dataset, GSLO achieves up to 12.8% better heterogeneity than SKATER* and up to 48.1% better heterogeneity than
    SKATERCON*. GSLO is up to 37.5Ã— faster than SKATER* and up to 95.9Ã— faster than SKATERCON* under the HID dataset. GSLO
    achieves the best effectiveness in both datasets. The reason behind the good performance is similar to the one explained
    in Section 7.2.3.


    #### 7.2.5 Using GSLO to Solve the ğ‘-regions problem

    When the threshold value is set to 0, PRUC resembles the basic ğ‘-regions problem [15]. In this experiment, we compare
    GSLO to SKATER and SKATERCON when solving the ğ‘-regions problem. Figure 10 illustrates that GSLO achieves better results
    than both SKATER and SKATERCON for both heterogeneity and runtime. Under the TIGER dataset, GSLO achieves up to 4.1Ã— better
    heterogeneity than SKATER and 8.7Ã— better heterogeneity than SKATERCON. In addition, GSLO is up to 31.2Ã— faster than SKATER
    and up to 73.2Ã— faster than SKATERCON. Under the HID dataset, GSLO achieves up to 22% better heterogeneity than SKATER
    and up to 23.3% better heterogeneity than SKATERCON. Moreover, GSLO is up to 180.9Ã— faster than SKATER and up to 425Ã—
    faster than SKATERCON.


    #### 7.2.6 The scalability of GSLO

    Figure 11 demonstrates the scalability of GSLO compared to SKATER* and SKATERCON* on the TIGER dataset of different sizes.
    Within a predefined time limit, i.e., 4 hours, GSLO can handle up to 40k dataset while SKATER* and SKATERCON* can only
    handle up to 10k. Furthermore, GSLO achieves up to 5Ã— better heterogeneity than SKATER* and SKATERCON*. This experiment
    shows that GSLO can handle up to 4Ã— larger datasets than SKATER* and SKATERCON*.'
  citations:
  - marker: '[15]'
    intent_label: Problem Formulation
    topic_label: p-regions formulations
- block_id: 12
  content: In this paper, we introduce PRUC, a generalized version of the ğ‘-regions problem that accounts for user-defined
    constraints. We develop an efficient parallel stochastic solution to PRUC which is divided into Global Search and Local
    Optimization. Experimental results show that GSLO is up to more than 100Ã— faster and achieves up to 6Ã— better heterogeneity
    than the state-of-the-art algorithms. In addition, GSLO solves the original ğ‘-regions problem with up to 4Ã— better heterogeneity
    than existing algorithms. With respect to future work, we plan to use GSLO to solve other spatial regionalization problems,
    e.g., ğ‘-compact region problem [35], school redistricting problem [8, 9], Node-attributed Spatial Graph Partitioning [6],
    and MAX-P regions problem [14]. Also, we plan to investigate the support of incremental changes to the properties of input
    areas and multiple user-defined constraints.
  citations:
  - marker: '[35]'
    intent_label: Prospective Application
    topic_label: p-regions formulations
  - marker: '[14]'
    intent_label: Prospective Application
    topic_label: max-p regions formulations
  - marker: '[6]'
    intent_label: Prospective Application
    topic_label: Contiguity-aware graph embeddings with attribute and interaction signals
  - marker: '[8, 9]'
    intent_label: Prospective Application
    topic_label: p-regions formulations
