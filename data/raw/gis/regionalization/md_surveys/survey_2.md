# Spatial Regionalization: Formulations, Algorithms, and Applications

## Abstract
Spatial regionalization partitions a set of spatial polygons into contiguous, non-overlapping regions that optimize a specific objective function. This spatial operation serves diverse applications in environmental science, urban planning, public health, and economics. Due to the NP-hardness of this problem, most studies rely on heuristics and approximation techniques to balance solution quality with runtime efficiency. This tutorial reviews the main methods in the literature of spatial regionalization, organizing them into four categories: (i) linear and integer-programming formulations, (ii) top-down divisive strategies, (iii) bottom-up agglomerative strategies, and (iv) learning-based methods. For each category, we outline the core ideas and representative algorithms. We also discuss the open problems and future research directions.

## 1 Overview
Spatial regionalization is the problem of partitioning a spatial space into contiguous regions that optimize a chosen objective. It is widely utilized across various domains, including public health [ 8], e.g., delineating epidemic outbreak zones, environmental science [37], e.g., identifying homogeneous climate zones for climate change studies, and public policy [11, 12], e.g., school redistricting.

Spatial regionalization problems exhibit various forms, primarily differentiated by their input/output, constraints, and objective functions, yet all are NP-hard constrained optimization problems. One key distinction is whether the number of regions is predetermined as input or dynamically determined by the algorithm and produced as output. When the number of regions is input, the problem formulation is referred to as the p-regions problem [5, 18, 24, 26, 29]. Conversely, when the optimal number of regions is part of the solution to the optimization problem itself, the formulation is called the max-p regions problem [2, 3, 17, 19, 20, 22, 32–35].

Objective functions in spatial regionalization also vary considerably, fundamentally influencing the resulting region boundaries. Many algorithms measure heterogeneity as the sum of pairwise attribute dissimilarities within each region [2, 17, 18, 22, 29, 35], while others use deviations from a regional mean [ 6, 7]. Beyond these generic metrics, application-specific designs tailor the objective to domain goals. School redistricting systems such as REGAL [ 12] and SPATIAL [11] combine capacity balance with student travel distance to yield equitable, short-commute districts. Mobility and economic studies favor flow-modularity measures that keep commuter or freight movements largely inside each region [ 10, 25]. This tutorial emphasizes the general heterogeneity functions while noting these domain-driven variants.

User-defined constraints also play in categorizing regionalization problems. PRUC formulation [29], for example, enriches the standard p-regions problem by supporting an aggregate user-defined constraint, thereby increasing practical applicability. Similarly, EMP formulation [22] significantly expands the classic max-p problem by supporting multiple simultaneous constraints, enabling users to use all the SQL aggregate functions. Such enriched constraints broaden the range of real-world planning scenarios that regionalization algorithms can capture while still allowing heuristic solvers to scale.

Spatial regionalization is naturally relevant to the ACM SIGSPATIAL conference audience [2, 5, 7, 9, 11, 12, 27]. The audience of this tutorial will learn a comprehensive overview about the literature of spatial regionalization with in-depth technical details and discussions of challenges either from the algorithmic point of view (computing challenges) or from the application point of view (interdisciplinary challenges). We divide the existing regionalization algorithms into four categories. (i) Linear/integer programming models [15, 18, 23] that cast objectives and constraints as linear equations to provide exact solutions with solvers such as CPLEX. (ii) Top-down divisive approaches [6, 7, 21] that provide approximate solutions by starting with the whole space and iteratively divide it to yield successively finer, homogeneous regions. (iii) Bottom-up agglomerative heuristics [2, 3, 11, 12, 16, 17, 19, 21, 22, 29–31, 35] that provide approximate solutions by merging small adjacent polygons to form larger regions. (iv) Learning-based methods [27, 28, 36].

Figure 1 summarizes the two major categorizations used in this tutorial. Throughout this manuscript, the terms spatial polygons, spatial units, and spatial areas are used interchangeably where the context allows clear interpretation. The rest of this section briefly outlines each part.

### 1.1 Part 1: Spatial Regionalization Formulations
Part 1 begins by introducing classical spatial regionalization problems, followed by their variants concerning constraints and objective functions. As shown in Figure 1, spatial regionalization problems generally fall into two broad categories: (i) The p-regions formulations [18, 26, 29], in which the analyst specifies a fixed number of regions ( p) in advance. The objective is to partition spatial units into exactly p regions, minimizing internal heterogeneity regarding selected attributes. (ii) The max-p regions formulations [2, 3, 17, 19, 22, 35] treat the number of regions as an outcome of the optimization process itself. Therefore, the goal is to identify the maximum number of feasible regions, each satisfying minimum size or other feasibility constraints.

Various objective functions quantify intra-region heterogeneity in these formulations. Some methods define heterogeneity using pairwise attribute differences among all spatial units within a region, effectively summing up the dissimilarities between every pair of constituent units [ 2, 17, 18, 22, 29, 35]. Other approaches measure heterogeneity as deviations from a regional mean or centroid [6, 7], summing the differences between each spatial unit’s attribute values and the regional average. Although differing mathematically, these functions all aim to form internally homogeneous regions based on chosen attributes.

Different formulations impose different constraints. For instance, PRUC [29] augments p-regions with a single user-defined aggregate threshold (e.g., minimum population) per region. Enriched Max-P (EMP) [22] expands max-p to support multiple simultaneous aggregate constraints, effectively allowing any SQL-style sum, count, or average condition within each region. These enriched formulations let analysts encode realistic policy rules while keeping the underlying optimization framework scalable.

### 1.2 Part 2: Exact Algorithms
A foundational approach to spatial regionalization is formulating it as an exact optimization problem, typically using a linear programming model [15, 18, 23]. This formulation is proposed in [18] where constraints and objectives are formulated as linear equations. Recent advancements [15] revise the linear formulation by using fewer variables in modeling the spatial contiguity, greatly reducing memory footprint. The linear model is solved using optimization tools such as CPLEX [1]. However, exact solutions via linear programming are computationally impractical for large datasets due to the NP-hard nature of the problem. In practice, exact optimization is affordable for a few hundred spatial units, sufficient for detailed case studies or for validating heuristic quality, but becomes prohibitive for larger-sized datasets.

### 1.3 Part 3: Top-down Divisive Algorithms
Top-down divisive methods [6, 7, 21] begin by considering all spatial units as a single region and iteratively divide them into increasingly homogeneous subregions. Typically, these methods model the spatial units as nodes within a spatial neighborhood graph, with edges representing adjacency. A common strategy involves transforming this graph into a spanning tree and iteratively removing edges to partition the graph into clusters. For instance, the Spatial ’K’luster Analysis by Tree Edge Removal (SKATER) algorithm [6] constructs a minimum spanning tree (MST) using edge weights based on dissimilarity between adjacent units. SKATER progressively cuts edges that significantly reduce within-region heterogeneity until the desired number of regions is achieved. SKATER-CON [7], an extension of SKATER, generates multiple random MSTs, applies SKATER to each tree, and integrates these results into a final consensus regionalization. REDCAP [21] is a special case that combines both bottom-up and top-down strategies. It first applies a dynamically constrained agglomerative phase that heuristically merges neighboring units to build a spatially contiguous hierarchy, and then partitions that hierarchy by removing edges that mostly reduce within-region heterogeneity.

### 1.4 Part 4: Bottom-up Agglomerative Algorithms
Bottom-up algorithms are widely used for spatial regionalization, forming regions by merging smaller spatial areas (polygons) into larger contiguous clusters. These algorithms typically employ a two-phase heuristic: an initial solution construction phase to establish feasible regions, followed by an heuristic search phase to optimize region boundaries [2, 3, 9, 11, 12, 16, 17, 19, 21, 22, 29–31, 35, 38]. In the initial solution phase, spatial areas are selected as seeds and expanded into preliminary regions while ensuring contiguity. The optimization phase then iteratively reassigns or swaps areas between regions to improve the objective function. Variations among these methods include different approaches to seed selection [2, 11, 12, 17, 29], heuristics guiding areas reassignment [29–31, 35], and supported constraints or criteria [17, 18, 22, 29].

The foundational bottom-up method, AZP [30], begins with a random partition and employs local greedy search, transferring neighboring boundary units between regions whenever such moves improve the objective. To avoid local optima, subsequent improvement [31] introduces heuristics, including Tabu Search and Simulated Annealing, enabling occasional acceptance of inferior solutions for overall improvement. ARISeL [16] further optimizes initial seeding by strategically selecting dispersed initial seeds, yielding more robust starting partitions and enhancing final outcomes. Similarly, GSLO [29] selects spatially dispersed seeds and employs parallel computation alongside combined heuristic search strategies for significantly improved efficiency. The bottom-up methods are also broadly utilized in max-p regionalization problems [2, 3, 17, 19, 22, 35], aiming to maximize region count under given constraints by growing from the seeded regions. Variations of such include compactness requirements [19], simultaneous multiple constraints [22], and efficient heuristic methods for large-scale applications [2, 3]. Domain-specific adaptations such as REGAL [12] and SPATIAL [11] apply bottom-up agglomeration to specialized contexts, e.g., school districting.

### 1.5 Part 5: Learning-based Algorithms
Learning-based spatial regionalization algorithms employ modern representation-learning techniques, most commonly graph neural networks (GNNs), to discover regions. A typical two-step pattern first learns low-dimensional embeddings for each spatial polygon on an adjacency graph that encodes contiguity, then clusters the embeddings while enforcing that only neighbouring units can merge. Region2Vec [27, 28] follows this paradigm: they train an unsupervised GNN whose loss jointly rewards attribute similarity and interaction intensity between adjacent polygons, and subsequently apply a contiguity-constrained linkage to obtain regions. MNCD-KE [36] adopts a related two-stage strategy: a multilayer community detector generates “kernel” units that are already cohesive in both attributes and flows, after which a kernel-extension heuristic greedily grows each seed while respecting contiguity, size, and compactness constraints.

### 1.6 Part 6: Open Problems and Future Research
Spatial regionalization research faces two key challenges. First, the lack of a unified query framework. Such a framework would accept arbitrary user-defined constraints and automatically select or compose the optimal solution strategy. Currently, each problem variant relies on a specialized algorithm, forcing practitioners to manually align problem requirements with specific code bases. A prototype of such a framework was introduced in [4], but it remains limited, lacking comprehensive support for diverse workloads and objective functions. Second, the absence of standardized benchmarks and datasets. Most studies use customized datasets and evaluation metrics, hindering consistent comparisons across algorithms. Finally, recent work [13, 14] suggest that quantum computing could tackle the combinatorial explosion inherent in spatial regionalization by exploring large solution spaces more efficiently than classical heuristics. Integrating quantum optimization could open a new path toward globally optimal yet tractable spatial rationalization.

## 2 Previous Tutorials
An earlier version of this tutorial will be presented at SSTD 2025 conference (http://sstd2025.github.io/). This edition enriches that material by adding a whole new part about learning-based regionalization techniques (Part 5) and introducing quantum computing as a whole new direction for spatial regionalization, positioning this in the literature of spatial optimization (Part 6).