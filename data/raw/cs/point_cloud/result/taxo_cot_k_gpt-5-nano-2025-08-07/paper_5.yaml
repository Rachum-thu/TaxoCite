"citations":
- "title": "Bert: Pre-training of deep bidirectional transformers for language understanding"
  "unique_context_marker": "[1]"
  "block_ids":
  - 0
  "intent_labels":
  - []
  "topic_labels":
  - - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
- "title": "Exploring the limits of transfer learning with a unified text-to-text transformer"
  "unique_context_marker": "[2]"
  "block_ids":
  - 0
  "intent_labels":
  - []
  "topic_labels":
  - - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
- "title": "Masked autoencoders are scalable vision learners"
  "unique_context_marker": "[3]"
  "block_ids":
  - 0
  "intent_labels":
  - []
  "topic_labels":
  - - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
- "title": "Representation learning with contrastive predictive coding"
  "unique_context_marker": "[4]"
  "block_ids":
  - 0
  "intent_labels":
  - []
  "topic_labels":
  - - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
- "title": "Momentum contrast for unsupervised visual representation learning"
  "unique_context_marker": "[5]"
  "block_ids":
  - 0
  "intent_labels":
  - []
  "topic_labels":
  - - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
- "title": "Flamingo: a visual language model for few-shot learning"
  "unique_context_marker": "[6]"
  "block_ids":
  - 0
  "intent_labels":
  - []
  "topic_labels":
  - - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
- "title": "A simple framework for contrastive learning of visual representations"
  "unique_context_marker": "[7]"
  "block_ids":
  - 0
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Self-supervised video representation learning by context and motion decoupling"
  "unique_context_marker": "[8]"
  "block_ids":
  - 0
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Pointcontrast: Unsupervised pre-training for 3d point cloud understanding"
  "unique_context_marker": "[9]"
  "block_ids":
  - 0
  - 2
  "intent_labels":
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "4dcontrast: Contrastive learning with dynamic correspondences for 3d scene understanding"
  "unique_context_marker": "[10]"
  "block_ids":
  - 0
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Joint data and feature augmentation for self-supervised representation learning on point clouds"
  "unique_context_marker": "[11]"
  "block_ids":
  - 2
  "intent_labels":
  - - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
  "topic_labels":
  - - "Self-supervised and Cross-modal Pretraining"
    - "Contrastive and cross-modal objectives"
    - "Input Representations and Modalities"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Multi-trusted cross-modal information bottleneck for 3d self-supervised representation learning"
  "unique_context_marker": "[12]"
  "block_ids":
  - 2
  "intent_labels":
  - - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
  "topic_labels":
  - - "Self-supervised and Cross-modal Pretraining"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Self-contrastive learning with hard negative sampling for self-supervised point cloud learning"
  "unique_context_marker": "[13]"
  "block_ids":
  - 2
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Exploring data-efficient 3d scene understanding with contrastive scene contexts"
  "unique_context_marker": "[14]"
  "block_ids":
  - 2
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Learning the predictability of the future"
  "unique_context_marker": "[15]"
  "block_ids":
  - 3
  - 5
  "intent_labels":
  - []
  - []
  "topic_labels":
  - - "Input Representations and Modalities"
    - "Self-supervised and Cross-modal Pretraining"
    - "Contrastive and cross-modal objectives"
    - "Self-supervised and Cross-modal Pretraining"
    - "Hierarchical structures"
  - - "Contrastive and cross-modal objectives"
    - "Hierarchical structures"
    - "Hierarchical structures"
    - "Hierarchical structures"
    - "Other Topic"
- "title": "Poincar√© glove: Hyperbolic word embeddings"
  "unique_context_marker": "[16]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - - "Hierarchical structures"
    - "Self-supervised and Cross-modal Pretraining"
    - "Contrastive and cross-modal objectives"
    - "Self-supervised and Cross-modal Pretraining"
    - "Hierarchical structures"
- "title": "Hyperbolic graph convolutional neural networks"
  "unique_context_marker": "[17]"
  "block_ids":
  - 3
  "intent_labels":
  - - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
  "topic_labels":
  - - "Graph-based neural models"
    - "Self-supervised and Cross-modal Pretraining"
    - "Contrastive and cross-modal objectives"
    - "Self-supervised and Cross-modal Pretraining"
    - "Hierarchical structures"
- "title": "Hyperbolic image embeddings"
  "unique_context_marker": "[18]"
  "block_ids":
  - 3
  "intent_labels":
  - - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
  "topic_labels":
  - - "Hybrid multi-modal representations"
    - "Self-supervised and Cross-modal Pretraining"
    - "Contrastive and cross-modal objectives"
    - "Self-supervised and Cross-modal Pretraining"
    - "Hierarchical structures"
- "title": "Hyperbolic vision transformers: Combining improvements in metric learning"
  "unique_context_marker": "[19]"
  "block_ids":
  - 3
  - 6
  "intent_labels":
  - - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
  - - "Background"
    - "Prior Methods"
    - "Prior Methods"
    - "Domain Overview"
    - "Prior Methods"
  "topic_labels":
  - - "Hybrid multi-modal representations"
    - "Self-supervised and Cross-modal Pretraining"
    - "Contrastive and cross-modal objectives"
    - "Self-supervised and Cross-modal Pretraining"
    - "Hierarchical structures"
  - []
- "title": "Edgcnet: Joint dynamic hyperbolic graph convolution and dual squeeze-and-attention for 3d point cloud segmentation"
  "unique_context_marker": "[20]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Self-supervised 3d behavior representation learning based on homotopic hyperbolic embedding"
  "unique_context_marker": "[21]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Hyperbolic representation learning: Revisiting and advancing"
  "unique_context_marker": "[22]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Rethinking the compositionality of point clouds through regularization in the hyperbolic space"
  "unique_context_marker": "[23]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Hyperbolic geometry"
  "unique_context_marker": "[24]"
  "block_ids":
  - 5
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Other Topic"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Other Topic"
- "title": "Smooth manifolds"
  "unique_context_marker": "[25]"
  "block_ids":
  - 5
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Other Topic"
    - "Hierarchical structures"
    - "Hierarchical structures"
    - "Other Topic"
- "title": "Learning representations and generative models for 3d point clouds"
  "unique_context_marker": "[26]"
  "block_ids":
  - 5
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Hierarchical structures"
    - "Hierarchical structures"
    - "Hierarchical structures"
    - "Other Topic"
- "title": "A scalable active framework for region annotation in 3d shape collections"
  "unique_context_marker": "[27]"
  "block_ids":
  - 10
  "intent_labels":
  - []
  "topic_labels":
  - - "Hybrid multi-modal representations"
    - "Self-supervised and Cross-modal Pretraining"
    - "Raw point-based representations"
    - "Self-supervised and Cross-modal Pretraining"
    - "Raw point-based representations"
- "title": "Disn: Deep implicit surface network for high-quality single-view 3d reconstruction"
  "unique_context_marker": "[28]"
  "block_ids":
  - 10
  "intent_labels":
  - []
  "topic_labels":
  - - "Projection-based representations"
    - "Projection-based representations"
    - "Projection-based representations"
    - "Projection-based representations"
    - "Hybrid multi-modal representations"
- "title": "Dynamic graph cnn for learning on point clouds"
  "unique_context_marker": "[29]"
  "block_ids":
  - 10
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "How to train your vit? data, augmentation, and regularization in vision transformers"
  "unique_context_marker": "[30]"
  "block_ids":
  - 10
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Decoupled weight decay regularization"
  "unique_context_marker": "[31]"
  "block_ids":
  - 10
  "intent_labels":
  - []
  "topic_labels":
  - - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
- "title": "Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling"
  "unique_context_marker": "[32]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "Foldingnet: Point cloud auto-encoder via deep grid deformation"
  "unique_context_marker": "[33]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "Self-supervised pretraining of 3d features on any point-cloud"
  "unique_context_marker": "[34]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "Unsupervised feature learning for point cloud understanding by contrasting and clustering using graph convolutional neural networks"
  "unique_context_marker": "[35]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "Spatio-temporal self-supervised representation learning for 3d point clouds"
  "unique_context_marker": "[36]"
  "block_ids":
  - 11
  "intent_labels":
  - []
  "topic_labels":
  - - "3D Shape Classification: Learning Strategies"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
    - "Self-supervised and Cross-modal Pretraining"
- "title": "Unsupervised point cloud pre-training via occlusion completion"
  "unique_context_marker": "[37]"
  "block_ids":
  - 11
  "intent_labels":
  - []
  "topic_labels":
  - - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
- "title": "Crosspoint: Self-supervised cross-modal contrastive learning for 3d point cloud understanding"
  "unique_context_marker": "[38]"
  "block_ids":
  - 11
  - 12
  "intent_labels":
  - []
  - - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Prior Methods"
    - "Research Gap"
  "topic_labels":
  - - "3D Shape Classification: Learning Strategies"
    - "Self-supervised and Cross-modal Pretraining"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Self-supervised and Cross-modal Pretraining"
  - []
- "title": "Self-supervised intra-modal and cross-modal contrastive learning for point cloud understanding"
  "unique_context_marker": "[39]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "3d shapenets: A deep representation for volumetric shapes"
  "unique_context_marker": "[40]"
  "block_ids":
  - 11
  "intent_labels":
  - []
  "topic_labels":
  - - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
- "title": "Umap: Uniform manifold approximation and projection for dimension reduction"
  "unique_context_marker": "[41]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "Self-supervised few-shot learning on point clouds"
  "unique_context_marker": "[42]"
  "block_ids":
  - 11
  "intent_labels":
  - []
  "topic_labels":
  - - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
    - "3D Shape Classification: Learning Strategies"
- "title": "Self-supervised deep learning on point clouds by reconstructing space"
  "unique_context_marker": "[43]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "Vipformer: Efficient vision-and-pointcloud transformer for unsupervised pointcloud understanding"
  "unique_context_marker": "[44]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "Learning transferable visual models from natural language supervision"
  "unique_context_marker": "[45]"
  "block_ids":
  - 12
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Deep residual learning for image recognition"
  "unique_context_marker": "[46]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
