"citations":
- "title": "Deep learning for lidar point clouds in autonomous driving: A review"
  "unique_context_marker": "[1]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
- "title": "Deep learning for image and point cloud fusion in autonomous driving: A review"
  "unique_context_marker": "[2]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
- "title": "Spg: Unsupervised domain adaptation for 3d object detection via semantic point generation"
  "unique_context_marker": "[3]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - - "Raw point-based representations"
    - "Convolution-based operators"
    - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
- "title": "Text to point cloud localization with relation-enhanced transformer"
  "unique_context_marker": "[4]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - - "Point Cloud Registration"
    - "Point Cloud Registration"
    - "Point Cloud Registration"
    - "Raw point-based representations"
    - "Deep learning-based registration"
- "title": "Joint representation learning for text and 3d point cloud"
  "unique_context_marker": "[5]"
  "block_ids":
  - 1
  - 4
  "intent_labels":
  - - "Research Gap"
    - "Research Gap"
    - "Research Gap"
    - "Prior Methods"
    - "Research Gap"
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - []
- "title": "Parts2words: Learning joint embedding of point clouds and texts by bidirectional matching between parts and words"
  "unique_context_marker": "[6]"
  "block_ids":
  - 1
  - 4
  "intent_labels":
  - - "Research Gap"
    - "Research Gap"
    - "Research Gap"
    - "Prior Methods"
    - "Research Gap"
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - []
- "title": "Vse++: Improving visual-semantic embeddings with hard negatives"
  "unique_context_marker": "[7]"
  "block_ids":
  - 1
  - 3
  - 14
  - 16
  "intent_labels":
  - []
  - []
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - []
  - - "Transformer-based attention models"
    - "Transformer-based attention models"
    - "Transformer-based attention models"
    - "Transformer-based attention models"
    - "Transformer-based attention models"
- "title": "Learning the best pooling strategy for visual semantic embedding"
  "unique_context_marker": "[8]"
  "block_ids":
  - 1
  - 3
  - 14
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - []
- "title": "Cross-modal active complementary learning with self-refining correspondence"
  "unique_context_marker": "[9]"
  "block_ids":
  - 1
  - 14
  "intent_labels":
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - []
- "title": "Focus your attention: A bidirectional focal attention network for image-text matching"
  "unique_context_marker": "[10]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Similarity reasoning and filtration for image-text matching"
  "unique_context_marker": "[11]"
  "block_ids":
  - 1
  - 3
  - 14
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - []
- "title": "Negative-aware attention framework for image-text matching"
  "unique_context_marker": "[12]"
  "block_ids":
  - 1
  - 14
  "intent_labels":
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - []
- "title": "Scanrefer: 3d object localization in rgb-d scans using natural language"
  "unique_context_marker": "[13]"
  "block_ids":
  - 1
  - 4
  - 6
  - 14
  "intent_labels":
  - []
  - []
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Referit3d: Neural listeners for fine-grained 3d object identification in real-world scenes"
  "unique_context_marker": "[14]"
  "block_ids":
  - 1
  - 4
  - 6
  - 14
  "intent_labels":
  - []
  - []
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Ll3da: Visual interactive instruction tuning for omni-3d understanding reasoning and planning"
  "unique_context_marker": "[15]"
  "block_ids":
  - 1
  - 6
  - 14
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Deep learning on point clouds and its application: A survey"
  "unique_context_marker": "[16]"
  "block_ids":
  - 1
  "intent_labels":
  - - "Importance of Problem"
    - "Importance of Problem"
    - "Importance of Problem"
    - "Domain Overview"
    - "Importance of Problem"
  "topic_labels":
  - - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
- "title": "Learning with noisy correspondence for cross-modal matching"
  "unique_context_marker": "[17]"
  "block_ids":
  - 1
  - 14
  "intent_labels":
  - - "Importance of Problem"
    - "Importance of Problem"
    - "Importance of Problem"
    - "Domain Overview"
    - "Importance of Problem"
  - - "Metrics Utilization"
    - "Metrics Utilization"
    - "Result Comparison"
    - "Result Comparison"
    - "Metrics Utilization"
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - []
- "title": "Learning from noisy correspondence with tri-partition for cross-modal matching"
  "unique_context_marker": "[18]"
  "block_ids":
  - 1
  "intent_labels":
  - - "Importance of Problem"
    - "Importance of Problem"
    - "Importance of Problem"
    - "Domain Overview"
    - "Importance of Problem"
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Improving cross-modal retrieval with set of diverse embeddings"
  "unique_context_marker": "[19]"
  "block_ids":
  - 14
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Fine-grained image-text matching by cross-modal hard aligning network"
  "unique_context_marker": "[20]"
  "block_ids":
  - 3
  - 14
  "intent_labels":
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - []
- "title": "Learning semantic relationship among instances for image-text matching"
  "unique_context_marker": "[21]"
  "block_ids":
  - 3
  - 14
  - 15
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - []
  - []
- "title": "Romo: Robust unsupervised multimodal learning with noisy pseudo labels"
  "unique_context_marker": "[22]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Rono: robust discriminative learning with noisy labels for 2d-3d cross-modal retrieval"
  "unique_context_marker": "[23]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Discover cross-modality nuances for visible-infrared person re-identification"
  "unique_context_marker": "[24]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Representation learning with contrastive predictive coding"
  "unique_context_marker": "[25]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Large scale online learning of image similarity through ranking"
  "unique_context_marker": "[26]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Inter-intra modal representation augmentation with dct-transformer adversarial network for image-text matching"
  "unique_context_marker": "[27]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Robust noisy correspondence learning with equivariant similarity consistency"
  "unique_context_marker": "[28]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Stacked cross attention for image-text matching"
  "unique_context_marker": "[29]"
  "block_ids":
  - 3
  - 14
  "intent_labels":
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Shapeglot: Learning language for shape differentiation"
  "unique_context_marker": "[30]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Text2shape: Generating shapes from natural language by learning joint embeddings"
  "unique_context_marker": "[31]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Scannet: Richly-annotated 3d reconstructions of indoor scenes"
  "unique_context_marker": "[32]"
  "block_ids":
  - 4
  - 6
  - 14
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
  - - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
  - - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
    - "Raw point-based representations"
- "title": "Instancerefer: Cooperative holistic understanding for visual grounding on point clouds through instance multi-level contextual referring"
  "unique_context_marker": "[33]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Transrefer3d: Entity-and-relation aware transformer for fine-grained 3d visual grounding"
  "unique_context_marker": "[34]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Scan2cap: Context-aware dense captioning in rgb-d scans"
  "unique_context_marker": "[35]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Context-aware alignment and mutual masking for 3d-language pre-training"
  "unique_context_marker": "[36]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Imagenet: A large-scale hierarchical image database"
  "unique_context_marker": "[37]"
  "block_ids":
  - 5
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning"
  "unique_context_marker": "[38]"
  "block_ids":
  - 5
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Scanqa: 3d question answering for spatial scene understanding"
  "unique_context_marker": "[39]"
  "block_ids":
  - 6
  "intent_labels":
  - []
  "topic_labels":
  - - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
    - "Contrastive and cross-modal objectives"
- "title": "Attention is all you need"
  "unique_context_marker": "[40]"
  "block_ids":
  - 10
  - 11
  "intent_labels":
  - []
  - []
  "topic_labels":
  - []
  - []
- "title": "Cross-modal retrieval with partially mismatched pairs"
  "unique_context_marker": "[41]"
  "block_ids":
  - 12
  - 14
  - 16
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - []
  - []
  - []
- "title": "Multi-view visual semantic embedding"
  "unique_context_marker": "[42]"
  "block_ids":
  - 14
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Esa: External space attention aggregation for image-text retrieval"
  "unique_context_marker": "[43]"
  "block_ids":
  - 14
  - 15
  - 16
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - []
  - []
  - - "Transformer-based attention models"
    - "Transformer-based attention models"
    - "Transformer-based attention models"
    - "Transformer-based attention models"
    - "Transformer-based attention models"
- "title": "Focal loss for dense object detection"
  "unique_context_marker": "[44]"
  "block_ids":
  - 12
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Generalized cross entropy loss for training deep neural networks with noisy labels"
  "unique_context_marker": "[45]"
  "block_ids":
  - 12
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Dynamic graph cnn for learning on point clouds"
  "unique_context_marker": "[46]"
  "block_ids":
  - 14
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation"
  "unique_context_marker": "[47]"
  "block_ids":
  - 14
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Bert: Pre-training of deep bidirectional transformers for language understanding"
  "unique_context_marker": "[48]"
  "block_ids":
  - 14
  "intent_labels":
  - []
  "topic_labels":
  - []
