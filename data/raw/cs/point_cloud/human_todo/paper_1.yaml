title: 'Banana: Banach Fixed-Point Network for Pointcloud Segmentation with Inter-Part Equivariance'
blocks:
- block_id: 0
  content: 'Equivariance has gained strong interest as a desirable network property that in-

    herently ensures robust generalization. However, when dealing with complex

    systems such as articulated objects or multi-object scenes, effectively capturing

    inter-part transformations poses a challenge, as it becomes entangled with the over-

    all structure and local transformations. The interdependence of part assignment and

    per-part group action necessitates a novel equivariance formulation that allows for

    their co-evolution. In this paper, we present Banana, a Banach fixed-point network

    for pointcloud segmentation with inter-part equivariance by construction. Our key

    insight is to iteratively solve a fixed-point problem, where point-part assignment

    labels and per-part SE(3)-equivariance co-evolve simultaneously. We provide

    theoretical derivations of both per-step equivariance and global convergence, which

    induces an equivariant final convergent state. Our formulation naturally provides

    a strict definition of inter-part equivariance that generalizes to unseen inter-part

    configurations. Through experiments conducted on both articulated objects and

    multi-object scans, we demonstrate the efficacy of our approach in achieving

    strong generalization under inter-part transformations, even when confronted with

    substantial changes in pointcloud geometry and topology.'
  citations: []
- block_id: 1
  content: 'From articulated objects to multi-object scenes, multi-body systems, i.e. shapes composed of multiple

    parts where each part can be moved separately, are prevalent in various daily-life scenarios. However,

    modeling such systems presents considerable challenges compared to rigid objects, primarily due

    to the infinite shape variations resulting from inter-part pose transformations with exponentially

    growing complexities. Successfully modeling these shapes demands generalization across potential

    inter-part configurations. While standard data augmentation techniques can potentially alleviate

    such problems, exhaustive augmentation can be highly expensive especially given the complexity

    of such systems compared to rigid objects. Meanwhile, recent rigid-shape analysis techniques have

    made significant progress in building generalization through the important concept of equivariance

    [38, 14, 78, 2, 80, 70, 19, 11, 15, 3, 35, 41, 54]. Equivariance dictates that when a transformation

    is applied to the input data, the network’s output should undergo a corresponding transformation.

    For example, if a point cloud is rotated by 90 degrees, the segmentation masks should also rotate

    accordingly. However, to the best of our knowledge, no existing work has managed to extend the

    formulation of equivariance to inter-part configurations.


    In this paper, we address the challenge of achieving inter-part equivariance in the context of part

    segmentation, a fundamental task in point cloud analysis, which is also the key to generalizing

    equivaraince from single object to multi-body system. Extending equivariance to multi-body systems

    presents notable challenges in both formulation and realization. When dealing with a shape that

    allows for inter-part motions, the model must exhibit equivariance to both global and local state

    changes, which can only be defined by combining part assignment and per-part transformations.

    For example, to model an oven’s inter-part states, we first need to differentiate between the parts

    corresponding to the door and the body and then define the movement of each individual part. An

    intriguing "chicken or the egg" problem arises when attempting to build inter-part equivariance

    without access to a provided segmentation, where segmentation is necessary to define equivariance,

    but segmentation itself is the desired output that we aim to produce.


    Our key insight to tackle this seeming dilemma is to model inter-part equivariance as a sequential

    fixed-point problem by co-evolving part segmentation labels and per-partSE(3)-equivariance. We

    provide theoretical derivations for both the per-step behavior and global convergence behavior, which

    are crucial aspects of a fixed-point problem. We show that our formulation establishes per-step

    equivariance through network construction, which then induces an overall inter-part equivariance

    upon convergence. Thus, by having equivariant per-step progression and global convergence, our

    formulation naturally gives rise to a strict definition of inter-part equivariance through iterative

    inference that generalizes to unseen part configurations. We further bring our formulation to concrete

    model designs by proposing a novel part-aware equivariant network with a weighted message-passing

    paradigm. With localized network operators and per-part SE(3)-equivaraint features, the network is

    able to guarantee per-step inter-part equivariance as well as facilitate stable convergence during the

    iterative inference. We test our framework on articulated objects to generalize from static rest states

    to novel articulates and multi-object scenes to generalize from clean synthetic scenes to cluttered real

    scans. Our model shows strong generalization in both scenarios even under significant changes in

    pointcloud geometry or topology.


    To summarize, our key contributions are

    - To the best of our knowledge, we are the first to provide a strict definition of inter-part

    equivariance for pointcloud segmentation and introduce a learning framework with such

    equivariance by construction.

    - We propose a fixed-point framework with one-step training and iterative inference and show

    that the per-step equivariance induces an overall equivariance upon convergence.

    - We design a part-aware equivariant message-passing network with stable convergence.

    - Experiments show our strong generalization under inter-part configuration changes even

    when they cause subsequent changes in pointcloud geometry or topology.'
  citations:
  - marker: '[2]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[3]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[11]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[14]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[15]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[19]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[35]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[38]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[41]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[54]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[70]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[78]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[80]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
- block_id: 2
  content: 'Equivariant pointcloud networks. Existing works in equivariant 3D learning mainly focus on

    rigid SE(3) transformations. As a well-studied problem, it has developed comprehensive theories

    [38, 14, 78, 2, 80] and abundant network designs [70, 19, 11, 15, 3, 35, 41, 54], which benefit a

    variety of 3D vision and robotics tasks ranging from pose estimation [43, 45, 53, 60, 88], shape

    reconstruction [11, 10], to object interaction and manipulation [18, 26, 59, 62, 79, 81]. A few recent

    works have extended SE(3) equivariance to part level [85, 40, 49]. [85] employs a local equivariant

    feature extractor for object bounding box prediction, showing robustness under object-level and

    scene-level pose changes. [40] learns an SE(3)-equivaraint object prior and applies it to object

    detection and segmentation in scenes with robustness to scene configuration changes. [49] learns

    part-level equivariance and pose canonicalization from a collection of articulated objects with a

    two-stage coarse-to-fine network. However, all these works are purely heuristics-based, and none has

    provided a strict definition of inter-part equivariance.


    Multi-body systems. From small-scale articulated objects to large-scale multi-object scenes, there is

    a wide range of 3D observations that involve multiple movable parts or objects, exhibiting various

    configurations and temporal variations. This has sparked a rich variety of works dedicated to

    addressing the challenges in multi-body systems, studying their part correspondences [55, 48, 8,

    47, 42], segmentations [84, 75, 66, 30, 29, 69, 7, 12], reconstructions [33, 36, 31, 52, 39], or

    rearrangements [77, 67], to name just a few. However, as we know the system is acted via products

    of group actions; a more structured network that exploits such motion prior by construction is desired.

    Only a few works have studied this problem. [85] exploits global and local gauge equivariance in

    3D object detection via bottom-up point grouping but without a systematical study of inter-object

    transformations. [40] further exploits equivariance of object compositions in scene segmentation,

    but as an EM-based approach, it requires exhaustive and inefficient enumerations and no global

    convergence is guaranteed. In contrast, our approach offers a theoretically sound framework that

    achieves multi-body equivariance by construction, which enables robust analysis for various tasks

    and provides a more structured and reliable solution compared to existing methods.


    Iterative inference. From recurrent neural networks [22, 28] to flow [16, 58, 17, 37, 82] or diffusion-

    based generative models [64, 65, 27, 63, 50, 87], iterative inference has played many diverse yet

    essential roles in the development of computer vision. Though naturally adapted to sequential or

    temporal data, iterative inference can also be applied to static learning problems such as image

    analysis [21, 20, 72, 25] and pointcloud segmentation [83, 46]. Recent studies also show that

    iterative inference presents stronger generalizability than one-step forward predictions [61, 6], with

    explanations of their relations to the "working memory" of human minds [4, 5] or human visual

    systems [44, 34]. In our work, we employ iterative inference on static pointclouds to co-evolve two

    intertwined attributes: part segmentation and inter-part equivaraince, in order to address a seemingly

    contradictory situation.'
  citations:
  - marker: '[2]'
    intent_label: Prior Methods
    topic_label: Convolution-based operators
  - marker: '[3]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[4]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[5]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[6]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[7]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[8]'
    intent_label: Prior Methods
    topic_label: Deep learning-based registration
  - marker: '[10]'
    intent_label: Prospective Application
    topic_label: Generative modeling pretraining
  - marker: '[11]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[12]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[14]'
    intent_label: Prior Methods
    topic_label: Convolution-based operators
  - marker: '[15]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[16]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[17]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[18]'
    intent_label: Prospective Application
    topic_label: Raw point supervised architectures
  - marker: '[19]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[20]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[21]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[22]'
    intent_label: Prior Methods
    topic_label: Sequential RNN-based models
  - marker: '[25]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[26]'
    intent_label: Prospective Application
    topic_label: Raw point supervised architectures
  - marker: '[27]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[28]'
    intent_label: Prior Methods
    topic_label: Sequential RNN-based models
  - marker: '[29]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[30]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[31]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[33]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[34]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[35]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[36]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[37]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[38]'
    intent_label: Prior Methods
    topic_label: Convolution-based operators
  - marker: '[39]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[40]'
    intent_label: Research Gap
    topic_label: Raw point supervised architectures
  - marker: '[41]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[42]'
    intent_label: Prior Methods
    topic_label: Deep learning-based registration
  - marker: '[43]'
    intent_label: Prospective Application
    topic_label: Deep learning-based registration
  - marker: '[44]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[45]'
    intent_label: Prospective Application
    topic_label: Deep learning-based registration
  - marker: '[46]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[47]'
    intent_label: Prior Methods
    topic_label: Deep learning-based registration
  - marker: '[48]'
    intent_label: Prior Methods
    topic_label: Deep learning-based registration
  - marker: '[49]'
    intent_label: Research Gap
    topic_label: Raw point supervised architectures
  - marker: '[50]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[52]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[53]'
    intent_label: Prospective Application
    topic_label: Deep learning-based registration
  - marker: '[54]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[55]'
    intent_label: Prior Methods
    topic_label: Deep learning-based registration
  - marker: '[58]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[59]'
    intent_label: Prospective Application
    topic_label: Raw point supervised architectures
  - marker: '[60]'
    intent_label: Prospective Application
    topic_label: Deep learning-based registration
  - marker: '[61]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[62]'
    intent_label: Prospective Application
    topic_label: Raw point supervised architectures
  - marker: '[63]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[64]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[65]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[66]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[67]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[69]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[70]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[72]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[75]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[77]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[78]'
    intent_label: Prior Methods
    topic_label: Convolution-based operators
  - marker: '[79]'
    intent_label: Prospective Application
    topic_label: Raw point supervised architectures
  - marker: '[80]'
    intent_label: Prior Methods
    topic_label: Convolution-based operators
  - marker: '[81]'
    intent_label: Prospective Application
    topic_label: Raw point supervised architectures
  - marker: '[82]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[83]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[84]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[85]'
    intent_label: Research Gap
    topic_label: Raw point supervised architectures
  - marker: '[87]'
    intent_label: Prior Methods
    topic_label: Generative modeling pretraining
  - marker: '[88]'
    intent_label: Prospective Application
    topic_label: Deep learning-based registration
- block_id: 3
  content: ''
  citations: []
- block_id: 4
  content: 'Let X ∈ RN×3 be a pointcloud with P parts. Segmentations on X are represented as point-part

    assignment matrices y ∈ [0, 1]N×P which sum up to 1 along the P dimension. As the action of

    SE(3)P on X and its resulting equivariance is subject to the part decompositions, we define the action

    of SE(3)P on (pointcloud, segmentation) pairs (X, y). When y is a binary mask, the P parts of X are

    P disjoint sub-pointclouds and each SE(3) component of SE(3)P acts on one part separately. More

    concretely, for any transformation A = (T1, · · · , TP ) ∈ SE(3)P, we define A(X, y) := (X′, y)

    where the n-th point xn is transformed to x′n by

    x′n := Σp=1^P ynp(xnRp + tp).

    where Rp and tp are the rotation and translation components of Tp ∈ SE(3). For soft segmentation

    masks, we view each point as probabilistically assigned to one of the P parts.


    Equivariance. Similar to SE(3)-equivariance on rigid shapes f(TX) = Tf(X), ∀T ∈ SE(3), we

    define the inter-part equivariance on (X, y) pairs by saying that a function f is SE(3)P -equivariant

    if ∀A ∈ SE(3)P,

    f(A(X, y)) = Af(X, y).

    Note that if the function outputs f(X, y) are no longer (pointcloud, segmentation) pairs, the SE(3)P-

    action on its outputs needs to be specified. A special case is when SE(3)P acts trivially on f(X, y)

    by f(A(X, y)) = f(X, y), which defines the common-sense “invariance”. For a pointcloud segmen-

    tation network with per-point part-label outputs y ∈ [0, 1]N×P, we desire it to be SE(3)P-invariant

    under the above definitions, that is f(A(X, y)) ≡ y, ∀A ∈ SE(3)P.'
  citations: []
- block_id: 5
  content: '“Chicken or the egg”. The "chicken or the egg" nature of segmentation with inter-part equivariance

    immediately emerges from the above definition: to enforce SE(3)P -equivariance for a neural network

    f(·; Θ), the part segmentation y is required as input, which is also exactly the desired output of the

    network. That this,

    f(X, y; Θ) = y.

    To resolve this dilemmatic problem, we approach Eq. 3 as a fixed-point equation on function

    f(·, y; Θ) w.r.t. y. And instead of using single-step forward predictions, we solve it with Banach

    fixed-point iterations.


    Training. At training time, we aim to optimize the network weights Θ such that the labeled point

    clouds (Xi, yi), i ∈ I from the dataset become fixed points of the function f(·, Θ):

    Θ* = arg min_Θ 1/|I| Σ_i∈I ||f(Xi, yi; Θ) − yi||.

    However, there exists a trivial solution which is the identity function f(·, y; Θ) ≡ y, meaning that any

    arbitrary segmentation can satisfy the objective for any pointclouds. Thus, to avoid such degenerated

    cases, we have to limit the network expressivity. More specifically, we limit the Lipschitz constant L

    of the network w.r.t. y which is defined by

    ||f(X, y1; Θ) − f(X, y2; Θ)|| ≤ L||y1 − y2||, ∀X, ∀y1, y2.

    If f degenerates to the identical mapping, its Lipschitz L = 1, which violates the above constraint.

    When L < 1, f is a contractive function and has a unique fixed point based on the Banach fixed-point

    theorem. Our training objective is to align this fixed point with the ground-truth segmentation.


    Iterative inference. At inference time, given an input pointcloud X0, the learnable parameters Θ*

    fixed in f and we look for a segmentation y that satisfies

    f_X0,Θ*(y) := f(X0, y; Θ*) = y.

    We solve this equation with Banach fixed-point iterations [1]

    y* = lim_{k→∞} y^(k) = lim_{k→∞} f^{(k)}_{X0,Θ*}(y^(0))

    where y^(0) is a random initialization of the segmentation on X0. For a contractive function f, the

    uniqueness of y* induces a well-defined mapping from pointclouds to segmentations f*_Θ : X0 → y*.'
  citations:
  - marker: '[1]'
    intent_label: Algorithm/Principle Adoption
    topic_label: Raw point supervised architectures
- block_id: 6
  content: 'For an input pairs (X, y) with known segmentation y, we employ an SE(3)-equivariant backbone

    [15] on each individual part and construct an SE(3)P -equivariant network, which will be further

    explained in Section 4. This guarantees the inter-part equivariance at training time and at each

    timestep during inference, but most importantly we desire the overall SE(3)P -equivariance at the

    convergence point of the Banach iteration. Here we prove two properties:


    Self-coherence of convergent state. At each inference timestep k, we have SE(3)P -equivariance

    subject to y^(k), that is, ∀A ∈ SE(3)P,

    f(A(X0, y^(k)); Θ) = f(X0, y^(k); Θ), ∀k ∈ N.

    Because of the continuity of f and the compactness of [0, 1]N×P, we can take limits w.r.t. k on both

    sides, which gives

    f(A(X0, y*); Θ) = f(X0, y*; Θ) = f*_Θ(X0).

    This shows the self-coherence of the convergent point between f*_Θ and y*.


    Generalization to novel inter-part states. Suppose the network has seen (X, y_gt) in the training

    set and learned f_Θ(X, y_gt; Θ*) = y_gt with the loss function in Eq. 4 minimized to zero. Now apply

    an inter-part transformation A ∈ SE(3)P and test the network on (X′, y_gt) := A(X, y_gt). We

    would like to show f*_Θ(X′) = f*_Θ(X) = y_gt. First of all, we know that y_gt itself is a fixed point of

    f(X′, ·; Θ), which is due to the equivariance w.r.t. y_gt at training time:

    f(X′, y_gt; Θ) = f(A(X, y_gt); Θ) = f(X, y_gt; Θ).

    Now if f is a contractive function on y, we have the uniqueness of Banach fixed-points and thus

    y_gt is the only fixed point for f(X′, ·; Θ), implying that the iterations in Eq. 7 must converge to y_gt.

    In less ideal cases when the training loss is not zero but a small error ε, we view it as the distance

    ||y^(1) − y^(0)|| between the ground-truth y^(0) = y_gt and the one-step iteration output y^(1). The

    distance between the actual fixed-point y* and the ground-truth y_gt is then bounded by

    ||y* − y_gt|| = Σ_{k=0}^∞ ||y^(k+1) − y^(k)|| ≤ Σ_{k=0}^∞ L^k ||y^(1) − y^(0)|| = 1/(1 − L) ε

    where L is the Lipschitz constant of the network.'
  citations:
  - marker: '[15]'
    intent_label: Model/Architecture Adoption
    topic_label: Raw point supervised architectures
- block_id: 7
  content: 'A pointcloud segmentation represented by y ∈ [0, 1]N×P inherently carries an order between the

    P parts, which is the assumption in semantic segmentation problems. But in various real-world

    scenarios, it is common to encounter situations where multiple disjoint parts are associated with the

    same semantic label, without any clear or coherent part orderings. In order to tackle this challenge, we

    also extend our method to encompass the instance segmentation problem without part orderings. For

    simplicity, here we assume that all parts can be permuted together by SP. In practice, permutations

    only occur among the parts within each semantic label, for which we can easily substitute the SP

    below with its subgroup and the conclusion still holds. We define an equivalence relation on [0, 1]N×P

    by

    y1 ∼ y2 ⇐⇒ ∃σ ∈ SP, s.t. y1σ = y2,

    which gives us a quotient space [0, 1]N×P /SP and each equivalent class ˆy in this quotient space

    represents an instance segmentation without part ordering. We can define a metric on ˆy by

    d(ˆy1, ˆy2) := min_{σ∈SP} ||y1σ − y2||,

    which makes ([0, 1]N×P /SP, d) a complete metric space, on which the Banach fixed-point theorem

    holds and so are the iterations and convergence properties. Proofs for the well-definedness of d and

    the completeness of the quotient space are shown in the supplementary material.'
  citations: []
- block_id: 8
  content: 'In this section, we present our part-aware equivariant network for segmentation label updates. We utilize a SE(3)-equivariant
    framework called Vector Neurons (VN) [15] as the backbone to

    encode per-point features V ∈ RN×C×3, ensuring equivariance within each part. Subsequently,

    these features are transformed into invariant representations, eliminating relative poses to facilitate

    inter-part information propagation and global aggregations.


    Segmentation-weighted message passing. Key to our part-aware equivariant network is a message-

    passing module weighted by the input segmentation y. Intuitively, given a point xn ∈ X with latent feature Vn, for its
    neighborhood points xm ∈ N, we only allow information

    propagation between xn and xm if they belong to the same part. When the part segmentation

    y is a soft mask, we compute the probability pnm of xn and xm belonging to the same part by

    pnm = y_n y_m^T, y_n, y_m ∈ [0, 1]^{1×P} and weight the local message passing with

    V′_n = (Σ_{m∈N} pnm φ(Vm − Vn, Vn)) / (Σ_{m∈N} pnm).

    Proof of inter-part equivariance for this module can be found in the supplementary material.


    Network architecture. The overall network architecture for segmentation label

    updates is as follows. Given an input pair (X, y), we first extract a per-point SE(3)-equivariant local feature

    V ∈ RN×C×3 within each part masked by y. V is then passed through a sequence of weighted

    convolutions with the message passing defined above. To enable efficient inter-part information

    exchange, after each message-passing layer, we compute a global invariant feature through a per-point

    VN-invariant layer, followed by a global pooling and a concatenation between per-point and global

    features. After the point convolutions, the per-point equivariant features Vn are converted to invariant

    features Sn with inter-part poses canceled. We then apply a global pooling on Sn to obtain a global

    shape code, which is decomposed into P part codes Q1, · · · , QP as in [13]. Finally, we compute a

    point-part assignment score for all (Sn, Qp) pairs (resulting in an N × P tensor) and apply a softmax

    activation along its P dimension to obtain the updated segmentation y′. For instance segmentation

    without part permutations (Sec. 3.4), we modify the computation of the part feature Q by replacing

    the global feature decomposition with point feature grouping based on y.


    For pointcloud networks with set-invariance across all points, directly restricting the upper bound of

    the network Lipschitz using weight truncations [71, 23, 86] will greatly harm network expressivity as

    it limits the output range on each point. On the other hand, the space of all possible segmentations

    [0, 1]N×P has extremely high dimensionality, making the computation of Lipschitz regularization

    losses [68] rather inefficient. Therefore, we do not explicitly constrain the Lipschitz constant of our

    network. Nevertheless, we confine all operations involving y to local neighborhoods per point, as

    shown in the message passing equation. This practical approach generally ensures a small Lipschitz constant for the network
    in most scenarios. The stability of fixed-point convergence will be studied in Sec. 5.3.'
  citations:
  - marker: '[13]'
    intent_label: Model/Architecture Adoption
    topic_label: Raw point supervised architectures
  - marker: '[15]'
    intent_label: Model/Architecture Adoption
    topic_label: Raw point supervised architectures
  - marker: '[23]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[68]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[71]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
  - marker: '[86]'
    intent_label: Prior Methods
    topic_label: Raw point supervised architectures
- block_id: 9
  content: ''
  citations: []
- block_id: 10
  content: 'We begin by evaluating our method on articulated-object part segmentation using on four categories of

    the Shape2Motion dataset [73]: washing machine, oven, eyeglasses, and refrigerator. To demonstrate

    the generalizability of our approach, we train our model on objects in a single rest state, such as ovens

    with closed doors. This training setup aligns with many synthetic datasets featuring static shapes [9, 51]. Subsequently,
    we assess the performance of our model on articulated

    states, where global and inter-part pose transformations are applied, replicating real-world scenarios.

    We evaluate our model on both unseen articulation states of the training instances and

    on unseen instances. In both cases, the joint angles are uniformly sampled from the

    motion range for each category. We compare our network to the most widely adopted object-level

    part segmentation networks PointNet [56] and DGCNN [74] without equivariance, plus VNN [15]

    with global SE(3)-equivariance. All IoUs are computed for semantic parts. In the case of eyeglasses

    and refrigerators, which have two parts sharing the same semantic label, we train our network with

    three motion part inputs but output two semantic part labels. This is feasible because our weighted

    message passing is agnostic to the number of parts.


    Our iterative inference process on novel states after training on the rest states demonstrates the

    ability to converge to correct segmentations. The inter-part pose transformations

    can cause significant changes in pointcloud geometry and topology, yet our method can robustly

    generalize to the unseen articulations with inter-part equivariance.'
  citations:
  - marker: '[9]'
    intent_label: Domain Overview
    topic_label: Raw point-based representations
  - marker: '[15]'
    intent_label: Result Comparison
    topic_label: Raw point supervised architectures
  - marker: '[51]'
    intent_label: Domain Overview
    topic_label: Raw point-based representations
  - marker: '[56]'
    intent_label: Result Comparison
    topic_label: Pointwise MLP architectures
  - marker: '[73]'
    intent_label: Benchmark Utilization
    topic_label: Raw point supervised architectures
  - marker: '[74]'
    intent_label: Result Comparison
    topic_label: Graph-based neural models
- block_id: 11
  content: 'We also test our instance segmentation framework (without part orders) on multi-object scans.


    Segmentation transfer on DynLab. DynLab [29] is a collection of scanned laboratory scenes, each

    with 2-3 rigidly moving solid objects captured under 8 different configurations with object positions

    randomly changed. We overfit our model to the first configuration of each scene and apply it to the 7

    novel configurations, transferring the segmentation from the first scan to the others via inter-object

    equivariance.


    We compare our method to a variety of multi-body segmentation methods, including motion-based

    co-segmentation methods (DeepPart [84], NPP [24], MultiBodySync [29]), direct segmentation

    prediction models (PointNet++ [57], MeteorNet [48]), geometry-based point grouping (Ward-linkage

    [76]), and pre-trained indoor instance segmentation modules (PointGroup [32]). The baseline setups

    follow [29]. One thing to note is that motion-based co-

    segmentation can also be viewed as learning inter-object equivariance via Siamese training, yet they

    cannot reach the performance of equivariance by construction.


    Synthetic to real chair scans. We train our model using a synthetic dataset constructed from clean

    ShapeNet chair models [9] with all instances lined up and facing the same direction. We

    then test our model on the real chair scans from [40] with diverse scene configurations. The configurations range from
    easy to hard, including: Z (all chairs standing on the floor), SO(3)

    (chairs laid down), and Pile (chairs piled into clutters). Remarkably, our model with inter-object

    equivariance demonstrates successful generalization across all these scenarios, even in the most

    challenging Pile setting with cluttered objects.'
  citations:
  - marker: '[9]'
    intent_label: Resource Utilization
    topic_label: Raw point-based representations
  - marker: '[24]'
    intent_label: Result Comparison
    topic_label: Weakly and unsupervised segmentation
  - marker: '[29]'
    intent_label: Benchmark Utilization
    topic_label: Weakly and unsupervised segmentation
  - marker: '[32]'
    intent_label: Result Comparison
    topic_label: Raw point supervised architectures
  - marker: '[40]'
    intent_label: Benchmark Utilization
    topic_label: Raw point-based representations
  - marker: '[48]'
    intent_label: Result Comparison
    topic_label: Raw point supervised architectures
  - marker: '[57]'
    intent_label: Result Comparison
    topic_label: Raw point supervised architectures
  - marker: '[76]'
    intent_label: Result Comparison
    topic_label: Weakly and unsupervised segmentation
  - marker: '[84]'
    intent_label: Result Comparison
    topic_label: Weakly and unsupervised segmentation
- block_id: 12
  content: 'We show the importance of our locally confined message passing and SE(3)-features to

    the convergence of test-time iterations. As opposed to extracting part-level equivariant features, one

    can also apply pose canonicalizations to each part individually and employ non-equivariant learning

    methods in the canonical space. For SE(3)-transformations with a translation component in R3 and a

    rotation component in SO(3), the former can be canonicalized by subtracting the part centers and the

    latter by per-part PCA. Thus we compare our full model with two ablated versions with part-level

    equivariance replaced by canonicalization: PCA, where we canonicalize both the part translations

    and rotations and simply employ a non-equivariant DGCNN [74] for the weighted message passing;

    VNN, where we only canonicalize the part translations but preserve the SO(3)-equivariant structures

    in the network.


    The segmentation IoUs of the full model and the ablated versions on the Shape2Motion

    oven category show that despite canonicalizations being agnostic to per-part SE(3) transformations, they rely on

    absolute poses and positions, which breaks the locality of network operations, resulting in a significant

    increase in the Lipschitz constant of the network. Consequently, when any local equivariant operator

    is replaced by canonicalization, the network performance experiences a drastic drop.


    To further examine the convergence ranges, we test the three models under different y^(0) initializations

    by adding random noises ξ ∼ U(0, 1) to y_gt according to y^(0) = (1 − α)y_gt + αξ, α ∈ [0, 1]. The

    performance changes of the three models with gradually increased noise levels on y^(0) show that

    the PCA rotation canonicalization has a theoretically unbounded Lipschitz constant, making the

    network unable to converge stably even within a small neighborhood of y_gt. The SO(3)-equivariant

    VNN with translation canonicalization perfectly overfits to the ground-truth fixed point but exhibits a

    rapid decline in performance as the initial y^(0) deviates from y_gt. In contrast, our SE(3)-equivariant

    network demonstrates stable performance across different noise levels.'
  citations:
  - marker: '[74]'
    intent_label: Model/Architecture Adoption
    topic_label: Graph-based neural models
- block_id: 13
  content: 'In this work, we propose Banana, which provides both theoretical insights and experimental analysis

    of inter-part equivariance. While equivariance is typically examined from an algebraic perspective,

    we approach it from an analysis standpoint and obtain a strict formulation of inter-part equivariance

    at the convergent point of an iteration sequence. Based on our theoretical formulation, we propose

    a novel framework that co-evolves segmentation labels and per-part SE(3)-equivariance, showing

    strong generalization under both global and per-part transformations even when these transformations

    result in subsequent changes to the pointcloud geometry or topology. Experimentally, we show

    that our model can generalize from rest-state articulated objects to unseen articulations, and from

    synthetic toy multi-object scenes to real scans with diverse object configurations.'
  citations: []
- block_id: 14
  content: 'While our local segmentation-weighted message passing reduces the Lipschitz constant of the network, practically
    providing stability during test-time iterations, it is

    important to note that it is not explicitly bounded or regularized. Lipschitz bounds and regularizations

    for set-invariant networks without compromising network expressivity would be an interesting and

    important problem for future study. In addition, we study the full SE(3)P action on multi-body

    systems, but in many real-world scenarios, different parts or objects may not move independently due

    to physical constraints. Limiting the SE(3)P-action to its subset of physically plausible motions can

    potentially increase our feature-embedding conciseness and learning efficiency.'
  citations: []
- block_id: 15
  content: 'Our study focuses on the general 3D geometry and its equivariance properties.

    Specifically, we investigate everyday appliances in common scenes, for which we do not anticipate

    any direct negative social impact. However, we acknowledge that our work could potentially be

    misused for harmful purposes. On the other hand, our research also has potential applications in areas

    that can benefit society, such as parsing proteins in medical science and building home robots for

    senior care.'
  citations: []
