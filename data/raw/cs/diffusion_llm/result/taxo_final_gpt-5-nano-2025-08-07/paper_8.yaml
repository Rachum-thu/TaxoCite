"citations":
- "title": "Domain adaptation for large-scale sentiment classification: A deep learning approach"
  "unique_context_marker": "[1]"
  "block_ids":
  - 1
  "intent_labels":
  - "Domain Overview"
  "topic_labels":
  - "Sentiment and opinion benchmarks"
- "title": "Opinion mining and sentiment analysis"
  "unique_context_marker": "[2]"
  "block_ids":
  - 1
  "intent_labels":
  - "Domain Overview"
  "topic_labels":
  - "Deep learning foundations for text classification"
- "title": "Twitter sentiment classification using distant supervision"
  "unique_context_marker": "[3]"
  "block_ids":
  - 1
  - 3
  "intent_labels":
  - "Prior Methods"
  - "Prior Methods"
  "topic_labels":
  - "Deep learning foundations for text classification"
  - "Feature extraction with linear classifiers"
- "title": "Thumbs up? Sentiment classification using machine learning techniques"
  "unique_context_marker": "[4]"
  "block_ids":
  - 3
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Encoder-only transformers"
- "title": "Sentiment classification of movie reviews using contextual valence shifters"
  "unique_context_marker": "[5]"
  "block_ids":
  - 1
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Deep learning foundations for text classification"
- "title": "NRC-Canada: Building the state-of-the-art in sentiment analysis of tweets"
  "unique_context_marker": "[6]"
  "block_ids":
  - 1
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Deep learning foundations for text classification"
- "title": "Adaptive co-training SVM for sentiment classification on tweets"
  "unique_context_marker": "[7]"
  "block_ids":
  - 1
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Deep learning foundations for text classification"
- "title": "Effective attention modeling for aspect-level sentiment classification"
  "unique_context_marker": "[8]"
  "block_ids":
  - 1
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Recurrent and hybrid networks"
- "title": "Long short-term memory"
  "unique_context_marker": "[9]"
  "block_ids":
  - 1
  - 12
  "intent_labels":
  - "Prior Methods"
  - "Result Comparison"
  "topic_labels":
  - "Recurrent and hybrid networks"
  - "Recurrent and hybrid networks"
- "title": "Learning to attend via word-aspect associative fusion for aspect-based sentiment analysis"
  "unique_context_marker": "[10]"
  "block_ids":
  - 4
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Recurrent and hybrid networks"
- "title": "Interactive attention networks for aspect-level sentiment classification"
  "unique_context_marker": "[11]"
  "block_ids":
  - 4
  - 12
  "intent_labels":
  - "Prior Methods"
  - "Result Comparison"
  "topic_labels":
  - "Recurrent and hybrid networks"
  - "Recurrent and hybrid networks"
- "title": "Multi-grained attention network for aspect-level sentiment classification"
  "unique_context_marker": "[12]"
  "block_ids":
  - 1
  - 12
  "intent_labels":
  - "Prior Methods"
  - "Result Comparison"
  "topic_labels":
  - "Recurrent and hybrid networks"
  - "Recurrent and hybrid networks"
- "title": "Attention-over-attention neural networks for reading comprehension"
  "unique_context_marker": "[13]"
  "block_ids":
  - 1
  - 4
  - 7
  "intent_labels":
  - "Prior Methods"
  - "Prior Methods"
  - "Model/Architecture Adoption"
  "topic_labels":
  - "Deep learning foundations for text classification"
  - "Recurrent and hybrid networks"
  - "Encoder-only transformers"
- "title": "Aspect level sentiment classification with attention-over-attention neural networks"
  "unique_context_marker": "[14]"
  "block_ids":
  - 4
  - 12
  "intent_labels":
  - "Prior Methods"
  - "Result Comparison"
  "topic_labels":
  - "Recurrent and hybrid networks"
  - "Recurrent and hybrid networks"
- "title": "Aspect-context interactive attention representation for aspect-level sentiment classification"
  "unique_context_marker": "[15]"
  "block_ids":
  - 1
  - 4
  "intent_labels":
  - "Prior Methods"
  - "Prior Methods"
  "topic_labels":
  - "Deep learning foundations for text classification"
  - "Recurrent and hybrid networks"
- "title": "Attention is all you need"
  "unique_context_marker": "[16]"
  "block_ids":
  - 1
  - 5
  - 7
  - 8
  "intent_labels":
  - "Domain Overview"
  - "Model/Architecture Adoption"
  - "Model/Architecture Adoption"
  - "Model/Architecture Adoption"
  "topic_labels":
  - "Pre-trained language models"
  - "Encoder-only transformers"
  - "Encoder-only transformers"
  - "Encoder-only transformers"
- "title": "Improving language understanding by generative pre-training"
  "unique_context_marker": "[17]"
  "block_ids":
  - 1
  "intent_labels":
  - "Domain Overview"
  "topic_labels":
  - "Decoder-only transformers"
- "title": "Language models are unsupervised multitask learners"
  "unique_context_marker": "[18]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "Language models are few-shot learners"
  "unique_context_marker": "[19]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "BERT: Pre-training of deep bidirectional transformers for language understanding"
  "unique_context_marker": "[20]"
  "block_ids":
  - 1
  "intent_labels":
  - "Domain Overview"
  "topic_labels":
  - "Encoder-only transformers"
- "title": "Distilling the knowledge in a neural network"
  "unique_context_marker": "[21]"
  "block_ids":
  - 1
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "PLM-based fine-tuning strategies"
- "title": "Distilling task-specific knowledge from BERT into simple neural networks"
  "unique_context_marker": "[22]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "MobileBERT: A compact task-agnostic BERT for resource-limited devices"
  "unique_context_marker": "[23]"
  "block_ids":
  - 1
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "PLM-based fine-tuning strategies"
- "title": "ALBERT: A lite BERT for self-supervised learning of language representations"
  "unique_context_marker": "[24]"
  "block_ids":
  - 1
  - 8
  "intent_labels":
  - "Prior Methods"
  - "Model/Architecture Adoption"
  "topic_labels":
  - "Encoder-only transformers"
  - "Pre-trained language models"
- "title": "SemEval-2016 task 5: Aspect based sentiment analysis"
  "unique_context_marker": "[25]"
  "block_ids":
  - 1
  - 11
  "intent_labels":
  - "Benchmark Utilization"
  - "Benchmark Utilization"
  "topic_labels":
  - "Sentiment and opinion benchmarks"
  - "Sentiment and opinion benchmarks"
- "title": "Predicting the semantic orientation of adjectives"
  "unique_context_marker": "[26]"
  "block_ids":
  - 3
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Encoder-only transformers"
- "title": "Building lexicon for sentiment analysis from massive collection of html documents"
  "unique_context_marker": "[27]"
  "block_ids":
  - 3
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Encoder-only transformers"
- "title": "Semi-supervised polarity lexicon induction"
  "unique_context_marker": "[28]"
  "block_ids":
  - 3
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Encoder-only transformers"
- "title": "A maximum entropy approach to natural language processing"
  "unique_context_marker": "[29]"
  "block_ids":
  - 3
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Sentiment and opinion benchmarks"
- "title": "Document-level sentiment classification: An empirical comparison between SVM and ANN"
  "unique_context_marker": "[30]"
  "block_ids":
  - 3
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Deep learning foundations for text classification"
- "title": "Effective LSTMs for target-dependent sentiment classification"
  "unique_context_marker": "[31]"
  "block_ids":
  - 4
  - 12
  "intent_labels":
  - "Prior Methods"
  - "Result Comparison"
  "topic_labels":
  - "Recurrent and hybrid networks"
  - "Recurrent and hybrid networks"
- "title": "Attention-based LSTM for aspect-level sentiment classification"
  "unique_context_marker": "[32]"
  "block_ids":
  - 4
  - 12
  "intent_labels":
  - "Prior Methods"
  - "Result Comparison"
  "topic_labels":
  - "Recurrent and hybrid networks"
  - "Recurrent and hybrid networks"
- "title": "Syntactic edge-enhanced graph convolutional networks for aspect-level sentiment classification with interactive attention"
  "unique_context_marker": "[33]"
  "block_ids":
  - 4
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Graph neural methods for text"
- "title": "A novel scheme for domain-transfer problem in the context of sentiment analysis"
  "unique_context_marker": "[34]"
  "block_ids":
  - 4
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Semi-supervised and adversarial adaptation"
- "title": "Exploiting document knowledge for aspect-level sentiment classification"
  "unique_context_marker": "[35]"
  "block_ids":
  - 4
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Semi-supervised and adversarial adaptation"
- "title": "Aspect and opinion term extraction for hotel reviews using transfer learning and auxiliary labels"
  "unique_context_marker": "[36]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "An iterative knowledge transfer network with routing for aspect-based sentiment analysis"
  "unique_context_marker": "[37]"
  "block_ids":
  - 4
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Semi-supervised and adversarial adaptation"
- "title": "Utilizing BERT for aspect-based sentiment analysis via constructing auxiliary sentence"
  "unique_context_marker": "[38]"
  "block_ids":
  - 4
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Encoder-only transformers"
- "title": "BERT post-training for review reading comprehension and aspect-based sentiment analysis"
  "unique_context_marker": "[39]"
  "block_ids":
  - 4
  - 12
  "intent_labels":
  - "Prior Methods"
  - "Result Comparison"
  "topic_labels":
  - "Prompt-driven classification paradigms"
  - "PLM-based fine-tuning strategies"
- "title": "Deep sparse rectifier neural networks"
  "unique_context_marker": "[40]"
  "block_ids":
  - 7
  "intent_labels":
  - "Algorithm/Principle Adoption"
  "topic_labels":
  - "Encoder-only transformers"
- "title": "Deep residual learning for image recognition"
  "unique_context_marker": "[41]"
  "block_ids":
  - 8
  "intent_labels":
  - "Model/Architecture Adoption"
  "topic_labels":
  - "Encoder-only transformers"
- "title": "Layer normalization"
  "unique_context_marker": "[42]"
  "block_ids":
  - 8
  "intent_labels":
  - "Model/Architecture Adoption"
  "topic_labels":
  - "Encoder-only transformers"
- "title": "Target-dependent sentiment classification with BERT"
  "unique_context_marker": "[43]"
  "block_ids":
  - 9
  "intent_labels":
  - "Model/Architecture Adoption"
  "topic_labels":
  - "Feature extraction with linear classifiers"
- "title": "Adam: A method for stochastic optimization"
  "unique_context_marker": "[44]"
  "block_ids":
  - 9
  - 11
  "intent_labels":
  - "Algorithm/Principle Adoption"
  - "Hyperparameter Utilization"
  "topic_labels":
  - "PLM-based fine-tuning strategies"
  - "PLM-based fine-tuning strategies"
- "title": "Aspect level sentiment classification with deep memory network"
  "unique_context_marker": "[45]"
  "block_ids":
  - 12
  "intent_labels":
  - "Result Comparison"
  "topic_labels":
  - "Recurrent and hybrid networks"
- "title": "Recurrent attention network on memory for aspect sentiment analysis"
  "unique_context_marker": "[46]"
  "block_ids":
  - 12
  "intent_labels":
  - "Result Comparison"
  "topic_labels":
  - "Recurrent and hybrid networks"
- "title": "Deep mask memory network with semantic dependency and context moment for aspect level sentiment classification"
  "unique_context_marker": "[47]"
  "block_ids":
  - 12
  "intent_labels":
  - "Result Comparison"
  "topic_labels":
  - "Recurrent and hybrid networks"
- "title": "Attentional encoder network for targeted sentiment classification"
  "unique_context_marker": "[48]"
  "block_ids":
  - 12
  "intent_labels":
  - "Result Comparison"
  "topic_labels":
  - "Encoder-only transformers"
