"citations":
- "title": "Computer Vision: Principles, Algorithms, Applications, Learning"
  "unique_context_marker": "[1]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Foundations of Statistical Natural Language Processing"
  "unique_context_marker": "[2]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Localization of stroke lesion in MRI images using object detection techniques: A comprehensive review"
  "unique_context_marker": "[3]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Auqanto: Actionable uncertainty quantification optimization in deep learning architectures for medical image classification"
  "unique_context_marker": "[4]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Dual cross-attention for medical image segmentation"
  "unique_context_marker": "[5]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Anatomically constrained and attention-guided deep feature fusion for joint segmentation and deformable medical image registration"
  "unique_context_marker": "[6]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Clinical named entity recognition and relation extraction using natural language processing of medical free text: A systematic review"
  "unique_context_marker": "[7]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Forensic implications of classification of accident-related deaths: A case report and review of the medical and legal literature"
  "unique_context_marker": "[8]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Simulating doctors’ thinking logic for chest X-ray report generation via transformer-based semantic query learning"
  "unique_context_marker": "[9]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Medical named entity recognition using surrounding sequences matching"
  "unique_context_marker": "[10]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Leveraging multi-source knowledge for Chinese clinical named entity recognition via relational graph convolutional network"
  "unique_context_marker": "[11]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Learning spatiotemporal embedding with gated convolutional recurrent networks for translation initiation site prediction"
  "unique_context_marker": "[12]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Context-aware poly(a) signal prediction model via deep spatial–temporal neural networks"
  "unique_context_marker": "[13]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Image-to-word transformation based on dividing and vector quantizing images with words"
  "unique_context_marker": "[14]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Show and tell: A neural image caption generator"
  "unique_context_marker": "[15]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Advancing semantic interoperability of image annotations: Automated conversion of non-standard image annotations in a commercial PACs to the annotation and image markup"
  "unique_context_marker": "[16]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Rethinking low-light enhancement via transformer-GAN"
  "unique_context_marker": "[17]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "XGPT: Cross-modal generative pre-training for image captioning"
  "unique_context_marker": "[18]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "OSCAR: Object-semantics aligned pre-training for vision-language tasks"
  "unique_context_marker": "[19]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Learning transferable visual models from natural language supervision"
  "unique_context_marker": "[20]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "VLMO: Unified vision-language pre-training with mixture-of-modality-experts"
  "unique_context_marker": "[21]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Unsupervised vision-and-language pre-training via retrieval-based multi-granular alignment"
  "unique_context_marker": "[22]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "VLDeFormer: Vision–language decomposed transformer for fast cross-modal retrieval"
  "unique_context_marker": "[23]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Exploiting structured knowledge in text via graph-guided representation learning"
  "unique_context_marker": "[24]"
  "block_ids":
  - 1
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "VideoBERT: A joint model for video and language representation learning"
  "unique_context_marker": "[25]"
  "block_ids":
  - 3
  - 10
  - 11
  "intent_labels":
  - - "Prior Methods"
    - "Background"
    - "Prior Methods"
    - "Domain Overview"
    - "Prior Methods"
  - []
  - []
  "topic_labels":
  - []
  - - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
  - - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
- "title": "A guide to annotation of neurosurgical intraoperative video for machine learning analysis and computer vision"
  "unique_context_marker": "[26]"
  "block_ids":
  - 3
  "intent_labels":
  - - "Prospective Application"
    - "Background"
    - "Prior Methods"
    - "Prospective Application"
    - "Prior Methods"
  "topic_labels":
  - - "Pre-trained language models"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
- "title": "Visual question generation for explicit questioning purposes based on target objects"
  "unique_context_marker": "[27]"
  "block_ids":
  - 3
  "intent_labels":
  - - "Prospective Application"
    - "Background"
    - "Prior Methods"
    - "Prospective Application"
    - "Prior Methods"
  "topic_labels":
  - - "Pre-trained language models"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
- "title": "Multimodal video-text matching using a deep bifurcation network and joint embedding of visual and textual features"
  "unique_context_marker": "[28]"
  "block_ids":
  - 3
  "intent_labels":
  - - "Prospective Application"
    - "Background"
    - "Prior Methods"
    - "Prospective Application"
    - "Prior Methods"
  "topic_labels":
  - - "Pre-trained language models"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
- "title": "Unified vision-language pre-training for image captioning and VQA"
  "unique_context_marker": "[29]"
  "block_ids":
  - 3
  "intent_labels":
  - - "Prospective Application"
    - "Background"
    - "Prior Methods"
    - "Prospective Application"
    - "Prior Methods"
  "topic_labels":
  - - "Pre-trained language models"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
- "title": "VLP: A survey on vision-language pre-training"
  "unique_context_marker": "[30]"
  "block_ids":
  - 3
  "intent_labels":
  - - "Prior Methods"
    - "Model/Architecture Adoption"
    - "Model/Architecture Adoption"
    - "Prior Methods"
    - "Prior Methods"
  "topic_labels":
  - - "Pre-trained language models"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
- "title": "ViLBERT: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks"
  "unique_context_marker": "[31]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Learning video representations using contrastive bidirectional transformer"
  "unique_context_marker": "[32]"
  "block_ids":
  - 3
  - 10
  - 11
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - - "Pre-trained language models"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
  - - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
  - - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
- "title": "HERO: Hierarchical encoder for video+language omni-representation pre-training"
  "unique_context_marker": "[33]"
  "block_ids":
  - 3
  - 10
  - 11
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - - "Pre-trained language models"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
  - - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
  - - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
- "title": "MMFT-BERT: Multimodal fusion transformer with BERT encodings for visual question answering"
  "unique_context_marker": "[34]"
  "block_ids":
  - 3
  - 10
  - 11
  "intent_labels":
  - []
  - []
  - []
  "topic_labels":
  - - "Pre-trained language models"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
  - - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
  - - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
- "title": "VL-BERT: Pre-training of generic visual-linguistic representations"
  "unique_context_marker": "[35]"
  "block_ids":
  - 3
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "ACTBERT: Learning global-local video-text representations"
  "unique_context_marker": "[36]"
  "block_ids":
  - 3
  - 6
  - 10
  - 11
  "intent_labels":
  - []
  - []
  - []
  - []
  "topic_labels":
  - []
  - - "Pre-trained language models"
    - "Other Topic"
    - "Other Topic"
    - "Other Topic"
    - "Other Topic"
  - - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
    - "Encoder-only transformers"
  - - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Encoder-only transformers"
    - "Pre-trained language models"
- "title": "Knowledge distillation: A survey"
  "unique_context_marker": "[37]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
- "title": "Multi-target knowledge distillation via student self-reflection"
  "unique_context_marker": "[38]"
  "block_ids":
  - 4
  - 7
  "intent_labels":
  - []
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
  - - "Other Topic"
    - "PLM-based fine-tuning strategies"
    - "Other Topic"
    - "Semi-supervised and adversarial adaptation"
    - "Semi-supervised and adversarial adaptation"
- "title": "A novel multi-knowledge distillation approach"
  "unique_context_marker": "[39]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
- "title": "DistInit: Learning video representations without a single labeled video"
  "unique_context_marker": "[40]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
- "title": "CKD: Cross-task knowledge distillation for text-to-image synthesis"
  "unique_context_marker": "[41]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
- "title": "AWSD: Adaptive weighted spatiotemporal distillation for video representation"
  "unique_context_marker": "[42]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
- "title": "Transformer-based cross-modal information fusion network for semantic segmentation"
  "unique_context_marker": "[43]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
- "title": "STFuse: Infrared and visible image fusion via semisupervised transfer learning"
  "unique_context_marker": "[44]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
- "title": "Multimodal and multiview distillation for real-time player detection on a football field"
  "unique_context_marker": "[45]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
- "title": "Not only look, but also listen: Learning multimodal violence detection under weak supervision"
  "unique_context_marker": "[46]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
- "title": "Decoupled multimodal distilling for emotion recognition"
  "unique_context_marker": "[47]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
- "title": "Multimodal distillation for egocentric action recognition"
  "unique_context_marker": "[48]"
  "block_ids":
  - 4
  "intent_labels":
  - []
  "topic_labels":
  - - "Semi-supervised and adversarial adaptation"
    - "PLM-based fine-tuning strategies"
    - "Other Topics"
    - "Other Topics"
    - "Other Topics"
- "title": "Dataset of breast ultrasound images"
  "unique_context_marker": "[49]"
  "block_ids":
  - 10
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Evaluation of 2D and 3D ultrasound tracking algorithms and impact on ultrasound-guided liver radiotherapy margins"
  "unique_context_marker": "[50]"
  "block_ids":
  - 10
  "intent_labels":
  - []
  "topic_labels":
  - []
- "title": "Improving realism in patient-specific abdominal ultrasound simulation using cycleGANs"
  "unique_context_marker": "[51]"
  "block_ids":
  - 10
  "intent_labels":
  - []
  "topic_labels":
  - []
