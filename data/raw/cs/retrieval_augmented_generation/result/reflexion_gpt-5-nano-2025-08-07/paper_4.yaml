"citations":
- "title": "Reliable, Adaptable, and Attributable Language Models with Retrieval"
  "unique_context_marker": "[1]"
  "block_ids":
  - 2
  "intent_labels":
  - "Importance of Problem"
  "topic_labels":
  - "Context Curation and Compression"
- "title": "Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension"
  "unique_context_marker": "[2]"
  "block_ids":
  - 13
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "Context Curation and Compression"
- "title": "xRAG: Extreme Context Compression for Retrieval-augmented Generation with One Token"
  "unique_context_marker": "[3]"
  "block_ids":
  - 1
  - 4
  - 16
  - 19
  "intent_labels":
  - "Prior Methods"
  - "Research Gap"
  - "Result Comparison"
  - "Result Comparison"
  "topic_labels":
  - "Context Curation and Compression"
  - "Input-Layer Integration"
  - "Other Topic"
  - "Other Topic"
- "title": "Adapting Language Models to Compress Contexts"
  "unique_context_marker": "[4]"
  "block_ids":
  - 4
  - 16
  "intent_labels":
  - "Research Gap"
  - "Result Comparison"
  "topic_labels":
  - "Context Curation and Compression"
  - "Other Topic"
- "title": "The Power of Noise: Redefining Retrieval for RAG Systems"
  "unique_context_marker": "[5]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "Learning to Transform, Combine, and Reason in Open-Domain Question Answering"
  "unique_context_marker": "[6]"
  "block_ids":
  - 1
  "intent_labels":
  - "Domain Overview"
  "topic_labels":
  - "Input-Layer Integration"
- "title": "ELI5: Long Form Question Answering"
  "unique_context_marker": "[7]"
  "block_ids":
  - 1
  - 8
  "intent_labels":
  - "Domain Overview"
  - "Prior Methods"
  "topic_labels":
  - "Context Curation and Compression"
  - "Context Curation and Compression"
- "title": "In-context Autoencoder for Context Compression in a Large Language Model"
  "unique_context_marker": "[8]"
  "block_ids":
  - 1
  - 4
  - 16
  "intent_labels":
  - "Prior Methods"
  - "Research Gap"
  - "Result Comparison"
  "topic_labels":
  - "Context Curation and Compression"
  - "Context Curation and Compression"
  - "Other Topic"
- "title": "Debertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing"
  "unique_context_marker": "[9]"
  "block_ids":
  - 12
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "Retriever Type"
- "title": "RAGGED: Towards Informed Design of Retrieval Augmented Generation Systems"
  "unique_context_marker": "[10]"
  "block_ids":
  - 1
  - 8
  "intent_labels":
  - "Domain Overview"
  - "Prior Methods"
  "topic_labels":
  - "Context Curation and Compression"
  - "Context Curation and Compression"
- "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"
  "unique_context_marker": "[11]"
  "block_ids":
  - 1
  "intent_labels":
  - "Domain Overview"
  "topic_labels":
  - "Training Strategies"
- "title": "Atlas: Few-shot Learning with Retrieval Augmented Language Models"
  "unique_context_marker": "[12]"
  "block_ids":
  - 1
  - 8
  "intent_labels":
  - "Domain Overview"
  - "Prior Methods"
  "topic_labels":
  - "Context Curation and Compression"
  - "Context Curation and Compression"
- "title": "LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models"
  "unique_context_marker": "[13]"
  "block_ids":
  - 1
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Context Curation and Compression"
- "title": "FreebaseQA: A New Factoid QA Data Set Matching Trivia-Style Question-Answer Pairs with Freebase"
  "unique_context_marker": "[14]"
  "block_ids":
  - 13
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "NLP Applications"
- "title": "Crowdsourcing Multiple Choice Science Questions"
  "unique_context_marker": "[15]"
  "block_ids":
  - 13
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "NLP Applications"
- "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"
  "unique_context_marker": "[16]"
  "block_ids":
  - 1
  - 8
  - 13
  - 14
  "intent_labels":
  - "Hyperparameter Utilization"
  - "Prior Methods"
  - "Resource Utilization"
  - "Benchmark Utilization"
  "topic_labels":
  - "NLP Applications"
  - "Context Curation and Compression"
  - "NLP Applications"
  - "Context Curation and Compression"
- "title": "Natural questions: a benchmark for question answering research"
  "unique_context_marker": "[17]"
  "block_ids":
  - 13
  - 14
  "intent_labels":
  - "Resource Utilization"
  - "Benchmark Utilization"
  "topic_labels":
  - "NLP Applications"
  - "Context Curation and Compression"
- "title": "SPLADE-v3: New baselines for SPLADE"
  "unique_context_marker": "[18]"
  "block_ids":
  - 12
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "Retriever Type"
- "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"
  "unique_context_marker": "[19]"
  "block_ids": []
  "intent_labels": []
  "topic_labels": []
- "title": "Unlocking Context Constraints of LLMs: Enhancing Context Efficiency of LLMs with Self-Information-Based Content Filtering"
  "unique_context_marker": "[20]"
  "block_ids":
  - 3
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Context Curation and Compression"
- "title": "Lost in the Middle: How Language Models Use Long Contexts"
  "unique_context_marker": "[21]"
  "block_ids":
  - 1
  "intent_labels":
  - "Domain Overview"
  "topic_labels":
  - "Trustworthiness and Robustness"
- "title": "When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories"
  "unique_context_marker": "[22]"
  "block_ids":
  - 14
  "intent_labels":
  - "Benchmark Utilization"
  "topic_labels":
  - "Context Curation and Compression"
- "title": "Text Embeddings Reveal (Almost) As Much As Text"
  "unique_context_marker": "[23]"
  "block_ids":
  - 2
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Context Curation and Compression"
- "title": "Generative Representational Instruction Tuning"
  "unique_context_marker": "[24]"
  "block_ids":
  - 1
  - 4
  "intent_labels":
  - "Prior Methods"
  - "Research Gap"
  "topic_labels":
  - "Context Curation and Compression"
  - "Context Curation and Compression"
- "title": "Ms marco: A human-generated machine reading comprehension dataset"
  "unique_context_marker": "[25]"
  "block_ids":
  - 13
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "NLP Applications"
- "title": "The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale"
  "unique_context_marker": "[26]"
  "block_ids":
  - 21
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "Training Strategies"
- "title": "KILT: a benchmark for knowledge intensive language tasks"
  "unique_context_marker": "[27]"
  "block_ids":
  - 13
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "Sequential Training"
- "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"
  "unique_context_marker": "[28]"
  "block_ids":
  - 13
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "NLP Applications"
- "title": "BERGEN: A Benchmarking Library for Retrieval-Augmented Generation"
  "unique_context_marker": "[29]"
  "block_ids":
  - 13
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "Joint Training"
- "title": "ASQA: Factoid Questions Meet Long-Form Answers"
  "unique_context_marker": "[30]"
  "block_ids":
  - 13
  - 14
  "intent_labels":
  - "Resource Utilization"
  - "Benchmark Utilization"
  "topic_labels":
  - "NLP Applications"
  - "Context Curation and Compression"
- "title": "LLoCO: Learning Long Contexts Offline"
  "unique_context_marker": "[31]"
  "block_ids":
  - 1
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Context Curation and Compression"
- "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"
  "unique_context_marker": "[32]"
  "block_ids":
  - 1
  "intent_labels":
  - "Domain Overview"
  "topic_labels":
  - "Parameter-Accessible Generators (White-box)"
- "title": "RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation"
  "unique_context_marker": "[33]"
  "block_ids":
  - 3
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Other Topic"
- "title": "WikiQA: A Challenge Dataset for Open-Domain Question Answering"
  "unique_context_marker": "[34]"
  "block_ids":
  - 13
  "intent_labels":
  - "Resource Utilization"
  "topic_labels":
  - "NLP Applications"
- "title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"
  "unique_context_marker": "[35]"
  "block_ids":
  - 1
  - 8
  - 13
  - 14
  "intent_labels":
  - "Domain Overview"
  - "Prior Methods"
  - "Resource Utilization"
  - "Benchmark Utilization"
  "topic_labels":
  - "NLP Applications"
  - "Context Curation and Compression"
  - "NLP Applications"
  - "Context Curation and Compression"
- "title": "Accelerating Inference of Retrieval-Augmented Generation via Sparse Context Selection"
  "unique_context_marker": "[36]"
  "block_ids":
  - 3
  "intent_labels":
  - "Prior Methods"
  "topic_labels":
  - "Other Topic"
