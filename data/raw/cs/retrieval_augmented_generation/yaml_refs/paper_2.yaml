citations:
  - title: "Gpt-4 technical report"
    unique_context_marker: "[1]"
  - title: "Query Refinement Prompts for Closed-Book Long-Form Question Answering"
    unique_context_marker: "[2]"
  - title: "A general language assistant as a laboratory for alignment"
    unique_context_marker: "[3]"
  - title: "Training a helpful and harmless assistant with reinforcement learning from human feedback"
    unique_context_marker: "[4]"
  - title: "Benchmarking Foundation Models with Language-Model-as-an-Examiner"
    unique_context_marker: "[5]"
  - title: "Improving language models by retrieving from trillions of tokens"
    unique_context_marker: "[6]"
  - title: "Language models are few-shot learners"
    unique_context_marker: "[7]"
  - title: "FELM: Benchmarking Factuality Evaluation of Large Language Models"
    unique_context_marker: "[8]"
  - title: "FacTool: Factuality Detection in Generative AIâ€“A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios"
    unique_context_marker: "[9]"
  - title: "Deep reinforcement learning from human preferences"
    unique_context_marker: "[10]"
  - title: "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"
    unique_context_marker: "[11]"
  - title: "ELI5: Long Form Question Answering"
    unique_context_marker: "[12]"
  - title: "GPTScore: Evaluate as You Desire"
    unique_context_marker: "[13]"
  - title: "Enabling Large Language Models to Generate Text with Citations"
    unique_context_marker: "[14]"
  - title: "How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection"
    unique_context_marker: "[15]"
  - title: "Retrieval augmented language model pre-training"
    unique_context_marker: "[16]"
  - title: "RefChecker for Fine-grained Hallucination Detection"
    unique_context_marker: "[17]"
  - title: "Unsupervised dense information retrieval with contrastive learning"
    unique_context_marker: "[18]"
  - title: "TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks"
    unique_context_marker: "[19]"
  - title: "Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension"
    unique_context_marker: "[20]"
  - title: "Wice: Real-world entailment for claims in wikipedia"
    unique_context_marker: "[21]"
  - title: "Dense passage retrieval for open-domain question answering"
    unique_context_marker: "[22]"
  - title: "Large language models are zero-shot reasoners"
    unique_context_marker: "[23]"
  - title: "Evaluating the factual consistency of abstractive text summarization"
    unique_context_marker: "[24]"
  - title: "Aquamuse: Automatically generating datasets for query-based multi-document summarization"
    unique_context_marker: "[25]"
  - title: "Natural questions: a benchmark for question answering research"
    unique_context_marker: "[26]"
  - title: "Fast and Accurate Factual Inconsistency Detection Over Long Documents"
    unique_context_marker: "[27]"
  - title: "Evaluating verifiability in generative search engines"
    unique_context_marker: "[28]"
  - title: "WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences"
    unique_context_marker: "[29]"
  - title: "G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment"
    unique_context_marker: "[30]"
  - title: "Teaching language models to support answers with verified quotes"
    unique_context_marker: "[31]"
  - title: "Augmented language models: a survey"
    unique_context_marker: "[32]"
  - title: "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation"
    unique_context_marker: "[33]"
  - title: "WebGPT: Browser-assisted question-answering with human feedback"
    unique_context_marker: "[34]"
  - title: "GPT-4 technical report"
    unique_context_marker: "[35]"
  - title: "Training language models to follow instructions with human feedback"
    unique_context_marker: "[36]"
  - title: "WebCPM: Interactive Web Search for Chinese Long-form Question Answering"
    unique_context_marker: "[37]"
  - title: "Squad: 100,000+ questions for machine comprehension of text"
    unique_context_marker: "[38]"
  - title: "In-Context Retrieval-Augmented Language Models"
    unique_context_marker: "[39]"
  - title: "Is reinforcement learning (not) for natural language processing?: Benchmarks, baselines, and building blocks for natural language policy optimization"
    unique_context_marker: "[40]"
  - title: "Coqa: A conversational question answering challenge"
    unique_context_marker: "[41]"
  - title: "REPLUG: Retrieval-Augmented Black-Box Language Models"
    unique_context_marker: "[42]"
  - title: "Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage"
    unique_context_marker: "[43]"
  - title: "Process for adapting language models to society (palms) with values-targeted datasets"
    unique_context_marker: "[44]"
  - title: "Lamda: Language models for dialog applications"
    unique_context_marker: "[45]"
  - title: "Llama 2: Open foundation and fine-tuned chat models"
    unique_context_marker: "[46]"
  - title: "Evaluating open question answering evaluation"
    unique_context_marker: "[47]"
  - title: "Survey on factuality in large language models: Knowledge, retrieval and domain-specificity"
    unique_context_marker: "[48]"
  - title: "Neural text generation with unlikelihood training"
    unique_context_marker: "[49]"
  - title: "Fine-Grained Human Feedback Gives Better Rewards for Language Model Training"
    unique_context_marker: "[50]"
  - title: "Face4RAG: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese"
    unique_context_marker: "[51]"
  - title: "Preference-grounded Token-level Guidance for Language Model Fine-tuning"
    unique_context_marker: "[52]"
  - title: "AlignScore: Evaluating Factual Consistency with a Unified Alignment Function"
    unique_context_marker: "[53]"