FoRAG: Factuality-optimized Retrieval Augmented Generation
for Web-enhanced Long-form Question Answering
Tianchi Cai
Ant Group
Hangzhou, China
tianchicai@gmail.com
Zhiwen Tan
Ant Group
Hangzhou, China
ender.tzw@antgroup.com
Xierui Song
Ant Group
Hangzhou, China
songxierui.sxr@antgroup.com
Tao Sun
Ant Group
Hangzhou, China
suntao.sun@antgroup.com
Jiyan Jiang
Tsinghua University
Beijing, China
scjjy95@outlook.com
Yunqi Xu
Ant Group
Hangzhou, China
xuyunqi.xyq@antgroup.com
Yinger Zhang
Ant Group
Hangzhou, China
zhangyinger@zju.edu.cn
Jinjie Gu
Ant Group
Hangzhou, China
jinjie.gujj@antgroup.com
ABSTRACT
Retrieval Augmented Generation (RAG) has become prevalent in
question-answering (QA) tasks due to its ability of utilizing search
engine to enhance the quality of long-form question-answering
(LFQA). Despite the emergence of various open source methods
and web-enhanced commercial systems such as Bing Chat, two
critical problems remain unsolved, i.e., the lack of factuality and
clear logic in the generated long-form answers. In this paper, we
remedy these issues via a systematic study on answer generation in
web-enhanced LFQA. Specifically, we first propose a novel outline-
enhanced generator to achieve clear logic in the generation of
multifaceted answers and construct two datasets accordingly. Then
we propose a factuality optimization method based on a carefully
designed doubly fine-grained RLHF framework, which contains
automatic evaluation and reward modeling in different levels of
granularity. Our generic framework comprises conventional fine-
grained RLHF methods as special cases. Extensive experiments
verify the superiority of our proposed Factuality-optimized RAG
(FoRAG) method on both English and Chinese benchmarks. In par-
ticular, when applying our method to Llama2-7B-chat, the derived
model FoRAG-L-7B outperforms WebGPT-175B in terms of three
commonly used metrics (i.e., coherence, helpfulness, and factual-
ity), while the number of parameters is much smaller (only 1/24 of
that of WebGPT-175B). Our datasets and models are made publicly
available for better reproducibility.1
1https://huggingface.co/forag
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Â© 2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3672065
CCS CONCEPTS
â€¢Computing methodologies â†’ Natural language generation.
ACM Reference Format:
Tianchi Cai, Zhiwen Tan, Xierui Song, Tao Sun, Jiyan Jiang, Yunqi Xu,
Yinger Zhang, and Jinjie Gu. 2024. FoRAG: Factuality-optimized Retrieval
Augmented Generation for Web-enhanced Long-form Question Answering .
In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD â€™24), August 25â€“29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 30 pages. https://doi.org/10.1145/3637528.3672065
1 INTRODUCTION
Retrieval Augmented Generation (RAG), a technique that augments
Large Language Models (LLMs) with a retriever by appending the
retrieved relevant passages to the current context [32], has recently
attracted considerable research attention [ 6, 16]. The access to
search engine supplements massive and latest knowledge to LLMs,
boosting their performance on various knowledge intensive tasks,
such as open domain dialogue [45] and question answering (QA)
[43].
Following this paradigm, many web-enhanced commercial sys-
tems have been developed, such as Bing Chat2 and perplexity.ai.3
They generate answers to user queries in natural language with
reference to web pages, which we refer to as the web-enhanced
long-form question-answering (LFQA) task. Although these sys-
tems can generate coherent and helpful answers, recent researches
have revealed the low factuality issue of these systems, such that
only about half of the statements generated are fully supported by
the retrieved references [14, 28]. This poses an unignorable threat
to the trustworthiness of existing web-enhanced LFQA systems.
Despite its prevalence, there lacks an effective method to opti-
mize factuality in web-enhanced LFQA as far as we are concerned.
There are two intrinsic difficulties. First, previous studies mostly
rely on human evaluation [28, 31, 34], which is generally expensive
to acquire. In web-enhanced LFQA task, factuality is even more
2Bing Chat: https://www.bing.com/chat.
3perplexity.ai: https://www.perplexity.ai.
arXiv:2406.13779v1  [cs.CL]  19 Jun 2024
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
â€¦â€¦
Web Page 1â€¦â€¦Web Page N
How do ancient civilizations get covered by dirt, sand, etc?
The reason ancient cities get buried is because of a survivorship bias. Most ancient cities got buried under the dust and rubble of structures that had collapsed over the centuries and millennia that followed theirâ€¦â€¦
I. Natural Processes:Wind and dust storms, Erosion, â€¦â€¦II. Human Activities:Abandonment, Agriculture, ConstructionIII. Conclusion:Variation in burial rates and processes,â€¦â€¦
Holistic-levelSentence-levelSubclaim-level
â€¦ buildings and structures â€¦ ğ’“"ğ’Š=argminğ’“#ğ’Š Loss(ğ’“"ğ’Š,ğ’“ğ’Š) =argminğ‘¹%ğ’Š,ğ’‹ Loss(Agg&(ğ‘¹2ğ’Š,ğ’‹ ),ğ’“ğ’Š) 
Reward Model Granularity
ğ‘¹2ğ’Š,ğ’‹
Sequence-levelToken-levelâ€¦ â€¦
Web-Enhanced Input
Relevant Passage 1
PPO
Relevant Passage Nâ€¦â€¦
Segmentation+Retrieval
Outline-Enhanced GeneratorFactuality Optimization
Generator
Query
Search Engine
Reference
Answer
Cause-EffectOrganizational Pattern
Outline
Answer
ğ‘¹2ğ’Š,ğ’ğ‘¹2ğ’Š,ğ’*ğŸğ‘¹2ğ’Š,ğ’*ğŸğ‘¹2ğ’Š,ğ’*ğŸ‘
Evaluation Granularity
There are several ways ancient civilizationscan get covered by dirtâ€¦â€¦Natural processes:Wind and dust storms: Over time, wind can carry large amounts â€¦â€¦â€¦â€¦Human activities:Abandonment: When a civilization is abandoned, buildings and structures are no longer maintained and â€¦â€¦â€¦â€¦Conclusion:Variation in burial rates and processes,â€¦â€¦
There are several ways ancient civilizationscan get covered by dirtâ€¦â€¦
â€¦â€¦
ğ‘Ÿ=âœ“
ğ’“ğ’Š	=âœ“
ğ’“ğŸ	=âœ•ğ’“ğŸ	=âœ“
Buildings are no longer maintained.A civilization is abandoned.ğ‘¹ğ’Š,ğŸ=ğ‘¹ğ’Š,ğŸ=âœ“âœ•
ğ’“ğ’Š=Agg&																	=Agg&1,0,1=ğŸ.ğŸ”ğŸ”	
â€¦â€¦ğ‘¹ğŸ,ğŸ=ğ’“ğŸ=Agg&ğ‘¹ğŸ,ğ’‹=0.5ğ‘¹ğŸ,ğŸ=âœ“âœ•
â€¦â€¦ğ‘¹ğŸ,ğŸ=ğ’“ğŸ=Agg&ğ‘¹ğŸ,ğ’‹=ğ‘¹ğŸ,ğ’‰=âœ“âœ“ âœ“
GPT-4Evaluation
â€¦â€¦
â€¦â€¦
Structures are no longer maintained.ğ‘¹ğ’Š,ğŸ‘=âœ“subclaim i2subclaim i3
subclaim i1When a civilization is abandoned, buildingsand structures are no longer maintained and â€¦â€¦
sentence iNatural processesâ€¦â€¦sentence 2sentence 1There are several ways â€¦â€¦
sentence isentence i
âœ“âœ•âœ“
Figure 1: Illustrations of the input for LLM in web-enhanced LFQA task (upper left), the existing generator (lower left), our
outline-enhanced generator (middle) and our doubly fine-grained factuality optimization method (right). Before generating a
long answer, the outline-enhanced generator first drafts an organization pattern and an outline to promote a clear logic for
generation. The doubly fined-grained RLHF optimizes factuality by incorporating fine-grained designs on two core steps, i.e.
factuality evaluation and reward modeling, with methods on multiple levels of granularities proposed on each step.
time-consuming and difficult to manually annotate compared to
other language generation tasks, since it involves comparing the
factual details of two lengthy texts [50]. Second, the most commonly
used fine-tuning method for human preference alignment, i.e., Rein-
forcement Learning from Human Feedback (RLHF), conventionally
adopts the holistic reward, such that each answer only has a single
evaluation score. Such a reward provides a relatively sparse train-
ing signal, which undermines the reliability of RLHF [ 40, 50]. In
web-enhanced LFQA, the sparsity problem is even exaggerated, as
the answers are in long form.
Besides the above factuality issue, different from conventional
QA tasks with short answers, web-enhanced LFQA poses extra chal-
lenges due to the pervasive ambiguity of many real-world questions.
A desirable answer to these questions is preferred to be multifac-
eted [2], which requires organizing and consolidating information
from multiple aspects and references [25]. The problem might be
one possible reason why existing open source methods such as
WebGLM [29] have no explicit improvement over closed source
methods such as WebGPT-175B.
To resolve the above issues, in this paper, we conduct a system-
atic study of web-enhanced LFQA. Specifically, we first propose
a novel outline-enhanced generator, which achieves clear logic in
the generation of multifaceted answers. We then propose an inno-
vative factuality optimization approach based on a novel doubly
fine-grained RLHF framework. Specifically, we design new auto-
matic evaluation and reward modeling steps in different granulari-
ties, which allows to optimize factuality for RAG in a flexible way.
Our generic method contains several existing fine-grained RLHF
methods as special cases.
Extensive experiments demonstrate the effectiveness of our pro-
posed method, which achieves state-of-the-art performance on both
Chinese and English benchmarks. Specifically, the outline-enhanced
generator significantly improves the coherence and helpfulness,
while the doubly fine-grained factuality optimization method sub-
stantially promotes the factuality on both answer and sentence
levels. Remarkably, applying our method to Llama2-7B-chat yields
a fine-tuned model FoRAG-L-7B, which, for the first time, surpasses
the WebGPT-175B on coherence, helpfulness, and factuality, while
the number of parameters of FoRAG-L-7B is much smaller (only
1/24 of that of WebGPT-175B).
The contributions of this work are summarized as follows:
â€¢ We propose a new outline-enhanced generator to promote
a clear logic of long answer generation in RAG, which sig-
nificantly improves the coherence and helpfulness of the
generated answers. Two large-scale outline-enhanced LFQA
datasets are accordingly constructed.
â€¢ We propose a novel factual optimization method for web-
enhanced RAG based on a novel doubly fine-grained RLHF
framework, which eschews the need of expensive human
annotation.
â€¢ We conduct extensive experiments to show that our method
achieves state-of-the-art performance on both Chinese and
English benchmarks. Notably, the FoRAG-L-7B model fine-
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
tuned by our method outperforms WebGPT-175B on coher-
ence, helpfulness, and factuality, with only 1/24 of the pa-
rameters in WebGPT-175B. Both datasets and models are
publicly available for better reproducibility.
2 RELATED WORK
In this section, we review prior work in three related fields, i.e.,
open-domain question answering, retrieval augmented generation,
as well as web-enhanced LFQA.
Open-domain Question Answering . In the field of open-
domain QA, traditional efforts have centered around reading com-
prehension techniques, with foundational datasets like SQuAD
[38] providing human-written questions and extracted answers.
Subsequent datasets, including Natural Questions [26], TriviaQA
[20], and CoQA [41], continue this trend but largely cater to brief
answers. Recognizing the value of more informative, long-form re-
sponses, recent initiatives such as ELI5 [12] have begun to compile
questions demanding detailed answers, prompting research into
advanced generative techniques to meet this need.
Retrieval-Augmented Generation. Retrieval-Augmented Gen-
eration (RAG) enhances language model (LM) performance by inte-
grating external knowledge retrieval with in-context learning. The
knowledge retrieval techniques in RAG include sparse methods
such as BM25 and TF-IDF and dense retrieval systems, including
DPR [22] and Contriever [18]. To utilize the retriever, various meth-
ods are proposed. REALM proposes a joint optimization of retriever
and language modeling [16]. Retro uses a frozen retriever to en-
hance the generation ability model with a novel chunked cross-
attention mechanism [6]. Atlas studies the few-shot ability for RAG
models. Others combine black-box LMs with custom or fine-tuned
retrieval systems [39, 42]. Different from these work, we treat the
retrieval step as a black box and focus on improving the generation
quality given the query and retrieved passages.
Web-enhanced LFQA. The web-enhanced LFQA takes a new
approach to QA tasks which utilizes the retrieval ability of search
engine to improve the generation performance on long-form QA.
Closely related to our work, WebGPT [34] uses the questions from
ELI5 and explores the ability of LLMs in navigating through the web,
retrieving passages from web, and generating long-form responses.
Despite its notable capabilities, the dataset, and models are not
accessible to the public. Following this idea, WebCPM [37] builds
and releases an open-source web-enhanced LFQA model in Chinese.
WebGLM [29] provides an more efficient and cost-effective method
by replacing the expert annotation with evaluations using LLMs
and utilizing a non-interactive way to use search engine. However,
its resulting model, the WebGLM-10B does not outperforms the
WebGPT-175B. Compared to these works, we consider optimizing
the logic structure and factuality of the generation, which has not
been studied in web-enhanced LFQA as far as we know.
3 PRELIMINARY
In this section, we briefly review the RAG pipeline in web-enhanced
LFQA task, which for simplicity of presentation, we adopt the term
web-enhanced RAG to describe in the sequel. The web-enhanced
RAG pipeline is demonstrated in the left column of Figure 1.
In web-enhanced RAG, for a given user input ğ‘¥, the system first
utilizes a web search engine to retrieve a list of relevant website
URLs, then crawls the websites and extracts the relevant text seg-
ments ğ‘§, which are usually calledreference or context for generation
[37]. This extraction is commonly done by first segmenting the
web pages into text segments and then using pre-trained dense
retrievers to extract the top-k segments [29].
After deriving the contextğ‘§, the RAG system generates an answer
ğ‘¦ based on the context ğ‘§ and the user query ğ‘¥. Following [ 40],
the response generation can be formulated as a Markov Decision
Process (MDP) < S, A, R, ğ‘ƒ, ğ›¾ >. In such a process, each episode
starts with a sampled state ğ‘  âˆˆ S , where ğ‘  = (ğ‘¥, ğ‘§) is a prompt that
contains a query ğ‘¥ and a relevant context ğ‘§ (here the parenthesis
denotes string concatenation). At each stepğ‘¡ during this episode, the
state ğ‘ ğ‘¡ = (ğ‘¥, ğ‘§, ğ‘1, ..., ğ‘ğ‘¡ âˆ’1) is described by the query ğ‘¥, the context
ğ‘§, and all the previously generated tokens (ğ‘1, ..., ğ‘ğ‘¡ âˆ’1), which is
denoted ğ’‚ğ‘¡ âˆ’1 for short. Given the state ğ‘ ğ‘¡ , the LLM, denoted by
ğœ‹ğœƒ , defines a probability distribution ğ‘ âˆ¼ ğœ‹ğœƒ (Â·|ğ‘ ğ‘¡ ) over all tokens
ğ‘ âˆˆ A conditioned on the current state ğ‘ ğ‘¡ , where ğœƒ denotes the
trainable parameters of the LLM. After generating the specific token
ğ‘ğ‘¡ âˆˆ A , the state will transit to ğ‘ ğ‘¡ +1 = (ğ‘ ğ‘¡ , ğ‘ğ‘¡ ) at the next time step
ğ‘¡ + 1 by appending the latest generated ğ‘ğ‘¡ token to the current
state ğ‘ ğ‘¡ . This episode terminates when the length ğ‘¡ exceeds a pre-
defined threshold ğ‘‡ or an end-of-sequence token is generated. In
the above definition of MDP, the parameter ğ›¾ is a discount factor.
In most of the language generation tasks, we have a task specific
evaluation metric R (ğ’‚ğ‘‡ , ğ‘¥, ğ‘§) that depends on the final context
ğ‘ ğ‘‡ = (ğ‘¥, ğ‘§, ğ‘1, ..., ğ‘ğ‘‡ ) which consists of the generated sequence ğ’‚ğ‘‡
and the initial context ğ‘¥, ğ‘§, which is typically given at the end
of sequence to reflect the quality of the generated sequence, e.g.,
whether the sequence is helpful or harmless [4]. Depending on the
evaluation granularity, R (ğ’‚ğ‘‡ , ğ‘¥, ğ‘§) might be a scalar or a vector or
even a matrix, we denotes the three cases by ğ‘Ÿ, ğ’“, ğ‘¹, respectively
(see later explanations in Section 5.2) .
Besides helpfulness or harmlessness, one crucial criterion of
response generation in RAG is factuality (or verifiability), which
leverages the extent to which the generated response is trustful.
In general, the response ğ‘¦ is considered to be truthful if its con-
tents are factually consistent with the retrieved text ğ‘§ [48]. In most
previous works [33, 47], factuality is mainly evaluated by human
annotation or via the NLI model (i.e., whether the context can entail
the information contained by the response) [53] or general purpose
LLMs [17, 21, 27], such as ChatGPT [36] or GPT4 [35].
4 OUTLINE-ENHANCED RAG
In this section, we propose the Outline-Enhanced generation tech-
nique, which is able to generate well-structured responses of high
quality. Illustrated in Figure 1 (middle), the outline-enhanced gen-
erator takes a two-stage generation, where the generator first gen-
erates an organizational pattern and outline to improve the logic
structure. In the following, we describe our technique and the cor-
responding construction of two outline-enhanced LFQA datasets.
4.1 Outline-Enhanced Generator
In most existing open-source methods [29, 34, 37], the responses are
directly generated, i.e., the retrieved contents are concatenated with
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
Table 1: The statistics of web-enhanced long-form QA
datasets. Applying our outline-enhanced generation tech-
nique yields significantly longer answers (Ans. (OE)) com-
pared with the original answer (Ans. (Ori)).
Dataset Avg. Length (in Tokens)4
# Samples
Query Ans. (Ori.) Ans. (OE)
WebCPM (zh) 44.1 374.1 623.1 5,500
WebGLM (en) 17.8 151.3 409.0 43,579
WebGPT-13b (en) 20.9 212.4 407.4 272
WebGPT-175b (en) 20.9 208.9 414.2 272
the original query and fed into a generation model using certain
prompt template (Figure 1 lower left). Compared to those generated
by closed-source methods, these responses are shorter and often
found unorganized, lacking a clear logical structure.
To enhance the performance, one possible way is to make the
responses more organized. Indeed, some researchers have found
that carefully designed prompts that comprise task descriptions
and a few demonstrations will improve the quality of the generated
responses on various tasks [7]. For example, the technique of â€œLetâ€™s
think step by step" [23] substantially improves the performance by
encouraging the chain-of-thought reasoning ability.
Inspired by the above works, we introduce the outline-enhanced
technique into response generation. Our proposed generator in-
cludes an outline stage and an expansion stage, which aligns with
the intuition that when answering a question, human usually first
outlines and organizes the answer before expanding each point.
Specifically, to generate high-quality output with a clear logic flow,
we prompt the model to first output an outline of the final answer,
and then concatenate the draft into the prompt to generate the full
response. In the following, we elaborate the two stages in detail.
Outline Stage. In this stage, the generator first drafts an outline
of the answer using an outline template, with the user query ğ‘¥ and
context ğ‘§ as input. The outline template guides the LLM to first
consider which organizational pattern is best suitable to the current
question, e.g., â€œcause and effect" or â€œcompare and contrast". Then
the LLM uses the organizational pattern to output an outline. For
example, when the selected pattern is â€œcompare and contrast", the
generated outline will include various perspectives that will later
be used to expand on the similarities and differences.
Expansion Stage. Based on the outline generated at the former
stage, the LLM expands each perspective to construct the final
answer. Specifically, The model is then asked to generate an answer
to the question, given the input containing the query ğ‘¥, the context
ğ‘§ and the outline ğ‘œ generated in the first stage.
The training of the outline-enhanced generator follows the stan-
dard supervised fine-tuning (SFT) procedure, which is widely adopted
in previous works [4, 36].
4We utilize the tokenizer of https://huggingface.co/meta-llama/Llama-2-7b-chat-hf.
4.2 Outline-Enhanced Long-Form QA Dataset
As far as we know, there are only two open-sourced web-enhanced
long-form QA datasets available for training web-enhanced RAG
models.5 The English dataset, i.e. the WebGLM-QA [29], contains
44ğ‘˜ samples, while the Chinese dataset, i.e. WebCPM [ 37], con-
tains 5, 500 samples. The queries in both datasets are sampled from
ELI5 [12], where WebGLM-QA sample question from it, and We-
bCPM additionally uses human annotators to translate the question
into Chinese. The Web search engine are used to collect relevant
passages.
We construct an outline-enhanced bilingual long-form QA dataset
using the queries and relevant passages from these two datasets.
We apply our outline-enhanced generation technique using GPT4
[1] to collect outline-enhanced answers. We design a prompt to
instruct GPT4 to execute the outline stage and the expansion stage
in a step-by-step manner, which is provided in Appendix A. The
detailed statistics of the existing datasets and our outline-enhanced
answers are presented in Table 1. It is clear that our demonstration
answers are much longer than that in existing works, due to the
stronger logic structure (examples are provided in Appendix D). The
outline-enhanced answers derived from WebCPM and WebGLM
are publicly available. 1
Note that the imbalance of the amount of training samples in
English and Chinese datasets may pose difficulty to train a bilingual
web-enhanced RAG model. To overcome this difficulty, we further
collect 39ğ‘˜ queries and relevant passages in Chinese from public
sources, and follow the same process to generate outline-enhanced
answers. These data will be released to the public after passing the
censoring process of data release.
5 FACTUALITY-OPTIMIZED RAG
In this section, we propose a novel factuality optimization method
to address the aforementioned factuality issue in web-enhanced
LFQA. Specifically, we first discuss the difficulty of directly ap-
plying the conventional RLHF method to factuality optimization,
then develop a novel doubly fine-grained RLHF framework, which
characterizes different granularities of automated evaluation and
reward modeling, upon which our method is built.
5.1 Difficulties of Directly Applying RLHF
In LLM alignment, reinforcement learning with human feedback
(RLHF) [10, 36] is a widely used technique to reduce undesirable gen-
erations, e.g., harmful responses in chat assistant tasks [4]. Viewing
nonfactuality as a certain kind of undesirable behaviors, a natural
way to promote factuality in web-enhanced RAG is to utilize RLHF
to prevent the generator from producing nonfactual responses. To
proceed, we first give a detailed description of RLHF.
Conventionally, RLHF is conducted on manually annotated pref-
erence data. For example, given the query ğ‘¥ and the retrieved con-
text ğ‘§, the factuality of an answer ğ’‚ğ‘‡ (tokenized as (ğ‘1, . . . , ğ‘ğ‘‡ ))
can be annotated as ğ‘Ÿ âˆ¼ R ( ğ’‚ğ‘‡ , ğ‘¥, ğ‘§), where ğ‘Ÿ âˆˆ [ 0, 1] reflects the
underlying human preference. RLHF trains a reward model Ë†ğ‘… to
estimate the factuality given any query ğ‘¥, reference ğ‘§, and answer
ğ’‚, i.e., to learn the human preference function R. Then RL methods
5The WebGPT demo website contains 272 samples, which can be used for evaluation
but not sufficient for training.
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 2: The reward model training losses when combining different fine-grained evaluation and fine-grained reward modeling
techniques are displayed. Note that our doubly fine-grained RLHF framework provides a unified framework, containing the
existing RLHF [10] and fine-grained RLHF approaches [50, 52] as special cases.
Reward model
granularity
Evaluation Granularity
Holistic Sentence-level Subclaim-level
Sequence-level Logloss( Ë†ğ‘¹ğœ™, ğ‘Ÿ)[10] Ãğ¿
ğ‘–=1 Logloss( Ë†ğ‘¹ğœ™ [ğ‘–], ğ’“ğ‘–)[50] Ãğ¿
ğ‘–=1 MSE( Ë†ğ‘¹ğœ™ [ğ‘–], Aggğ‘— (ğ‘¹ğ‘– ğ‘—))
Token-level Logloss(Aggğ‘¡ ( Ë†ğ‘Ÿğ‘¡ ), ğ‘Ÿ)[52] Ãğ¿
ğ‘–=1 Logloss(Aggğ‘¡ ( Ë†ğ‘Ÿğ‘¡ ) [ğ‘–], ğ’“ğ‘–) Ãğ¿
ğ‘–=1 MSE(Aggğ‘¡ ( Ë†ğ‘Ÿğ‘¡ ) [ğ‘–], Aggğ‘— (ğ‘¹ğ‘– ğ‘—))
such as PPO are applied to optimize the generation model based
on the trained reward model Ë†ğ‘…. The optimization problem can be
formulated as
max
ğœƒ
âˆ‘ï¸
ğ‘ 1âˆ¼D
ğ‘‡âˆ‘ï¸
ğ‘¡ =1
Eğ‘ğ‘¡ âˆ¼ğœ‹ğœƒ (Â· |ğ‘ ğ‘¡ ) ) [1(ğ‘¡ = ğ‘‡ )ğ‘Ÿ ] âˆ’ ğ›½DKL (ğœ‹ğœƒ (Â·|ğ‘ ğ‘¡ )|| ğœ‹ref(Â·|ğ‘ ğ‘¡ )),
where 1 is the indicator function, DKL is KL divergence regulariza-
tion, and ğ›½ is the regularization strength. In the above formulation,
the regularization term is introduced to prevent the generation
model from deviating too far from a reference model ğœ‹ref. The
reference model is often set as the model after SFT (e.g., our outline-
enhanced RAG model as proposed above).
Directly applying the conventional RLHF method to factuality
optimization in web-enhanced LFQA will encounter two intrinsic
difficulties. First, the manually annotated factuality labels are typ-
ically expensive to collect, which involves comparing the factual
details between a long answer and its corresponding lengthy refer-
ence. Second, as shown in the above equation, the standard RLHF
uses the holistic reward, i.e., 1(ğ‘¡ = ğ‘‡ )ğ‘¹ (ğ’‚, ğ‘¥, ğ‘§), which is not zero
only for the last token of the whole response. This holistic reward
can only provide a sparse signal for the training of the generation
model ğœ‹ğœƒ . In web-enhanced LFQA where the answers are usually
longer, the sparsity problem due to the use of the holistic reward
will be even exaggerated.
5.2 Doubly Fine-grained RLHF
In light of the above difficulties of conventional RLHF in factuality
optimization for web-enhanced RAG, we propose a doubly fine-
grained RLHF framework to conduct factuality optimization in a
fine-grained manner. Our framework is inspired by recent study
on fine-grained RLHF [50, 52]. Unlike these previous works that
mainly focus on a single dimension, our framework incorporates
fine-grained designs of two core steps, i.e., factuality evaluation
and reward modeling.
Before elaborating our framework in details, we first introduce
necessary notations and definitions, which enables to characterize
multiple rewards for an answer that constitute a denser reward
signal ğ‘¹ğœ™ for the RL process. Specifically, following [50], we first
segment the output ğ’‚ into ğ¿ text spans (ğ’‚1, ğ’‚2, . . . , ğ’‚ğ¿) correspond-
ing to the evaluation granularity (which will be described later)
of ğ‘¹ğœ™ , where each segment ğ’‚ ğ‘— ends at the step ğ‘‡ğ‘— . The dense re-
ward signal ğ‘¹ğœ™ is an ğ¿-dimensional vector, whose ğ‘—-th dimension
represents the reward ğ‘¹ğœ™ (ğ’‚|ğ‘¥, ğ‘§) [ğ‘—] âˆˆ [ 0, 1] for each segment ğ’‚ ğ‘—
given query ğ‘¥ and retrieved context ğ‘§ as the input, which is as-
signed to the final token in ğ’‚ ğ‘— . Especially, when ğ¿ = 1, our method
degenerates to the standard RLHF with holistic reward.
Fine-grained Evaluation. Recall that to perform high quality
automatic factuality evaluation, recent methods have been pro-
posed to first decompose a long answer into shorter pieces and
then evaluate the factuality of each piece with respect to the given
reference [21, 27]. Inspired by these methods, we consider three
different levels of granularity in the answer decomposition and
automated segment evaluation:
â€¢ Holistic: It is the standard granularity to evaluate the answers
[10]. Each generated answer is associated with a single fac-
tuality score ğ‘Ÿ.
â€¢ Sentence-level: As is suggested by previous research on auto-
matic evaluation [24, 27], we can segment the answer into
sentences,6 then evaluate each sentence individually. In this
case, the evaluation result is denoted as ğ’“ğ‘– where ğ‘– is the
index for the sentence.
â€¢ Subclaim-level: Following [9, 21, 33], we can further decom-
pose each sentence into multiple subclaims via an LLM, each
containing a single piece of factual information (see Appen-
dix C for the prompts we use). After the decomposition, we
evaluate each subclaim individually. Since the decomposition
using LLM breaks the association between the subclaim and
the original answer, we aggregate the scores of all subclaims
into a single score to evaluate the factuality of the sentence.
More specifically, assuming there are ğ‘— subclaims for sen-
tence ğ‘–, then the evaluation score for the sentence is given
as ğ’“ğ‘– = Aggğ‘— (ğ‘¹ğ‘– ğ‘—), where ğ‘¹ğ‘– ğ‘— denotes the factuality score
of the subclaim ğ‘— of sentence ğ‘–, and Agg is the aggregation
function (in the form of average, minimum, or maximum).
Fine-grained Reward Modeling. Recall that to build a reward
model to estimate the factuality of a given answer, standard RLHF
methods typically use a sequence-level reward model that produces
a single factuality score for each answer. Recently, a token-level
reward modeling method has been introduced to provide token-
level feedback [52]. Enlightened by these methods, we can construct
the reward model in two possible levels of granularity.
â€¢ Sequence-level: A single reward Ë†ğ‘¹ğœ™ (ğ’‚|ğ‘¥, ğ‘§) is learned for each
sequence, whose actual form depends on the granularity of
the evaluation. In this way, the associated reward reflects
the factuality of the corresponding sequence, which is then
assigned to the last token of each sequence.
6We uses pySBD https://github.com/nipunsadvilkar/pySBD for segmentation.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
â€¢ Token-level: A reward Ë†ğ‘Ÿ (ğ‘ ğ‘¡ , ğ‘ğ‘¡ ) learned for each token in
the sequence. In this way, the reward of the sequence is
calculated by aggregating the all token-level rewards i.e.,
Ë†ğ‘¹ğœ™ (ğ’‚|ğ‘¥, ğ‘§) = Aggğ‘¡ ( Ë†ğ‘Ÿ (ğ‘ ğ‘¡ , ğ‘ğ‘¡ )).
The training loss of each combination of automated evaluation
and reward modeling in different levels of granularity is illustrated
in Table 2. In most cases, the reward ğ‘Ÿ is binary labelled, and the
reward model is trained with the Logloss:
Logloss( Ë†ğ‘¹ğœ™, ğ‘Ÿ) = âˆ’
âˆ‘ï¸
(ğ‘¥,ğ‘§,ğ’‚,ğ‘Ÿ ) âˆˆ D
ğ¿âˆ‘ï¸
ğ‘–=1
ğ’“ğ‘– log( Ë†ğ‘¹ğœ™ (ğ’‚|ğ‘¥, ğ‘§) [ğ‘–])
+(1 âˆ’ ğ’“ğ‘– ) log(1 âˆ’ Ë†ğ‘¹ğœ™ (ğ’‚|ğ‘¥, ğ‘§) [ğ‘–]) .
When the aggregation step in subclaim-level evaluation yields con-
tinuous-valued reward ğ‘Ÿ, we choose to use the MSE loss for reward
model training instead
MSE( Ë†ğ‘¹ğœ™, ğ‘Ÿ) =
âˆ‘ï¸
(ğ‘¥,ğ‘§,ğ’‚,ğ‘Ÿ ) âˆˆ D
ğ¿âˆ‘ï¸
ğ‘–=1
( Ë†ğ‘¹ğœ™ (ğ’‚|ğ‘¥, ğ‘§) [ğ‘–] âˆ’ ğ’“ğ‘– )2.
After the reward model Ë†ğ‘¹ is learned, we adopt PPO to optimize
the generation model by maximizing the following reward
Ë†ğ‘Ÿğ‘¡ (ğ‘ ğ‘¡ , ğ‘ğ‘¡ ) =
ğ¿âˆ‘ï¸
ğ‘—=1
1(ğ‘¡ = ğ‘‡ğ‘— ) Ë†ğ‘¹ğœ™ (ğ’‚|ğ‘¥, ğ‘§) [ğ‘—] âˆ’ ğ›½ log ğœ‹ğœƒ (ğ‘ğ‘¡ |ğ‘ ğ‘¡ )
ğœ‹ref(ğ‘ğ‘¡ |ğ‘ ğ‘¡ ) .
Compared to the conventional RLHF with a single reward for each
answer, our formulation has ğ¿ non-zero rewards corresponding to
the segments, which alleviates the sparse feedback signal problem
in conventional RLHF.
Note that our proposed framework unifies the existing fine-
grained RLHF works [50, 52] by containing these methods as special
cases. Moreover, although our framework is motivated by optimiza-
tion factuality for web-enhanced RAG, it can also be generalized to
other RLHF tasks.
6 EXPERIMENT
In this section, we conduct extensive experiments to validate the
effectiveness of our outline-enhanced generation technique and
factuality optimization methods.
6.1 Experimental setup
Datasets. We conduct experiments on two commonly used datasets
for web-enhanced long-form QA.
The WebGPTâ€™s dataset. Although the training dataset originally
used for WebGPT is not publicly available, the 272 samples released
on the WebGPT demo website7 can be used as a testbed for per-
formance comparison [29]. In this dataset, each sample consists
of a question from the ELI5 dataset [ 12], several Bing retrieved
web pages, and extracted references. Note that it is a pure English
dataset.
The WebCPMâ€™s dataset. [37]. This is a Chinese dataset constructed
similarly to the WebGPT dataset. As there is no official train-test
split, we randomly split 4,676 samples for training, 426 for valida-
tion, and 398 for testing.
7https://openaipublic.blob.core.windows.net/webgpt-answer-viewer/index.html
Compared Methods. We compare our method with three web-
enhanced baseline methods.
WebGPT [34] supports interactive web search for long-form QA.
It has two versions, namely WebGPT-13B and WebGPT-175B, where
the latter one is the currently state-of-the-art performing model for
web-enhanced QA. Note that when comparing with WebGPT, we
directly use the responses collected from its website.
WebCPM [37] is an open source web-enhanced RAG involving
interactive web search. It is the first work on Chinese web-enhanced
RAG. It is trained on a dataset which contains 5,500 question-answer
pairs in Chinese with references.
WebGLM [29] is an open source web-enhanced QA system with
human performance. It simplifies the interactive web search ap-
proach in WebGPT and WebCPM by a two-step retriever and gen-
erator framework. It is trained on the WebGLM-QA dataset, which
focuses on English only.
Metrics. We adopt three commonly used metrics for web-enhanced
RAG, i.e., coherence, helpfulness, and factuality. As existing works
show that GPT4â€™s evaluation is highly consistent to human anno-
tations in both English [5, 13, 15, 19, 30] and Chinese [51], we use
GPT4 to evaluate these metrics. For the completeness of our study,
we also justify the consistency between GPT4 and human annota-
tion in Chinese in ablation study. Following the framework of [30],
we evaluates the coherence (Cohr.) and helpfulness (Help.) metrics.
We count the scores greater than or equal to 4 as the judging criteria.
For evaluation of factuality consistency, we adopt the method in
[8] to achieve fine-grained evaluation. In addition, since the longer
answers are more likely to have factuality mistakes, for the fairness
of the evaluation, we report the scores at two granularities, i.e.,
query-level (Fact/q.) and sentence-level (Fact/s.). The prompts we
used for the evaluations are given in Appendix B.
Models and Training Configuration. Our experiments are
conducted by fine-tuning on Llama2-7B-chat [46] and ChatGLM2-
6B [11], which are widely used LLMs for question-answering in
English and Chinese respectively. The prompt templates at fine-
tuning and inference stages are given in Appendix A. The maxi-
mum context length is set to 4096 for Llama2-7B-chat and 8192 for
ChatGLM2-6B. Both models are fine-tuned on 8 A100 GPUs for 5
epochs with a initial learning rate of 1e-5 and a cosine learning
rate scheduler. Following the configuration of WebCPM [37], we
adopt beam search for each inference on a single A100 GPU with
the num_beams parameter set to 3. We use our outline-enhanced
dataset to conduct supervised fine-tuning (SFT) [36], and our multi-
granularity evaluation data to conduct corresponding factuality
optimization. In order to decrease noise in the RLHF step, we nor-
malize the reward. Specifically, for each prompt (ğ‘¥, ğ‘§), we generate
a response ğ’‚ğ‘‡ using the SFT model, and estimates its reward score
Ë†ğ‘…(ğ’‚ğ‘‡ , ğ‘¥, ğ‘§) using the learned reward model. For any model gener-
ated answer ğ’‚â€²
ğ‘‡ â€², we take Ëœğ‘…(ğ’‚â€²
ğ‘‡ â€², ğ‘¥, ğ‘§) = Ë†ğ‘…(ğ’‚â€²
ğ‘‡ â€², ğ‘¥, ğ‘§) âˆ’ Ë†ğ‘…(ğ’‚ğ‘‡ , ğ‘¥, ğ‘§) as
the estimated reward, and the same technique is applied to sentence-
level and subclaim level factuality evaluations.
6.2 Main results
The main empirical results of our method trained on Llama2-7B-
chat (FoRAG-L 7B) and ChatGLM2-6B (FoRAG-C 6B) are depicted in
Table 3 and Table 4. We here mainly report the results of FoRAG-L
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 3: Performance comparison of the existing web-enhanced RAGs with our FoRAG.
Model
Answer Evaluation
WebCPM (zh) WebGPT (en)
Cohr. Help. Fact/q. Fact/s. Avg. Len. Cohr. Help. Fact/q. Fact/s. Avg. Len.
WebGPT 175b - - - - - 0.6911 0.9154 0.8823 0.9752 209
WebGPT 13b - - - - - 0.5478 0.7390 0.7977 0.9642 212
WebGLM 10B - - - - - 0.5919 0.8566 0.8639 0.9688 169
WebCPM 10B 0.4899 0.6985 0.6784 0.8916 549 0.7316 0.8566 0.8125 0.9764 330
FoRAG-C 6B (Ours) 0.8618 0.7764 0.7739 0.9639 655 0.8603 0.8640 0.7610 0.9804 443
FoRAG-L 7B (Ours) 0.9121 0.8668 0.8216 0.9727 625 0.9889 0.9595 0.8897 0.9894 447
Table 4: Comparison of variants of FoRAG with or without outline-enhanced (Out. Enh.), factuality optimization (Fac. Opt.).
Model Out.
Enh.
Fac.
Opt.
Answer Evaluation
WebCPM (zh) WebGPT (en)
Cohr. Help. Fact/q. Fact/s. Avg. Len. Cohr. Help. Fact/q. Fact/s. Avg. Len.
FoRAG-C 6B
âœ— âœ— 0.4598 0.6332 0.7613 0.9081 583 0.4081 0.7721 0.7868 0.9464 177
âœ— âœ“ 0.4724 0.6407 0.8065 0.9395 585 0.5184 0.7868 0.8566 0.9763 181
âœ“ âœ— 0.8643 0.7814 0.6055 0.9197 622 0.8566 0.8529 0.5993 0.9530 417
âœ“ âœ“ 0.8618 0.7764 0.7739 0.9639 655 0.8603 0.8640 0.7610 0.9804 443
FoRAG-L 7B
âœ— âœ— 0.4296 0.6181 0.8090 0.8875 556 0.5221 0.8676 0.8750 0.9728 186
âœ— âœ“ 0.4447 0.6256 0.8618 0.9394 570 0.5368 0.8860 0.8970 0.9818 189
âœ“ âœ— 0.9095 0.8668 0.6583 0.9345 613 0.9816 0.9559 0.7978 0.9768 424
âœ“ âœ“ 0.9121 0.8668 0.8216 0.9727 625 0.9889 0.9595 0.8897 0.9894 447
7B, which attains the best performance among all possible combina-
tions of the granularities of evaluation and reward model. A detailed
performance comparison of different granularity combinations will
be given in Section 6.3.
Overall Performance. In Table 3, we compare the overall per-
formance of FoRAG-L 7B and FoRAG-C 6B with all existing methods
on both datasets. Note that among the examined baselines, only
WebCPM 10B can answer in Chinese, since WebGPT does not re-
lease model weights or answers in Chinese, and WebGLM has a
well-known issue of being unable to answer in Chinese 8. From
the results, we observe that on both English and Chinese datasets,
FoRAG-C 6B surpasses all baselines on five out of six metrics, and
FoRAG-L 7B performs the best on all metrics. Notably, FoRAG-L
7B substantially outperforms WebGPT 175B that contains 24 times
more parameters, showing superiority of our method in bilingual
web-enhanced RAG tasks.
Evaluation of Outline-Enhanced Generator . We evaluate
the effectiveness of outline-enhanced generator as a core design in
dataset collection and RAG model design by showing that, with-
out such technique, the reduced method will deteriorate severely.
Specifically, for the reduced variant, we train the backbone mod-
els on a merged dataset from WebCPM and WebGLM-QA, which
contains 4.7k samples in Chinese and 44k samples in English. Note
that here we use the demonstration answers as provided in the
original datasets, i.e., the answers in WebCPM are human written
8Please refer to the discussion on the issue at WebGLMâ€™s official codebase https:
//github.com/THUDM/WebGLM/issues/7.
and answers in WebGLM-QA are GPT4 generated, which can be
considered in high quality.
In Table 4, we compare the performance of our proposed method
with the reduced variant. The results show that applying our tech-
nique of outline-enhanced generator significantly boosts the per-
formance in terms of coherence and helpfulness on both datasets.
As for factuality, the sentence-level measurements of our methods
are a little bit higher or comparable with the counterpart models
without outline-enhanced techniques. In addition, applying our
technique increases the length of model generations (see Appendix
E for examples of generations).
Evaluation of Factuality Optimization . We then evaluate
the effectiveness of the factuality optimization technique by com-
paring our method with the counterpart method without such a
mechanism. As presented in Table 4, adding factuality optimization
technique significantly raises the factuality consistency score in
both query and sequence levels, without affecting the other two
metrics or the generation length. The above results justify the in-
troduction of factuality optimization technique to our proposed
method.
6.3 Comparison of Various Factuality
Optimization Granularities
In this subsection, we compare the performance of various im-
plementations of our method on different evaluation and reward
model granularities (as described in Table 2), with the following
two commonly used alignment methods as baselines:
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
Table 5: The comparison of performance using various factuality optimization techniques on our FoRAG-L 7B. The â€œ-" indicates
no extra factuality optimization is performed, i.e., the SFT model.
Factuality
Optimization
Answer Evaluation
WebCPM (zh) WebGPT (en)
Cohr. Help. Fact/q. Fact/s. Avg. Len. Cohr. Help. Fact/q. Fact/s. Avg. Len.
- 0.9095 0.8668 0.6583 0.9345 613 0.9816 0.9559 0.7978 0.9768 424
Unlikelihood 0.9070 0.8618 0.7286 0.9477 591 0.9816 0.9522 0.8419 0.9794 442
MLE w. Filtering 0.9171 0.8568 0.6783 0.9331 592 0.9852 0.9522 0.7831 0.9754 423
RLHF
Holistic + Token 0.9020 0.8543 0.7236 0.9414 608 0.9816 0.9485 0.8382 0.9768 444
Sentence + Token 0.9095 0.8593 0.7814 0.9628 610 0.9816 0.9559 0.8603 0.9836 446
Subclaim + Token 0.9121 0.8593 0.7864 0.9658 616 0.9852 0.9559 0.8713 0.9851 446
Holistic 0.9146 0.8618 0.7563 0.9526 622 0.9852 0.9559 0.8493 0.9797 448
Sentence 0.9095 0.8593 0.8065 0.9704 612 0.9889 0.9595 0.8787 0.9866 447
Subclaim 0.9121 0.8668 0.8216 0.9727 625 0.9889 0.9595 0.8897 0.9894 447
MLE with Filtering (filter.) [44]: This method applies a filter to
drop the samples with factual inconsistency errors and preserve
the factually consistent ones. Then it follows the standard SFT
procedure, i.e., fine-tuning the model by optimizing the maximum
likelihood estimation loss on the positive samples.
Unlikelihood [49]: This method fine-tunes the model by maximiz-
ing the likelihood of positive (i.e., factually consistent) samples and
minimizing the likelihood of negative (i.e., factually inconsistent)
samples simultaneously.
For a fair comparison, all the methods are fine-tuned from the
same model, i.e., Llama2 after SFT on our outline-enhanced dataset.
The empirical results are presented in Table 5. From the results,
we observe that our proposed method attains better factual consis-
tency than the baselines, regardless of the granularity of evaluation
or reward modeling. In addition, among all the granularities of
evaluation, subclaim-level evaluation performs the best. We also
notice that token-level reward modeling performs worse than the
conventional segment-level reward modeling, presumably because
the length of our datasets may make token-level modeling over-fit.
6.4 Ablation study
We now conduct ablation study to justify the rational of some
certain design choices in our proposed method.
Effectiveness of the Outline-Expansion Two-Step Answer
Generation. To illustrate the impact of our outline-enhanced gen-
eration technique, we train two baseline models that generate an-
swers directly based on our dataset, which lack the outline stage,
referred to FoRAG-C 6B w/o outline and FoRAG-L 7B w/o outline
in Table 6. The outcomes clearly show that our outline-enhanced
generation approach significantly augments the modelâ€™s capabil-
ities by enhancing the coherence and helpfulness of the answers
generated, with a particularly notable improvement observed in
the Chinese language task.
On GPT4 Evaluation Quality. To evaluate how well GPT4
correlates with human judgment in Chinese, we recruit 10 native
Chinese-speaking annotators. Their task is to manually review
coherence, helpfulness, and both query-level and sentence-level
Table 6: Ablation study on outline-enhanced generation.
WebCPM (zh) WebGPT (en)
Method Cohr. Help. Cohr. Help.
FoRAG-C 6B w/o outline 0.8467 0.7613 0.8492 0.8529
FoRAG-C 6B 0.8643 0.7814 0.8566 0.8529
FoRAG-L 7B w/o outline 0.8543 0.8593 0.9779 0.9522
FoRAG-L 7B 0.9095 0.8668 0.9816 0.9559
Table 7: Alignment between GPT4-aided automated and hu-
man evaluations.
Metrics Cohr. Help. Fact/q. Fact/s.
GPT4 vs Human 91.5% 83.0% 77.0% 95.5%
Human vs Human - - 69.5% 93.1%
factuality on the Chinese generated results. A subset of 200 exam-
ples is selected, and we conduct two rounds of human evaluation
on it. In each round, each sample is randomly assigned to one anno-
tator. We report the agreement rate (the ratio of overlap) between
two-round human labels and GPT4Å› judgements in Table 7. The
results confirm a robust correlation between GPT4 and human rat-
ings on Chinese QA evaluation. Except on the query-level factuality,
human suffers from comparing two lengthy texts, a conclusion that
is consistent with [50].
Effects of Imbalance Dataset. To evaluate how the imbalance
of the two languages in the dataset affects the training effect on
the resulting bilingual LLMs, we perform further ablation study on
the level of imbalance. We fix the number of training samples to
be 40k. Then we tune the ratio of Chinese to English on five level,
ranging from 1:10, 1:3, 1:1 to 3:1, 10:1. We then randomly sample the
corresponding amount of samples from our dataset and train the
models based on Llama2-7B using SFT. The evaluation results, as
depicted in Figure 2 show that with a increasing amount of data, the
modelâ€™s performance on the corresponding language increases on
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
1/10 1/3 1 3 10
Ratio of Chinese to English
0.80
0.85
0.90
0.95
1.00Evaluation Results
WebCPM Cohr.
WebCPM Help.
WebCPM Fact/s.
WebGPT Cohr.
WebGPT Help.
WebGPT Fact/s.
Figure 2: Evaluation results in terms of various metrics of
different models fine-tuned from Llama2-7B. We vary the
ratio of the Chinese samples to the English samples in the
training dataset.
both coherency and helpfulness metrics. Meanwhile, the factuality
metric is not affected by this ratio. Note that the performance of
Llama2-7B is more sensitive to the number of training samples
in Chinese. This may be because the pre-training of Llama2-7B
contains more corpus in English, and therefore a few examples is
enough to adopt to the new task.
6.5 Evaluation of Training Efficiency
We finally evaluate the training efficiency of our proposed method.
In the following, we will examine the additionial computation cost
of the two new modules of FoRAG, i.e., outline-enhanced generation
and doubly fine-grained RLHF, respectively.
The first step, i.e., outline-enhanced generation, has almost neg-
ligible effect on training time. During inference, it requires roughly
10% more tokens to be generated, and the extra time consumed at
inference stage is roughly proportionally to this increase in tokens
generated. Note that this extra inference time can be eliminated
using context distillation techniques[3, 49].
The second step, i.e., doubly fine-grained RLHF, has no impact on
inference time. To evaluate the additional computational expense
during training, we consider a naive implementation of FoRAG that
sequentially evaluates the reward for each sentence. In Table 8, we
compare the training time of FoRAG and the counterpart method
with holistic RLHF. The results show the best performed version, the
subclaim version of the doubly fine-grained RLHF framework, takes
about 67.7% more time than standard RLHF. Note that the additional
computational cost can be further reduced via implementation with
a multi-head reward layer and carefully designed attention mask
can use one forward pass to calculate the reward for all sentences,
which will make the extra computational cost insignificant.
In summary, FoRAG outperforms the baseline method with rea-
sonable additional computational cost.
7 CONCLUSION
In this paper, we propose a novel answer generation method FoRAG
for web-enhanced LFQA to tackle the factuality issue and lack of
Table 8: Evaluation on training efficiency of doubly fine-
grained RLHF. We report the time consumed (in hours) for
training reward models (RM) and RLHF on different gran-
ularities. We also report the extra time cost in percentage
compared with the holistic RLHF method.
RM RLHF Total Percentage
Holistic 1.1 32.0 33.1 -
Sentence 4.6 45.6 50.2 +51.7%
Subclaim 5.1 50.4 55.5 +67.7%
Holistic + Token 1.3 32.8 34.1 +3.0%
Sentence + Token 5.3 46.4 51.7 +56.2%
Subclaim + Token 6.0 52.0 58.0 +75.2%
clear logical structure in existing methods. To this end, we first de-
vise an outline-enhanced generator to fulfill clear logic in long-form
answers and accordingly construct two datasets. Then we propose
to optimize factuality in a carefully designed doubly fine-grained
RLHF framework. Our developed framework contains automatic
evaluation and reward modeling in different levels of granularity,
and compasses traditional fine-grain RLHF methods as special cases.
Empirically, FoRAG achieves state-of-the-art performance in terms
of coherence, helpfulness, and factuality on both English and Chi-
nese benchmarks. Notably, applying FoRAG to Llama2-7B-chat, we
derive FoRAG-L-7B, which outperforms WebGPT-175B with only
1/24 in the number of parameters of WebGPT-175B.
REFERENCES
[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-
cia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal
Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774
(2023).
[2] Reinald Kim Amplayo, Kellie Webster, Michael Collins, Dipanjan Das, and Shashi
Narayan. 2022. Query Refinement Prompts for Closed-Book Long-Form Question
Answering. arXiv preprint arXiv:2210.17525 (2022).
[3] Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom
Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et al. 2021.
A general language assistant as a laboratory for alignment. arXiv preprint
arXiv:2112.00861 (2021).
[4] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova
DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. 2022.
Training a helpful and harmless assistant with reinforcement learning from
human feedback. arXiv preprint arXiv:2204.05862 (2022).
[5] Yushi Bai, Jiahao Ying, Yixin Cao, Xin Lv, Yuze He, Xiaozhi Wang, Jifan Yu,
Kaisheng Zeng, Yijia Xiao, Haozhe Lyu, Jiayin Zhang, Juanzi Li, and Lei Hou.
2023. Benchmarking Foundation Models with Language-Model-as-an-Examiner.
arXiv:2306.04181 [cs.CL]
[6] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Ruther-
ford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bog-
dan Damoc, Aidan Clark, et al. 2022. Improving language models by retrieving
from trillions of tokens. In International conference on machine learning . PMLR,
2206â€“2240.
[7] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al. 2020. Language models are few-shot learners. Advances in neural
information processing systems 33 (2020), 1877â€“1901.
[8] Shiqi Chen, Yiran Zhao, Jinghan Zhang, I-Chun Chern, Siyang Gao, Pengfei
Liu, and Junxian He. 2023. FELM: Benchmarking Factuality Evaluation of Large
Language Models. arXiv:2310.00741 [cs.CL]
[9] I Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou,
Junxian He, Graham Neubig, Pengfei Liu, et al . 2023. FacTool: Factuality De-
tection in Generative AIâ€“A Tool Augmented Framework for Multi-Task and
Multi-Domain Scenarios. arXiv preprint arXiv:2307.13528 (2023).
[10] Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario
Amodei. 2017. Deep reinforcement learning from human preferences. Advances
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
in neural information processing systems 30 (2017).
[11] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and
Jie Tang. 2022. GLM: General Language Model Pretraining with Autoregressive
Blank Infilling. In Proceedings of the 60th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers) . 320â€“335.
[12] Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and
Michael Auli. 2019. ELI5: Long Form Question Answering. In Proceedings of the
57th Annual Meeting of the Association for Computational Linguistics . 3558â€“3567.
[13] Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. 2023. GPTScore:
Evaluate as You Desire. arXiv preprint arXiv:2302.04166 (2023).
[14] Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen. 2023. Enabling Large
Language Models to Generate Text with Citations.arXiv preprint arXiv:2305.14627
(2023).
[15] Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding,
Jianwei Yue, and Yupeng Wu. 2023. How Close is ChatGPT to Human Experts?
Comparison Corpus, Evaluation, and Detection. arXiv:2301.07597 [cs.CL]
[16] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. 2020.
Retrieval augmented language model pre-training. In International conference on
machine learning. PMLR, 3929â€“3938.
[17] Xiangkun Hu, Dongyu Ru, Qipeng Guo, Lin Qiu, and Zheng Zhang. 2023. Re-
fChecker for Fine-grained Hallucination Detection. (2023). https://github.com/
amazon-science/RefChecker
[18] Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bo-
janowski, Armand Joulin, and Edouard Grave. 2021. Unsupervised dense in-
formation retrieval with contrastive learning. arXiv preprint arXiv:2112.09118
(2021).
[19] Dongfu Jiang, Yishan Li, Ge Zhang, Wenhao Huang, Bill Yuchen Lin, and Wenhu
Chen. 2023. TIGERScore: Towards Building Explainable Metric for All Text
Generation Tasks. ArXiv abs/2310.00752 (2023). https://api.semanticscholar.org/
CorpusID:263334281
[20] Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. 2017. Triviaqa:
A large scale distantly supervised challenge dataset for reading comprehension.
arXiv preprint arXiv:1705.03551 (2017).
[21] Ryo Kamoi, Tanya Goyal, Juan Diego Rodriguez, and Greg Durrett. 2023. Wice:
Real-world entailment for claims in wikipedia. arXiv preprint arXiv:2303.01432
(2023).
[22] Vladimir Karpukhin, Barlas OÄŸuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey
Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-
domain question answering. arXiv preprint arXiv:2004.04906 (2020).
[23] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke
Iwasawa. 2022. Large language models are zero-shot reasoners. Advances in
neural information processing systems 35 (2022), 22199â€“22213.
[24] Wojciech KryÅ›ciÅ„ski, Bryan McCann, Caiming Xiong, and Richard Socher. 2019.
Evaluating the factual consistency of abstractive text summarization. arXiv
preprint arXiv:1910.12840 (2019).
[25] Sayali Kulkarni, Sheide Chammas, Wan Zhu, Fei Sha, and Eugene Ie. 2020. Aqua-
muse: Automatically generating datasets for query-based multi-document sum-
marization. arXiv preprint arXiv:2010.12694 (2020).
[26] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur
Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton
Lee, et al. 2019. Natural questions: a benchmark for question answering research.
Transactions of the Association for Computational Linguistics 7 (2019), 453â€“466.
[27] Barrett Martin Lattimer, Patrick Chen, Xinyuan Zhang, and Yi Yang. 2023. Fast
and Accurate Factual Inconsistency Detection Over Long Documents. arXiv
preprint arXiv:2310.13189 (2023).
[28] Nelson F Liu, Tianyi Zhang, and Percy Liang. 2023. Evaluating verifiability in
generative search engines. arXiv preprint arXiv:2304.09848 (2023).
[29] Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng, Zhengxiao Du, Peng Zhang,
Yuxiao Dong, and Jie Tang. 2023. WebGLM: Towards An Efficient Web-Enhanced
Question Answering System with Human Preferences. In Proceedings of the 29th
ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<conf-loc>,
<city>Long Beach</city>, <state>CA</state>, <country>USA</country>, </conf-
loc>) (KDD â€™23). Association for Computing Machinery, New York, NY, USA,
4549â€“4560. https://doi.org/10.1145/3580305.3599931
[30] Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang
Zhu. 2023. G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment.
In Proceedings of the 2023 Conference on Empirical Methods in Natural Language
Processing, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for
Computational Linguistics, Singapore, 2511â€“2522. https://doi.org/10.18653/v1/
2023.emnlp-main.153
[31] Jacob Menick, Maja Trebacz, Vladimir Mikulik, John Aslanides, Francis Song,
Martin Chadwick, Mia Glaese, Susannah Young, Lucy Campbell-Gillingham,
Geoffrey Irving, et al. 2022. Teaching language models to support answers with
verified quotes. arXiv preprint arXiv:2203.11147 (2022).
[32] GrÃ©goire Mialon, Roberto DessÃ¬, Maria Lomeli, Christoforos Nalmpantis, Ram
Pasunuru, Roberta Raileanu, Baptiste RoziÃ¨re, Timo Schick, Jane Dwivedi-Yu, Asli
Celikyilmaz, et al. 2023. Augmented language models: a survey. arXiv preprint
arXiv:2302.07842 (2023).
[33] Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh,
Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2023. FActScore: Fine-
grained Atomic Evaluation of Factual Precision in Long Form Text Generation.
arXiv preprint arXiv:2305.14251 (2023).
[34] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina
Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu
Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew
Knight, Benjamin Chess, and John Schulman. 2022. WebGPT: Browser-assisted
question-answering with human feedback. arXiv:2112.09332 [cs.CL]
[35] OpenAI. 2023. GPT-4 technical report. arXiv preprint arXiv:2303.08774 (2023).
[36] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022.
Training language models to follow instructions with human feedback. Advances
in Neural Information Processing Systems 35 (2022), 27730â€“27744.
[37] Yujia Qin, Zihan Cai, Dian Jin, Lan Yan, Shihao Liang, Kunlun Zhu, Yankai Lin,
Xu Han, Ning Ding, Huadong Wang, et al . 2023. WebCPM: Interactive Web
Search for Chinese Long-form Question Answering. In Proceedings of the 61st
Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
Papers). 8968â€“8988.
[38] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.
Squad: 100,000+ questions for machine comprehension of text. arXiv preprint
arXiv:1606.05250 (2016).
[39] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin
Leyton-Brown, and Yoav Shoham. 2023. In-Context Retrieval-Augmented Lan-
guage Models. Transactions of the Association for Computational Linguistics 11
(2023), 1316â€“1331. https://doi.org/10.1162/tacl_a_00605
[40] Rajkumar Ramamurthy, Prithviraj Ammanabrolu, KiantÃ© Brantley, Jack Hessel,
Rafet Sifa, Christian Bauckhage, Hannaneh Hajishirzi, and Yejin Choi. 2022. Is
reinforcement learning (not) for natural language processing?: Benchmarks,
baselines, and building blocks for natural language policy optimization. arXiv
preprint arXiv:2210.01241 (2022).
[41] Siva Reddy, Danqi Chen, and Christopher D Manning. 2019. Coqa: A conversa-
tional question answering challenge. Transactions of the Association for Compu-
tational Linguistics 7 (2019), 249â€“266.
[42] Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike
Lewis, Luke Zettlemoyer, and Wen tau Yih. 2023. REPLUG: Retrieval-Augmented
Black-Box Language Models. arXiv:2301.12652 [cs.CL]
[43] Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller,
Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, et al. 2022. Blenderbot 3:
a deployed conversational agent that continually learns to responsibly engage.
arXiv preprint arXiv:2208.03188 (2022).
[44] Irene Solaiman and Christy Dennison. 2021. Process for adapting language
models to society (palms) with values-targeted datasets. Advances in Neural
Information Processing Systems 34 (2021), 5861â€“5873.
[45] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kul-
shreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022.
Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239
(2022).
[46] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-
mine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-
ale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv
preprint arXiv:2307.09288 (2023).
[47] Cunxiang Wang, Sirui Cheng, Zhikun Xu, Bowen Ding, Yidong Wang, and Yue
Zhang. 2023. Evaluating open question answering evaluation. arXiv preprint
arXiv:2305.12421 (2023).
[48] Cunxiang Wang, Xiaoze Liu, Yuanhao Yue, Xiangru Tang, Tianhang Zhang,
Cheng Jiayang, Yunzhi Yao, Wenyang Gao, Xuming Hu, Zehan Qi, et al. 2023.
Survey on factuality in large language models: Knowledge, retrieval and domain-
specificity. arXiv preprint arXiv:2310.07521 (2023).
[49] Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun Cho, and
Jason Weston. 2019. Neural text generation with unlikelihood training. arXiv
preprint arXiv:1908.04319 (2019).
[50] Zeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, Alane Suhr, Prithviraj Am-
manabrolu, Noah A Smith, Mari Ostendorf, and Hannaneh Hajishirzi. 2023. Fine-
Grained Human Feedback Gives Better Rewards for Language Model Training.
arXiv preprint arXiv:2306.01693 (2023).
[51] Yunqi Xu, Tianchi Cai, Jiyan Jiang, and Xierui Song. 2024. Face4RAG: Factual
Consistency Evaluation for Retrieval Augmented Generation in Chinese. In
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and
Data Mining.
[52] Shentao Yang, Shujian Zhang, Congying Xia, Yihao Feng, Caiming Xiong, and
Mingyuan Zhou. 2023. Preference-grounded Token-level Guidance for Language
Model Fine-tuning. arXiv preprint arXiv:2306.00398 (2023).
[53] Yuheng Zha, Yichi Yang, Ruichen Li, and Zhiting Hu. 2023. AlignScore: Evalu-
ating Factual Consistency with a Unified Alignment Function. arXiv preprint
arXiv:2305.16739 (2023).
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
A PROMPTS FOR GENERATION
The following is the prompt template used to invoke GPT4 to generate outline-enhanced answers.
###Task###
Answer the question based on the materials provided.
###Requirements###
Step One: Develop an answer outline based on the question and materials.
1. Choose a suitable organizational pattern for the answer structure, such as general-specific-general, progressive, comparative, cause-effect,
parallel, chronological, among others.
2. Enumerate the essential points that need to be included in the outline, aligned with the the chosen structure.
3. The relationship between key points can be parallel, contrastive, progressive, etc., but should not be repetitive or inclusive.
4. Formulate a clear and concise outline that includes at least 1 but no more than 5 key points.
5. Each main point should reference only one specific part of the provided materials and must include the materialâ€™s number within the
outline.
Step Two: Answer the question based on the materials and outline.
1. Utilize the outline as a blueprint to develop a comprehensive and informative answer.
2. Write the answer using formatting tools such as numbered lists, bullet points, subheadings, LaTeX formulas, etc., where appropriate.
3. Refrain from using basic sequential connectors like â€œfirstly, " â€œsecondly, " or â€œfurthermore, " in the answer.
4. Avoid redundancy and repetition of content within the answer.
5. Do not cite the number of the materials in the answer.
6. Adhere strictly to the information contained within the provided materials, without adding any information that is not included in the
materials.
###Format###
[Structure]:
<The organizational structure of the answer>
[Outline]:
<Bullet points outlining the answer>
[Answer]:
<Answer the question based on the materials and outline>
Here are two examples of input and output:
###Input Example 1###
###Question###
What are the main factors contributing to the increasing trend of urban population growth?
###Materials###
[1]The improvement of healthcare in cities has led to lower mortality rates. With access to state-of-the-art hospitals, specialized clinics,
and a higher concentration of medical professionals, city residents benefit from quicker and more effective response to health needs. The
advancements in healthcare infrastructure, such as the implementation of digital health records and telemedicine, have further streamlined
patient care, making it more accessible and efficient.
[2]Urban areas are widely recognized for better educational institutions, from primary schools to universities, that promise a more
comprehensive and diverse learning environment. These institutions are often equipped with advanced resources, experienced educators, and
a broader range of programs and extracurricular activities, which are highly attractive to families who prioritize their childrenâ€™s education.
[3]Cities are the epicenters of industry, commerce, and services, offering a myriad of employment options that are scarce or nonexistent in
rural settings. The diversity of the urban job market, with its potential for higher wages, career advancement, and the chance to engage
in more specialized work, draws individuals in pursuit of a better livelihood. Rural to urban migration is driven by the search for better
employment opportunities.
###Output Example 1###
[Structure]:
Parallel
[Outline]:
1. Advancements in healthcare (based on [1])
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
2. Enhanced educational opportunities (based on [2])
3. Employment prospects (based on [3])
[Answer]:
Urban population growth is driven by several compelling factors that make living in cities increasingly attractive.
One of the most significant contributors to this trend is the comprehensive improvement in healthcare that cities offer. Residents benefit
from lower mortality rates due to access to superior medical facilities including state-of-the-art hospitals and specialized clinics. Furthermore,
the urban healthcare infrastructure has been enhanced by technological advancements, such as the implementation of digital health records
and the growing availability of telemedicine services.
In addition to healthcare, the quality of education available in cities acts as a strong magnet for families and individuals. Cities typically
boast:
- Better educational institutions, which provide a more comprehensive and diverse learning environment.
- Access to experienced educators and advanced educational resources that are not as readily available in rural areas.
- A broad range of extracurricular activities that are highly attractive for those prioritizing education for their children.
Finally, the wide array of employment options available in urban areas is a another driver of population growth. The concentration of
industry, commerce, and services in cities creates a diverse job market with the potential for higher wages, career advancement, and
specialized work. This draws people from rural areas in search of better employment prospects, thereby increasing the urban population.
###Input Example 2###
###Question###
What makes smartphones an essential tool for modern life?
###Materials###
[1]Smartphones provide a convenient means of communication, allowing people to stay connected with friends and family through calls,
texts, and various messaging apps.
[2]They offer access to a wide array of information and entertainment options, such as browsing the internet, streaming videos, and playing
games.
[3]Smartphones have built-in features that replace the need for other devices, like a camera, GPS, and notebook, making them a multifunctional
tool that fits in your pocket.
###Output Example 2###
[Structure]:
General-Specific-General
[Outline]:
1. Communication hub (based on [1])
2. Multifunctional device (based on [3])
[Answer]:
Smartphones have become indispensable in contemporary life primarily because they serve as a central hub for communication and a
versatile multifunctional device.
### Central Hub for Communication
The ability to instantly connect with others via calls, texts, and various messaging applications is one of the most valued features of
smartphones. This constant connectivity has revolutionized the way we maintain personal and professional relationships.
### Versatile Multifunctional Device
Smartphones eliminate the need to carry multiple gadgets by incorporating essential tools like a high-quality camera, a reliable GPS
navigation system, and the functionality of a notebook, all within a single, portable device.
In essence, the critical role of smartphones in modern life can be attributed to their unparalleled capacity to keep us connected to the world
around us and their ability to perform multiple functions that simplify our daily routines.
Below is the question you need to answer and the corresponding materials. Please output according to the above requirements, format, and
examples:
###Question###
{query}
###Materials###
{doc}
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 10: Prompt for Chinese Generation
###ä»»åŠ¡###
æ ¹æ®èµ„æ–™å›ç­”é—®é¢˜ã€‚
###è¦æ±‚###
ç¬¬ä¸€æ­¥ï¼šæ ¹æ®é—®é¢˜å’Œèµ„æ–™ç”Ÿæˆå›ç­”æçº²ã€‚
1. å†³å®šå›ç­”ç»“æ„ï¼Œä»æ€»åˆ†æ€»ã€é€’è¿›ã€å¯¹æ¯”ã€å› æœã€å¹¶åˆ—ã€æ—¶åºç­‰ç»“æ„ä¸­é€‰æ‹©åˆé€‚çš„æ¥ç»„ç»‡å›ç­”ã€‚
2. æ ¹æ®å›ç­”ç»“æ„ï¼Œåœ¨æçº²ä¸­è¦å®Œæ•´åœ°åˆ—å‡ºç­”æ¡ˆä¸­éœ€è¦åŒ…æ‹¬çš„è¦ç‚¹ã€‚
3. è¦ç‚¹ä¹‹é—´å¯ä»¥æ˜¯å¹¶åˆ—ã€å¯¹ç…§ã€é€’è¿›ç­‰å…³ç³»ï¼Œä¸å¯ä»¥æ˜¯é‡å¤æˆ–è€…åŒ…å«å…³ç³»ã€‚
4. è¦ç‚¹è¦ä¿æŒç²¾ç‚¼ï¼Œè‡³å°‘æœ‰1ç‚¹ï¼Œä¸èƒ½å¤šäº5ç‚¹ï¼Œ
5. æ¯ä¸ªè¦ç‚¹ä»…å¯å‚è€ƒ1æ®µèµ„æ–™ï¼Œå¹¶åœ¨æçº²ä¸­æ ‡æ³¨èµ„æ–™ç¼–å·ã€‚
ç¬¬äºŒæ­¥ï¼šæ ¹æ®èµ„æ–™å’Œæçº²å¯¹é—®é¢˜è¿›è¡Œå›ç­”ã€‚
1. å›ç­”è¦ä»¥æçº²ä¸ºè“æœ¬ï¼Œå¯¹é—®é¢˜è¿›è¡Œè¯¦ç»†çš„å›ç­”ã€‚
2. å›ç­”ä¸­å¯ä»¥é‡‡ç”¨ç¼–å·æˆ–é¡¹ç›®åˆ—è¡¨ã€å°æ ‡é¢˜ã€latexå…¬å¼ç­‰æ ¼å¼ã€‚
3. å›ç­”ä¸­å‡å°‘ä½¿ç”¨â€œé¦–å…ˆâ€ã€â€œå…¶æ¬¡â€ã€â€œå†è€…â€ç­‰ç®€å•çš„è¿æ¥è¯ã€‚
4. å›ç­”ä¸­ä¸è¦ç”Ÿæˆé‡å¤å†…å®¹ã€‚
5. å›ç­”ä¸­ä¸è¦æ ‡æ³¨èµ„æ–™æ¥æºã€‚
6. å›ç­”åº”å½“ä¸¥æ ¼ä¾æ®èµ„æ–™ï¼Œä¸é‡‡ç”¨ä¸åœ¨èµ„æ–™ä¸­çš„å†…å®¹ã€‚
###æ ¼å¼###
ã€ç»“æ„ã€‘ï¼š
<å›ç­”çš„ç»„ç»‡ç»“æ„>
ã€æçº²ã€‘ï¼š
<åˆ†ç‚¹ä»‹ç»å›ç­”æ€è·¯>
ã€å›ç­”ã€‘ï¼š
<æ ¹æ®èµ„æ–™å’Œæçº²å›ç­”é—®é¢˜>
ä¸‹é¢æ˜¯1ä¸ªç¤ºä¾‹è¾“å…¥å’Œ2ä¸ªæ»¡è¶³è¦æ±‚çš„ç¤ºä¾‹è¾“å‡ºï¼š
###ç¤ºä¾‹è¾“å…¥###
###é—®é¢˜###
2023å¹´è¥¿å®‰æˆ¿è´·åˆ©ç‡æœ€æ–°æ¶ˆæ¯
###èµ„æ–™###
[1 ]ä¸€ã€è¥¿å®‰å•†ä¸šè´·æ¬¾å›ºå®šåˆ©ç‡
1å¹´ä»¥å†…ï¼ˆå«ï¼‰â€”â€”4.35%
5å¹´(å«)ä»¥ä¸‹â€”â€”4.75%
5å¹´ä»¥ä¸Šâ€”â€”4.9%
è´·æ¬¾å¸‚åœºæŠ¥ä»·åˆ©ç‡LPRï¼šç›®å‰1å¹´æœŸLPRä¸º3.45%ï¼Œ5å¹´æœŸLPRä¸º4.2%
é¦–å¥—ä½æˆ¿å•†ä¸šæ€§ä¸ªäººä½æˆ¿è´·æ¬¾åˆ©ç‡ä¸‹é™ä¸ºä¸ä½äºç›¸åº”æœŸé™LPRå‡20ä¸ªåŸºç‚¹ã€‚
äºŒå¥—ä½æˆ¿å•†ä¸šæ€§ä¸ªäººä½æˆ¿è´·æ¬¾åˆ©ç‡ä¸‹é™ä¸ºä¸ä½äºç›¸åº”æœŸé™è´·æ¬¾å¸‚åœºæŠ¥ä»·LPRåˆ©ç‡åŠ 20ä¸ªåŸºç‚¹ã€‚
äºŒã€è¥¿å®‰å…¬ç§¯é‡‘è´·æ¬¾åˆ©ç‡
5å¹´(å«)ä»¥ä¸‹â€”â€”2.6%
5å¹´ä»¥ä¸Šâ€”â€”3.1%
[2 ]ç›®å‰è¥¿å®‰ä¸»æµé“¶è¡Œçš„é¦–å¥—æˆ¿åˆ©ç‡é›†ä¸­åœ¨4%å·¦å³ï¼ŒäºŒå¥—æˆ¿åˆ©ç‡å·®åŸºæœ¬ç»´æŒåœ¨4.9%ã€‚
[3 ]é¦–å…ˆï¼Œè™½ç„¶LPRåœ¨7æœˆæ²¡æœ‰å˜åŠ¨ï¼Œä½†è¥¿å®‰é¦–å¥—æˆ¿è´·æ¬¾åˆ©ç‡å·²ç»ä½è‡³4%ï¼Œå¹¶ä¸”ä½äº2009å¹´æˆ¿è´·åˆ©ç‡æ‰“ä¸ƒæŠ˜åçš„4.156%ï¼
è¿™ç‚¹ä¹Ÿæ°æ°å’Œæ¥¼å¸‚èµ°è®¿åˆ°çš„ä¿¡æ¯ä¸è°‹è€Œåˆï¼Œæ®äº†è§£ï¼Œè¥¿å®‰ç›®å‰å¤šæ•°é“¶è¡Œé¦–å¥—æˆ¿è´·åˆ©ç‡ä¸»è¦é›†ä¸­äº4%ï¼ŒäºŒå¥—æˆ¿è´·åˆ©ç‡åŸºæœ¬åœ¨4.9%å·¦
å³ã€‚
[4 ]7æœˆ20æ—¥ï¼Œä¸­å›½äººæ°‘é“¶è¡Œæˆæƒå…¨å›½é“¶è¡Œé—´åŒä¸šæ‹†å€Ÿä¸­å¿ƒå…¬å¸ƒäº†æœ€æ–°ä¸€æœŸè´·æ¬¾å¸‚åœºæŠ¥ä»·åˆ©ç‡ï¼ˆLPRï¼‰ï¼š1å¹´æœŸLPRä¸º3.55%ï¼Œ5å¹´æœŸä»¥
ä¸ŠLPRä¸º4.20%ï¼Œå‡ä¸ä¸Šä¸ªæœˆæŒå¹³ã€‚ä½†è¥¿å®‰æˆ¿è´·åˆ©ç‡è¾ƒä¸Šæœˆå°å¹…ä¸‹è¡Œï¼Œè¥¿å®‰å¤šå®¶é“¶è¡Œé¦–å¥—æˆ¿è´·åˆ©ç‡ä»4.1%é™è‡³4%ã€‚
ä»Šå¹´6æœˆï¼ŒLPRæ—¶éš”10ä¸ªæœˆè¿æ¥ä¸‹è°ƒï¼Œ1å¹´æœŸå’Œ5å¹´æœŸä»¥ä¸ŠLPRå‡è·Ÿéšæ”¿ç­–åˆ©ç‡ä¸‹è°ƒ10ä¸ªåŸºç‚¹ã€‚è®°è€…äº†è§£åˆ°ï¼Œä»6æœˆä¸‹æ—¬å¼€å§‹ï¼Œè¥¿å®‰å„
å¤§é“¶è¡Œç›¸ç»§è½å®é¦–å¥—æˆ¿è´·åˆ©ç‡æ”¿ç­–åŠ¨æ€è°ƒæ•´æœºåˆ¶ï¼Œè¿›è¡Œåˆ©ç‡è°ƒæ•´ã€‚ç›®å‰ï¼Œè¥¿å®‰åœ°åŒºå…­å¤§è¡ŒåŠæ‹›å•†é“¶è¡Œã€å®å¤é“¶è¡Œã€åŒ—äº¬é“¶è¡Œã€è¥¿
å®‰é“¶è¡Œç­‰åä½™å®¶é“¶è¡Œé¦–å¥—æˆ¿è´·åˆ©ç‡é™è‡³4%ï¼Œè¾ƒLPRä¸‹æµ®0.2%ã€‚äºŒå¥—æˆ¿è´·åˆ©ç‡åŒæ­¥ä¸‹è¡Œï¼Œè·Œç ´5%å¤§å…³ï¼Œç»´æŒåœ¨4.9%ã€‚
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
###ç¤ºä¾‹è¾“å‡º1###
ã€ç»“æ„ã€‘ï¼š
æ€»åˆ†æ€»
ã€æçº²ã€‘ï¼š
1. é¦–å¥—æˆ¿å•†ä¸šè´·æ¬¾åˆ©ç‡(ä»…ä½¿ç”¨[2 ]å›ç­”)
2. äºŒå¥—æˆ¿å•†ä¸šè´·æ¬¾åˆ©ç‡(ä»…ä½¿ç”¨[2 ]å›ç­”)
3. å…¬ç§¯é‡‘è´·æ¬¾åˆ©ç‡ï¼ˆä»…ä½¿ç”¨[1 ]å›ç­”ï¼‰
ã€å›ç­”ã€‘ï¼š
è¥¿å®‰çš„æˆ¿è´·å¸‚åœºåœ¨2023å¹´å‘ˆç°äº†ä¸€å®šçš„è°ƒæ•´è¶‹åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å•†ä¸šè´·æ¬¾å’Œå…¬ç§¯é‡‘è´·æ¬¾åˆ©ç‡æ–¹é¢ã€‚é’ˆå¯¹ä¸åŒçš„è´·æ¬¾å¹´é™ï¼Œé¦–å¥—å’ŒäºŒå¥—
ä½æˆ¿çš„è´·æ¬¾åˆ©ç‡æœ‰æ‰€ä¸åŒã€‚ä¸‹é¢æ˜¯å…·ä½“çš„åˆ©ç‡æƒ…å†µå’Œé“¶è¡Œå¯¹æˆ¿è´·åˆ©ç‡çš„è°ƒæ•´æ¦‚è¿°ã€‚
### é¦–å¥—æˆ¿å•†ä¸šè´·æ¬¾åˆ©ç‡
é¦–å¥—ä½æˆ¿å•†ä¸šè´·æ¬¾åˆ©ç‡é›†ä¸­åœ¨4%å·¦å³ï¼Œè¾ƒLPRä¸‹æµ®0.2%ã€‚
### äºŒå¥—æˆ¿å•†ä¸šè´·æ¬¾åˆ©ç‡
äºŒå¥—æˆ¿å•†ä¸šè´·æ¬¾åˆ©ç‡åŸºæœ¬ç»´æŒåœ¨4.9%å·¦å³ã€‚
### å…¬ç§¯é‡‘è´·æ¬¾åˆ©ç‡
å…¬ç§¯é‡‘è´·æ¬¾åˆ©ç‡5å¹´(å«)ä»¥ä¸‹ä¸º2.6%ï¼Œ5å¹´ä»¥ä¸Šä¸º3.1%ã€‚
è¥¿å®‰çš„æˆ¿è´·å¸‚åœºåœ¨2023å¹´ç»å†äº†ç§¯æçš„è°ƒæ•´ï¼Œå°¤å…¶æ˜¯é¦–å¥—æˆ¿è´·æ¬¾åˆ©ç‡çš„ä¸‹é™ï¼Œä¸ºè´­æˆ¿è€…å¸¦æ¥äº†æ›´ä¸ºä¼˜æƒ çš„å€Ÿæ¬¾æ¡ä»¶ã€‚ä¸æ­¤åŒæ—¶ï¼Œ
å…¬ç§¯é‡‘è´·æ¬¾çš„ä½åˆ©ç‡ä¹Ÿä¸ºæœ‰èµ„æ ¼çš„å€Ÿæ¬¾äººæä¾›äº†é¢å¤–çš„ç»æµæ”¯æŒã€‚è¿™äº›è°ƒæ•´å¯¹äºç¨³å®šæˆ¿åœ°äº§å¸‚åœºã€æ”¯æŒåˆç†ä½æˆ¿éœ€æ±‚æœ‰ç€é‡è¦çš„
ä½œç”¨ã€‚
###ç¤ºä¾‹è¾“å‡º2###
ã€ç»“æ„ã€‘ï¼š
å¹¶åˆ—
ã€æçº²ã€‘ï¼š
1. è¥¿å®‰å•†ä¸šè´·æ¬¾å›ºå®šåˆ©ç‡ï¼ˆä»…ä½¿ç”¨[1 ]å›ç­”ï¼‰
2. è¥¿å®‰å…¬ç§¯é‡‘è´·æ¬¾åˆ©ç‡ï¼ˆä»…ä½¿ç”¨[1 ]å›ç­”ï¼‰
3. é¦–å¥—ä¸äºŒå¥—æˆ¿è´·æ¬¾åˆ©ç‡æœ€æ–°å˜åŒ–ï¼ˆä»…ä½¿ç”¨[4 ]å›ç­”ï¼‰
ã€å›ç­”ã€‘ï¼š
2023å¹´è¥¿å®‰çš„æˆ¿è´·åˆ©ç‡æœ€æ–°æ¶ˆæ¯å¦‚ä¸‹ï¼š
å•†ä¸šè´·æ¬¾å›ºå®šåˆ©ç‡ï¼š
- 1å¹´ä»¥å†…ï¼ˆå«ï¼‰çš„åˆ©ç‡ä¸º4.35%
- 5å¹´ï¼ˆå«ï¼‰ä»¥ä¸‹çš„åˆ©ç‡ä¸º4.75%
- 5å¹´ä»¥ä¸Šçš„åˆ©ç‡ä¸º4.9%
å…¬ç§¯é‡‘è´·æ¬¾åˆ©ç‡ï¼š
- 5å¹´ï¼ˆå«ï¼‰ä»¥ä¸‹ä¸º2.6%
- 5å¹´ä»¥ä¸Šä¸º3.1%
æ®æŠ¥é“ï¼Œ7æœˆ20æ—¥ï¼Œè™½ç„¶LPRæ²¡æœ‰å˜åŠ¨ï¼Œä½†è¥¿å®‰é¦–å¥—æˆ¿è´·æ¬¾åˆ©ç‡å·²ç»ä½è‡³4%ï¼Œä½äº2009å¹´æˆ¿è´·åˆ©ç‡æ‰“ä¸ƒæŠ˜åçš„4.156%ï¼ŒäºŒå¥—æˆ¿è´·åˆ©
ç‡åŒæ­¥ä¸‹è¡Œï¼Œç»´æŒåœ¨4.9%ã€‚åœ¨6æœˆLPRä¸‹è°ƒåï¼Œè¥¿å®‰å„å¤§é“¶è¡Œç›¸ç»§è½å®é¦–å¥—æˆ¿è´·åˆ©ç‡æ”¿ç­–åŠ¨æ€è°ƒæ•´æœºåˆ¶ï¼Œè¿›è¡Œåˆ©ç‡è°ƒæ•´ã€‚
ä¸‹é¢æ˜¯ä½ è¦å›ç­”çš„é—®é¢˜å’Œç›¸åº”çš„èµ„æ–™ï¼Œè¯·æ ¹æ®ä¸Šè¿°è¦æ±‚ã€æ ¼å¼å’Œç¤ºä¾‹è¿›è¡Œè¾“å‡ºï¼š
###é—®é¢˜###
{query}
###èµ„æ–™###
{doc}
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
B PROMPTS FOR EV ALUATION
As mentioned, the followings are the prompts we used to invoke GPT4 to evalute the coherence, helpfulness, and factuality.
Table 11: Prompt for English Coherence Evaluation
You will be given one answer written for a question.
Your task is to rate the answer on one metric.
Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as
needed.
Evaluation Criteria:
Coherence (1-5) - the collective quality of all sentences. The answer should have no datelines, system-internal formatting, capitalization
errors or obviously ungrammatical sentences (e.g., fragments, missing components) that make the text difficult to read. There should be no
unnecessary repetition in the answer. Unnecessary repetition might take the form of whole sentences that are repeated or repeated facts.
The answer should be well-structured and well-organized. The answer should not just be a heap of related information, but should build
from sentence to sentence to a coherent body of information about a topic.
Evaluation Steps:
1. Read the entire answer thoroughly to get a general understanding of the content and structure.
2. Look for any dateline references or system-internal formatting errors. These issues should not be present in a coherent answer.
3. Examine the grammar and sentence construction for flaws such as sentence fragments, run-on sentences, or missing components that
could hinder readability.
4. Identify any unnecessary repetition within the answer. This includes repeated sentences or redundant information that does not contribute
to the progression of the text.
5. Assess the structure and organization of the answer. It should have a logical flow, with each sentence building upon the previous
information and contributing to a comprehensive understanding of the topic.
6. Assign a score for coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.
Answer: {answer}
Evaluation Form (scores ONLY):
- Coherence:
Table 12: Prompt for Chinese Coherence Evaluation
ä½ å°†è·å¾—é’ˆå¯¹æŸä¸ªé—®é¢˜ç¼–å†™çš„ä¸€ä¸ªç­”æ¡ˆã€‚
ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸€é¡¹æŒ‡æ ‡å¯¹ç­”æ¡ˆè¿›è¡Œè¯„åˆ†ã€‚
è¯·ä½ ç¡®ä¿ä»”ç»†é˜…è¯»å¹¶ç†è§£è¿™äº›è¯´æ˜ã€‚è¯·åœ¨å®¡é˜…æ—¶ä¿æŒæœ¬æ–‡æ¡£å¤„äºæ‰“å¼€çŠ¶æ€ï¼Œå¹¶æ ¹æ®éœ€è¦è¿›è¡Œå‚è€ƒã€‚
è¯„ä»·æ ‡å‡†ï¼š
è¿è´¯æ€§(1-5) - æ‰€æœ‰å¥å­çš„é›†ä½“è´¨é‡ã€‚ç­”æ¡ˆä¸åº”åŒ…å«æ—¥æœŸçº¿ã€ç³»ç»Ÿå†…éƒ¨æ ¼å¼ã€å¤§å†™é”™è¯¯æˆ–æ˜æ˜¾ä¸åˆè¯­æ³•çš„å¥å­ï¼ˆä¾‹å¦‚ç‰‡æ®µã€ç¼ºå°‘ç»„
ä»¶ï¼‰ï¼Œä»¥å…æ–‡æœ¬éš¾ä»¥é˜…è¯»ã€‚ç­”æ¡ˆä¸­ä¸åº”æœ‰ä¸å¿…è¦çš„é‡å¤ã€‚ä¸å¿…è¦çš„é‡å¤å¯èƒ½è¡¨ç°ä¸ºé‡å¤æ•´ä¸ªå¥å­æˆ–é‡å¤äº‹å®ã€‚ç­”æ¡ˆåº”è¯¥ç»“æ„è‰¯
å¥½ã€ç»„ç»‡è‰¯å¥½ã€‚ç­”æ¡ˆä¸åº”è¯¥åªæ˜¯ä¸€å †ç›¸å…³ä¿¡æ¯ï¼Œè€Œåº”è¯¥é€å¥æ„å»ºæœ‰å…³æŸä¸ªä¸»é¢˜çš„è¿è´¯ä¿¡æ¯ä½“ã€‚
è¯„ä¼°æ­¥éª¤ï¼š
1. é€šè¯»æ•´ä¸ªç­”æ¡ˆï¼Œå¤§è‡´äº†è§£å†…å®¹å’Œç»“æ„ã€‚
2. æŸ¥æ‰¾ä»»ä½•æ—¥æœŸçº¿å¼•ç”¨æˆ–ç³»ç»Ÿå†…éƒ¨æ ¼å¼é”™è¯¯ã€‚è¿™äº›é—®é¢˜ä¸åº”è¯¥å‡ºç°åœ¨ä¸€ä¸ªè¿è´¯çš„ç­”æ¡ˆä¸­ã€‚
3. æ£€æŸ¥è¯­æ³•å’Œå¥å­ç»“æ„æ˜¯å¦å­˜åœ¨ç¼ºé™·ï¼Œä¾‹å¦‚å¥å­ç‰‡æ®µã€è¿è´¯å¥å­æˆ–å¯èƒ½å¦¨ç¢å¯è¯»æ€§çš„ç¼ºå¤±æˆåˆ†ã€‚
4. æ‰¾å‡ºç­”æ¡ˆä¸­ä»»ä½•ä¸å¿…è¦çš„é‡å¤ã€‚è¿™åŒ…æ‹¬é‡å¤çš„å¥å­æˆ–å¯¹æ–‡æœ¬çš„è¿›å±•æ²¡æœ‰è´¡çŒ®çš„å†—ä½™ä¿¡æ¯ã€‚
5. è¯„ä¼°ç­”æ¡ˆçš„ç»“æ„å’Œç»„ç»‡ã€‚å®ƒåº”è¯¥æœ‰ä¸€ä¸ªé€»è¾‘æµç¨‹ï¼Œæ¯ä¸ªå¥å­éƒ½å»ºç«‹åœ¨å‰é¢çš„ä¿¡æ¯çš„åŸºç¡€ä¸Šï¼Œå¹¶æœ‰åŠ©äºå…¨é¢ç†è§£è¯¥ä¸»é¢˜ã€‚
6. æ ¹æ®è¯„ä¼°æ ‡å‡†ï¼ŒæŒ‰ç…§1 åˆ°5 çš„èŒƒå›´ä¸ºä¸€è‡´æ€§æ‰“åˆ†ï¼Œå…¶ä¸­1 ä¸ºæœ€ä½ï¼Œ5 ä¸ºæœ€é«˜ã€‚
å›ç­”ï¼š{answer}
è¯„ä¼°å½¢å¼ï¼ˆä»…åˆ†æ•°ï¼‰ï¼š
- è¿è´¯æ€§ï¼š
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
Table 13: Prompt for English Helpfulness Evaluation
You will be given one answer written for a question.
Your task is to rate the answer on one metric.
Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as
needed.
Evaluation Criteria:
Helpfulness (1-5) - the degree to which the answer effectively meets the needs of the person seeking information. The answer should be
articulated in a way that is easy to understand. The answer should directly address the question posed, focusing on the specific information
or solution sought by the inquirer. The information provided should be correct and based on factual, verifiable data or recognized expertise.
The answer includes all necessary details to fully respond to the question. It leaves no critical aspects of the question unaddressed.
Evaluation Steps:
1. Begin by thoroughly reading and understanding the question asked. Identify the main points and what the inquirer is seeking.
2. Read the answer thoroughly to understand the information provided. Evaluate if the answer is articulated in a way that is easy to
understand.
3. Evaluate whether the answer directly addresses the question. The information provided should be relevant to what was asked.
4. Ensure that the information provided is correct, factual, and based on verifiable data or recognized expertise.
5. Determine if the answer includes all necessary details. A helpful answer should fully respond to the question without leaving critical
aspects unaddressed.
6. Assign a score for helpfulness on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.
Question: {query}
Answer: {answer}
Evaluation Form (scores ONLY):
- Helpfulness:
Table 14: Prompt for Chinese Helpfulness Evaluation
ä½ å°†è·å¾—é’ˆå¯¹æŸä¸ªé—®é¢˜ç¼–å†™çš„ä¸€ä¸ªç­”æ¡ˆã€‚
ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸€é¡¹æŒ‡æ ‡å¯¹ç­”æ¡ˆè¿›è¡Œè¯„åˆ†ã€‚
è¯·ä½ ç¡®ä¿ä»”ç»†é˜…è¯»å¹¶ç†è§£è¿™äº›è¯´æ˜ã€‚è¯·åœ¨å®¡é˜…æ—¶ä¿æŒæœ¬æ–‡æ¡£å¤„äºæ‰“å¼€çŠ¶æ€ï¼Œå¹¶æ ¹æ®éœ€è¦è¿›è¡Œå‚è€ƒã€‚
è¯„ä»·æ ‡å‡†ï¼š
å¸®åŠ©æ€§(1-5) - ç­”æ¡ˆæœ‰æ•ˆæ»¡è¶³å¯»æ±‚ä¿¡æ¯çš„äººçš„éœ€æ±‚çš„ç¨‹åº¦ã€‚ç­”æ¡ˆåº”è¯¥ä»¥æ˜“äºç†è§£çš„æ–¹å¼è¡¨è¾¾ã€‚ç­”æ¡ˆåº”ç›´æ¥è§£å†³æå‡ºçš„é—®é¢˜ï¼Œé‡ç‚¹å…³
æ³¨è¯¢é—®è€…å¯»æ±‚çš„å…·ä½“ä¿¡æ¯æˆ–è§£å†³æ–¹æ¡ˆã€‚æ‰€æä¾›çš„ä¿¡æ¯åº”æ­£ç¡®ä¸”åŸºäºäº‹å®ã€å¯éªŒè¯çš„æ•°æ®æˆ–å…¬è®¤çš„ä¸“ä¸šçŸ¥è¯†ã€‚ç­”æ¡ˆåŒ…æ‹¬å®Œæ•´å›ç­”é—®
é¢˜çš„æ‰€æœ‰å¿…è¦ç»†èŠ‚ã€‚å®ƒæ²¡æœ‰é—æ¼é—®é¢˜çš„æ‰€æœ‰å…³é”®æ–¹é¢ã€‚
è¯„ä¼°æ­¥éª¤ï¼š
1. é¦–å…ˆå½»åº•é˜…è¯»å¹¶ç†è§£æ‰€æå‡ºçš„é—®é¢˜ã€‚ç¡®å®šè¦ç‚¹ä»¥åŠè¯¢é—®è€…æƒ³è¦ä»€ä¹ˆã€‚
2. ä»”ç»†é˜…è¯»ç­”æ¡ˆï¼Œç†è§£æ‰€æä¾›çš„ä¿¡æ¯ã€‚è¯„ä¼°ç­”æ¡ˆæ˜¯å¦ä»¥æ˜“äºç†è§£çš„æ–¹å¼è¡¨è¾¾ã€‚
3. è¯„ä¼°ç­”æ¡ˆæ˜¯å¦ç›´æ¥è§£å†³é—®é¢˜ã€‚æä¾›çš„ä¿¡æ¯åº”ä¸æ‰€è¯¢é—®çš„å†…å®¹ç›¸å…³ã€‚
4. ç¡®ä¿æ‰€æä¾›çš„ä¿¡æ¯æ­£ç¡®ã€çœŸå®ï¼Œå¹¶ä¸”åŸºäºå¯éªŒè¯çš„æ•°æ®æˆ–å…¬è®¤çš„ä¸“ä¸šçŸ¥è¯†ã€‚
5. ç¡®å®šç­”æ¡ˆæ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦çš„è¯¦ç»†ä¿¡æ¯ã€‚æœ‰ç”¨çš„ç­”æ¡ˆåº”è¯¥å……åˆ†å›ç­”é—®é¢˜ï¼ŒåŒæ—¶ä¸é—æ¼å…³é”®æ–¹é¢ã€‚
6. æ ¹æ®è¯„ä¼°æ ‡å‡†ï¼ŒæŒ‰1 åˆ°5 çš„ç­‰çº§ä¸ºå¸®åŠ©æ€§æ‰“åˆ†ï¼Œå…¶ä¸­1 ä¸ºæœ€ä½ï¼Œ5 ä¸ºæœ€é«˜ã€‚
é—®é¢˜ï¼š{query}
å›ç­”ï¼š{answer}
è¯„ä¼°å½¢å¼ï¼ˆä»…åˆ†æ•°ï¼‰ï¼š
- å¸®åŠ©æ€§ï¼š
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Table 15: Prompt for English Factuality Evaluation
I will show you a question, a series of text segments, and a few reference documents. All the segments can be linked together to form a
complete answer to the question. Your task is to assess whether each text segment contains factual errors with the help of the reference
documents.
Please evaluate according to the following requirements:
1. If the text segment only contains general introductions such as â€œthe method is as follows" or â€œaccording to the material, " without conveying
specific information, directly judge it as â€œcorrect. "
2. If the text segments can find corresponding sentences in the reference document or the question as support, or can be inferred from the
corresponding sentences, directly judge them as â€œcorrect. " Pay attention to the semantic consistency of key words and details.
3. If there are any pieces of information in the text segment that cannot be found in the reference document or the question, nor can they be
inferred from the corresponding sentences, directly judge them as â€œincorrect. "
Please generate the output in the following format:
Assessment Details: For each segment, use the reference documents and question to explain the rationale and judgment result.
Final Answer: List the numbers of the segments with errors (separated by commas). Please only output the numbers, do not output
more details. If all information in the text segments is supported and semantically consistent with the reference documents, even if some
information in the reference documents is not covered, please output â€œcompletely correct. "
Hereâ€™s an example:
Question: How many nuclear power plants are there in the world?
Segments:
<1>There are a total of 440 operating nuclear reactors in the world, with a total installed capacity of over 390 gigawatts (GW).
<2>These reactors are distributed in 30 countries around the world, with the United States owning the most reactors, followed by France,
China, Japan, and Russia.
<3>Among them, China is building 16 new reactors with the fastest growth, followed by India with 8 under construction.
Reference Documents:
```
[1]Nuclear power plants operate in 32 countries, generating about one-tenth of the worldâ€™s electricity. Most are located in Europe, North
America, East Asia, and South Asia. The United States is the largest producer of nuclear power, while France has the largest share of electricity
from nuclear power, at about 70%. China has the fastest-growing nuclear power program, with 16 new reactors under construction, followed
by India with 8 under construction.
[2]As of May 2023, there are 410 operable nuclear reactors in the world, with a total electric power capacity of 368.6 gigawatts.
```
Hereâ€™s what your output should look like:
Assessment Details:
<1>Segment 1 states: â€œThere are a total of 440 operating nuclear reactors in the world, with a total installed capacity of over 390 gigawatts
(GW). " This information is inconsistent with the information in the reference document [2]: â€œthere are 410 operable nuclear reactors in the
world, with a total electric power capacity of 368.6 gigawatts. " Therefore, segment 1 is incorrect.
<2>The information in segment 2 â€œThese reactors are distributed in 30 countries around the world" is inconsistent with the information in
reference document [1]: â€œNuclear power plants operate in 32 countries, " and the reference document does not mention the number of nuclear
reactors in â€œFrance, China, Japan, and Russia, " so segment 2 is incorrect.
<3>Segment 3 states: â€œChina is building 16 new reactors with the fastest growth, followed by India with 8 under construction. " This is
consistent with reference document [1]: â€œChina has the fastest-growing nuclear power program, with 16 new reactors under construction,
followed by India with 8 under construction. " Therefore, segment 3 is correct.
Final Answer: 1,2
This means that only segments 1 and 2 contain errors, while segment 3 can find corresponding sentences in the reference document to
support it and is judged to be correct.
Below is the input:
Question: {question}
Segments: {segments}
Reference Documents:``` {docs} ```
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
Table 16: Prompt for Chinese Factuality Evaluation
æˆ‘å°†å‘æ‚¨å±•ç¤ºä¸€ä¸ªé—®é¢˜ã€ä¸€ç³»åˆ—æ–‡æœ¬ç‰‡æ®µå’Œä¸€ä»½å‚è€ƒæ–‡æ¡£ã€‚æ‰€æœ‰çš„ç‰‡æ®µå¯ä»¥è¿èµ·æ¥å½¢æˆå¯¹é—®é¢˜çš„å®Œæ•´å›ç­”ã€‚æ‚¨çš„ä»»åŠ¡æ˜¯åœ¨å‚è€ƒæ–‡
æ¡£çš„å¸®åŠ©ä¸‹è¯„ä¼°æ¯ä¸ªæ–‡æœ¬ç‰‡æ®µæ˜¯å¦åŒ…å«äº‹å®é”™è¯¯ã€‚
è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚è¿›è¡Œè¯„ä¼°ï¼š
1. å¦‚æœæ–‡æœ¬ç‰‡æ®µä»…åŒ…å«ç±»ä¼¼â€œæ–¹æ³•å¦‚ä¸‹â€ã€â€œæ ¹æ®èµ„æ–™å¯å¾—â€è¿™æ ·çš„é€šç”¨å¼€åœºç™½è€Œæ²¡æœ‰ä¼ é€’å…·ä½“ä¿¡æ¯ï¼Œç›´æ¥åˆ¤å®šä¸ºâ€œæ­£ç¡®â€ã€‚
2. å¦‚æœæ–‡æœ¬ç‰‡æ®µéƒ½èƒ½åœ¨å‚è€ƒæ–‡æ¡£æˆ–è€…é—®é¢˜ä¸­æ‰¾åˆ°ç›¸åº”å¥å­ä½œä¸ºæ”¯æŒï¼Œæˆ–è€…å¯ä»¥ä»ç›¸åº”å¥å­æ¨ç†å¾—åˆ°ï¼Œç›´æ¥åˆ¤å®šä¸ºâ€œæ­£ç¡®â€ã€‚å…³æ³¨å…³
é”®è¯å’Œç»†èŠ‚çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚
3. å¦‚æœæ–‡æœ¬ç‰‡æ®µä¸­æœ‰ä»»ä½•ä¿¡æ¯åœ¨å‚è€ƒæ–‡æ¡£æˆ–è€…é—®é¢˜ä¸­æ‰¾ä¸åˆ°æ˜ç¡®çš„æ”¯æ’‘ï¼Œä¹Ÿä¸èƒ½æ ¹æ®ç›¸åº”å¥å­æ¨ç†å¾—åˆ°ï¼Œç›´æ¥åˆ¤å®šä¸ºâ€œé”™è¯¯â€ã€‚
è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç”Ÿæˆè¾“å‡ºï¼š
è¯„ä¼°æ˜ç»†ï¼šå¯¹äºæ¯ä¸€æ¡ç‰‡æ®µï¼Œç»“åˆå‚è€ƒæ–‡æ¡£æˆ–è€…é—®é¢˜è¯´æ˜åˆ¤å®šç†ç”±å’Œåˆ¤å®šç»“æœã€‚
æœ€ç»ˆç­”æ¡ˆï¼šåˆ—å‡ºå¸¦æœ‰é”™è¯¯çš„ç‰‡æ®µçš„ç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰ã€‚è¯·åªè¾“å‡ºç¼–å·ï¼Œä¸è¦è¾“å‡ºæ›´å¤šç»†èŠ‚ã€‚å¦‚æœæ‰€æœ‰æ–‡æœ¬ç‰‡æ®µä¸­çš„ä¿¡æ¯éƒ½å¾—åˆ°
äº†æ”¯æŒä¸”ä¸å‚è€ƒæ–‡æ¡£è¯­ä¹‰ä¸€è‡´ï¼Œå³ä½¿å‚è€ƒæ–‡æ¡£ä¸­æœ‰å…¶ä»–ä¿¡æ¯æœªè¢«æ¶µç›–ï¼Œè¯·è¾“å‡ºâ€œå®Œå…¨æ­£ç¡®â€ã€‚
è¿™é‡Œæœ‰ä¸€ä¸ªä¾‹å­ï¼š
é—®é¢˜ï¼šå…¨ä¸–ç•Œå…±æœ‰å¤šå°‘åº§æ ¸ç”µç«™ï¼Ÿ
ç‰‡æ®µï¼š
<1>ä¸–ç•Œä¸Šå…±æœ‰440åº§è¿è¡Œä¸­çš„æ ¸ç”µååº”å †ï¼Œæ€»è£…æœºå®¹é‡è¶…è¿‡390å‰ç“¦ç‰¹ï¼ˆGWï¼‰ã€‚
<2>è¿™äº›ååº”å †åˆ†å¸ƒåœ¨ä¸–ç•Œä¸Š30ä¸ªå›½å®¶ï¼Œç¾å›½æ‹¥æœ‰æœ€å¤šçš„ååº”å †ï¼Œå…¶æ¬¡æ˜¯æ³•å›½ã€ä¸­å›½ã€æ—¥æœ¬å’Œä¿„ç½—æ–¯ã€‚
<3>å…¶ä¸­ï¼Œä¸­å›½æ­£åœ¨æ–°å»º16åº§ååº”å †ï¼Œå¢é•¿æœ€å¿«ï¼Œå…¶æ¬¡æ˜¯å°åº¦ï¼Œæœ‰8åº§åœ¨å»ºã€‚
å‚è€ƒæ–‡æ¡£ï¼š
```
[1]æ ¸ç”µç«™åœ¨32ä¸ªå›½å®¶è¿è¥ï¼Œäº§ç”Ÿäº†ä¸–ç•Œä¸Šçº¦ååˆ†ä¹‹ä¸€çš„ç”µåŠ›ã€‚å¤§å¤šæ•°ä½äºæ¬§æ´²ã€åŒ—ç¾ã€ä¸œäºšå’Œå—äºšã€‚ç¾å›½æ˜¯æœ€å¤§çš„æ ¸èƒ½ç”Ÿäº§å›½ï¼Œ
è€Œæ³•å›½çš„æ ¸ç”µæ‰€å çš„ç”µåŠ›æ¯”é‡æœ€å¤§ï¼Œçº¦ä¸º70%ã€‚ä¸­å›½æ‹¥æœ‰å¢é•¿æœ€å¿«çš„æ ¸ç”µè®¡åˆ’ï¼Œæ­£åœ¨å»ºè®¾16åº§æ–°çš„ååº”å †ï¼Œå…¶æ¬¡æ˜¯å°åº¦ï¼Œæœ‰8åº§åœ¨
å»ºã€‚
[2]æˆªè‡³2023å¹´5æœˆï¼Œä¸–ç•Œä¸Šæœ‰410åº§å¯è¿è¡Œçš„æ ¸ç”µååº”å †ï¼Œæ€»ç”µåŠ›å®¹é‡ä¸º368.6å‰ç“¦ç‰¹ã€‚
```
ä»¥ä¸‹æ˜¯æ‚¨çš„è¾“å‡ºï¼š
è¯„ä¼°æ˜ç»†ï¼š
<1>ç‰‡æ®µ1æåˆ°ï¼šâ€œä¸–ç•Œä¸Šå…±æœ‰440åº§è¿è¡Œä¸­çš„æ ¸ç”µååº”å †ï¼Œæ€»è£…æœºå®¹é‡è¶…è¿‡390å‰ç“¦ç‰¹ï¼ˆGWï¼‰ã€‚â€ è¿™ä¸€ä¿¡æ¯ä¸å‚è€ƒæ–‡æ¡£[2]ä¸­çš„ä¿¡æ¯
ä¸ä¸€è‡´ï¼šâ€œä¸–ç•Œä¸Šæœ‰410åº§å¯è¿è¡Œçš„æ ¸ç”µååº”å †ï¼Œæ€»ç”µåŠ›å®¹é‡ä¸º368.6å‰ç“¦ç‰¹ã€‚â€ å› æ­¤ç‰‡æ®µ1æ˜¯é”™è¯¯çš„ã€‚
<2>ç‰‡æ®µ2ä¸­çš„ä¿¡æ¯â€œååº”å †åˆ†å¸ƒåœ¨ä¸–ç•Œä¸Š30ä¸ªå›½å®¶â€ä¸å‚è€ƒæ–‡æ¡£[1]ä¸­çš„ä¿¡æ¯ä¸ä¸€è‡´ï¼šâ€œæ ¸ç”µç«™åœ¨32ä¸ªå›½å®¶è¿è¥â€ï¼Œè€Œä¸”å‚è€ƒæ–‡æ¡£ä¸­æ²¡
æœ‰æåŠâ€œæ³•å›½ã€ä¸­å›½ã€æ—¥æœ¬å’Œä¿„ç½—æ–¯â€çš„æ ¸ååº”å †æ•°é‡ï¼Œå› æ­¤ç‰‡æ®µ2æ˜¯é”™è¯¯çš„ã€‚
<3>ç‰‡æ®µ3æåˆ°ï¼šâ€œä¸­å›½æ­£åœ¨æ–°å»º16åº§ååº”å †ï¼Œå¢é•¿æœ€å¿«ï¼Œå…¶æ¬¡æ˜¯å°åº¦ï¼Œæœ‰8åº§åœ¨å»ºã€‚â€ä¸å‚è€ƒæ–‡æ¡£[1]ä¸€è‡´ï¼šâ€œä¸­å›½æ‹¥æœ‰å¢é•¿æœ€å¿«çš„æ ¸
ç”µè®¡åˆ’ï¼Œæ­£åœ¨å»ºè®¾16åº§æ–°çš„ååº”å †ï¼Œå…¶æ¬¡æ˜¯å°åº¦ï¼Œæœ‰8åº§åœ¨å»ºã€‚â€ï¼Œå› æ­¤ç‰‡æ®µ3æ˜¯æ­£ç¡®çš„ã€‚
æœ€ç»ˆç­”æ¡ˆï¼š1,2
è¿™æ„å‘³ç€åªæœ‰ç‰‡æ®µ1å’Œ2åŒ…å«é”™è¯¯ï¼Œè€Œç‰‡æ®µ3éƒ½èƒ½åœ¨å‚è€ƒæ–‡æ¡£ä¸­æ‰¾åˆ°ç›¸åº”å¥å­ä½œä¸ºæ”¯æŒï¼Œè¢«åˆ¤å®šä¸ºæ­£ç¡®ã€‚
ä»¥ä¸‹æ˜¯æˆ‘çš„è¾“å…¥ï¼š
é—®é¢˜ï¼š{question}
ç‰‡æ®µï¼š{segments}
å‚è€ƒæ–‡æ¡£ï¼š``` {docs} ```
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
C PROMPTS FOR DECOMPOSITION
The following are the prompts we used to decompose sentences into subclaims.
Table 17: Prompt for English Sentence Decomposition
Please breakdown the following sentence into independent facts: He is also a successful producer and engineer, having worked with a wide
variety of artists, including Willie Nelson, Tim McGraw, and Taylor Swift.
- He is successful.
- He is a producer.
- He is a engineer.
- He has worked with a wide variety of artists.
- Willie Nelson is an artist.
- He has worked with Willie Nelson.
- Tim McGraw is an artist.
- He has worked with Tim McGraw.
- Taylor Swift is an artist.
- He has worked with Taylor Swift.
Please breakdown the following sentence into independent facts: Michael Collins (born October 31, 1930) is a retired American astronaut
and test pilot who was the Command Module Pilot for the Apollo 11 mission in 1969.
- Michael Collins was born on October 31, 1930.
- Michael Collins is retired.
- Michael Collins is an American.
- Michael Collins was an astronaut.
- Michael Collins was a test pilot.
- Michael Collins was the Command Module Pilot.
- Michael Collins was the Command Module Pilot for the Apollo 11 mission.
- Michael Collins was the Command Module Pilot for the Apollo 11 mission in 1969.
Please breakdown the following sentence into independent facts: He was an American composer, conductor, and musical director.
- He was an American.
- He was a composer.
- He was a conductor.
- He was a musical director.
Please breakdown the following sentence into independent facts: In 1970, the Empire State Building in New York City was the tallest building
in the United States and the world, standing at 1,250 feet tall.
- The Empire State Building is in New York City.
- In 1970, the Empire State Building was the tallest building in the United States.
- In 1970, the Empire State Building was the tallest building in the world.
- The Empire State Building stands at 1,250 feet tall.
Please breakdown the following sentence into independent facts: The Willis Tower (formerly the Sears Tower) in Chicago was the first to do
so, reaching 1,450 feet in 1973.
- The Willis Tower is formerly called the Sears Tower.
- The Willis Tower is in Chicago.
- The Willis Tower reached 1,450 feet in 1973.
Please breakdown the following sentence into independent facts: The current tallest building in the United States is One World Trade Center
in New York City, which stands at 1,776 feet.
- The current tallest building in the United States is One World Trade Center.
- One World Trade Center is in New York City.
- One World Trade Center stands at 1,776 feet.
Please breakdown the following sentence into independent facts: William E. Moerner is an American physical chemist who was affiliated
with the University of Sussex as a visiting professor.
- William E. Moerner is an American.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
- William E. Moerner is an physical chemist.
- William E. Moerner was affiliated with the University of Sussex.
- William E. Moerner was affiliated with the University of Sussex as a visiting professor.
Please breakdown the following sentence into independent facts: Sir Harold Walter Kroto, an English chemist, shared the 1996 Nobel Prize
in Chemistry with Robert Curl and Richard Smalley for their discovery of a new form of carbon, buckminsterfullerene, also known as
buckyballs.
- Sir Harold Walter Kroto is English.
- Sir Harold Walter Kroto is an chemist.
- Sir Harold Walter Kroto won the Nobel Prize in 1996.
- Sir Harold Walter Kroto won the Nobel Prize in Chemistry.
- Sir Harold Walter Kroto shared the Nobel Prize with Robert Curl and Richard Smalley.
- They won the prize for their discovery of a new form of carbon, buckminsterfullerene, also known as buckyballs.
Please breakdown the following sentence into independent facts: {sentence}
Table 18: Prompt for Chinese Sentence Decomposition
è¯·å°†ä¸‹é¢çš„å¥å­åˆ†è§£ä¸ºç‹¬ç«‹çš„é™ˆè¿°ï¼šç‹ç¾²ä¹‹æ˜¯ä¸œæ™‹æ—¶æœŸçš„ä¹¦æ³•å®¶ï¼Œè¢«èª‰ä¸ºä¹¦åœ£ï¼Œå…¶ä»£è¡¨ä½œã€Šå…°äº­åºã€‹è¢«è®¤ä¸ºæ˜¯æ¥·ä¹¦çš„å·…å³°ä¹‹ä½œã€‚
- ç‹ç¾²ä¹‹æ˜¯ä¸œæ™‹æ—¶æœŸçš„äººç‰©ã€‚
- ç‹ç¾²ä¹‹æ˜¯ä¹¦æ³•å®¶ã€‚
- ç‹ç¾²ä¹‹è¢«èª‰ä¸ºä¹¦åœ£ã€‚
- ç‹ç¾²ä¹‹çš„ä»£è¡¨ä½œæ˜¯ã€Šå…°äº­åºã€‹ã€‚
- ã€Šå…°äº­åºã€‹è¢«è®¤ä¸ºæ˜¯æ¥·ä¹¦çš„å·…å³°ä¹‹ä½œã€‚
è¯·å°†ä¸‹é¢çš„å¥å­åˆ†è§£ä¸ºç‹¬ç«‹çš„é™ˆè¿°ï¼šåŒ—äº¬ä½æˆ¿å…¬ç§¯é‡‘ç¼´å­˜äººè´­ä¹°åŒ—äº¬å¸‚è¡Œæ”¿åŒºåŸŸå†…å•†å“ä½æˆ¿ã€ç»æµé€‚ç”¨æˆ¿åŠé™ä»·å•†å“æˆ¿ã€å…¬æœ‰ä½
æˆ¿åŠé›†èµ„åˆä½œå»ºæˆ¿ã€å±æ”¹æ‹†è¿å¾æ”¶å›è¿æˆ¿ï¼Œå¯ç”³è¯·æå–ä½æˆ¿å…¬ç§¯é‡‘ã€‚
- åŒ—äº¬ä½æˆ¿å…¬ç§¯é‡‘ç¼´å­˜äººè´­ä¹°åŒ—äº¬å¸‚è¡Œæ”¿åŒºåŸŸå†…å•†å“ä½æˆ¿å¯ç”³è¯·æå–ä½æˆ¿å…¬ç§¯é‡‘ã€‚
- åŒ—äº¬ä½æˆ¿å…¬ç§¯é‡‘ç¼´å­˜äººè´­ä¹°åŒ—äº¬å¸‚è¡Œæ”¿åŒºåŸŸå†…ç»æµé€‚ç”¨æˆ¿å¯ç”³è¯·æå–ä½æˆ¿å…¬ç§¯é‡‘ã€‚
- åŒ—äº¬ä½æˆ¿å…¬ç§¯é‡‘ç¼´å­˜äººè´­ä¹°åŒ—äº¬å¸‚è¡Œæ”¿åŒºåŸŸå†…é™ä»·å•†å“æˆ¿å¯ç”³è¯·æå–ä½æˆ¿å…¬ç§¯é‡‘ã€‚
- åŒ—äº¬ä½æˆ¿å…¬ç§¯é‡‘ç¼´å­˜äººè´­ä¹°åŒ—äº¬å¸‚è¡Œæ”¿åŒºåŸŸå†…å…¬æœ‰ä½æˆ¿å¯ç”³è¯·æå–ä½æˆ¿å…¬ç§¯é‡‘ã€‚
- åŒ—äº¬ä½æˆ¿å…¬ç§¯é‡‘ç¼´å­˜äººè´­ä¹°åŒ—äº¬å¸‚è¡Œæ”¿åŒºåŸŸå†…é›†èµ„åˆä½œå»ºæˆ¿å¯ç”³è¯·æå–ä½æˆ¿å…¬ç§¯é‡‘ã€‚
- åŒ—äº¬ä½æˆ¿å…¬ç§¯é‡‘ç¼´å­˜äººè´­ä¹°åŒ—äº¬å¸‚è¡Œæ”¿åŒºåŸŸå†…å±æ”¹æ‹†è¿å¾æ”¶å›è¿æˆ¿å¯ç”³è¯·æå–ä½æˆ¿å…¬ç§¯é‡‘ã€‚
è¯·å°†ä¸‹é¢çš„å¥å­åˆ†è§£ä¸ºç‹¬ç«‹çš„é™ˆè¿°ï¼šä¸­å›½çš„èŒ¶æ–‡åŒ–æœ‰ç€å‡ åƒå¹´çš„å†å²ï¼Œæ¶µç›–äº†èŒ¶å¶çš„ç§æ¤ã€åŠ å·¥ã€é¥®ç”¨ä¹ ä¿—ä»¥åŠèŒ¶è‰ºè¡¨æ¼”ç­‰æ–¹
é¢ï¼Œæ˜¯ä¸­å›½ä¼ ç»Ÿæ–‡åŒ–ä¸­ä¸å¯åˆ†å‰²çš„ä¸€éƒ¨åˆ†ï¼Œä¹Ÿå¯¹å‘¨è¾¹å›½å®¶å¦‚æ—¥æœ¬å’ŒéŸ©å›½çš„èŒ¶æ–‡åŒ–äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚
- ä¸­å›½çš„èŒ¶æ–‡åŒ–æœ‰å‡ åƒå¹´çš„å†å²ã€‚
- èŒ¶æ–‡åŒ–åŒ…æ‹¬èŒ¶å¶ç§æ¤ã€‚
- èŒ¶æ–‡åŒ–åŒ…æ‹¬èŒ¶å¶åŠ å·¥ã€‚
- èŒ¶æ–‡åŒ–åŒ…æ‹¬èŒ¶å¶é¥®ç”¨ä¹ ä¿—ã€‚
- èŒ¶æ–‡åŒ–åŒ…æ‹¬èŒ¶è‰ºè¡¨æ¼”ã€‚
- èŒ¶æ–‡åŒ–æ˜¯ä¸­å›½ä¼ ç»Ÿæ–‡åŒ–ä¸­ä¸å¯åˆ†å‰²çš„ä¸€éƒ¨åˆ†ã€‚
- æ—¥æœ¬æ˜¯ä¸­å›½çš„å‘¨è¾¹å›½å®¶
- éŸ©å›½æ˜¯ä¸­å›½çš„å‘¨è¾¹å›½å®¶
- ä¸­å›½çš„èŒ¶æ–‡åŒ–å¯¹æ—¥æœ¬çš„èŒ¶æ–‡åŒ–æœ‰æ·±è¿œå½±å“ã€‚
- ä¸­å›½çš„èŒ¶æ–‡åŒ–å¯¹éŸ©å›½çš„èŒ¶æ–‡åŒ–æœ‰æ·±è¿œå½±å“ã€‚
è¯·å°†ä¸‹é¢çš„å¥å­åˆ†è§£ä¸ºç‹¬ç«‹çš„é™ˆè¿°ï¼šå¸ƒæ´›èŠ¬å±äºéç”¾ä½“ç±»è§£çƒ­é•‡ç—›è¯ï¼Œå®ƒé€šè¿‡æŠ‘åˆ¶å‰åˆ—è…ºç´ çš„åˆæˆä»è€Œå‘æŒ¥è§£çƒ­ã€é•‡ç—›çš„ä½œç”¨ï¼Œ
ä»è€Œè¾¾åˆ°ä½¿å‘çƒ­è€…é€€çƒ­ã€ç¼“è§£ç–¼ç—›å¸¦æ¥çš„ä¸é€‚æ„Ÿç­‰ä½œç”¨ã€‚
- å¸ƒæ´›èŠ¬æ˜¯éç”¾ä½“ç±»è§£çƒ­é•‡ç—›è¯ã€‚
- å¸ƒæ´›èŠ¬é€šè¿‡æŠ‘åˆ¶å‰åˆ—è…ºç´ çš„åˆæˆæ¥å‘æŒ¥ä½œç”¨ã€‚
- å¸ƒæ´›èŠ¬å…·æœ‰è§£çƒ­çš„ä½œç”¨ã€‚
- å¸ƒæ´›èŠ¬å…·æœ‰é•‡ç—›çš„ä½œç”¨ã€‚
- å¸ƒæ´›èŠ¬èƒ½å¸®åŠ©å‘çƒ­è€…é€€çƒ­ã€‚
- å¸ƒæ´›èŠ¬èƒ½ç¼“è§£ç–¼ç—›å¸¦æ¥çš„ä¸é€‚æ„Ÿã€‚
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
è¯·å°†ä¸‹é¢çš„å¥å­åˆ†è§£ä¸ºç‹¬ç«‹çš„é™ˆè¿°ï¼šå± å‘¦å‘¦æ˜¯ä¸€ä½æ°å‡ºçš„ä¸­å›½è¯ç†å­¦å®¶ï¼Œä»¥å…¶å‘ç°æŠ—ç–Ÿç–¾è¯ç‰©é’è’¿ç´ è€Œé—»åäºä¸–ï¼Œè¿™ä¸€å‘ç°æºäº
å¯¹ä¸­å›½å¤ä»£è¯ä¹¦çš„æ·±å…¥ç ”ç©¶ï¼Œå¯¹å…¨çƒæŠ—å‡»ç–Ÿç–¾çš„åŠªåŠ›ä½œå‡ºäº†å†å²æ€§çš„è´¡çŒ®ï¼Œå¥¹çš„å·¥ä½œä¸ä»…æŒ½æ•‘äº†æ— æ•°ç”Ÿå‘½ï¼Œè¿˜å› æ­¤è£è·2015å¹´è¯º
è´å°”ç”Ÿç†å­¦æˆ–åŒ»å­¦å¥–ã€‚
- å± å‘¦å‘¦æ˜¯æ°å‡ºçš„ã€‚
- å± å‘¦å‘¦æ˜¯ä¸­å›½äººã€‚
- å± å‘¦å‘¦æ˜¯è¯ç†å­¦å®¶ã€‚
- å± å‘¦å‘¦å› å‘ç°é’è’¿ç´ è€Œæˆä¸ºä¸–ç•Œé—»åã€‚
- é’è’¿ç´ æ˜¯æŠ—ç–Ÿç–¾è¯ç‰©ã€‚
- é’è’¿ç´ çš„å‘ç°æ˜¯åŸºäºå¯¹ä¸­å›½å¤ä»£è¯ä¹¦çš„ç ”ç©¶ã€‚
- å± å‘¦å‘¦çš„ç ”ç©¶å¯¹å…¨çƒæŠ—å‡»ç–Ÿç–¾åšå‡ºäº†é‡å¤§è´¡çŒ®ã€‚
- é’è’¿ç´ çš„å‘ç°æŒ½æ•‘äº†æ— æ•°äººçš„ç”Ÿå‘½ã€‚
- å± å‘¦å‘¦è·å¾—äº†2015å¹´è¯ºè´å°”ç”Ÿç†å­¦æˆ–åŒ»å­¦å¥–ã€‚
è¯·å°†ä¸‹é¢çš„å¥å­åˆ†è§£ä¸ºç‹¬ç«‹çš„é™ˆè¿°ï¼šä¸­å›½çš„æ•…å®«æ˜¯æ˜æ¸…ä¸¤ä»£çš„çš‡å®«ï¼Œå åœ°è¶…è¿‡72ä¸‡å¹³æ–¹ç±³ï¼ŒåŒ…å«äº†çº¦8000é—´æˆ¿å±‹ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„å†
å²æ–‡ç‰©ï¼Œæ¯å¹´å¸å¼•æ•°ç™¾ä¸‡æ¸¸å®¢å‰æ¥å‚è§‚ï¼Œæ˜¯ä¸–ç•Œä¸Šç°å­˜è§„æ¨¡æœ€å¤§ã€ä¿å­˜æœ€ä¸ºå®Œæ•´çš„æœ¨è´¨ç»“æ„å¤å»ºç­‘ç¾¤ä¹‹ä¸€ã€‚
- æ•…å®«æ˜¯ä¸­å›½çš„ã€‚
- æ•…å®«æ›¾æ˜¯æ˜ä»£çš„çš‡å®«ã€‚
- æ•…å®«æ›¾æ˜¯æ¸…ä»£çš„çš‡å®«ã€‚
- æ•…å®«å åœ°è¶…è¿‡72ä¸‡å¹³æ–¹ç±³ã€‚
- æ•…å®«åŒ…å«çº¦8000é—´æˆ¿å±‹ã€‚
- æ•…å®«å†…æ‹¥æœ‰ä¸°å¯Œçš„å†å²æ–‡ç‰©ã€‚
- æ¯å¹´æœ‰æ•°ç™¾ä¸‡æ¸¸å®¢å‚è§‚æ•…å®«ã€‚
- æ•…å®«æ˜¯ä¸–ç•Œä¸Šæœ€å¤§çš„æœ¨è´¨ç»“æ„å¤å»ºç­‘ç¾¤ä¹‹ä¸€ã€‚
- æ•…å®«çš„ä¿å­˜çŠ¶å†µéå¸¸å®Œæ•´ã€‚
è¯·å°†ä¸‹é¢çš„å¥å­åˆ†è§£ä¸ºç‹¬ç«‹çš„é™ˆè¿°ï¼šè¢éš†å¹³ï¼Œè¢«ç§°ä¸ºâ€œæ‚äº¤æ°´ç¨»ä¹‹çˆ¶â€ï¼Œæ˜¯ä¸­å›½è‘—åçš„å†œå­¦å®¶ï¼Œå…¶é¢†å¯¼çš„ç§‘ç ”å›¢é˜ŸæˆåŠŸå¼€å‘å‡ºäº†ç¬¬
ä¸€ä»£æ‚äº¤æ°´ç¨»ï¼Œå¤§å¹…æé«˜äº†æ°´ç¨»äº§é‡ï¼Œä»–çš„ç ”ç©¶æˆæœè¢«å¹¿æ³›åº”ç”¨äºäºšæ´²ã€éæ´²ç­‰å¤šä¸ªå›½å®¶å’Œåœ°åŒºï¼Œæå¤§åœ°ç¼“è§£äº†è¿™äº›åœ°åŒºçš„é¥¥é¥¿
é—®é¢˜ï¼Œè¢éš†å¹³æœ¬äººå› æ­¤è·å¾—äº†åŒ…æ‹¬â€œä¸–ç•Œç²®é£Ÿå¥–â€åœ¨å†…çš„ä¼—å¤šå›½é™…è£èª‰ï¼Œè¢«ä¸–ç•Œå„å›½èª‰ä¸ºäººç±»ç²®é£Ÿç”Ÿäº§çš„è‹±é›„ã€‚
- è¢éš†å¹³è¢«ç§°ä¸ºâ€œæ‚äº¤æ°´ç¨»ä¹‹çˆ¶â€ã€‚
- è¢éš†å¹³æ˜¯ä¸­å›½äººã€‚
- è¢éš†å¹³æ˜¯è‘—åçš„å†œå­¦å®¶ã€‚
- è¢éš†å¹³é¢†å¯¼çš„ç§‘ç ”å›¢é˜Ÿå¼€å‘å‡ºäº†ç¬¬ä¸€ä»£æ‚äº¤æ°´ç¨»ã€‚
- æ‚äº¤æ°´ç¨»çš„å¼€å‘æ˜¾è‘—æå‡äº†æ°´ç¨»äº§é‡ã€‚
- æ‚äº¤æ°´ç¨»æŠ€æœ¯è¢«åº”ç”¨äºäºšæ´²å¤šä¸ªå›½å®¶å’Œåœ°åŒºã€‚
- æ‚äº¤æ°´ç¨»æŠ€æœ¯è¢«åº”ç”¨äºéæ´²å¤šä¸ªå›½å®¶å’Œåœ°åŒºã€‚
- è¢éš†å¹³çš„å·¥ä½œå¸®åŠ©ç¼“è§£äº†ä¸–ç•Œé¥¥é¥¿é—®é¢˜ã€‚
- è¢éš†å¹³è·å¾—äº†åŒ…æ‹¬â€œä¸–ç•Œç²®é£Ÿå¥–â€åœ¨å†…çš„å¤šé¡¹å›½é™…è£èª‰ã€‚
- è¢éš†å¹³è¢«ä¸–ç•Œå„å›½èª‰ä¸ºäººç±»ç²®é£Ÿç”Ÿäº§çš„è‹±é›„ã€‚
è¯·å°†ä¸‹é¢çš„å¥å­åˆ†è§£ä¸ºç‹¬ç«‹çš„é™ˆè¿°ï¼šæ•¦ç…Œæ˜¯ä¸­å›½ç”˜è‚ƒçœçš„ä¸€ä¸ªå†å²ååŸï¼Œä¸ç»¸ä¹‹è·¯çš„é‡è¦èŠ‚ç‚¹ï¼Œä»¥å…¶ä¿å­˜ä¸‹æ¥çš„ä¸€ç³»åˆ—å£ç”»å’Œé›•
å¡‘é—»åäºä¸–ï¼Œå…¶ä¸­æœ€è‘—åçš„è«è¿‡äºæ•¦ç…Œè«é«˜çªŸï¼Œè¿™äº›è‰ºæœ¯ä½œå“ä¸ä»…å±•ç¤ºäº†å¤ä»£ä¸ç»¸ä¹‹è·¯çš„ç¹è£ï¼Œä¹Ÿåæ˜ äº†ä¸åŒå®—æ•™æ–‡åŒ–çš„äº¤èï¼Œ
æ•¦ç…Œæˆä¸ºäº†ç ”ç©¶ä¸­å›½å¤ä»£å†å²ã€å®—æ•™å’Œæ–‡åŒ–äº¤æµçš„å®è´µèµ„æ–™ã€‚
- æ•¦ç…Œåœ¨ä¸­å›½ç”˜è‚ƒçœã€‚
- æ•¦ç…Œæ˜¯å†å²ååŸã€‚
- æ•¦ç…Œæ˜¯ä¸ç»¸ä¹‹è·¯çš„é‡è¦èŠ‚ç‚¹ã€‚
- æ•¦ç…Œä»¥å£ç”»é—»åäºä¸–ã€‚
- æ•¦ç…Œä»¥é›•å¡‘é—»åäºä¸–ã€‚
- æ•¦ç…Œè«é«˜çªŸæ˜¯æ•¦ç…Œæœ€è‘—åçš„ã€‚
- è«é«˜çªŸçš„è‰ºæœ¯ä½œå“å±•ç¤ºäº†å¤ä»£ä¸ç»¸ä¹‹è·¯çš„ç¹è£ã€‚
- æ•¦ç…Œè‰ºæœ¯åæ˜ äº†ä¸åŒå®—æ•™æ–‡åŒ–çš„äº¤èã€‚
- æ•¦ç…Œæ˜¯ç ”ç©¶ä¸­å›½å¤ä»£å†å²çš„å®è´µèµ„æ–™ã€‚
- æ•¦ç…Œæ˜¯ç ”ç©¶ä¸­å›½å¤ä»£å®—æ•™çš„å®è´µèµ„æ–™ã€‚
- æ•¦ç…Œæ˜¯ç ”ç©¶ä¸­å›½å¤ä»£æ–‡åŒ–äº¤æµçš„å®è´µèµ„æ–™ã€‚
è¯·å°†ä¸‹é¢çš„å¥å­åˆ†è§£ä¸ºç‹¬ç«‹çš„é™ˆè¿°ï¼š{sentence}
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
D DATASET MODIFICATION SAMPLES
We samples query, reference, and answers from WebGLM-QA (English-only) and WebCPM (Chinese-only) and compare them with the
answer constructed using our outline-enhanced technique. Answers in our dataset has organization pattern, the outline and the answer. It is
clear that our answers are longer and have a better logic structure.
Table 19: Examples for Dataset Modification
Query References Answer in Original Dataset Answer in Our Dataset
why
arenâ€™t
all tin
cans
ring
pull??
[1]Thanks to @alanwood01, we
think weâ€™ve been using ring pulls
on tin cans in completely the wrong
way. But what do you think?
[2]Thanks to @alanwood01, we
think weâ€™ve been using ring pulls
on tin cans in completely the wrong
way. But what do you think?
[3]Theyâ€™re not 100% ideal in all cir-
cumstances. Soup cans with ring
pulls must have much thinner lids
to work, which means the lids are
more vulnerable to damage. As an
educated guess, I would imagine
that the ring pull lids cost slightly
more to manufacture, too, which
isnâ€™t at all a small consideration
when youâ€™re talking about some-
thing as low-margin as most gro-
ceries.
[4]Ring pulls are expensive com-
pared to the standard lid. Itâ€™s frac-
tions of a penny, but it adds up
when you manufacture a few mil-
lion units in cans a day.
[5]â€œIn my civilized European coun-
try all cans are ring-pull, even the
ones with tuna. OP must be a prim-
itive American, where you have to
use stupid can openers for every-
thing.
Ring pull cans are not used univer-
sally because they are more expen-
sive to manufacture compared to
the standard lid[3], and the soup
can lids must be thinner to work,
making them more vulnerable to
damage[3]. In addition, the cost dif-
ference adds up when manufactur-
ing a few million cans a day[4],
making the ring pull lids less cost-
effective.[3]
[Structure]:
Cause-Effect
[Outline]:
1. Manufacturing cost considerations (based on
[3] and [4])
2. Practicality in terms of product safety and in-
tegrity (based on [3])
[Answer]:
The absence of ring pulls on all tin cans can be
attributed primarily to two factors: cost concerns
and practicality related to product safety.
### Manufacturing Cost Considerations
Ring pulls, while convenient for consumers, are
more expensive to produce than standard lids.
This cost difference, although seemingly minor
on a per-unit basis, becomes significant when con-
sidering the scale of production. Manufacturers
often produce millions of cans daily, and even frac-
tions of a penny per can add up to a considerable
amount. As groceries are generally low-margin
products, companies are inclined to minimize pro-
duction costs wherever possible to maintain prof-
itability.
### Practicality for Product Safety
In addition to cost implications, the feasibility of
using ring pulls on certain products is limited by
the need for thinner lids. This requirement for
a thinner lid makes the cans more vulnerable to
damage, posing a risk to the integrity of the prod-
uct inside. Soup cans, for example, must main-
tain their structure to ensure safe storage and
transportation. The decision to forgo ring pulls
on some tin cans is a measure to prevent potential
damage and the associated waste or customer dis-
satisfaction that could result from compromised
product packaging.
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Why
donâ€™t
surfers
wear
life
vests
and
hel-
mets?
[1]One of the major reasons surfers
donâ€™t use life vests is that when
they are in the water they are
strapped to a giant floatation device,
their surfboard.
[2]Other than the fact that they
look bad, the main reason why
surfers donâ€™t wear life jackets is
that they get in the way. With a
PFD on, it will be harder to paddle
and duck dive. Furthermore, surfers
are literally standing on a big PFD
â€“ their surfboards â€“ which are at-
tached to their legs with a rope.
[3]Letâ€™s be honest here, this is prob-
ably the #1 reasons apart from the
â€œwe donâ€™t really need itâ€ reason that
surfers donâ€™t wear life jackets.
[4]Now, arguably the main reason
why most surfers donâ€™t wear life
jackets is that they get in the way
both in terms of fun and, ironically,
in the way of safety as well.
[5]While surfers donâ€™t wear life
vests (there are specific require-
ments for a device to be considered
life saving), itâ€™s not a surprise that
big wave surfers wear special inflat-
able PFDs.
Surfers generally donâ€™t wear life
vests and helmets because they are
strapped to a giant floatation device,
their surfboard[1], and life jackets
get in the way of paddling and duck
diving[2][4]. Furthermore, surfers
donâ€™t need to wear life jackets be-
cause they are standing on a big
PFD - their surfboards - which are
attached to their legs with a rope[2].
For bigger waves, some surfers
wear special inflatable PFDs[5].
[Structure]:
Comparative
[Outline]:
1. Surfboard as a flotation device (based on [1])
2. Hindrance to movement and safety (based on
[2] and [4])
3. Aesthetic and traditional reasons (based on [3])
4. Exception for big wave surfers (based on [5])
[Answer]:
Surfers typically eschew traditional life vests and
helmets due to a combination of practical, safety,
and cultural reasons, as well as the nature of their
equipment.
### Surfboard as a Flotation Device
A primary reason surfers donâ€™t utilize life vests is
their surfboard, which essentially acts as a large
flotation device. Since surfboards are buoyant and
tethered to the surfer by a leash, they provide
significant flotation support without the need for
an additional life vest.
### Hindrance to Movement and Safety
Life vests are generally avoided because they can
interfere with the surferâ€™s ability to move freely.
The requirement to paddle effectively and per-
form duck dives â€” a maneuver used to dive be-
neath oncoming waves â€” is hampered by the bulk
of a personal flotation device (PFD). Ironically,
rather than increasing safety, a life vest can ac-
tually present a hazard by restricting mobility in
the water.
### Aesthetic and Traditional Reasons
The avoidance of life vests is also influenced by
aesthetics and tradition within the surfing com-
munity. Surfers often prefer the freedom of not
wearing what may be considered unattractive
gear, adhering to a longstanding cultural norm of
surfing without excessive equipment.
### Exception for Big Wave Surfers
While standard practice is to not wear life vests,
there is an exception for big wave surfers, who
may use specialized inflatable PFDs. These de-
vices are designed with the specific risks of big
wave surfing in mind, balancing the need for flota-
tion with the necessity of not hindering move-
ment.
In conclusion, the decision not to wear life vests
and helmets while surfing is largely based on the
surfboardâ€™s role as a flotation aid, the importance
of unhindered movement for both performance
and safety, cultural factors regarding appearance,
and exceptions made for the unique conditions
faced by big wave surfers.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
.NETæ˜¯
ä»€
ä¹ˆï¼Ÿ
[1].NETæ˜¯ä¸€ç§ç”¨äºæ„å»ºå¤šç§åº”
ç”¨ çš„ å… è´¹ å¼€ æº å¼€ å‘ å¹³ å° ï¼Œ å¯
ä»¥ä½¿ç”¨å¤šç§è¯­è¨€ï¼Œç¼–è¾‘å™¨å’Œåº“
å¼€å‘Webåº”ç”¨ã€Web APIå’Œå¾®æœ
åŠ¡ã€äº‘ä¸­ çš„æ— æœåŠ¡å™¨å‡½æ•°ã€äº‘
åŸç”Ÿåº”ç”¨ã€ç§»åŠ¨åº”ç”¨ã€æ¡Œé¢åº”
ç”¨ã€Windows WPFã€Windowsçª—
ä½“ã€é€šç”¨Windowså¹³å°(UWP)ã€
æ¸¸ æˆ ã€ ç‰© è” ç½‘(IoT)ã€ æœº å™¨ å­¦
ä¹  ã€ æ§ åˆ¶ å° åº” ç”¨ ã€Windowsæœ
åŠ¡ ã€‚.NETç±» åº“ åœ¨ ä¸ åŒ åº” ç”¨ å’Œ åº”
ç”¨ç±»å‹ä¸­å…±äº«åŠŸèƒ½ï¼Œæ— è®ºæ„å»º
å“ªç§ç±»å‹çš„åº”ç”¨ï¼Œä»£ç å’Œé¡¹ç›®æ–‡
ä»¶çœ‹èµ·æ¥éƒ½ä¸€æ ·ï¼Œå¯ä»¥è®¿é—®æ¯ä¸ª
åº”ç”¨çš„ç›¸ åŒè¿è¡Œæ—¶ã€APIå’Œè¯­è¨€
åŠŸèƒ½ã€‚
.NETæ˜¯ä¸€ç§ç”¨äºæ„å»ºå¤šç§åº”ç”¨
çš„ å… è´¹ å¼€ æº å¼€ å‘ å¹³ å° ï¼Œ å¯ ä»¥
ä½¿ ç”¨ å¤š ç§ è¯­ è¨€ ï¼Œ ç¼– è¾‘ å™¨ å’Œ åº“
å¼€å‘Webåº”ç”¨ã€Web APIå’Œå¾®æœ
åŠ¡ã€äº‘ä¸­ çš„æ— æœåŠ¡å™¨å‡½æ•°ã€äº‘
åŸç”Ÿåº”ç”¨ã€ç§»åŠ¨åº”ç”¨ã€æ¡Œé¢åº”
ç”¨ã€Windows WPFã€Windowsçª—
ä½“ã€é€šç”¨Windowså¹³å°(UWP)ã€
æ¸¸ æˆ ã€ ç‰© è” ç½‘(IoT)ã€ æœº å™¨ å­¦
ä¹  ã€ æ§ åˆ¶ å° åº” ç”¨ ã€Windowsæœ
åŠ¡ ã€‚.NETç±» åº“ åœ¨ ä¸ åŒ åº” ç”¨ å’Œ åº”
ç”¨ç±»å‹ä¸­å…±äº«åŠŸèƒ½ï¼Œæ— è®ºæ„å»º
å“ªç§ç±»å‹çš„åº”ç”¨ï¼Œä»£ç å’Œé¡¹ç›®æ–‡
ä»¶çœ‹èµ·æ¥éƒ½ä¸€æ ·ï¼Œå¯ä»¥è®¿é—®æ¯ä¸ª
åº”ç”¨çš„ç›¸åŒè¿è¡Œæ—¶ã€APIå’Œè¯­è¨€
åŠŸèƒ½ã€‚
ã€ç»“æ„ã€‘ï¼š
å¹¶åˆ—
ã€æçº²ã€‘ï¼š
1. .NETçš„å®šä¹‰ä¸æ€§è´¨ï¼ˆä»…ä½¿ç”¨[1]å›ç­”ï¼‰
2. .NETçš„å¼€æºç‰¹æ€§ï¼ˆä»…ä½¿ç”¨[1]å›ç­”ï¼‰
3. .NETçš„åº”ç”¨é¢†åŸŸï¼ˆä»…ä½¿ç”¨[1]å›ç­”ï¼‰
4. .NETçš„ç¼–ç¨‹è¯­è¨€æ”¯æŒä¸APIï¼ˆä»…ä½¿ç”¨[1]å›
ç­”ï¼‰
ã€å›ç­”ã€‘ï¼š
.NETæ˜¯ä¸€ç§å¤šåŠŸèƒ½çš„å¼€å‘å¹³å°ï¼Œæ—¨åœ¨æ”¯æŒå¼€
å‘äººå‘˜æ„å»ºå„ç§ç±»å‹çš„åº”ç”¨ç¨‹åºã€‚å®ƒå…·æœ‰å¤š
ç§ç‰¹ç‚¹å’ŒåŠŸèƒ½ï¼Œä¸‹é¢è¿›è¡Œè¯¦ç»†ä»‹ç»ï¼š
1. .NETçš„å®šä¹‰ä¸æ€§è´¨
.NETæ˜¯ä¸€ä¸ªå…è´¹ä¸”å¼€æºçš„å¼€å‘å¹³å°ï¼Œå®ƒæä¾›
äº†ä¸€å¥—å·¥å…·å’Œèµ„æºï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿä½¿ç”¨å¤šç§
ç¼–ç¨‹è¯­è¨€ã€ç¼–è¾‘å™¨å’Œåº“æ¥æ„å»ºåº”ç”¨ç¨‹åºã€‚
2. .NETçš„å¼€æºç‰¹æ€§
ä½œä¸ºä¸€ä¸ª å¼€æºå¹³å°ï¼Œ.NETå…è®¸å¼€å‘è€…è‡ªç”±åœ°
è®¿é—®å…¶æºä»£ç ï¼Œå…±åŒè´¡çŒ®å’Œæ”¹è¿›å¹³å°çš„åŠŸèƒ½
å’Œæ€§èƒ½ã€‚
3. .NETçš„åº”ç”¨é¢†åŸŸ
è¯¥å¹³å°é€‚ç”¨äºå¤šç§åº”ç”¨ç¨‹åºçš„å¼€å‘ï¼ŒåŒ…æ‹¬ä½†
ä¸é™äºWebåº”ç”¨ç¨‹åºã€Web APIå’Œå¾®æœåŠ¡ã€æ— 
æœåŠ¡å™¨å‡½æ•°ã€äº‘åŸç”Ÿåº”ç”¨ã€ç§»åŠ¨åº”ç”¨ã€æ¡Œé¢
åº”ç”¨ã€æ¸¸æˆã€ç‰©è”ç½‘(IoT) è®¾å¤‡ã€æœºå™¨å­¦ä¹ é¡¹
ç›®ä»¥åŠæ§åˆ¶å°åº”ç”¨ç¨‹åºç­‰ã€‚
4. .NETçš„ç¼–ç¨‹è¯­è¨€æ”¯æŒä¸API
.NETæ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€ï¼Œè¿™æ„å‘³ç€å¼€å‘è€…å¯
ä»¥æ ¹æ®è‡ªå·±çš„åå¥½é€‰æ‹©åˆé€‚çš„è¯­è¨€æ¥æ„å»ºé¡¹
ç›®ã€‚æ­¤å¤–ï¼Œ.NETæä¾›äº†ä¸°å¯Œçš„APIå’Œç±»åº“æ¥ä¿ƒ
è¿›ä¸åŒåº”ç”¨ç¨‹åºä¹‹é—´åŠŸèƒ½çš„å…±äº«ï¼Œæ— è®ºæ˜¯å“ª
ç§ç±»å‹çš„åº”ç”¨ï¼Œå…¶ä»£ç å’Œé¡¹ç›®æ–‡ä»¶åœ¨ç»“æ„ä¸Š
éƒ½ä¿æŒä¸€è‡´æ€§ï¼Œå¼€å‘è€…å¯ä»¥è®¿é—®ç›¸åŒçš„è¿è¡Œ
æ—¶ç¯å¢ƒã€APIå’Œè¯­è¨€åŠŸèƒ½ï¼Œè¿™æå¤§åœ°ä¾¿åˆ©äº†å¼€
å‘è¿‡ç¨‹å’Œç»´æŠ¤å·¥ä½œã€‚
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
ç‹— å¦‚
ä½• ç†
è§£ äºº
ç±» è¯­
è¨€ï¼Ÿ
[1]ç‹—ç‹— å¯¹äºé“²å±å®˜çš„è¯­è¨€æœ¬èº«
ä¼šè¿›è¡Œæ€è€ƒå’Œç†è§£ï¼Œä½†ä¹Ÿä¼šè§‚
å¯Ÿé“²å±å®˜è¯´è¯æ—¶çš„è¡¨æƒ…å’ŒåŠ¨ä½œæ¥
å¸®åŠ©è§£è¯»ï¼Œè¿™å°±è¯´æ˜å’±ä»¬ä½ä¼°äº†
ç‹—ç‹—çš„å­¦ä¹ èƒ½åŠ›ã€‚è€Œå¯¹äºç‹—ç‹—èƒ½
å¬æ‡‚äººè¯è¿˜æœ‰å¦ä¸€ä¸ªè§£é‡Šï¼Œé‚£å°±
æ˜¯æ¡ä»¶åå°„ã€‚ä¸é”™ï¼Œå°±æ‹¿ä¸Šé¢æ
åˆ°çš„ç»™ç‹—ç‹—èµ·åå­—ä»¥åŠä¸€äº›å¸¸ç”¨
çš„æŒ‡ä»¤ï¼Œé€šè¿‡åå¤è®°å¿†ç‹—ç‹—å°±èƒ½
å½¢æˆæ¡ä»¶åå°„è®°ä½è¿™äº›è¯æ±‡çš„å«
ä¹‰ã€‚æ¯ç§ç”Ÿç‰©éƒ½æœ‰å±äºè‡ªå·±çš„é‚£
å¥—è¯­è¨€åŠŸèƒ½ç³»ç»Ÿï¼Œäººä¸ç‹—ä¹‹é—´çš„
è¯­è¨€ç³»ç»Ÿæ˜æ˜¾æ˜¯ä¸åŒçš„ï¼Œé‚£ä¹ˆæƒ³
è¦åšåˆ°å®Œå…¨äº†è§£å½¼æ­¤çš„
[2]è¯è¯­ è‚¯å®šæ˜¯ä¸å¤ªå¯èƒ½çš„ã€‚ä¸
è¿‡è™½ç„¶ç‹—ç‹—ä¸èƒ½å®Œå…¨æ˜ç™½é“²å±å®˜
çš„å¯¹è¯ï¼Œå´å¯ä»¥é€šè¿‡æƒ…ç»ªæ¥è¾¨åˆ«
è¯è¯­çš„æ„æ€ï¼Œè¯´åˆ°åº•è¿™ä¹Ÿæ˜¯ç‹—ç‹—
ç»è¿‡æ•°åƒå¹´çš„é©¯åŒ–åä¸äººç±»è¾¾æˆ
çš„é»˜å¥‘ï¼Œå®ƒä»¬å¹¶ä¸åªæ˜¯ä¾é æ¡ä»¶
åå°„æ¥è¯»æ‡‚é“²å±å®˜ï¼Œæ›´å¤šçš„æ—¶å€™
å®ƒä»¬ä¹Ÿåœ¨æ€è€ƒï¼Œä¹Ÿåœ¨åŠªåŠ›èµ°è¿›é“²
å±å®˜çš„ä¸–ç•Œã€‚
[3]è™½ç„¶ä¸åŒçŠ¬ç±»å¯¹ç†è§£äººç±»è¯­
è¨€çš„æ°´å¹³å’ŒåŠ¨æœºä¼šæœ‰ä¸åŒï¼Œä½†å½“
å®ƒä»¬å¬åˆ°å­¦è¿‡çš„å•è¯æ—¶ï¼Œè„‘éƒ¨éƒ½
ä¼šäº§ç”Ÿç¥ç»ååº”è€Œä¸åªæ˜¯å·´ç”«æ´›
å¤«çš„æ¡ä»¶åå°„ã€‚æœ¬æ¬¡ç ”ç©¶çš„ç»“æœ
ä¸èƒ½è¯´æ˜è¯­è¨€æ˜¯å’Œç‹—æ²Ÿé€šæœ€æœ‰æ•ˆ
çš„æ–¹å¼ï¼ŒçœŸæ­£æœ‰æ•ˆçš„å…¶å®æ˜¯çŠ¬ç±»
çš„ç¥ç»å¥–åŠ±æœºåˆ¶ï¼Œæ‰èƒ½è®©è®­ç‹—æ›´
åŠ æœ‰æ•ˆã€‚è€Œäººç±»æ›´å€¾å‘äºé€šè¿‡è¯­
è¨€æ¥è®­ç»ƒç‹—ï¼Œè¿™æ˜¯ä»äººç±»çš„è®¤çŸ¥
è§’åº¦å‡ºå‘å¾—åˆ°çš„ä¸»è§‚æ€§å¸¸è¯†ï¼Œå®
é™…ä¸Šå¯¹äºçŠ¬ç±»æ¥è¯´è§†è§‰æ„Ÿå®˜æ‰æ›´
åŠ æœ‰æ•ˆã€‚
ç‹—å¯¹äººç±»è¯­è¨€çš„ç†è§£ä¸»è¦ä»ä¸¤ä¸ª
è§’åº¦æ¥è¯´ï¼Œä¸€æ˜¯ç‹—å¬åˆ°å­¦è¿‡çš„å•
è¯æ—¶ï¼Œè„‘éƒ¨éƒ½ä¼šäº§ç”Ÿç¥ç»ååº”è€Œ
ä¸åªæ˜¯å·´ç”«æ´›å¤«çš„æ¡ä»¶åå°„ã€‚ç‹—
ç‹—å¯¹äºäººç±»çš„è¯­è¨€æœ¬èº«ä¼šè¿›è¡Œæ€
è€ƒå’Œç†è§£ï¼Œä½†ä¹Ÿä¼šè§‚å¯Ÿäººç±»è¯´è¯
æ—¶çš„è¡¨æƒ…å’ŒåŠ¨ä½œæ¥å¸®åŠ©è§£è¯»ã€‚äºŒ
æ˜¯æ¡ä»¶åå°„ï¼Œé€šè¿‡åå¤è®°å¿†ç‹—ç‹—
å°±èƒ½å½¢æˆæ¡ä»¶åå°„è®°ä½è¿™äº›è¯æ±‡
çš„å«ä¹‰ã€‚
ã€ç»“æ„ã€‘ï¼š
å› æœ
ã€æçº²ã€‘ï¼š
1. ç‹— ç‹—çš„ è¯­ è¨€ ç† è§£ åŒ… æ‹¬ è¯­ è¨€ å’Œ é è¯­ è¨€ å›  ç´ 
ï¼ˆä»…ä½¿ç”¨[1]å›ç­”ï¼‰
2. ç‹—ç‹—å¯¹äºäººç±»è¯è¯­çš„ç†è§£ä¸æƒ…ç»ªè¾¨è¯†ç›¸å…³
ï¼ˆä»…ä½¿ç”¨[2]å›ç­”ï¼‰
3. ç‹— ç‹— ç† è§£ äºº ç±» è¯­ è¨€ çš„ ç¥ ç» æœº åˆ¶ ï¼ˆ ä»… ä½¿
ç”¨[3]å›ç­”ï¼‰
ã€å›ç­”ã€‘ï¼š
ç‹—ç‹—ç†è§£äººç±»è¯­è¨€çš„è¿‡ç¨‹æ˜¯ä¸€ä¸ªå¤æ‚çš„è®¤çŸ¥
æ´»åŠ¨ï¼Œæ¶‰åŠåˆ°å¤šç§å› ç´ å’Œæœºåˆ¶ã€‚
é¦–å…ˆï¼Œç‹—ç‹—ä¸ä»…ä»… æ˜¯é€šè¿‡å¬è§‰æ¥å—äººç±»çš„è¯­
è¨€ï¼Œå®ƒä»¬è¿˜ä¼šç»“åˆäººç±»çš„è¡¨æƒ…å’ŒåŠ¨ä½œæ¥è¾…åŠ©
ç†è§£ã€‚è¿™è¡¨æ˜ç‹—ç‹—å…·å¤‡ä¸€å®šçš„å­¦ä¹ èƒ½åŠ›ï¼Œèƒ½
å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šæ€è€ƒå’Œç†è§£å®ƒä»¬çš„ä¸»äººæ‰€è¡¨
è¾¾çš„å†…å®¹ã€‚åŒæ—¶ï¼Œç‹—ç‹—ä¹Ÿä¼šé€šè¿‡æ¡ä»¶åå°„æœº
åˆ¶æ¥è®°ä½å’Œå“åº”ä¸»äººçš„å‘½ä»¤å’Œåå­—ã€‚
å…¶æ¬¡ï¼Œç‹—ç‹—èƒ½å¤Ÿé€šè¿‡æ„ŸçŸ¥äººç±»çš„æƒ…ç»ªæ¥è¾¨åˆ«
è¯è¯­çš„æ„ä¹‰ï¼Œè¿™æ˜¯æ•°åƒå¹´é©¯åŒ–è¿‡ç¨‹ä¸­å½¢æˆçš„
ä¸€ç§ä¸äººç±»çš„æ²Ÿé€šé»˜å¥‘ã€‚åœ¨å’Œäººç±»çš„äº’åŠ¨è¿‡
ç¨‹ä¸­ï¼Œå®ƒä»¬å¹¶ä¸å®Œå…¨ä¾èµ–æ¡ä»¶åå°„ï¼Œè€Œæ˜¯é€š
è¿‡è§‚å¯Ÿå’Œæ€è€ƒæ¥æ›´æ·±å…¥åœ°ç†è§£äººç±»çš„ä¸–ç•Œã€‚
æœ€åï¼Œç§‘å­¦ç ”ç©¶è¡¨æ˜ï¼Œç‹—ç‹—åœ¨å¬åˆ°ç†Ÿæ‚‰çš„å•
è¯æ—¶ä¼šåœ¨å¤§è„‘ä¸­äº§ç”Ÿç¥ç»ååº”ï¼Œè¿™ä¸ä»…ä»… æ˜¯
ç®€å•çš„æ¡ä»¶åå°„ã€‚æœ‰æ•ˆçš„çŠ¬ç±»è®­ç»ƒå®é™…ä¸Šå’Œ
å®ƒä»¬çš„ç¥ç»å¥–åŠ±æœºåˆ¶æœ‰å…³ï¼Œè€Œéå•çº¯çš„è¯­è¨€
è®­ç»ƒã€‚äººç±»å¯èƒ½æ›´å€¾å‘äºç”¨è¯­è¨€æ¥è®­ç»ƒç‹—ï¼Œ
ä½†ä»ç‹—çš„è®¤çŸ¥è§’åº¦çœ‹ï¼Œè§†è§‰æ„Ÿå®˜å¯èƒ½æ˜¯æ›´æœ‰
æ•ˆçš„æ²Ÿé€šæ–¹å¼ã€‚
ç»¼ä¸Šæ‰€è¿°ï¼Œç‹—ç‹—ç†è§£äººç±»è¯­è¨€çš„èƒ½åŠ›æ˜¯å¤šæ–¹
é¢çš„ï¼Œæ¶‰åŠåˆ°è¯­è¨€çš„å¬è§‰å¤„ç†ã€éè¯­è¨€çš„æƒ…
ç»ªå’Œè‚¢ä½“è¯­è¨€è®¤çŸ¥ï¼Œä»¥åŠå¤§è„‘çš„ç¥ç»å¥–åŠ±æœº
åˆ¶ã€‚è¿™äº›å› ç´ å…±åŒä½œç”¨ï¼Œè®©ç‹—ç‹—èƒ½å¤Ÿæ›´å¥½åœ°
ç†è§£å’Œå“åº”äººç±»çš„æŒ‡ä»¤å’Œæƒ…æ„Ÿã€‚
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
E GENERATION IMPROVEMENT SAMPLES
We provide examples from the test set of WebGLM-QA (in English) and WebCPM (in Chinese). For each test set, we compare the open
sourced method with best performance on that dataset with our FoRAG-L 7B.
Table 20: Examples for Generation Improvement
Query References Answer from SOTA Model Answer from Our Best Model
IPodå’Œ
ç£ å¸¦
æ’­
æ”¾ æœº
çš„ å·¥
ä½œ åŸ
ç†ï¼Ÿ
[1]ipod video çš„ èŠ¯ ç‰‡
æ˜¯WM8758ï¼Œtouchçš„
æ˜¯WM8758BGï¼Œ ä¼¼ ä¹ æ˜¯ å¤š äº†
ä¸¤ ä¸ª å­— æ¯ å ç¼€ ã€‚ ä¸­ é—´ ä¸¤ ä¸ª æ˜¯
é—ªå­˜ç‰‡ï¼Œå³è¾¹çš„æ˜¯å¾®å¤„ç†å™¨ã€‚
åœ¨MP3æ’­æ”¾å™¨ä¸­ï¼Œè§£ç èŠ¯ç‰‡å°†å­˜
å‚¨åœ¨é—ªå­˜æˆ–è€…ç¡¬ç›˜é‡Œé¢çš„æ•°æ®æ ¼
å¼æ­Œæ›²è§£ç æˆæ•°å­—ä¿¡å·ï¼Œå†é€š
è¿‡æ¨¡æ‹Ÿè¾“å‡ºç”µè·¯è½¬åŒ–ä¸ºæ¨¡æ‹Ÿä¿¡
å·ï¼Œå¹¶é€šè¿‡è€³æœºæ’­æ”¾å‡ºæ¥â€ è¿™ä¸ª
æ•°æ¨¡è½¬æ¢çš„è¿‡ç¨‹ï¼Œå’Œâ€œå†…æ ¸â€æ˜¯æ— 
å…³çš„ï¼Œâ€œå†…æ ¸â€åªè¾“å‡ºæ•°å­—ä¿¡å·è€Œ
å·²ï¼Œå¾ˆæ˜¾ç„¶â€œè§£ç èŠ¯ç‰‡â€å¹¶ä¸æ˜¯ä¸‰
æ˜Ÿã€è¥¿æ ¼ç›ã€portal player ä¹‹ç±»
çš„â€œå†…æ ¸â€ ã€‚
[2]åœ¨éŸ³é¢‘é¢† åŸŸï¼Œç£å¸¦ï¼ˆä»¥å°å‹
ç£å¸¦çš„å½¢å¼ ï¼‰æ˜¯åˆ†å‘éŸ³ä¹çš„æµ
è¡Œæ–¹å¼ã€‚ç£å¸¦æœ¬èº«å®é™…ä¸Šéå¸¸
ç®€å•ã€‚å®ƒç”±è–„çš„å¡‘æ–™åŸºæç»„æˆï¼Œ
å¹¶ä¸è¯¥åŸºåº•ç²˜åˆï¼Œæ˜¯ä¸€ç§æ°§åŒ–
é“ç²‰æœ«æ¶‚å±‚ã€‚æ°§åŒ–ç‰©é€šå¸¸ä¸ç²˜åˆ
å‰‚æ··åˆä»¥å°†å…¶é™„ç€åˆ°å¡‘æ–™ä¸Šï¼Œå¹¶
ä¸”è¿˜åŒ…æ‹¬æŸç§å¹²æ¶¦æ»‘å‰‚ä»¥é¿å…ç£¨
æŸè®°å½•å™¨ã€‚æ°§åŒ–é“ï¼ˆFeOï¼‰æ˜¯æˆ‘
ä»¬å¸¸è§çš„çº¢é”ˆã€‚æ°§åŒ–é“ï¼ˆFe 2 O
3ï¼‰æ˜¯é“çš„å¦ä¸€ç§æ°§åŒ–ç‰©ã€‚ç£èµ¤
é“çŸ¿æˆ–æ°§åŒ–é“æ˜¯è¯¥ç‰©è´¨çš„é€šç”¨å
ç§°ã€‚è¿™ç§æ°§åŒ–ç‰©æ˜¯ä¸€ç§é“ç£æ€§æ
æ–™ï¼Œè¿™æ„å‘³ç€å¦‚æœå°†å…¶æš´éœ²åœ¨ç£
åœºä¸­ï¼Œå®ƒä¼šè¢«ç£åœºæ°¸ä¹…ç£åŒ–ã€‚è¿™
ç§èƒ½åŠ›èµ‹äºˆç£å¸¦ä¸¤ä¸ªæœ€å¸å¼•äººçš„
åŠŸèƒ½ï¼šæ‚¨å¯ä»¥ç«‹å³å½•åˆ¶ä»»ä½•æƒ³è¦
çš„å†…å®¹ï¼Œå½•åƒå¸¦ä¼šè®°ä½æ‚¨å½•åˆ¶çš„
å†…å®¹ï¼Œä»¥ä¾¿éšæ—¶æ’­æ”¾ã€‚æ‚¨å¯ä»¥éš
æ—¶æ“¦é™¤ç£å¸¦å¹¶åœ¨å…¶ä¸Šè®°å½•å…¶ä»–å†…
å®¹ã€‚
IPodå’Œç£å¸¦æ’­æ”¾æœºçš„å·¥ä½œåŸç†æ˜¯
é€šè¿‡è§£ç èŠ¯ç‰‡å°†å­˜å‚¨åœ¨é—ªå­˜æˆ–
è€…ç¡¬ç›˜é‡Œé¢çš„æ•°æ®æ ¼å¼æ­Œæ›²è§£
ç æˆæ•°å­—ä¿¡å·ï¼Œå†é€šè¿‡æ¨¡æ‹Ÿè¾“å‡º
ç”µè·¯è½¬åŒ–ä¸ºæ¨¡æ‹Ÿä¿¡å·ï¼Œå¹¶é€šè¿‡è€³
æœºæ’­æ”¾å‡ºæ¥ã€‚è¿™ç§æ•°æ¨¡è½¬æ¢çš„
è¿‡ ç¨‹ ï¼Œ å’Œâ€œå†… æ ¸â€æ˜¯ æ—  å…³ çš„ ï¼Œâ€œå†…
æ ¸â€åªè¾“å‡ºæ•°å­—ä¿¡å·è€Œå·²ï¼Œå¾ˆæ˜¾
ç„¶â€œè§£ç èŠ¯ç‰‡â€å¹¶ä¸æ˜¯ä¸‰æ˜Ÿã€è¥¿æ ¼
ç›ã€portal playerä¹‹ç±»çš„â€œå†…æ ¸â€ã€‚
æ­¤å¤–ï¼Œç£å¸¦æœ¬èº«å®é™…ä¸Šéå¸¸ç®€
å•ï¼Œå®ƒç”±è–„çš„å¡‘æ–™åŸºæç»„æˆï¼Œå¹¶
ä¸è¯¥åŸºåº•ç²˜åˆï¼Œæ˜¯ä¸€ç§æ°§åŒ–é“ç²‰
æœ«æ¶‚å±‚ã€‚æ°§åŒ–ç‰©é€šå¸¸ä¸ç²˜åˆå‰‚æ··
åˆä»¥å°†å…¶é™„ç€åˆ°å¡‘æ–™ä¸Šï¼Œå¹¶ä¸”è¿˜
åŒ…æ‹¬æŸç§å¹²æ¶¦æ»‘å‰‚ä»¥é¿å…ç£¨æŸè®°
å½•å™¨ã€‚è¿™ç§æ°§åŒ–ç‰©æ˜¯ä¸€ç§é“ç£æ€§
ææ–™ï¼Œè¿™æ„å‘³ç€å¦‚æœå°†å…¶æš´éœ²åœ¨
ç£åœºä¸­ï¼Œå®ƒä¼šè¢«ç£åœºæ°¸ä¹…ç£åŒ–ã€‚
è¿™ç§èƒ½åŠ›èµ‹äºˆç£å¸¦ä¸¤ä¸ªæœ€å¸å¼•äºº
çš„åŠŸèƒ½ï¼šæ‚¨å¯ä»¥ç«‹å³å½•åˆ¶ä»»ä½•æƒ³
è¦çš„å†…å®¹ï¼Œå½•åƒå¸¦ä¼šè®°ä½æ‚¨å½•åˆ¶
çš„å†…å®¹ï¼Œä»¥ä¾¿éšæ—¶æ’­æ”¾ï¼›æ‚¨å¯ä»¥
éšæ—¶æ“¦é™¤ç£å¸¦å¹¶åœ¨å…¶ä¸Šè®°å½•å…¶ä»–
å†…å®¹ã€‚è¿™ä¸¤ä¸ªåŠŸèƒ½ä½¿ç£å¸¦å’Œç£ç›˜
å¦‚æ­¤å—æ¬¢è¿ï¼Œå®ƒä»¬æ˜¯å³æ—¶çš„ï¼Œå¹¶
ä¸”å¾ˆå®¹æ˜“æ›´æ”¹ã€‚
ã€ç»“æ„ã€‘ï¼š
å¹¶åˆ—
ã€æçº²ã€‘ï¼š
1. IPod å’Œ ç£ å¸¦ æ’­ æ”¾ æœº çš„ èŠ¯ ç‰‡ åŠŸ èƒ½ ï¼ˆ ä»… ä½¿
ç”¨[1]å›ç­”ï¼‰
2. ç£å¸¦æ’­æ”¾æœºçš„ç‰©ç†ç»“æ„ï¼ˆä»…ä½¿ç”¨[2]å›ç­”ï¼‰
ã€å›ç­”ã€‘ï¼š
IPodå’Œç£å¸¦æ’­æ”¾æœºçš„å·¥ä½œåŸç†æ¶‰åŠåˆ°èŠ¯ç‰‡çš„
è§£ç åŠŸèƒ½ä»¥åŠç£å¸¦çš„ç‰©ç†ç»“æ„ã€‚
### IPodå’Œç£å¸¦æ’­æ”¾æœºçš„èŠ¯ç‰‡åŠŸèƒ½
åœ¨IPodæ’­ æ”¾ æœº ä¸Š ï¼Œ èŠ¯ ç‰‡ çš„ åŠŸ èƒ½ æ˜¯ è§£ ç  éŸ³ é¢‘
æ•° æ® ã€‚IPod Video ä½¿ ç”¨ çš„ æ˜¯WM8758èŠ¯ ç‰‡ ï¼Œ
è€ŒTouchç‰ˆæœ¬åˆ™ä½¿ç”¨WM8758BGç‰ˆæœ¬ï¼Œè¿™ä¸¤è€…
ä¹‹é—´çš„åŒºåˆ«åœ¨äºé—ªå­˜å’Œå¤„ç†å™¨çš„ç»„åˆã€‚è§£ç 
èŠ¯ç‰‡è´Ÿè´£å°†éŸ³ä¹æ–‡ä»¶ï¼Œä»¥åŠå…¶ä»–æ•°æ®æ ¼å¼çš„
æ­Œæ›²è§£ç æˆæ•°å­—ä¿¡å·ã€‚è¿™ä¸€è¿‡ç¨‹æ¶‰åŠåˆ°æ¨¡æ‹Ÿ
è¾“å‡ºç”µè·¯çš„è½¬æ¢ï¼Œå¹¶é€šè¿‡è€³æœºæ’­æ”¾å‡ºæ¥ã€‚è¿™
ä¸ªæ•°å­—åˆ°æ¨¡æ‹Ÿè½¬æ¢è¿‡ç¨‹å¹¶ä¸æ¶‰åŠèŠ¯ç‰‡æœ¬èº«çš„
å†…æ ¸åŠŸèƒ½ï¼Œè€Œæ˜¯é¢å¤–çš„è§£ç è¿‡ç¨‹ã€‚
### ç£å¸¦æ’­æ”¾æœºçš„ç‰©ç†ç»“æ„
ç£å¸¦æ’­æ”¾æœºçš„ç‰©ç†ç»“æ„ç›¸å¯¹ç®€å•ã€‚ç£å¸¦æ˜¯
ç”±å¡‘æ–™åŸºæç»„æˆï¼Œè¦†ç›–æœ‰ä¸€å±‚æ°§åŒ–é“ç²‰æœ«æ¶‚
å±‚ï¼Œè¿™æ˜¯ä¸€ç§é“ç£æ€§ææ–™ã€‚åœ¨ç£åœºä¸­ï¼Œæ°§åŒ–
é“ä¼šè¢«æ°¸ä¹…ç£åŒ–ï¼Œè¿™æ˜¯ç£å¸¦è®°å½•éŸ³ä¹å’Œè§†é¢‘
çš„åŸç†ã€‚ç£å¸¦å¯ä»¥è¢«ç«‹å³å½•åˆ¶å’Œæ“¦é™¤å†…å®¹ï¼Œ
ä»è€Œå…è®¸ç”¨æˆ·å¿«é€Ÿæ›´æ”¹åª’ä½“å†…å®¹ã€‚è¿™ç§å³æ—¶
æ€§å’Œå®¹æ˜“æ›´æ”¹çš„ç‰¹ç‚¹æ˜¯ç£å¸¦æ’­æ”¾æœºå—æ¬¢è¿çš„
åŸå› ä¹‹ä¸€ã€‚
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
ä»€ ä¹ˆ
é™ åˆ¶
äº† åœ°
çƒ ä¸Š
ç”Ÿ ç‰©
çš„ å¤§
å°ï¼Ÿ
[1]è‡³ å°‘ ä»¥ åœ° çƒ çš„ æ ‡ å‡† çœ‹ ï¼Œ é™
åˆ¶ åŠ¨ ç‰© ä½“ å‹ çš„ å›  ç´  ä¸» è¦ æœ‰ ä¸‰
ä¸ª ï¼š1ã€ æ°” æ¸© ï¼›2ã€ å¤§ æ°” å« æ°§
é‡ ã€‚3ã€ åŠ¨ ç‰© è‡ª èº« ç”Ÿ ç† æ„ é€  å› 
ç´ ï¼šä¸»è¦æ˜¯å‘¼å¸ç³»ç»Ÿã€å¾ªç¯ç³»ç»Ÿ
çš„æ•ˆèƒ½ä¼šå¯¹ä½“å‹æœ‰å¾ˆå¤§é™åˆ¶ã€‚æ°”
æ¸©å…¶å®ä¸»è¦å¯¹æ¤ç‰©æœ‰é‡å¤§å½±å“ï¼Œ
æ°”æ¸©é«˜ï¼Œæ¤ç‰©ç”Ÿé•¿å¿«ï¼ŒåŠ¨ç‰©ä¼šæœ‰
æ›´å¤šé£Ÿç‰©ï¼Œå®¹æ˜“é•¿å¾—æ›´å¤§ã€‚æ ¹æ®
åœ°è´¨å†å²æ¸©åº¦ä¸å·¨å‹åŠ¨ç‰©çš„å…³ç³»
çš„ç ”ç©¶è¡¨æ˜ï¼Œæ€»çš„æ¥è¯´æ°”æ¸©é«˜æœ‰
åˆ©äºåŠ¨ç‰©ä½“å‹å¢å¤§ï¼ˆè™½ç„¶æ²¡æœ‰å¤§
æ°”å«æ°§é‡çš„å½±å“å¤§ï¼‰ã€‚å¤§æ°”å«æ°§
é‡å’ŒåŠ¨ç‰©è‡ªèº«å‘¼å¸/å¾ªç¯ç³»ç»Ÿæ•ˆ
èƒ½å†³å®šäº†åŠ¨ç‰©æ–°é™ˆä»£è°¢çš„é€Ÿç‡ã€‚
åœ°çƒå†å²ä¸Šï¼Œæ°”æ¸©é«˜ã€å¤§æ°”å«æ°§
é‡é«˜çš„æ—¶ä»£ï¼ŒåŠ¨ç‰©ä½“å‹ä¹Ÿæ™®éå
å¤§ï¼Œä¾‹å¦‚å¤ç”Ÿä»£æŸäº›æ—¶æœŸçš„å·¨å‹
æ˜†è™«ç­‰ç­‰ï¼Œç°ä»£åœ°çƒå·²ç»å…»ä¸æ´»
é‚£æ ·å¤§çš„æ˜†è™«äº†ã€‚
åœ°çƒä¸Šç”Ÿç‰©çš„å¤§å°å—åˆ°æ°”æ¸©ã€
å¤§æ°”å«æ°§é‡å’ŒåŠ¨ç‰©è‡ªèº«ç”Ÿç†æ„
é€ å› ç´ çš„é™åˆ¶ã€‚é¦–å…ˆï¼Œæ°”æ¸©å¯¹æ¤
ç‰©æœ‰é‡å¤§å½±å“ï¼Œæ°”æ¸©é«˜ï¼Œæ¤ç‰©ç”Ÿ
é•¿å¿«ï¼ŒåŠ¨ç‰©ä¼šæœ‰æ›´å¤šé£Ÿç‰©ï¼Œå®¹æ˜“
é•¿å¾—æ›´å¤§ï¼›å…¶æ¬¡ï¼Œå¤§æ°”å«æ°§é‡å†³
å®šäº†åŠ¨ç‰©æ–°é™ˆä»£è°¢çš„é€Ÿç‡ï¼Œè€ŒåŠ¨
ç‰©è‡ªèº«å‘¼å¸/å¾ªç¯ç³»ç»Ÿæ•ˆèƒ½ä¹Ÿä¼š
å¯¹ä½“å‹æœ‰å¾ˆå¤§é™åˆ¶ï¼›æœ€åï¼Œæ ¹æ®
åœ°è´¨å†å²æ¸©åº¦ä¸å·¨å‹åŠ¨ç‰©çš„å…³ç³»
çš„ç ”ç©¶è¡¨æ˜ï¼Œæ€»çš„æ¥è¯´æ°”æ¸©é«˜æœ‰
åˆ©äºåŠ¨ç‰©ä½“å‹å¢å¤§ï¼ˆè™½ç„¶æ²¡æœ‰å¤§
æ°”å«æ°§é‡çš„å½±å“å¤§ï¼‰ã€‚å› æ­¤ï¼Œæ°”
æ¸©ã€å¤§æ°”å«æ°§é‡å’ŒåŠ¨ç‰©è‡ªèº«ç”Ÿç†
æ„é€ å› ç´ å…±åŒé™åˆ¶äº†åœ°çƒä¸Šç”Ÿç‰©
çš„å¤§å°ã€‚
ã€ç»“æ„ã€‘ï¼šæ€»åˆ†æ€»
ã€æçº²ã€‘ï¼š
1. æ°”æ¸©å¯¹ç”Ÿç‰©ä½“å‹çš„å½±å“ï¼ˆä»…ä½¿ç”¨[1]å›ç­”ï¼‰
2. å¤§ æ°” å« æ°§ é‡ å¯¹ ç”Ÿ ç‰© ä½“ å‹ çš„ å½± å“ ï¼ˆ ä»… ä½¿
ç”¨[1]å›ç­”ï¼‰
3. ç”Ÿ ç† æ„ é€  å›  ç´  å¯¹ ç”Ÿ ç‰© ä½“ å‹ çš„ å½± å“ ï¼ˆ ä»… ä½¿
ç”¨[1]å›ç­”ï¼‰
ã€å›ç­”ã€‘ï¼š
åœ°çƒä¸Šç”Ÿç‰©çš„å¤§å°å—åˆ°å¤šç§å› ç´ çš„é™åˆ¶ï¼Œå…¶
ä¸­æ°”æ¸©ã€å¤§æ°”å«æ°§é‡å’Œç”Ÿç‰©è‡ªèº«çš„ç”Ÿç†æ„é€ 
å› ç´ æ˜¯ä¸»è¦çš„é™åˆ¶å› ç´ ã€‚
### æ°”æ¸©å¯¹ç”Ÿç‰©ä½“å‹çš„å½±å“
æ°”æ¸©æ˜¯å½±å“ç”Ÿç‰©ä½“å‹çš„é‡è¦å› ç´ ï¼Œå°¤å…¶å¯¹æ¤
ç‰©æœ‰ç€æ˜¾è‘—çš„å½±å“ã€‚å½“æ°”æ¸©è¾ƒé«˜æ—¶ï¼Œæ¤ç‰©èƒ½
æ›´å¿«åœ°ç”Ÿé•¿ï¼Œè¿™æ„å‘³ç€åŠ¨ç‰©å°±æœ‰äº†æ›´å¤šçš„é£Ÿ
ç‰©æ¥æºï¼Œä»è€Œå¯èƒ½é•¿å¾—æ›´å¤§ã€‚åœ°çƒå†å²ä¸Šï¼Œ
é«˜æ¸©æ—¶æœŸé€šå¸¸ä¼´éšç€å¤§å‹ç”Ÿç‰©çš„å‡ºç°å’Œç¹
è¡ã€‚
### å¤§æ°”å«æ°§é‡å¯¹ç”Ÿç‰©ä½“å‹çš„å½±å“
å¤§æ°”ä¸­çš„å«æ°§é‡ä¹Ÿå¯¹ç”Ÿç‰©çš„ä½“å‹æœ‰é‡è¦å½±
å“ã€‚é«˜å¤§æ°”å«æ°§é‡æ„å‘³ç€ç”Ÿç‰©èƒ½å¤Ÿæ›´æœ‰æ•ˆ
åœ°è¿›è¡Œæ–°é™ˆä»£è°¢ï¼Œè¿™ä¼šåŠ é€Ÿç”Ÿç‰©ä½“å‹çš„å¢
å¤§ã€‚å¤ç”Ÿä»£æŸäº›æ—¶æœŸçš„åœ°çƒç¯å¢ƒå…·æœ‰è¾ƒé«˜çš„
æ°”æ¸©å’Œå¤§æ°”å«æ°§é‡ï¼Œè¿™å¯¼è‡´äº†å½“æ—¶å‡ºç°äº†å·¨
å‹ç”Ÿç‰©çš„ç°è±¡ã€‚è€Œéšç€åœ°çƒæ°”å€™çš„æ¸©å’ŒåŒ–ï¼Œ
ç°ä»£åœ°çƒä¸Šå·²ç»æ— æ³•å…»æ´»åƒå¤ç”Ÿä»£çš„å·¨å‹æ˜†
è™«äº†ã€‚
### ç”Ÿç†æ„é€ å› ç´ å¯¹ç”Ÿç‰©ä½“å‹çš„å½±å“
ç”Ÿç‰©çš„è‡ªèº«ç”Ÿç†æ„é€ ï¼Œå¦‚å‘¼ å¸ç³»ç»Ÿå’Œå¾ªç¯
ç³»ç»Ÿçš„æ•ˆèƒ½ï¼Œä¹Ÿä¼šå¯¹å…¶ä½“å‹æœ‰å¾ˆå¤§çš„é™åˆ¶ã€‚
ä¸€ä¸ªæœ‰æ•ˆçš„å‘¼å¸ç³»ç»Ÿå’Œå¾ªç¯ç³»ç»Ÿèƒ½å¤Ÿæä¾›è¶³
å¤Ÿçš„æ°§æ°”å’Œè¥å…»ç‰©è´¨ï¼Œä»¥æ”¯æŒç”Ÿç‰©ä½“å‹çš„å¢
é•¿ã€‚
ç»¼ä¸Šæ‰€è¿°ï¼Œæ°”æ¸©ã€å¤§æ°”å«æ°§é‡å’Œç”Ÿç‰©è‡ªèº«
çš„ç”Ÿç†æ„é€ å› ç´ å…±åŒé™åˆ¶äº†åœ°çƒä¸Šç”Ÿç‰©çš„å¤§
å°ã€‚æ°”æ¸©å¯¹æ¤ç‰©ç”Ÿé•¿é€Ÿç‡æœ‰ç€ç›´æ¥çš„å½±å“ï¼Œ
è€Œå¤§æ°”å«æ°§é‡å’Œç”Ÿç‰©çš„ç”Ÿç†ç³»ç»Ÿæ•ˆèƒ½åˆ™å½±å“
äº†æ–°é™ˆä»£è°¢é€Ÿç‡ï¼Œè¿™äº›å› ç´ å…±åŒå†³å®šäº†ç”Ÿç‰©
ä½“å‹çš„æœ€å¤§èŒƒå›´ã€‚
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
Why
do
iced
coffee
drinks
have
more
caf-
feine
than
hot
ones?
[1]While itâ€™s hard to pin down the
precise amount of caffeine in any
given iced coffee, we can make sev-
eral assumptions based on what
we know of caffeine. Since caffeine
is soluble in water, hot water re-
mains the best way to extract caf-
feine from coffee beans, giving iced
coffee an edge over cold brew due
to the brewing method.
But, iced coffee brewed with hot
water also tends to have a lower
coffee to water ratio that somewhat
dilutes the caffeine content, as does
the ice you need to chill the coffee.
[2]Iced coffee can be made with left-
over hot coffee, and will have more
caffeine in it than a cold brew coffee.
Cold-brew coffees can have a lot of
caffeine in them if they are highly
concentrated, but the amount of
caffeine that can be concentrated
down into the cold brew depends
on how the coffee was brewed ini-
tially.
[3]ICED COFFEE: A typical 16-oz.
iced coffee has 165 mg of caffeine.
COLD BREW: A typical 16-oz. cold
brew has 200 mg of caffeine. So,
in the simplest of terms, cold brew
has more caffeine than iced coffee
(and, depending on how itâ€™s brewed
sometimes it can be nearly double
that of its cold coffee counterpart!)
But, why is there such a huge dif-
ference in the caffeine contents of
these drinks?
THE BREW SAYS IT ALL
It all comes down to how each one
is brewed. Iced coffee is brewed
as regular coffee, which then goes
through a cooling process and is
served over ice. Cold brew, on the
other hand, is created by steeping
ground coffee at room temperature
and then filtering out the grounds.
So, itâ€™s essentially the most concen-
trated version of coffee you can get.
Once you filter out the grounds, the
concentrate is combined with water
for (generally) a 50/50 coffee con-
centrate/water split, and TA-DA!
You have cold brew.
There is more caffeine in iced coffee
than in hot coffee due to the brew-
ing method [1, 2, 3]. Iced coffee
is brewed as regular coffee, which
then goes through a cooling pro-
cess and is served over ice [1]. Cold
brew, on the other hand, is cre-
ated by steeping ground coffee at
room temperature and then filter-
ing out the grounds [1]. Once you
filter out the grounds, the concen-
trate is combined with water for
(generally) a 50/50 coffee concen-
trate/water split [1]. Iced coffee
brewed with hot water also tends to
have a lower coffee to water ratio
that somewhat dilutes the caffeine
content, as does the ice you need to
chill the coffee [2].
[Structure]:
Comparative-Cause-Effect
[Outline]:
1. Brewing method and extraction efficiency
(based on [1] and [3])
2. Coffee to water ratio and ice dilution (based on
[1])
3. Concentration of caffeine in cold brew (based
on [2] and [3])
[Answer]:
iced coffee drinks contain more caffeine than their
hot counterparts primarily due to differences in
the brewing process and the resulting concentra-
tion of caffeine.
### Brewing Method and Extraction Efficiency
The extraction of caffeine from coffee beans is
most efficient when using hot water, as caffeine
is soluble in water. This is the reason why iced
coffee, which is often made by pouring hot coffee
over ice, tends to have a higher caffeine content
compared to cold brew coffee. However, the caf-
feine content can be diluted in iced coffee due to
the use of hot water in the brewing process and
the inclusion of ice which requires water to chill
the drink.
### Coffee to Water Ratio and Ice Dilution
When making iced coffee, the coffee to water ratio
is typically higher than in cold brew coffee. This is
because iced coffee is made by brewing hot coffee
and then cooling it down, which results in a lower
concentration of caffeine per serving. Conversely,
cold brew coffee is brewed at room temperature
and then filtered to remove the grounds, concen-
trating the caffeine.
### Concentration of Caffeine in Cold Brew
Cold brew coffee can have a significantly higher
caffeine content than iced coffee. This is because
the cold brew process involves steeping ground
coffee at room temperature and filtering it to cre-
ate a highly concentrated coffee concentrate. Typ-
ically, a 16-ounce cold brew contains about 200
mg of caffeine, compared to iced coffee which may
have around 165 mg of caffeine. The difference in
caffeine content can sometimes be nearly double,
depending on the specific brewing methods used
for each drink.
In summary, the higher caffeine content in iced
coffee drinks as opposed to hot coffees is attrib-
uted to the brewing techniques that extract more
caffeine into the beverage, the dilution effect from
using ice, and the concentration of caffeine in the
cold brew process.
FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering KDD â€™24, August 25â€“29, 2024, Barcelona, Spain
Who
are the
Kur-
dish
peo-
ple?
[1]Kurds speak the Kurdish lan-
guages and the Zazaâ€“Gorani lan-
guages, which belong to the West-
ern Iranian branch of the Iranian
languages in the Indo-European
language family.[33][34]
[2]Kurds (Kurdish: Kurd) or
Kurdish people are an Ira-
nian[28][29][30] ethnic group
native to the mountainous region
of Kurdistan in Western Asia,
which spans southeastern Turkey,
northwestern Iran, northern Iraq,
and northern Syria.[31] There are
exclaves of Kurds in Central Anato-
lia, Khorasan, and the Caucasus, as
well as significant Kurdish diaspora
communities in the cities of west-
ern Turkey (in particular Istanbul)
and Western Europe (primarily in
Germany). The Kurdish population
is estimated to be between 30 and
45 million.[2][32]
[3]The Kurds are one of the indige-
nous peoples of the Mesopotamian
plains and the highlands in what
are now south-eastern Turkey,
north-eastern Syria, northern Iraq,
north-western Iran and south-
western Armenia.
Today, they form a distinctive com-
munity, united through race, cul-
ture and language, even though
they have no standard dialect. They
also adhere to a number of different
religions and creeds, although the
majority are Sunni Muslims.
[4]The Kurdish people are an eth-
nic minority group without an of-
ficial state. Before World War I,
Kurds lived a nomadic lifestyle un-
til the breakup of the Ottoman Em-
pire, which stripped them of their
freedom and divided them across
several nation states.
Today, there are an estimated 25-
30 million Kurds, the majority liv-
ing in a region that stretches across
parts of Turkey, Iraq, Iran, Syria and
Armenia.
Most Kurds are Sunni Muslims, but
the Kurdish population has diverse
cultural, social, religious and politi-
cal traditions as well as a variety of
dialects.
The Kurds are an Iranian ethnic
group native to the mountainous re-
gion of Kurdistan in Western Asia,
which spans southeastern Turkey,
northwestern Iran, northern Iraq,
and northern Syria. [1][2] They
are one of the indigenous peo-
ples of the Mesopotamian plains
and the highlands in what are
now south-eastern Turkey, north-
eastern Syria, northern Iraq, north-
western Iran and south-western Ar-
menia. [3]
Kurds speak the Kurdish languages
and the Zazaâ€“Gorani languages,
which belong to the Western Ira-
nian branch of the Iranian lan-
guages in the Indo-European lan-
guage family. [1] They are an eth-
nic minority group without an of-
ficial state. Before World War I,
Kurds lived a nomadic lifestyle un-
til the breakup of the Ottoman Em-
pire, which stripped them of their
freedom and divided them across
several nation states. [4] Today,
there are an estimated 25-30 mil-
lion Kurds, the majority living in
a region that stretches across parts
of Turkey, Iraq, Iran, Syria and Ar-
menia. [4] Most Kurds are Sunni
Muslims, but the Kurdish popula-
tion has diverse cultural, social, re-
ligious and political traditions as
well as a variety of dialects. [4]
[Structure]:
General-Specific-General
[Outline]:
1. Ethnic and linguistic identity (based on [1] and
[3])
2. Geographical distribution and diaspora (based
on [2])
3. Cultural and religious characteristics (based on
[3] and [4])
[Answer]:
The Kurdish people are an ethnic group with a
rich cultural and linguistic heritage, native to the
region known as Kurdistan in Western Asia.
### Ethnic and Linguistic Identity
Kurds speak Kurdish languages and Zazaâ€“Gorani
languages, which are part of the Western Iranian
branch of the Iranian languages within the Indo-
European family. This linguistic connection un-
derscores their unique identity, both as an ethnic
group and as a linguistic minority.
### Geographical Distribution and Diaspora
Geographically, Kurds are spread across a region
that includes parts of Turkey, Iraq, Iran, Syria,
and Armenia. Their historical homeland, known
as Kurdistan, encompasses significant exclaves in
Central Anatolia, Khorasan, and the Caucasus. In
addition to their native regions, Kurdish diaspora
communities are notable in western Turkey, par-
ticularly Istanbul, and in Western Europe, with a
substantial presence in Germany.
### Cultural and Religious Characteristics
Culturally, Kurds share a common identity
through race, language, and religion, even though
they do not have a standard dialect. The majority
of Kurds today adhere to Sunni Islam, reflecting a
common religious practice among the community.
Despite this religious affiliation, Kurdish culture
is diverse, encompassing various social, religious,
political traditions, and dialects.
Before the dissolution of the Ottoman Empire
following World War I, Kurds led a nomadic life.
The subsequent division of the Ottoman Empire
into several nation-states resulted in the loss of
Kurdish freedom and led to a complex political
situation where Kurds found themselves spread
across several countries, without an official state
of their own.
In summary, the Kurdish people are character-
ized by their distinct ethnic and linguistic back-
ground, their geographic distribution and dias-
pora, and the rich tapestry of their cultural and
religious practices. Despite facing historical chal-
lenges, they maintain a strong sense of identity
and community.
KDD â€™24, August 25â€“29, 2024, Barcelona, Spain Cai and Tan, et al.
Why
do we
use
shav-
ing
plugs
in
bath-
rooms,
are
they
safer
that
nor-
mal
3 pin
plugs?
[1]UK building regulations mean
you cannot fit a regular 3 pin mains
power socket in a bathroom, even
the â€˜shaver socketâ€™ has to be a safe
distance away from the bath or
shower. This is often why many
sockets are part of a light fitting
above a mirror and hidden behind
a little door, making it harder to ac-
cess. All to protect you and I from
injuring ourselves.
Other countries around the world
may have normal sockets in their
bathrooms. Why? For some it is be-
cause of the lower voltage used, so
the effects of electric shock and se-
rious injury are reduced. In other
cases it is less established safety
measures and in others there is
a trust that you as an individual
wonâ€™t do anything silly enough to
put your life at risk.
[2]A bathroom shaver socket is
a specialized electrical socket de-
signed for safe use of electrical
shavers in the bathroom. This
socket design is most commonly
seen in the United Kingdom and
some parts of Europe, and has been
largely replaced by the ground fault
circuit interrupter (GFCI) socket. It
is possible to use these types of
sockets for replacement of old sock-
ets or installation in a new bath-
room design, but usually a GFCI
socket is more appropriate. The
newer socket style may also be re-
quired under the building code.
The bathroom shaver socket is
mounted in an isolation trans-
former that cuts it off from the rest
of the electrical system. This limits
the risk of electrical shock, a con-
cern in the bathroom where lots
of water can be present. In addi-
tion, the current is very low. It will
power a shaver or electric tooth-
brush, but not an item like a heater
or a hair dryer. The circuit will shut
down if it gets too hot, thus keeping
the user as safe as possible.
In the UK, special sockets are re-
quired for bathrooms due to build-
ing regulations [2]. These sockets,
called bathroom shaver sockets, are
designed to be safer than a regu-
lar 3-pronged electrical socket [1].
They are mounted in an isolation
transformer that cuts them off from
the rest of the electrical system
[1]. This limits the risk of electri-
cal shock, which is a concern in the
bathroom given that lots of water
can be present [1]. The circuit will
shut down if it gets too hot, which
protects the user as safe as possible
[1]. Additionally, these sockets are
often part of a light fixture above
a mirror and hidden behind a little
door, which makes them harder to
access [2].
[Structure]:
Comparative
[Outline]:
1. Safety measures in the UK and similar regula-
tions elsewhere (based on [1])
2. Design differences between bathroom shaver
sockets and regular 3-pin plugs (based on [2])
3. Electrical safety and low-current design (based
on [2])
[Answer]:
The use of shaving plugs, also known as bathroom
shaver sockets, in bathrooms is primarily a result
of safety regulations and design considerations
that differentiate them from normal 3-pin plugs.
### Safety Measures and Regulations
In the UK and some other countries, building reg-
ulations dictate that regular 3-pin mains power
sockets are not permitted in bathrooms. This is
to prevent the risk of electric shock or injury due
to coming into contact with the socket while wet.
Therefore, sockets are often concealed and in-
stalled at a safe distance from bathing areas.
### Design Differences
The bathroom shaver socket is specifically de-
signed for safe use of electrical appliances like
shavers in the bathroom environment. It is char-
acterized by its isolation transformer which seg-
regates it from the rest of the electrical system,
thereby reducing the risk of electrical shock. This
design is a safety measure particularly pertinent
in bathrooms where water is likely to be present.
### Electrical Safety and Low-Current Design
The shaver socket is engineered to power only
devices that are safe to use in a wet environment,
such as shavers and electric toothbrushes. It is not
designed to power appliances that could present
a higher risk, like heaters or hair dryers. Addi-
tionally, the circuit is designed to shut down if it
overheats, which further ensures user safety.
In conclusion, shaving plugs are considered safer
than normal 3-pin plugs because of the specific
safety regulations they adhere to, their isolated de-
sign, and the low-current circuitry that prevents
riskier electrical appliances from being used in
wet environments.